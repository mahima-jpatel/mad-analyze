{"purpose": "Analyze movie ratings and genre popularity trends in a streaming platform dataset.", "raw_table": "MovieID,Title,Genre,ReleaseDate,Rating,Views\n1,Inception,SCI-FI,2010-07-16,8.8,150000\n2,The godfather,Crime,1972/03/24,9.2,85000\n3,Avengers: Endgame,Action,2019-04-26,8.4,200000\n4,La La Land,Romance,2016-12-09,8.0,120000\n5,Parasite,thriller,2019-05-30,8.6,90000\n6,The Lion King,Animation,1994-06-15,8.5,130000\n7,Joker,crime,2019-10-04,8.5,\n8,Interstellar,Sci-fi,2014-11-7,8.6,110000\n9,Unknown Movie,,2020-01-01,7.0,5000\n10,Titanic,Romance,1997/12/19,7.8,140000\n11,Avengers: Infinity War,Action,2018-04-23,8.5,185000\n12,The Shawshank Redemption,Drama,1994-09-22,9.3,100000\n13,Black Panther,Action,2018-02-16,7.3,175000\n14,Parasite,Thriller,2019-05-30,8.6,90000", "eda_steps": ["Check for missing values in each column", "Standardize Genre capitalization and identify unique genres", "Compute descriptive statistics for Rating and Views columns", "Identify duplicate movie entries based on Title and ReleaseDate", "Generate value counts for Genre to find most common categories", "Analyze date format inconsistencies and convert ReleaseDate to uniform format", "Find correlation between Rating and Views", "List movies with missing or zero Views"], "eda_results": {"missing_values": {"MovieID": 0, "Title": 0, "Genre": 1, "ReleaseDate": 0, "Rating": 0, "Views": 1}, "unique_genres": ["sci-fi", "crime", "action", "romance", "thriller", "animation", "drama", ""], "summary_stats": {"Rating": {"count": 14, "mean": 8.26, "std": 0.66, "min": 7.0, "max": 9.3}, "Views": {"count": 13, "mean": 114615, "std": 56942, "min": 5000, "max": 200000}}, "duplicate_movies": [{"Title": "Parasite", "ReleaseDate": "2019-05-30", "count": 2}], "genre_counts": {"action": 3, "thriller": 2, "crime": 2, "romance": 2, "sci-fi": 2, "animation": 1, "drama": 1, "": 1}, "release_date_formats": {"YYYY-MM-DD": 10, "YYYY/MM/DD": 2, "YYYY-M-D": 1, "Unknown or missing": 0}, "rating_views_correlation": 0.58, "movies_with_missing_or_zero_views": [{"MovieID": 7, "Title": "Joker", "Views": null}]}}
{"purpose": "Analyze trip patterns and vehicle usage in urban taxi operations to identify data quality issues and usage trends.", "raw_table": "TripID,VehicleType,StartDate,EndDate,DistanceKM,TripDurationMin,FareAmount,PaymentMethod\nT001,Sedan,2023-05-01 08:30,2023-05-01 08:50,12.5,20,25.00,Cash\nT002,SUV,05/02/2023 09:00 AM,05/02/2023 09:25 AM,15.0,25,30,card\nT003,sedan,2023/05/03 10:00,,10,,18.5,Card\nT004,van,2023-05-04 11:15,2023-05-04 11:45,20.0,30,40.00,CASH\nT005,,2023-05-05 12:00,2023-05-05 12:20,8.0,20,15.0,Card\nT006,SUV,2023-05-06 14:00,2023-05-06 14:45,25,45,50.00,cash\nT007,Van,05-07-2023 15:30,05-07-2023 16:00,18,30,,cash\nT008,sedan,2023-05-08 17:00,2023-05-08 17:25,12.0,25,28.00,Card\nT009,Sedan,2023-05-09 18:00,2023-05-09 18:20,NaN,20,22.00,cash\nT010,truck,2023-05-10 19:00,2023-05-10 19:50,30,50,60.00,CARD\nT011,SUV,2023-05-11 20:00,2023-05-11 20:30,22,30,45.00,Card\nT012,Sedan,2023-05-12 21:00,2023-05-12 21:15,10,15,20.00,Cash\nT013,Van,,2023-05-13 22:30,17,25,35.00,CASH\nT014,SUV,2023-05-14 23:00,2023-05-14 23:40,26,40,52.00,\n", "eda_steps": ["Check missing value percentages for each column", "Standardize VehicleType values to consistent capitalization and fill missing with 'Unknown'", "Parse StartDate and EndDate to datetime objects and identify rows with missing or inconsistent dates", "Compute descriptive statistics for numeric columns: DistanceKM, TripDurationMin, FareAmount", "Generate value counts for PaymentMethod after standardizing casing", "Calculate trip durations from StartDate and EndDate to validate TripDurationMin", "Identify top 3 vehicle types by number of trips", "Summarize distribution skewness for FareAmount and DistanceKM"], "eda_results": {"missing_values": {"TripID": 0, "VehicleType": 1, "StartDate": 1, "EndDate": 1, "DistanceKM": 1, "TripDurationMin": 1, "FareAmount": 1, "PaymentMethod": 1}, "vehicle_type_standardized_counts": {"Sedan": 5, "SUV": 4, "Van": 3, "Truck": 1, "Unknown": 1}, "payment_method_value_counts": {"Cash": 5, "Card": 7, "": 1}, "numeric_summary_stats": {"DistanceKM": {"count": 13, "mean": 17.55, "std": 6.73, "min": 8.0, "25%": 12.0, "50%": 18.0, "75%": 25.0, "max": 30.0}, "TripDurationMin": {"count": 13, "mean": 28.23, "std": 11.97, "min": 15, "25%": 20, "50%": 25, "75%": 40, "max": 50}, "FareAmount": {"count": 13, "mean": 33.88, "std": 13.97, "min": 15.0, "25%": 22.0, "50%": 30.0, "75%": 45.0, "max": 60.0}}, "date_parsing_issues": {"rows_with_missing_or_inconsistent_dates": [3, 12]}, "trip_duration_validation": {"rows_with_mismatched_duration": [2, 6]}, "top_vehicle_types": [{"Sedan": 5}, {"SUV": 4}, {"Van": 3}], "distribution_skewness": {"FareAmount": 0.45, "DistanceKM": 0.36}}}
{"purpose": "Analyze movie ratings and genre popularity to understand audience preferences and identify data quality issues.", "raw_table": "Movie_ID,Title,Genre,Release_Date,Rating,Duration,Revenue_millions\n1,Inception,Sci-fi,2010-07-16,8.8,148,829.9\n2,the Godfather,Crime,1972/03/24,9.2,175,134.97\n3,Avengers: Endgame,Action,2019-04-26,8.4,181,2797.8\n4,Titanic,romance,1997-12-19,7.8,195,2187.5\n5,Parasite,Thriller,2019-5-30,8.6,132,258.8\n6,The Shawshank Redemption,Drama,1994-09-23,,142,28.3\n7,gladiator,Action,2000-05-05,8.5,155,\n8,Joker,Crime,2019-10-04,8.5,122,1074.1\n9,Interstellar,Sci-Fi,2014-11-07,8.6,169,677.5\n10,Forrest Gump,Drama,1994-07-06,8.8,142,678.2\n11,La La Land,Musical,2016-12-09,8.0,128,446.1\n12,,Comedy,2003-06-13,6.5,95,78.4\n13,The Dark Knight,action,2008-07-18,9.0,152,1004.9\n14,Pulp Fiction,Crime,1994-10-14,8.9,154,213.9\n15,Avengers: Infinity War,Action,2018-04-27,8.4,149,2048.4", "eda_steps": ["Identify and count missing values in each column", "Standardize the Genre column capitalization", "Compute descriptive statistics for numeric columns: Rating, Duration, Revenue_millions", "Generate value counts for the Genre column", "Find movies with missing Titles", "Check for inconsistent date formats in Release_Date", "Identify top 3 highest revenue movies", "Calculate average rating per Genre"], "eda_results": {"missing_values": {"Movie_ID": 0, "Title": 1, "Genre": 0, "Release_Date": 0, "Rating": 1, "Duration": 0, "Revenue_millions": 1}, "genre_value_counts": {"Action": 4, "Crime": 3, "Sci-Fi": 2, "Drama": 2, "Romance": 1, "Thriller": 1, "Musical": 1, "Comedy": 1}, "standardized_genres": ["Sci-Fi", "Crime", "Action", "Romance", "Thriller", "Drama", "Action", "Crime", "Sci-Fi", "Drama", "Musical", "Comedy", "Action", "Crime", "Action"], "descriptive_statistics": {"Rating": {"count": 14, "mean": 8.34, "std": 0.79, "min": 6.5, "max": 9.2}, "Duration": {"count": 15, "mean": 149.0, "std": 26.5, "min": 95, "max": 195}, "Revenue_millions": {"count": 14, "mean": 897.5, "std": 772.8, "min": 28.3, "max": 2797.8}}, "missing_title_movies": [{"Movie_ID": 12, "Genre": "Comedy", "Release_Date": "2003-06-13"}], "inconsistent_date_formats": ["1972/03/24", "2019-5-30"], "top_3_revenue_movies": [{"Title": "Avengers: Endgame", "Revenue_millions": 2797.8}, {"Title": "Titanic", "Revenue_millions": 2187.5}, {"Title": "Avengers: Infinity War", "Revenue_millions": 2048.4}], "average_rating_per_genre": {"Action": 8.58, "Crime": 8.87, "Sci-Fi": 8.7, "Romance": 7.8, "Thriller": 8.6, "Drama": 8.8, "Musical": 8.0, "Comedy": 6.5}}}
{"purpose": "Analyze production line performance and identify common defect types", "raw_table": "BatchID,ProductionDate,ProductType,UnitsProduced,Defects,Operator,Shift\nB001,2023/01/15,WidgetA,1000,5,alice,Morning\nB002,15-01-2023,widgetA,950,,Bob,Evening\nB003,2023-01-16,WidgetB,890,12,Charlie,Night\nB004,01/17/2023,widgetb,920,8,,Morning\nb005,2023-01-18,WIDGETA,980,7,alice,evening\nB006,2023-1-18,WidgetC,870,3,David,Morning\nB007,18/01/2023,WidgetC,,6,bob,Night\nB008,2023-01-19,WidgetB,940,NaN,Charlie,Evening\nB009,2023/01/20,widgeTa,970,9,Alice,Morning\nB010,20-01-2023,WidgetC,910,4,David,Night\nB011,2023-01-21,WidgetA,1005,11,bob,MORNING\nB012,01/22/2023,widgetB,900,5,,Evening", "eda_steps": ["Standardize 'ProductionDate' to a consistent date format", "Check and report missing values per column", "Normalize 'ProductType' and 'Operator' columns to consistent capitalization", "Compute descriptive statistics for 'UnitsProduced' and 'Defects'", "Generate value counts for 'ProductType' and 'Shift' columns", "Calculate correlation between 'UnitsProduced' and 'Defects'", "Identify operators with the highest average defects", "Summarize distribution skewness for numeric columns"], "eda_results": {"missing_values": {"BatchID": 0, "ProductionDate": 0, "ProductType": 0, "UnitsProduced": 1, "Defects": 2, "Operator": 2, "Shift": 0}, "value_counts": {"ProductType": {"widgeta": 4, "widgetb": 4, "widgetc": 3}, "Shift": {"morning": 4, "evening": 4, "night": 3}}, "summary_stats": {"UnitsProduced": {"count": 14, "mean": 935.7, "std": 46.9, "min": 870, "25%": 900, "50%": 940, "75%": 980, "max": 1005}, "Defects": {"count": 12, "mean": 7.5, "std": 3.0, "min": 3, "25%": 5, "50%": 6, "75%": 9, "max": 12}}, "correlations": {"UnitsProduced_Defects": -0.42}, "top_categories": {"Operators_highest_avg_defects": {"bob": 8.7, "alice": 7.0, "charlie": 10.0, "david": 3.5}}, "distribution_skewness": {"UnitsProduced": -0.31, "Defects": 0.58}}}
{"purpose": "Explore real estate property listings to understand price distribution, common property types, and data quality issues.", "raw_table": "Listing_ID,Date_Listed,Property_Type,Bedrooms,Bathrooms,Price,Location\n101,2023/01/15,Apartment,2,1,350000,Downtown\n102,15-02-2023,Duplex,3,,450000,Uptown\n103,2023-03-05,apartment,2,1.5,NaN,Suburbs\n104,2023/3/15,Townhouse,4,3,600000,DOWNTOWN\n105,04-01-2023,Condo,,2,300000,Midtown\n106,2023-02-28,Apartment,3,2,400000,suburbs\n107,2023/02/20,duplex,3,2,470000,Uptown\n108,2023-03-01,Townhouse,4,3,610000,Downtown\n109,03/05/2023,Apartment,2,1,360000,midtown\n110,2023-01-10,Condo,1,1,280000,\n111,15/03/2023,,3,2,500000,Suburbs", "eda_steps": ["Check missing value percentages for each column", "Standardize the Property_Type values to consistent capitalization", "Convert Date_Listed to a uniform date format", "Compute descriptive statistics for numeric columns: Bedrooms, Bathrooms, Price", "Generate value counts for the Property_Type and Location columns", "Identify listings with missing Price values", "Calculate the correlation matrix for numeric columns", "Identify top 3 most common locations"], "eda_results": {"missing_values": {"Listing_ID": "0%", "Date_Listed": "0%", "Property_Type": "9%", "Bedrooms": "18%", "Bathrooms": "9%", "Price": "9%", "Location": "9%"}, "property_type_standardized": {"Apartment": 4, "Duplex": 2, "Townhouse": 2, "Condo": 2, "": 1}, "date_listed_uniform": ["2023-01-15", "2023-02-15", "2023-03-05", "2023-03-15", "2023-01-04", "2023-02-28", "2023-02-20", "2023-03-01", "2023-03-05", "2023-01-10", "2023-03-15"], "summary_stats": {"Bedrooms": {"count": 9, "mean": 2.78, "std": 1.04, "min": 1, "max": 4}, "Bathrooms": {"count": 10, "mean": 1.85, "std": 0.75, "min": 1, "max": 3}, "Price": {"count": 10, "mean": 422000, "std": 115247, "min": 280000, "max": 610000}}, "value_counts": {"Property_Type": {"Apartment": 4, "Duplex": 2, "Townhouse": 2, "Condo": 2, "Missing": 1}, "Location": {"Downtown": 3, "Uptown": 2, "Suburbs": 3, "Midtown": 2, "Missing": 1}}, "missing_price_listings": [103], "correlations": {"Bedrooms_Bathrooms": 0.88, "Bedrooms_Price": 0.79, "Bathrooms_Price": 0.76}, "top_locations": ["Downtown", "Suburbs", "Uptown"]}}
{"purpose": "Explore monthly climate data to identify temperature and precipitation patterns and data quality issues.", "raw_table": "Station,Date,Temperature_C,Precipitation_mm,Wind_Speed_kmh,Weather_Condition\nNorthPole,2023-01-01, -25.3,5.2, 15, Snowy\nsouthpole,01/15/2023,-28.7,,12, snowy\nEast-Coast,2023-02-01, 3.5,20.1,18, Rain\nwest-coast,2/15/2023,12.2,0, ,Clear\nnorthpole,2023-03-01,-10.0,2.3,20,sNOWY\nEast-Coast,2023-03-15,5.1,15.0,17,rain\nWest-Coast,2023/04/01,15.3,0.0,14,CLEAR\nSouthPole,2023-04-15,-30.1,NA,13,Snow\nNorthPole,, -20.5,3.1,16,snowy\nEast-Coast,2023-05-01,8.0,22.5,19,Rain\nWest-Coast,2023-05-15,17.8,1.0,15,clear\nSouthPole,2023-06-01,-27.3,4.0,12,Snowy\nEast-Coast,2023-06-15,,18.2,20,Rain\nWest-Coast,2023-07-01,19.0,0,16,Clear", "eda_steps": ["Check data types of each column and convert dates to a consistent format", "Identify and quantify missing values in each column", "Standardize categorical columns such as Station and Weather_Condition to consistent capitalization", "Compute descriptive statistics (mean, min, max) for Temperature_C, Precipitation_mm, and Wind_Speed_kmh", "Generate value counts for Weather_Condition and Station columns", "Calculate the correlation matrix between numeric variables", "Identify top 2 stations with highest average temperature", "Summarize distribution skewness for Temperature_C and Precipitation_mm"], "eda_results": {"missing_values": {"Station": 1, "Date": 1, "Temperature_C": 1, "Precipitation_mm": 2, "Wind_Speed_kmh": 1, "Weather_Condition": 0}, "data_types": {"Station": "string", "Date": "date", "Temperature_C": "float", "Precipitation_mm": "float", "Wind_Speed_kmh": "float", "Weather_Condition": "string"}, "value_counts": {"Weather_Condition": {"Snowy": 5, "Rain": 4, "Clear": 4}, "Station": {"NorthPole": 4, "SouthPole": 3, "East-Coast": 4, "West-Coast": 4}}, "summary_stats": {"Temperature_C": {"mean": -0.37, "min": -30.1, "max": 19.0, "skewness": 0.44}, "Precipitation_mm": {"mean": 8.16, "min": 0.0, "max": 22.5, "skewness": 1.21}, "Wind_Speed_kmh": {"mean": 15.0, "min": 12, "max": 20}}, "correlations": {"Temperature_C_Precipitation_mm": -0.62, "Temperature_C_Wind_Speed_kmh": 0.14, "Precipitation_mm_Wind_Speed_kmh": -0.05}, "top_stations_by_avg_temp": {"West-Coast": 15.575, "East-Coast": 5.4}}}
{"purpose": "Explore temperature and precipitation patterns across different climate zones over a two-week period.", "raw_table": "Date,ClimateZone,AvgTemperatureC,PrecipitationMM,WeatherCondition\n2024/04/01,Tropical,29.4,5.2,Rain\n2024-04-02,temperate,15.6,,Sunny\n04-03-2024,Polar,-5.0,0,Snow\n2024/04/04,TROPICAL,30.1,NaN,RAIN\n2024-04-05,Temperate,16.2,0,Cloudy\n2024-4-06,polar,-6,,snow\n2024/04/07,Tropical,28.9,7.1,Rain\n04/08/2024,Temperate,14.8,0.0,Sunny\n2024-04-09,Polar,,0,Snow\n2024/04/10,Tropical,30.3,6.8,rain\n2024-04-11,temperate,15.2,0,cloudy\n2024-04-12,Polar,-4.8,0,Snow\n2024/04/13,Tropical,29.7,5.5,Rain\n2024-4-14,Temperate,16.0,0,Sunny", "eda_steps": ["Standardize date formats to YYYY-MM-DD", "Normalize capitalization in ClimateZone and WeatherCondition columns", "Check for missing values in all columns", "Compute descriptive statistics for AvgTemperatureC and PrecipitationMM", "Generate value counts for ClimateZone and WeatherCondition", "Calculate mean AvgTemperatureC by ClimateZone", "Summarize total PrecipitationMM by ClimateZone", "Identify days with missing temperature or precipitation data"], "eda_results": {"missing_values": {"Date": 0, "ClimateZone": 0, "AvgTemperatureC": 1, "PrecipitationMM": 3, "WeatherCondition": 0}, "value_counts": {"ClimateZone": {"Tropical": 5, "Temperate": 5, "Polar": 4}, "WeatherCondition": {"Rain": 5, "Sunny": 3, "Snow": 4, "Cloudy": 2}}, "summary_stats": {"AvgTemperatureC": {"count": 13, "mean": 15.84, "std": 13.54, "min": -6.0, "25%": 14.8, "50%": 15.6, "75%": 29.7, "max": 30.3}, "PrecipitationMM": {"count": 11, "mean": 2.18, "std": 2.85, "min": 0, "25%": 0, "50%": 0, "75%": 6.8, "max": 7.1}}, "mean_temperature_by_climate_zone": {"Tropical": 29.68, "Temperate": 15.56, "Polar": -5.27}, "total_precipitation_by_climate_zone": {"Tropical": 30.6, "Temperate": 0, "Polar": 0}, "missing_data_days": ["2024-04-02 (Precipitation)", "2024-04-04 (Precipitation)", "2024-04-06 (Precipitation)", "2024-04-09 (AvgTemperatureC)"]}}
{"purpose": "Analyze sales performance and customer behavior in a retail store.", "raw_table": "OrderID,Product,Category,Quantity,Price,OrderDate,CustomerRegion\n1001,Widget A,Electronics,2,19.99,2023-1-05,North\n1002,gadget b,Electronics,1,29.99,01/15/2023,South\n1003,Widget A,Electronics,,19.99,2023/01/20,East\n1004,Thingy C,Household,3,,2023-1-25,West\n1005,Gadget B,Electronics,2,29.99,,north\n1006,widget a,Electronics,1,19.99,2023-02-02,South\n1007,Thingy c,Household,1,9.99,02-10-2023,East\n1008,Widget A,Electronics,5,19.99,2023/02/15,South\n1009,,Household,2,9.99,2023-02-20,south\n1010,Gadget B,Electronics,1,29.99,2023-02-25,West\n1011,Thingy C,household,1,9.99,2023-03-01,East\n1012,Widget A,Electronics,3,19.99,2023/03/05,North\n1013,Gadget b,Electronics,4,29.99,03-10-2023,NORTH\n1014,Thingy C,Household,,9.99,2023-03-15,West", "eda_steps": ["Check for missing values in each column and calculate percentages", "Standardize the capitalization of product and category names", "Convert OrderDate to a consistent date format", "Compute descriptive statistics for Quantity and Price columns", "Generate value counts for CustomerRegion and Category", "Identify top 2 best-selling products by total quantity sold", "Calculate total revenue per order and summarize", "Analyze order counts per month"], "eda_results": {"missing_values": {"OrderID": "0%", "Product": "7.14%", "Category": "0%", "Quantity": "14.29%", "Price": "7.14%", "OrderDate": "7.14%", "CustomerRegion": "0%"}, "standardized_categories": {"Electronics": 8, "Household": 6}, "standardized_products": {"Widget A": 5, "Gadget B": 4, "Thingy C": 5}, "date_range": {"min": "2023-01-05", "max": "2023-03-15"}, "quantity_stats": {"count": 12, "mean": 2.25, "std": 1.39, "min": 1, "max": 5}, "price_stats": {"count": 13, "mean": 19.13, "std": 7.95, "min": 9.99, "max": 29.99}, "customer_region_counts": {"North": 3, "South": 4, "East": 3, "West": 4}, "top_products_by_quantity": {"Widget A": 11, "Gadget B": 8}, "total_revenue_summary": {"mean": 54.19, "min": 19.99, "max": 149.95, "total_revenue": 650.25}, "orders_per_month": {"January": 5, "February": 5, "March": 4}}}
{"purpose": "Analyze student performance and attendance patterns in a high school dataset.", "raw_table": "StudentID,Name,Grade,Math_Score,English_Score,Attendance_Percentage,Enrollment_Date,Extra_Curricular\n101,alice,10,88,92,95.5,2021/09/01,Soccer\n102,Bob,10,78,,88.0,09-05-2021,BasketBall\n103,charlie,11,85,80,NA,2021-09-03,Drama\n104,David,11,90,85,92.0,2021/9/04,Swimming\n105,Eva,12,,87,85,2021/09/02,\n106,fiona,12,75,79,80,2021/09/03,BASKETBALL\n107,Gary,10,82,88,90.0,2021/09/01,Soccer\n108,hannah,11,NA,93,94.0,2021-9-02,Drama\n109,Ian,12,91,85,88.5,09/05/2021,swimming\n110,julia,10,89,90,95,2021/09/05,Chess\n", "eda_steps": ["Check for missing values in each column", "Compute descriptive statistics for Math_Score and English_Score", "Generate value counts for Grade and Extra_Curricular columns", "Standardize Enrollment_Date formats to YYYY-MM-DD", "Calculate correlation between Math_Score and English_Score", "Identify students with attendance below 85%", "Summarize unique counts of students per grade"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 0, "Grade": 0, "Math_Score": 2, "English_Score": 1, "Attendance_Percentage": 1, "Enrollment_Date": 0, "Extra_Curricular": 1}, "summary_stats": {"Math_Score": {"count": 8, "mean": 84.75, "std": 6.12, "min": 75, "max": 91}, "English_Score": {"count": 9, "mean": 86.78, "std": 4.59, "min": 79, "max": 93}, "Attendance_Percentage": {"count": 9, "mean": 89.11, "std": 5.06, "min": 80, "max": 95.5}}, "value_counts": {"Grade": {"10": 4, "11": 3, "12": 3}, "Extra_Curricular": {"Soccer": 2, "BasketBall": 2, "Drama": 2, "Swimming": 2, "Chess": 1, "": 1}}, "standardized_enrollment_dates": ["2021-09-01", "2021-09-05", "2021-09-03", "2021-09-04", "2021-09-02", "2021-09-03", "2021-09-01", "2021-09-02", "2021-09-05", "2021-09-05"], "correlations": {"Math_Score_vs_English_Score": 0.63}, "low_attendance_students": [{"StudentID": 105, "Name": "Eva", "Attendance_Percentage": 85}, {"StudentID": 106, "Name": "fiona", "Attendance_Percentage": 80}], "unique_students_per_grade": {"10": 4, "11": 3, "12": 3}}}
{"purpose": "Analyze customer call patterns and plan subscription distribution to identify usage and churn trends.", "raw_table": "CustomerID,SubscriptionPlan,CallDurationMinutes,CallDate,Churned,Region\nC001,premium, 45 ,2023/01/15,No,North\nc002,standard,30,15-02-2023,yes,South\nC003,PREMIUM,,2023-03-10,no,East\nc004,Standard,25,2023/3/15,Yes,west\nC005,,40,2023-04-01,No,North\nC006,Premium,35,04/05/2023,no,north\nC007,standard,20,2023-06-20,YES,South\nC008,Premium,50,2023-07-25,no,East\nC009,Standard,,07-30-2023,,West\nC010,PREMIUM,60,2023/08/05,No,Unknown\nC011,standard,15,2023/08/10,No,South", "eda_steps": ["Check the percentage of missing values in each column", "Standardize capitalization in SubscriptionPlan and Region columns", "Convert CallDate to a uniform date format", "Compute descriptive statistics for CallDurationMinutes", "Generate value counts for SubscriptionPlan and Churned columns", "Identify top regions by number of customers", "Calculate the correlation between CallDurationMinutes and Churned status (encoded as binary)", "Summarize missing data impact on churn"], "eda_results": {"missing_values": {"CustomerID": "0%", "SubscriptionPlan": "9.1%", "CallDurationMinutes": "18.2%", "CallDate": "0%", "Churned": "9.1%", "Region": "0%"}, "standardized_categories": {"SubscriptionPlan": ["Premium", "Standard", null], "Region": ["North", "South", "East", "West", "Unknown"]}, "call_date_range": {"min": "2023-01-15", "max": "2023-08-10"}, "summary_stats": {"CallDurationMinutes": {"count": 11, "mean": 36.36, "std": 14.92, "min": 15, "25%": 25, "50%": 35, "75%": 45, "max": 60}}, "value_counts": {"SubscriptionPlan": {"Premium": 5, "Standard": 5, "null": 1}, "Churned": {"No": 6, "Yes": 3, "null": 1}}, "top_regions": {"South": 3, "North": 3, "East": 2, "West": 2, "Unknown": 1}, "correlations": {"CallDurationMinutes_vs_Churned": -0.52}, "missing_data_impact": {"Missing CallDurationMinutes": "2 of 2 missing values correspond to churned customers", "Missing Churned": "1 record with missing churn status has missing CallDurationMinutes"}}}
{"purpose": "Analyze user engagement patterns and post popularity on a social media platform.", "raw_table": "user_id,post_id,post_date,num_likes,num_comments,post_type,user_region\nU001,P1001,2023-01-05,15,2,Image,North America\nU002,P1002,01/10/2023,20,5,video,Europe\nu003,P1003,2023-01-15,,3,text,ASIA\nU004,P1004,2023/01/20,5,0,Image,Europe\nU005,P1005,2023-1-22,12,,video,South America\nU006,P1006,2023-01-25,8,1,text,North america\nU007,P1007,2023-01-27,NaN,NaN,image,Asia\nU008,P1008,2023/01/29,25,7,Video,EUROPE\nu009,P1009,01-30-2023,18,NaN,Text,South america\nU010,P1010,2023-02-01,30,10,IMAGE,North America\nU011,P1011,,22,4,video,Europe\nU012,P1012,2023-02-05,17,3,Text,Asia", "eda_steps": ["Check for missing values in each column", "Standardize the date format in the post_date column", "Clean and unify capitalization in post_type and user_region columns", "Compute descriptive statistics (mean, median) for num_likes and num_comments", "Generate value counts for post_type and user_region", "Identify posts with missing engagement metrics", "Calculate the correlation between num_likes and num_comments", "Find the top 3 post_types by average number of likes"], "eda_results": {"missing_values": {"user_id": 0, "post_id": 0, "post_date": 1, "num_likes": 2, "num_comments": 3, "post_type": 0, "user_region": 0}, "standardized_date_format": {"earliest_date": "2023-01-05", "latest_date": "2023-02-05"}, "cleaned_categories": {"post_type": ["Image", "Video", "Text"], "user_region": ["North America", "Europe", "Asia", "South America"]}, "descriptive_stats": {"num_likes": {"mean": 16.89, "median": 17.0}, "num_comments": {"mean": 3.57, "median": 3.0}}, "value_counts": {"post_type": {"Image": 4, "Video": 4, "Text": 4}, "user_region": {"Europe": 4, "North America": 3, "Asia": 3, "South America": 2}}, "missing_engagement_posts": ["P1003", "P1005", "P1007", "P1009", "P1011"], "correlations": {"num_likes_vs_num_comments": 0.89}, "top_post_types_by_avg_likes": {"Image": 17.5, "Video": 19.25, "Text": 14.33}}}
{"purpose": "Analyze student performance and attendance patterns in a high school to identify data quality issues and summarize key statistics.", "raw_table": "Student_ID,Name,Grade,Subject,Test_Score,Attendance,Test_Date\n101,alice,10,Math,88,Present,2023/03/15\n102,Bob,10,science,92,Absent,15-03-2023\n103,CHARLIE,11,History,,Present,03-16-2023\n104,Diana,11,math,77,Present,2023-03-17\n105,Eva,10,Science,85,present,03/18/2023\n106,Frank,12,History,90,Absent,2023/03/19\n107,Grace,12,Math,not available,Present,2023-03-20\n108,Henry,11,Science,82,,2023-03-21\n109,Ian,10,History,78,Absent,21/03/2023\n110,Jane,12,Math,95,Present,2023-03-22\n111,Kate,11,science,89,Present,Mar 23, 2023", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in categorical columns (Name, Grade, Subject, Attendance)", "Convert Test_Score to numeric and identify non-numeric or missing values", "Parse and standardize Test_Date to ISO format (YYYY-MM-DD)", "Generate descriptive statistics for Test_Score", "Calculate value counts for Subject and Attendance", "Identify number of unique students by Grade", "Check correlation between Test_Score and Grade where possible"], "eda_results": {"missing_values": {"Student_ID": 0, "Name": 0, "Grade": 0, "Subject": 0, "Test_Score": 2, "Attendance": 1, "Test_Date": 0}, "standardized_categories": {"Name": ["Alice", "Bob", "Charlie", "Diana", "Eva", "Frank", "Grace", "Henry", "Ian", "Jane", "Kate"], "Grade": ["10", "10", "11", "11", "10", "12", "12", "11", "10", "12", "11"], "Subject": ["Math", "Science", "History", "Math", "Science", "History", "Math", "Science", "History", "Math", "Science"], "Attendance": ["Present", "Absent", "Present", "Present", "Present", "Absent", "Present", "Absent", "Absent", "Present", "Present"]}, "test_score_numeric_conversion": {"non_numeric_entries": ["not available"], "imputed_missing_values": 2}, "test_date_standardized": ["2023-03-15", "2023-03-15", "2023-03-16", "2023-03-17", "2023-03-18", "2023-03-19", "2023-03-20", "2023-03-21", "2023-03-21", "2023-03-22", "2023-03-23"], "summary_stats": {"Test_Score": {"count": 9, "mean": 85.56, "std_dev": 6.11, "min": 77, "25%": 78, "50%": 88, "75%": 90, "max": 95}}, "value_counts": {"Subject": {"Math": 4, "Science": 4, "History": 3}, "Attendance": {"Present": 7, "Absent": 4}}, "unique_students_per_grade": {"10": 4, "11": 4, "12": 3}, "correlation_TestScore_Grade": null}}
{"purpose": "Analyze monthly transaction patterns and customer segments in retail banking data.", "raw_table": "CustomerID,TransactionDate,TransactionType,Amount,AccountType,Branch\n1001,2023-01-15,Deposit,5000,Savings,New york\n1002,01/22/2023,WITHDRAWAL,250,checking,Los Angeles\n1003,2023/02/10,deposit,,Savings,Chicago\n1004,15-03-2023,Withdrawal,1000,Checking,los angeles\n1005,2023-03-20,Deposit,3000,,New York\n1006,April 5 2023,Deposit,4500,Savings,Houston\n1007,2023-04-18,Transfer,1500,Checking,Houston\n1008,2023-05-02,withdrawal,-500,checking,Dallas\n1009,,Deposit,7000,Savings,Dallas\n1010,2023-05-25,Deposit,2000,Savings,\n1011,2023-06-01,Withdrawal,abc,Savings,Chicago\n1012,06/15/2023,Transfer,1200,Checking,New york\n1013,2023-06-20,Deposit,3500,Savings,Chicago\n1014,2023-07-05,Deposit,4000,Checking,Dallas", "eda_steps": ["Check for missing values in each column", "Standardize the date format in the TransactionDate column to YYYY-MM-DD", "Convert Amount column to numeric and identify invalid entries", "Generate descriptive statistics (mean, median, std) for Amount grouped by TransactionType", "Count unique values in AccountType and Branch columns", "Calculate the number of transactions per month", "Identify the top 3 branches by total transaction Amount", "Check for negative or zero transaction amounts"], "eda_results": {"missing_values": {"CustomerID": 0, "TransactionDate": 1, "TransactionType": 0, "Amount": 2, "AccountType": 1, "Branch": 1}, "standardized_dates_sample": ["2023-01-15", "2023-01-22", "2023-02-10", "2023-03-15", "2023-03-20", "2023-04-05", "2023-04-18", "2023-05-02", "null", "2023-05-25", "2023-06-01", "2023-06-15", "2023-06-20", "2023-07-05"], "amount_conversion_issues": [{"CustomerID": 1003, "Amount": null}, {"CustomerID": 1011, "Amount": null}], "descriptive_stats_by_TransactionType": {"Deposit": {"mean": 4100, "median": 4000, "std_dev": 1423}, "Withdrawal": {"mean": 583, "median": 375, "std_dev": 750}, "Transfer": {"mean": 1350, "median": 1350, "std_dev": 212}}, "unique_value_counts": {"AccountType": {"Savings": 7, "Checking": 6, "": 1}, "Branch": {"New york": 3, "Los Angeles": 2, "Chicago": 3, "Houston": 2, "Dallas": 3, "": 1}}, "transactions_per_month": {"2023-01": 2, "2023-02": 1, "2023-03": 2, "2023-04": 2, "2023-05": 3, "2023-06": 3, "2023-07": 1}, "top_3_branches_by_total_amount": {"Dallas": 10500, "Chicago": 10500, "New york": 6200}, "negative_or_zero_amounts": {"CustomerID": 1008, "Amount": -500}}}
{"purpose": "Analyze urban bike-sharing trip patterns and identify data quality issues.", "raw_table": "Trip_ID,Start_Date,Start_Time,User_Type,Trip_Duration,Start_Station,End_Station\n1,2024-04-01,08:15 AM,Subscriber,12,Central Park,central park\n2,04/02/2024,0830,Customer,,Downtown,Midtown\n3,2024-4-3,9:45 AM,SUBSCRIBER,7,Downtown,Midtown\n4,2024/04/04,10:00,subscriber,15,,Uptown\n5,April 5 2024,11:30 AM,Customer,9,Midtown,Downtown\n6,2024-04-06,14:00,Subscriber,abc,Central Park,Uptown\n7,2024-4-07,07:00,Customer,20,uptown,Central Park\n8,2024-04-08,18:15:00,Subscriber,13,Downtown,\n9,2024-04-09,19:45:00,SUBSCRIBER,11,Midtown,midtown\n10,2024-04-10,20:00,Customer,8,Uptown,Downtown\n", "eda_steps": ["Standardize capitalization for User_Type and station names", "Parse and unify Start_Date and Start_Time into a single datetime column", "Check for missing values across all columns", "Compute descriptive statistics for Trip_Duration", "Generate value counts for User_Type", "Identify trips with non-numeric Trip_Duration and treat as missing", "Count unique Start_Station and End_Station values", "Summarize most frequent routes (Start_Station to End_Station pairs)"], "eda_results": {"missing_values": {"Trip_Duration": 2, "Start_Station": 1, "End_Station": 2}, "value_counts_User_Type": {"Subscriber": 6, "Customer": 4}, "trip_duration_stats": {"count": 8, "mean": 11.875, "std": 4.314, "min": 7, "25%": 9, "50%": 11, "75%": 15, "max": 20}, "unique_stations": {"Start_Station": 4, "End_Station": 4}, "top_routes": {"Central Park -> Uptown": 2, "Downtown -> Midtown": 2, "Midtown -> Downtown": 2}, "non_numeric_trip_duration_rows": [6]}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones to identify data quality issues and summarize key statistics.", "raw_table": "StationID,Date,ClimateZone,Temperature_C,Precipitation_mm\nS001,2023-01-15,Tropical,29.5,120\ns002,15-Feb-2023,temperate,13.2,85.4\nS003,2023/03/20,Arid,25,,\ns004,2023-04-18,TROPICAL,31.0,110.2\nS005,2023-05-15,temperate,,90\nS006,06-2023-06,Arid,28.1,5.5\ns007,2023-07-12,Polar,-5.2,0\nS008,2023-08-19,polar,-3.8,\ns009,2023-09-23,Temperate,16.7,78.9\nS010,2023-10-11,TROPICAL,30.2,115.3\nS011,2023-11-05,Arid,27.4,8.1\ns012,,Polar,-4.1,0.0\nS013,2023-12-14,Temperate,12.9,100\nS014,2023-13-01,Tropical,29.7,112.8", "eda_steps": ["Check for missing values in all columns", "Standardize the ClimateZone categories to consistent capitalization", "Parse and standardize all Date entries to ISO format (YYYY-MM-DD)", "Compute descriptive statistics for Temperature_C and Precipitation_mm", "Generate value counts for the ClimateZone column", "Identify rows with invalid or missing dates", "Calculate the percentage of missing Temperature_C and Precipitation_mm values", "Summarize temperature range within each ClimateZone"], "eda_results": {"missing_values": {"StationID": 0, "Date": 1, "ClimateZone": 0, "Temperature_C": 2, "Precipitation_mm": 3}, "standardized_climate_zones": {"Tropical": 5, "Temperate": 4, "Arid": 3, "Polar": 3}, "invalid_dates": ["S006 (06-2023-06)", "S014 (2023-13-01)", "s012 (missing)"], "temperature_stats": {"count": 12, "mean": 19.14, "std_dev": 13.68, "min": -5.2, "max": 31.0}, "precipitation_stats": {"count": 11, "mean": 68.2, "std_dev": 46.2, "min": 0.0, "max": 120.0}, "missing_percentage": {"Temperature_C": 14.3, "Precipitation_mm": 21.4}, "temperature_range_by_climate": {"Tropical": {"min": 29.5, "max": 31.0}, "Temperate": {"min": 12.9, "max": 16.7}, "Arid": {"min": 25.0, "max": 28.1}, "Polar": {"min": -5.2, "max": -3.8}}}}
{"purpose": "Analyze citizen complaint trends and identify common complaint categories in municipal services.", "raw_table": "Complaint_ID,Date_Received,Department,Complaint_Type,Status,Resolution_Time_Days,Priority_Level\n101,2023-01-15,Sanitation,littering,Closed,5,High\n102,01/22/2023,water,Water Leak,Open,,Medium\n103,2023/02/05,Roads,potholes,closed,7,high\n104,02-12-2023,Sanitation,Odor,In Progress,3,low\n105,2023-03-01,Water,water leak,Closed,2,Medium\n106,March 5 2023,parks,DAMAGED Bench,Closed,4,low\n107,,roads,Pothole,Open,,High\n108,2023-03-15,Sanitation,Littering,Closed,6,medium\n109,03/20/2023,Water,Water leak,Closed,3,Medium\n110,2023-03-25,parks,damaged bench,closed,5,Low\n111,2023-04-01,Transportation,Bus Delay,Open,,High\n112,04-05-2023,Transportation,bus delay,Closed,1,High\n113,2023-04-10,Sanitation,littering,Closed,4,Medium\n114,2023-4-12,Sanitation,,Open,,Low\n115,2023-04-15,roads,Potholes,Closed,8,High", "eda_steps": ["Check missing values percentage for each column", "Standardize and normalize date formats in the Date_Received column", "Convert all text columns to consistent capitalization", "Generate value counts for Department and Complaint_Type columns", "Calculate descriptive statistics for Resolution_Time_Days", "Identify the number of complaints by Status", "Analyze Priority_Level distribution", "Find average Resolution_Time_Days by Department", "Identify complaints with missing Complaint_Type", "Summarize trends over time by counting complaints per month"], "eda_results": {"missing_values": {"Complaint_ID": 0, "Date_Received": 1, "Department": 0, "Complaint_Type": 1, "Status": 0, "Resolution_Time_Days": 4, "Priority_Level": 0}, "date_standardization": {"formats_found": ["YYYY-MM-DD", "MM/DD/YYYY", "YYYY/MM/DD", "MM-DD-YYYY", "Month D YYYY"], "dates_standardized": 14, "missing_dates": 1}, "text_normalization": {"Department_unique_values_before": ["Sanitation", "water", "Roads", "parks", "Transportation"], "Department_unique_values_after": ["Sanitation", "Water", "Roads", "Parks", "Transportation"], "Complaint_Type_unique_values_before": ["littering", "Water Leak", "potholes", "Odor", "DAMAGED Bench", "Bus Delay", ""], "Complaint_Type_unique_values_after": ["Littering", "Water Leak", "Potholes", "Odor", "Damaged Bench", "Bus Delay", "Missing"]}, "value_counts": {"Department": {"Sanitation": 5, "Water": 3, "Roads": 3, "Parks": 2, "Transportation": 2}, "Complaint_Type": {"Littering": 3, "Water Leak": 3, "Potholes": 3, "Odor": 1, "Damaged Bench": 2, "Bus Delay": 2, "Missing": 1}, "Status": {"Closed": 9, "Open": 4, "In Progress": 1}, "Priority_Level": {"High": 5, "Medium": 4, "Low": 4}}, "descriptive_statistics_Resolution_Time_Days": {"count": 11, "mean": 4.6, "std_dev": 2.2, "min": 1, "25%": 3, "50%": 4, "75%": 6, "max": 8}, "average_resolution_time_by_department": {"Sanitation": 4.8, "Water": 3.3, "Roads": 7.5, "Parks": 4.5, "Transportation": 1.0}, "complaints_with_missing_complaint_type": 1, "monthly_complaint_counts": {"January 2023": 2, "February 2023": 2, "March 2023": 6, "April 2023": 5}}}
{"purpose": "Examine energy consumption patterns by building type and month to identify missing data and unusual usage trends.", "raw_table": "BuildingID,BuildingType,Month,EnergyConsumed_kWh,PeakDemand_kW\n1001,Residential,2023-01,1500,4.5\n1002,commercial,01/2023,2300,10.2\n1003,Industrial,2023-02,,15.0\n1004,Residential,Feb-2023,1600,5.0\n1005,COMMERCIAL,2023-03,2400,11.1\n1006,industrial,03/2023,4000,15.5\n1007,Residential,2023-03,1550,4.7\n1008,Commercial,April 2023,2350,10.8\n1009,Residential,2023-04,1580,4.9\n1010,industrial,Apr-2023,4050,16.0\n1011,Residential,2023/05,1620,5.1\n1012,commercial,May 2023,,10.5\n1013,Industrial,2023-05,4100,16.2", "eda_steps": ["Standardize the BuildingType column to consistent capitalization", "Parse the Month column into a uniform date format (YYYY-MM)", "Check for and report missing values in EnergyConsumed_kWh and PeakDemand_kW", "Compute descriptive statistics (mean, median, std) for EnergyConsumed_kWh grouped by BuildingType", "Generate value counts for BuildingType", "Identify months with incomplete data entries", "Calculate correlation between EnergyConsumed_kWh and PeakDemand_kW", "Identify any outliers in EnergyConsumed_kWh using basic statistical thresholds"], "eda_results": {"missing_values": {"EnergyConsumed_kWh": 2, "PeakDemand_kW": 0}, "value_counts": {"Residential": 5, "Commercial": 4, "Industrial": 4}, "standardized_months": ["2023-01", "2023-01", "2023-02", "2023-02", "2023-03", "2023-03", "2023-03", "2023-04", "2023-04", "2023-04", "2023-05", "2023-05", "2023-05"], "descriptive_stats_EnergyConsumed_kWh": {"Residential": {"mean": 1570, "median": 1580, "std_dev": 45.7}, "Commercial": {"mean": 2350, "median": 2350, "std_dev": 53.7}, "Industrial": {"mean": 4050, "median": 4050, "std_dev": 43.6}}, "incomplete_months": ["2023-02", "2023-05"], "correlation_EnergyConsumed_vs_PeakDemand": 0.98, "outliers_EnergyConsumed_kWh": {"BuildingID": 1003, "reason": "Missing value in EnergyConsumed_kWh"}}}
{"purpose": "Analyze quality control and production performance metrics for manufactured parts over a two-week period.", "raw_table": "BatchID,ProductionDate,Operator,PartType,DefectCount,Shift,Temperature\nB001,2024-04-01,alice,Widget,2,Morning,75\nB002,04/02/2024,Bob,widget,0,Afternoon,78\nB003,2024/04/03,CHARLIE,Gadget,,Morning,80\nB004,2024-04-04,Alice,Gadget,1,Night,76\nB005,4-5-2024,bob,Widget,3,MORNING,77\nB006,2024-04-06,Charlie,widget,0,Afternoon,\nB007,2024-4-07,Alice,Gadget,2,Night,79\nB008,2024/04/08,Bob,widget,1,Morning,74\nB009,2024-04-09,CHARLIE,Gadget,NaN,Afternoon,75\nB010,2024-04-10,alice,Widget,0,Night,77\nB011,4/11/2024,Bob,Widget,1,Morning,76\nB012,2024-04-12,Charlie,Gadget,2,Afternoon,78\nB013,2024-04-13,Alice,widget,1,Night,missing\nB014,2024/04/14,Bob,Widget,0,Morning,75", "eda_steps": ["Standardize the date format in ProductionDate column", "Clean and unify capitalization in Operator and PartType columns", "Identify and count missing values in each column", "Compute descriptive statistics for numeric columns DefectCount and Temperature", "Generate value counts for categorical columns Operator, PartType, and Shift", "Calculate average DefectCount grouped by PartType and Shift", "Check correlation between Temperature and DefectCount", "Identify batches with missing or invalid data for further review"], "eda_results": {"missing_values": {"BatchID": 0, "ProductionDate": 0, "Operator": 0, "PartType": 0, "DefectCount": 3, "Shift": 0, "Temperature": 2}, "value_counts": {"Operator": {"alice": 4, "bob": 4, "charlie": 4}, "PartType": {"widget": 8, "gadget": 6}, "Shift": {"morning": 6, "afternoon": 5, "night": 3}}, "summary_stats": {"DefectCount": {"count": 11, "mean": 1.09, "std": 1.05, "min": 0, "25%": 0, "50%": 1, "75%": 2, "max": 3}, "Temperature": {"count": 12, "mean": 76.92, "std": 1.87, "min": 74, "25%": 75, "50%": 77, "75%": 78, "max": 80}}, "average_defects_by_part_and_shift": {"widget": {"morning": 1.33, "afternoon": 0, "night": 0.5}, "gadget": {"morning": 0, "afternoon": 2, "night": 1.5}}, "correlations": {"Temperature_DefectCount": -0.12}, "invalid_batches": ["B003", "B009", "B013", "B006", "B013"]}}
{"purpose": "Analyze customer purchase behavior and product category distribution in an ecommerce dataset.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,TotalPrice,PaymentMethod\n1001,C001,2023-01-15,Electronics,2,299.99,599.98,Credit Card\n1002,c002,15/01/2023,home Appliances,1,89.5,89.5,credit card\n1003,C003,2023/01/16,Fashion,3,25.0,75.0,PayPal\n1004,C001,17-Jan-2023,Electronics,1,299.99,299.99,CREDIT CARD\n1005,,2023-01-18,Fashion,,20.0,60.0,Cash\n1006,C004,2023-01-19,Books,5,12.0,60.0,Paypal\n1007,C005,01-20-2023,Home appliances,2,85.0,170.0,Credit card\n1008,C006,2023-01-20,Fashion,1,25,25,PayPal\n1009,C007,2023/01/21,Electronics,1,299.99,299.99,Credit Card\n1010,C008,21-01-2023,Books,2,12,24,Cash\n1011,c009,,Fashion,1,30,30,Debit Card\n1012,C010,2023-01-22,HOME appliances,1,89.5,89.5,Paypal\n1013,C011,2023-01-23,Books,3,12,36,Cash\n1014,C012,2023-01-24,Fashion,2,,50,Credit Card", "eda_steps": ["Check and report the percentage of missing values per column", "Standardize the ProductCategory names to consistent capitalization", "Parse and standardize OrderDate to YYYY-MM-DD format", "Compute descriptive statistics for Quantity, UnitPrice, and TotalPrice", "Calculate value counts for PaymentMethod and ProductCategory", "Identify orders with missing Quantity or UnitPrice and analyze their impact on TotalPrice", "Compute correlation matrix between Quantity, UnitPrice, and TotalPrice", "Find top 2 most frequent ProductCategories", "Summarize the distribution skewness of TotalPrice"], "eda_results": {"missing_values": {"OrderID": "0%", "CustomerID": "7.14%", "OrderDate": "7.14%", "ProductCategory": "0%", "Quantity": "14.29%", "UnitPrice": "7.14%", "TotalPrice": "0%", "PaymentMethod": "0%"}, "standardized_ProductCategory_counts": {"Electronics": 3, "Home Appliances": 3, "Fashion": 5, "Books": 4}, "date_range": {"earliest": "2023-01-15", "latest": "2023-01-24"}, "descriptive_statistics": {"Quantity": {"count": 12, "mean": 2.08, "std": 1.32, "min": 1, "max": 5}, "UnitPrice": {"count": 13, "mean": 92.88, "std": 134.95, "min": 12, "max": 299.99}, "TotalPrice": {"count": 14, "mean": 108.39, "std": 126.59, "min": 24, "max": 599.98}}, "PaymentMethod_counts": {"Credit Card": 5, "Paypal": 3, "Cash": 3, "Debit Card": 1}, "orders_missing_quantity_or_unitprice": {"OrderIDs": [1005, 1014], "note": "These orders have missing Quantity or UnitPrice which may cause inaccurate TotalPrice calculations."}, "correlations": {"Quantity_vs_TotalPrice": 0.85, "UnitPrice_vs_TotalPrice": 0.95, "Quantity_vs_UnitPrice": 0.12}, "top_2_ProductCategories": {"Fashion": 5, "Books": 4}, "TotalPrice_skewness": 1.45}}
{"purpose": "Examine student performance and attendance patterns in a high school semester.", "raw_table": "StudentID,Name,Grade,Math_Score,English_Score,Attendance,Enrollment_Date\n101,alice,10,88,92,95%,2023-01-15\n102,BOB,11,74,,88%,15/02/2023\n103,Charlie,10,NA,85,90%,2023/03/10\n104,diana,12,91,89,NaN,2023-02-28\n105,Ed,11,65,73,85%,2023-01-05\n106,,10,78,80,92%,2023-04-01\n107,Fiona,12,82,87,98%,2023-2-17\n108,george,11,70,76,89%,03-03-2023\n109,Hannah,10,85,NA,94%,2023/03/05\n110,Ian,12,90,91,92%,2023-01-20\n111,Julia,11,NA,88,NaN,2023-02-25", "eda_steps": ["Check the percentage of missing values for each column", "Standardize the capitalization of the 'Name' and 'Grade' columns", "Convert 'Enrollment_Date' to a consistent date format", "Calculate summary statistics for Math_Score and English_Score", "Analyze the distribution of Attendance percentages", "Identify students with missing scores in Math or English", "Count the number of students per Grade", "Examine correlation between Math_Score and English_Score", "Find the earliest and latest enrollment dates"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 1, "Grade": 0, "Math_Score": 3, "English_Score": 2, "Attendance": 2, "Enrollment_Date": 0}, "cleaned_columns": {"Name": ["Alice", "Bob", "Charlie", "Diana", "Ed", "Unknown", "Fiona", "George", "Hannah", "Ian", "Julia"], "Grade": ["10", "11", "10", "12", "11", "10", "12", "11", "10", "12", "11"]}, "enrollment_date_range": {"earliest": "2023-01-05", "latest": "2023-04-01"}, "summary_stats": {"Math_Score": {"count": 8, "mean": 80.375, "std": 8.7, "min": 65, "max": 91}, "English_Score": {"count": 9, "mean": 85.78, "std": 5.05, "min": 73, "max": 92}, "Attendance": {"count": 9, "mean_percentage": 91.4, "min_percentage": 85, "max_percentage": 98}}, "students_missing_scores": {"Math_Score": ["103", "110", "111"], "English_Score": ["102", "109"]}, "students_per_grade": {"10": 4, "11": 4, "12": 3}, "correlation_Math_English": 0.82}}
{"purpose": "Analyze streaming platform movie and TV show metadata to understand content distribution and availability trends.", "raw_table": "Title,Type,Genre,Release Date,Duration (mins),Rating,Views\nThe Last Kingdom,TV Show,Drama,2015-10-10,60,8.4,1500000\nParasite,Movie,Thriller,03/08/2019,132,8.6,2100000\nStranger Things,TV SHOW, Sci-Fi,2016/07/15,50,8.7,\navengers: Endgame,movie,Action,2019-04-26,181,8.4,3200000\nla la land,Movie,ROMANCE,2016-12-09,128,8.0,1800000\nThe Office,TV Show,Comedy,2005-03-24,,8.9,2300000\nInception,movie,Sci-Fi,16-07-2010,148,8.8,2700000\nFleabag,TV show,Comedy,2016-07-21,27,8.7,900000\nJoker,movie,Drama,2019/10/04,122,8.5,2500000\nFriends,TV Show,Comedy,1994-09-22,22,8.9,4000000\nUnknown Movie,movie,Documentary,2020-01-01,90,,\nGame of Thrones,TV Show,Fantasy,2011-04-17,60,9.3,3500000\nThe Crown,TV show,Drama,2016/11/04,,8.7,1200000\nBlack Mirror,TV Show,Sci-fi,2011-12-04,60,8.8,1100000", "eda_steps": ["Check and summarize missing values across all columns", "Standardize the 'Type' and 'Genre' categorical columns for consistent capitalization", "Parse 'Release Date' into a consistent date format and identify any parsing issues", "Compute descriptive statistics for 'Duration (mins)', 'Rating', and 'Views'", "Generate value counts for 'Type' and 'Genre'", "Identify top 3 most viewed titles", "Calculate average rating by content type", "Summarize distribution of release years", "Examine correlation between 'Duration (mins)', 'Rating', and 'Views'"], "eda_results": {"missing_values": {"Title": 0, "Type": 0, "Genre": 0, "Release Date": 0, "Duration (mins)": 3, "Rating": 2, "Views": 2}, "standardized_values": {"Type": {"movie": 7, "tv show": 8}, "Genre": {"Drama": 3, "Thriller": 1, "Sci-Fi": 3, "Action": 1, "Romance": 1, "Comedy": 3, "Documentary": 1, "Fantasy": 1}}, "release_date_parsing": {"parsed_dates": 15, "failed_parses": 0, "year_range": [1994, 2020]}, "summary_stats": {"Duration (mins)": {"count": 12, "mean": 90.9, "std": 52.8, "min": 22, "25%": 50, "50%": 60, "75%": 132, "max": 181}, "Rating": {"count": 13, "mean": 8.56, "std": 0.33, "min": 8.0, "25%": 8.45, "50%": 8.7, "75%": 8.8, "max": 9.3}, "Views": {"count": 13, "mean": 2131538, "std": 1016697, "min": 900000, "25%": 1200000, "50%": 2100000, "75%": 2900000, "max": 4000000}}, "value_counts": {"Type": {"movie": 7, "tv show": 8}, "Genre": {"Drama": 3, "Thriller": 1, "Sci-Fi": 3, "Action": 1, "Romance": 1, "Comedy": 3, "Documentary": 1, "Fantasy": 1}}, "top_3_viewed_titles": {"Friends": 4000000, "Avengers: Endgame": 3200000, "Game of Thrones": 3500000}, "average_rating_by_type": {"movie": 8.47, "tv show": 8.62}, "release_year_distribution": {"1990s": 1, "2000s": 1, "2010s": 12, "2020s": 1}, "correlations": {"Duration-Rating": 0.45, "Duration-Views": 0.3, "Rating-Views": 0.55}}}
{"purpose": "Examine household electricity consumption patterns and identify data quality issues.", "raw_table": "HouseholdID,Date,Consumption_kWh,Energy_Source,Region\nH001,2023/01/01,35.4,solar,Southern\nH002,01-02-2023,42,,Northern\nH003,2023-01-03,NaN,Wind, EASTERN\nh004,2023/01/04,50.1,Coal,Western\nH005,2023-1-05,47.3,solar,Southern\nH006,2023/01/06,not recorded,Gas,north\nH007,07 Jan 2023,55.2,COAL,Western\nH008,2023/01/08,48.5,Solar,Southern\nH009,2023-01-09,44.0,wind,eastern\nH010,2023/01/10,53.3,gas,North\nH011,2023/01/11,49.7,,Western\nH012,,52.8,Solar,Southern", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize the Date column to a consistent date format", "Normalize Energy_Source values to lowercase", "Generate descriptive statistics for Consumption_kWh after cleaning", "Count unique HouseholdID entries to detect duplicates or inconsistencies", "Create frequency counts for Energy_Source categories", "Identify regions and count their occurrences", "Calculate correlation between Consumption_kWh and Energy_Source category encoded numerically", "Detect and report any non-numeric or anomalous values in Consumption_kWh"], "eda_results": {"missing_values": {"HouseholdID": 0, "Date": 1, "Consumption_kWh": 2, "Energy_Source": 2, "Region": 0}, "date_standardization": {"original_formats": ["2023/01/01", "01-02-2023", "2023-01-03", "2023/01/04", "2023-1-05", "07 Jan 2023"], "standardized_format": "YYYY-MM-DD", "example_standardized_dates": ["2023-01-01", "2023-01-02", "2023-01-03", "2023-01-04", "2023-01-05", "2023-01-07"]}, "energy_source_normalization": ["solar", "wind", "coal", "gas", "unknown"], "descriptive_statistics": {"Consumption_kWh": {"count": 11, "mean": 47.5, "std_dev": 6.1, "min": 35.4, "25%": 44.0, "50%": 48.5, "75%": 50.1, "max": 55.2}}, "householdid_uniqueness": {"total_records": 12, "unique_households": 12, "case_inconsistencies": ["h004"]}, "energy_source_counts": {"solar": 4, "coal": 2, "wind": 2, "gas": 2, "unknown": 2}, "region_counts": {"southern": 4, "northern": 2, "eastern": 2, "western": 3, "north": 1}, "correlation_energy_consumption": {"note": "Energy_Source was encoded as solar=1, wind=2, coal=3, gas=4, unknown=0", "correlation_coefficient": 0.12}, "anomalous_consumption_values": {"rows_with_non_numeric": [6], "rows_with_missing": [3]}}}
{"purpose": "Analyze user engagement metrics and posting behavior on a social media platform over one week.", "raw_table": "UserID,PostDate,Likes,Comments,ContentType,PostLength\nU001,2024-04-01,25,5,Image,120\nu002,4/2/2024,15,,video,250\nU003,2024/04/03,NaN,2,Text,80\nU004,2024-04-04,10,1,IMAGE,\nU005,2024-04-05,30,8,Text,100\nU006,04-06-2024,5,0,Video,NaN\nu007,2024-04-07,50,20,image,300\nU008,2024/4/07,45,15,Text,200\nU009,2024-04-07,,3,Image,150\nU010,2024/04/02,20,4,video,180", "eda_steps": ["Check and report the percentage of missing values in each column", "Standardize the capitalization of the ContentType column", "Convert PostDate to a uniform date format", "Compute descriptive statistics for Likes, Comments, and PostLength", "Generate value counts for ContentType", "Identify users with missing Likes or Comments data", "Summarize the distribution skewness for numeric engagement metrics", "Find the correlation between Likes, Comments, and PostLength"], "eda_results": {"missing_values": {"UserID": "0%", "PostDate": "0%", "Likes": "20%", "Comments": "10%", "ContentType": "0%", "PostLength": "20%"}, "standardized_content_types": {"image": 4, "video": 3, "text": 3}, "postdate_uniform_format_sample": ["2024-04-01", "2024-04-02", "2024-04-03", "2024-04-04", "2024-04-05", "2024-04-06", "2024-04-07"], "summary_stats": {"Likes": {"count": 8, "mean": 25, "std": 15.7, "min": 5, "25%": 15, "50%": 20, "75%": 30, "max": 50}, "Comments": {"count": 9, "mean": 6.7, "std": 6.4, "min": 0, "25%": 1, "50%": 4, "75%": 8, "max": 20}, "PostLength": {"count": 10, "mean": 168, "std": 71.4, "min": 80, "25%": 100, "50%": 150, "75%": 200, "max": 300}}, "value_counts_ContentType": {"image": 4, "video": 3, "text": 3}, "users_missing_likes_or_comments": ["U002", "U003", "U009"], "skewness": {"Likes": 0.89, "Comments": 1.2, "PostLength": 0.65}, "correlations": {"Likes_Comments": 0.92, "Likes_PostLength": 0.75, "Comments_PostLength": 0.68}}}
{"purpose": "Analyze the production efficiency and defect rates across different manufacturing shifts.", "raw_table": "BatchID,Production_Date,Shift,Units_Produced,Defect_Rate,Operator\n101,2024/01/15,morning,500,0.02,John Doe\n102,15-01-2024,Morning,480,0.03,Mary jane\n103,2024-01-16,Afternoon,NaN,0.01,alice smith\n104,01/17/2024,afternoon,470,NA,Bob Brown\n105,2024-01-18,NIGHT,530,0.04,John Doe\n106,18-01-2024,Night,520,,Mary Jane\n107,2024/01/19,Morning,495,0.02,\n108,19/01/2024,afternoon,485,0.03,Alice Smith\n109,2024-01-20,Night,510,0.05,Bob Brown\n110,,Morning,500,0.02,John Doe\n111,2024-01-21,Night,525,0.01,Mary Jane\n112,21-01-2024,morning,NaN,0.03,John Doe", "eda_steps": ["Check for missing values in each column", "Standardize the 'Shift' column to lowercase", "Fix inconsistent date formats and convert 'Production_Date' to datetime", "Compute descriptive statistics for 'Units_Produced' and 'Defect_Rate'", "Generate value counts for the 'Operator' column", "Calculate average defect rate by shift", "Identify batches with missing 'Units_Produced'", "Summarize the distribution skewness of defect rates"], "eda_results": {"missing_values": {"BatchID": 0, "Production_Date": 1, "Shift": 0, "Units_Produced": 2, "Defect_Rate": 2, "Operator": 1}, "standardized_shifts_value_counts": {"morning": 5, "afternoon": 3, "night": 4}, "date_conversion_issues": 0, "summary_stats": {"Units_Produced": {"count": 11, "mean": 501.82, "std": 19.34, "min": 470, "25%": 485, "50%": 500, "75%": 520, "max": 530}, "Defect_Rate": {"count": 10, "mean": 0.027, "std": 0.0139, "min": 0.01, "25%": 0.02, "50%": 0.025, "75%": 0.03, "max": 0.05}}, "operator_value_counts": {"John Doe": 4, "Mary Jane": 3, "Alice Smith": 2, "Bob Brown": 2, "": 1}, "average_defect_rate_by_shift": {"morning": 0.025, "afternoon": 0.0233, "night": 0.025}, "batches_missing_units_produced": [103, 112], "defect_rate_skewness": 1.2}}
{"purpose": "Explore patient demographics and lab test results to identify data quality issues and initial trends in a cardiology study.", "raw_table": "Patient_ID,Age,Gender,Admission_Date,Blood_Pressure_Systolic,Blood_Pressure_Diastolic,Cholesterol_mg_dl,Diagnosis\nP001,54,Male,2023/01/15,130,85,200,Hypertension\nP002,47,F,15-02-2023,125,80, ,Coronary artery disease\nP003,62,male,2023-03-07,140,90,220,hypertension\nP004,,Female,03/15/23,135,88,210,HyperTension\nP005,58,Female,2023/04/01,NaN,85,215,Coronary Artery Disease\nP006,49,M,2023-04-20,128,82,205,\nP007,53,female,2023/04/18,132,,190,Hypertension\nP008,60,Male,2023-05-05,138,86,230,coronary artery Disease\nP009,55,F,2023/5/10,135,89,225,Hypertension\nP010,61,Male,May 12 2023,142,91,240,Coronary artery disease", "eda_steps": ["Check and summarize missing values for all columns", "Standardize 'Gender' entries to consistent categories", "Standardize 'Diagnosis' text and identify unique diagnosis categories", "Convert 'Admission_Date' to a consistent date format", "Calculate descriptive statistics (mean, median, std) for numeric columns", "Generate value counts for 'Diagnosis' and 'Gender'", "Identify rows with missing or invalid numeric values", "Examine correlations between blood pressure and cholesterol levels"], "eda_results": {"missing_values": {"Patient_ID": 0, "Age": 1, "Gender": 0, "Admission_Date": 0, "Blood_Pressure_Systolic": 1, "Blood_Pressure_Diastolic": 1, "Cholesterol_mg_dl": 1, "Diagnosis": 1}, "standardized_gender_counts": {"Male": 5, "Female": 5}, "standardized_diagnosis_counts": {"Hypertension": 5, "Coronary Artery Disease": 4, "Missing": 1}, "admission_date_formats": {"Standardized_to_ISO": true, "Date_range": ["2023-01-15", "2023-05-12"]}, "numeric_summary_stats": {"Age": {"mean": 55.9, "median": 55.0, "std": 5.5}, "Blood_Pressure_Systolic": {"mean": 134.0, "median": 135.0, "std": 5.0}, "Blood_Pressure_Diastolic": {"mean": 86.4, "median": 86.5, "std": 3.4}, "Cholesterol_mg_dl": {"mean": 212.1, "median": 212.5, "std": 15.5}}, "rows_with_invalid_numeric_values": ["P004 (missing Age)", "P005 (NaN Blood_Pressure_Systolic)", "P007 (missing Blood_Pressure_Diastolic)", "P002 (missing Cholesterol_mg_dl)", "P006 (missing Diagnosis)"], "correlations": {"Blood_Pressure_Systolic_vs_Diastolic": 0.89, "Blood_Pressure_Systolic_vs_Cholesterol_mg_dl": 0.35, "Blood_Pressure_Diastolic_vs_Cholesterol_mg_dl": 0.4}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones to identify data quality issues and seasonal trends.", "raw_table": "Date,Climate_Zone,Avg_Temperature_C,Precipitation_mm,Measurement_Quality\n2024-01-15,Tropical,29.5,120.3,Good\n2024/02/15,TROPICAL,28.7,,good\n15-03-2024,Temperate,12.3,55.1,Moderate\n2024-04-15,temperate,15.0,60.0,Moderate\n2024-05-15,Arctic,,12.4,poor\n2024-06-15,ArCTic,-5.4,8.0,Poor\n2024/07/15,Temperate,18.1,NaN,Moderate\n2024-08-15,Tropical,30.0,130.0,GOOD\n2024-09-15,temperate,14.2,50.5,moderate\n09-10-2024,Arctic,-3.2,9.1,Poor\n2024-11-15,Tropical,27.8,115.0,Good\n2024-12-15,Temperate,10.5,48.0,Moderate\n2024-13-01,Temperate,11.0,52.0,Moderate", "eda_steps": ["Standardize date formats to YYYY-MM-DD", "Normalize capitalization of Climate_Zone and Measurement_Quality columns", "Check for missing values in all columns and calculate their percentages", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone and Measurement_Quality", "Identify rows with invalid dates or impossible values", "Examine correlation between Avg_Temperature_C and Precipitation_mm", "Summarize average temperature and precipitation by Climate_Zone"], "eda_results": {"missing_values": {"Date": "8.3%", "Climate_Zone": "0.0%", "Avg_Temperature_C": "16.7%", "Precipitation_mm": "16.7%", "Measurement_Quality": "0.0%"}, "value_counts": {"Climate_Zone": {"Temperate": 6, "Tropical": 4, "Arctic": 3}, "Measurement_Quality": {"Good": 4, "Moderate": 6, "Poor": 3}}, "summary_stats": {"Avg_Temperature_C": {"count": 10, "mean": 15.22, "std": 12.29, "min": -5.4, "25%": 10.5, "50%": 14.2, "75%": 28.7, "max": 30.0}, "Precipitation_mm": {"count": 10, "mean": 70.89, "std": 44.96, "min": 8.0, "25%": 50.5, "50%": 55.1, "75%": 120.3, "max": 130.0}}, "invalid_rows": [{"row_index": 12, "issue": "Invalid date format '2024-13-01' (month 13 does not exist)"}], "correlations": {"Avg_Temperature_C_vs_Precipitation_mm": -0.12}, "grouped_averages": {"Tropical": {"Avg_Temperature_C": 29.5, "Precipitation_mm": 121.75}, "Temperate": {"Avg_Temperature_C": 14.03, "Precipitation_mm": 52.7}, "Arctic": {"Avg_Temperature_C": -4.3, "Precipitation_mm": 9.83}}}}
{"purpose": "Examine crop yield patterns across different farm regions and identify data quality issues.", "raw_table": "Farm_ID,Region,Crop_Type,Yield_kg,Harvest_Date,Soil_pH,Farmer_Experience\n101,North,Wheat,2500,2023-09-15,6.5,10\n102,East,Maize,3200,15/09/2023,7.1,8\n103,south,wheat,,2023-09-18,6.8,12\n104,West,Rice,2800,09-20-2023,6.2,seven\n105,NORTH,Maize,3100,2023/09/19,,9\n106,East,Rice,2700,2023-09-20,6.4,6\n107,South,,2900,2023-9-21,6.7,11\n108,west,Wheat,2600,2023-09-22,,5\n109,East,Maize,NaN,2023-09-23,7.0,8\n110,north,Rice,2750,2023-09-24,6.3,10", "eda_steps": ["Check for missing values in each column", "Standardize Region and Crop_Type capitalization", "Compute descriptive statistics for numeric columns Yield_kg, Soil_pH, and Farmer_Experience", "Generate value counts for Crop_Type", "Identify inconsistent or non-numeric values in Farmer_Experience", "Analyze date format consistency in Harvest_Date and standardize", "Compute correlation matrix between numeric variables", "Identify farms with missing Crop_Type or Yield_kg"], "eda_results": {"missing_values": {"Farm_ID": 0, "Region": 0, "Crop_Type": 1, "Yield_kg": 2, "Harvest_Date": 0, "Soil_pH": 2, "Farmer_Experience": 1}, "standardized_values": {"Region": ["North", "East", "South", "West"], "Crop_Type": ["Wheat", "Maize", "Rice"]}, "descriptive_statistics": {"Yield_kg": {"count": 12, "mean": 2791.67, "std": 230.7, "min": 2500, "max": 3200}, "Soil_pH": {"count": 10, "mean": 6.55, "std": 0.28, "min": 6.2, "max": 7.1}, "Farmer_Experience": {"count": 12, "mean": 8.58, "std": 2.1, "min": 5, "max": 12}}, "value_counts": {"Crop_Type": {"Wheat": 3, "Maize": 3, "Rice": 3, "Missing": 1}}, "inconsistent_Farmer_Experience": {"non_numeric_entries": ["seven"]}, "Harvest_Date_formats": {"YYYY-MM-DD": 9, "DD/MM/YYYY": 1, "MM-DD-YYYY": 1, "YYYY/MM/DD": 1}, "correlations": {"Yield_kg_Soil_pH": 0.42, "Yield_kg_Farmer_Experience": 0.35, "Soil_pH_Farmer_Experience": -0.12}, "missing_key_info": {"Farms_missing_Crop_Type": [107], "Farms_missing_Yield_kg": [103, 109]}}}
{"purpose": "Analyze housing market characteristics and identify data quality issues to inform pricing strategy.", "raw_table": "Property_ID, Location, Price_USD, Bedrooms, Bathrooms, Listing_Date, Property_Type\n1001, downtown, 350000, 3, 2, 2023/01/15, Apartment\n1002, Suburb, 420000, 4, 3, 15-02-2023, House\n1003, DOWNTOWN, 390000, 3, 2, 2023-03-01, Apartment\n1004, suburb, , 3, 2, 2023/03/05, house\n1005, Uptown, 310000, 2, , 2023-02-20, Condo\n1006, uptown, 320000, 2, 1, 02/25/2023, Condo\n1007, Downtown, 450000, 5, 4, 2023-01-30, House\n1008, Suburb, 400000, 4, 3, 2023/02/28, HOUSE\n1009, uptown, 295000, 2, 1, 2023-03-10, Condo\n1010, DOWNTOWN, 370000, 3, 2, , Apartment\n1011, suburb, 410000, three, 2, 2023-03-12, House\n1012, Uptown, 330000, 2, 1, 2023-01-25, condo", "eda_steps": ["Check and summarize missing values for each column", "Standardize the Location and Property_Type columns capitalization", "Convert Listing_Date to a uniform date format and identify invalid or missing dates", "Convert Bedrooms and Bathrooms to numeric types, handling non-numeric entries", "Compute descriptive statistics for Price_USD, Bedrooms, and Bathrooms", "Generate value counts for Location and Property_Type", "Identify properties with missing Price_USD values", "Calculate correlation matrix for numeric variables", "Summarize the range and distribution of Listing_Date"], "eda_results": {"missing_values": {"Property_ID": 0, "Location": 0, "Price_USD": 1, "Bedrooms": 1, "Bathrooms": 1, "Listing_Date": 1, "Property_Type": 0}, "standardized_categories": {"Location": {"downtown": 4, "suburb": 3, "uptown": 4}, "Property_Type": {"apartment": 4, "house": 5, "condo": 4}}, "date_issues": {"invalid_or_missing_dates": 1, "date_range": {"min": "2023-01-15", "max": "2023-03-12"}}, "numeric_conversion": {"Bedrooms_non_numeric": 1, "Bathrooms_non_numeric": 0}, "descriptive_statistics": {"Price_USD": {"count": 14, "mean": 371071, "std_dev": 48062, "min": 295000, "max": 450000}, "Bedrooms": {"count": 14, "mean": 3.07, "std_dev": 1.07, "min": 2, "max": 5}, "Bathrooms": {"count": 13, "mean": 2.23, "std_dev": 0.86, "min": 1, "max": 4}}, "value_counts": {"Location": {"downtown": 4, "suburb": 3, "uptown": 4}, "Property_Type": {"apartment": 4, "house": 5, "condo": 4}}, "missing_price_properties": [1004], "correlations": {"Price_USD_Bedrooms": 0.87, "Price_USD_Bathrooms": 0.82, "Bedrooms_Bathrooms": 0.91}, "listing_date_summary": {"earliest_listing": "2023-01-15", "latest_listing": "2023-03-12", "total_days_range": 56}}}
{"purpose": "Analyze student performance and attendance patterns in a high school semester.", "raw_table": "StudentID,Name,GradeLevel,MathScore,EnglishScore,AttendanceRate,EnrollmentDate\n101,john doe,10,85,78,0.95,2023/01/15\n102,Jane Smith,11,92,,0.87,15-01-2023\n103,Alex johnson,10,76,85,,2023-01-16\n104,Emily Davis,12,88,90,0.92,01/16/2023\n105,Mike Brown,11,NaN,82,0.85,2023/1/17\n106,sarah miller,10,91,88,0.98,2023-01-18\n107,,12,84,79,0.90,2023-01-18\n108,Chris Wilson,11,89,85,0.93,2023/01/19\n109,Anna Lee,12,95,NaN,0.97,19-01-2023\n110,David Kim,10,83,80,missing,2023-01-20\n", "eda_steps": ["Check for missing values and their percentages in each column", "Standardize the EnrollmentDate column to YYYY-MM-DD format", "Compute descriptive statistics (mean, median, std) for MathScore and EnglishScore", "Generate value counts for GradeLevel", "Identify students with missing names", "Calculate correlation between MathScore and EnglishScore", "Summarize AttendanceRate distribution including min, max, and mean", "List students with AttendanceRate below 0.90"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 1, "GradeLevel": 0, "MathScore": 1, "EnglishScore": 2, "AttendanceRate": 1, "EnrollmentDate": 0}, "standardized_dates": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-16", "2023-01-17", "2023-01-18", "2023-01-18", "2023-01-19", "2023-01-19", "2023-01-20"], "summary_stats": {"MathScore": {"mean": 86.3, "median": 86.5, "std_dev": 5.5}, "EnglishScore": {"mean": 83.7, "median": 83.5, "std_dev": 4.3}}, "value_counts_GradeLevel": {"10": 4, "11": 3, "12": 3}, "missing_names": [107], "correlations": {"MathScore_EnglishScore": 0.72}, "attendance_rate_summary": {"min": 0.85, "max": 0.98, "mean": 0.91}, "low_attendance_students": [{"StudentID": 102, "Name": "Jane Smith", "AttendanceRate": 0.87}, {"StudentID": 105, "Name": "Mike Brown", "AttendanceRate": 0.85}]}}
{"purpose": "Analyze hourly electricity consumption patterns and identify data quality issues in smart meter readings.", "raw_table": "MeterID,Timestamp,Consumption_kWh,Region,Device_Status\n001,2023/04/01 01:00 AM,5.2,North,active\n002,2023-04-01 02:00,7.8,South,Active\n003,04-01-2023 03:00 AM,missing,East,inactive\n004,2023-04-01 04:00 AM,6.1,,Active\n005,2023-04-01 05:00 AM,4.9,west,ACTIVE\n006,2023-04-01 06:00 AM,5.5,North,Active\n007,2023-04-01 07:00 AM,8.0,South,Inactive\n008,2023-04-01 08:00,7.3,East,Active\n009,2023/04/01 09:00 AM,NaN,North,Active\n010,2023-04-01 10:00 AM,6.7,South,active\n011,April 1 2023 11:00 AM,5.8,West,active\n012,2023-4-1 12:00 PM,6.0,East,unknown\n", "eda_steps": ["Check for and summarize missing values in each column", "Standardize the capitalization in categorical columns 'Region' and 'Device_Status'", "Convert 'Timestamp' into a consistent datetime format", "Compute basic descriptive statistics for the 'Consumption_kWh' column", "Generate value counts for the 'Region' column", "Identify rows with non-numeric or missing consumption values", "Calculate the number of active vs inactive devices", "Find consumption mean by Region", "Check for any duplicated MeterID and Timestamp pairs"], "eda_results": {"missing_values": {"MeterID": 0, "Timestamp": 0, "Consumption_kWh": 2, "Region": 1, "Device_Status": 1}, "value_counts": {"Region": {"North": 3, "South": 3, "East": 3, "West": 2, "": 1}, "Device_Status": {"active": 7, "inactive": 2, "unknown": 1}}, "standardized_categories": {"Region": ["North", "South", "East", "West", ""], "Device_Status": ["active", "inactive", "unknown"]}, "datetime_conversion": {"earliest_timestamp": "2023-04-01T01:00:00", "latest_timestamp": "2023-04-01T12:00:00"}, "descriptive_statistics": {"Consumption_kWh": {"count": 10, "mean": 6.33, "std_dev": 1.06, "min": 4.9, "max": 8.0}}, "non_numeric_consumption_rows": [3, 9], "device_status_counts": {"active": 7, "inactive": 2, "unknown": 1}, "mean_consumption_by_region": {"North": 5.35, "South": 7.5, "East": 6.43, "West": 5.8, "": null}, "duplicate_meter_timestamp_pairs": 0}}
{"purpose": "Analyze monthly transaction patterns and customer segments in a retail banking dataset.", "raw_table": "Transaction_ID,Customer_ID,Transaction_Date,Transaction_Amount,Account_Type,Branch,Transaction_Type\nT001,Cust_01,2024-01-05,2500.00,Checking,New York,Deposit\nT002,Cust_02,01/15/2024,-100.50,SAVINGS,los angeles,Withdrawal\nT003,Cust_03,2024-01-20,,Checking,Chicago,Deposit\nT004,Cust_04,2024/01/18,500.00,checking,Houston,DEPOSIT\nT005,Cust_05,2024-01-25,-200.00, Savings,Los Angeles,Withdrawal\nT006,Cust_06,2024-02-01,3000,Checking,New york,Deposit\nT007,Cust_07,02-03-2024,-150.75,savings,Houston,withdrawal\nT008,Cust_08,2024-02-05,NaN,Checking,Chicago,Deposit\nT009,Cust_09,2024-02-07,1250.30,savings,New York,Deposit\nT010,Cust_10,2024-02-10,-500,Checking,Houston,WITHDRAWAL\nT011,Cust_11,2024-02-12,800.00,Checking,Los Angeles,Deposit\nT012,Cust_12,,450.00,Savings,Chicago,Deposit\nT013,Cust_13,2024-02-15,-75.25,checking,New York,Withdrawal\nT014,Cust_14,2024-02-18,1000,Checking,Houston,Deposit", "eda_steps": ["Check the percentage of missing values per column", "Standardize the Account_Type and Branch columns capitalization", "Convert Transaction_Date to a uniform date format", "Compute descriptive statistics for Transaction_Amount", "Generate value counts for Account_Type and Transaction_Type", "Identify the number of unique customers", "Calculate the total deposited and withdrawn amounts", "Examine correlation between Transaction_Amount and Account_Type", "Find top 3 branches by transaction volume"], "eda_results": {"missing_values": {"Transaction_ID": 0, "Customer_ID": 0, "Transaction_Date": 1, "Transaction_Amount": 2, "Account_Type": 0, "Branch": 0, "Transaction_Type": 0}, "standardized_categories": {"Account_Type": ["checking", "savings"], "Branch": ["new york", "los angeles", "chicago", "houston"], "Transaction_Type": ["deposit", "withdrawal"]}, "transaction_date_format": "All dates standardized to ISO format YYYY-MM-DD; missing date remains null", "summary_stats": {"Transaction_Amount": {"count": 12, "mean": 797.61, "std": 1226.5, "min": -500.0, "25%": -150.75, "50%": 500.0, "75%": 1250.3, "max": 3000.0}}, "value_counts": {"Account_Type": {"checking": 8, "savings": 5}, "Transaction_Type": {"deposit": 8, "withdrawal": 5}}, "unique_customers": 14, "total_amounts": {"deposit": 10300.3, "withdrawal": -1026.5}, "correlations": {"Transaction_Amount_vs_Account_Type": "No strong correlation observed (account type categorical; numeric analysis shows similar averages)"}, "top_branches_by_volume": {"houston": 5, "new york": 4, "los angeles": 3}}}
{"purpose": "Analyze customer purchase behavior and product category popularity in an online store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,TotalPrice,PaymentMethod\n1001,C001,2023-05-01,Electronics,2,299.99,599.98,Credit Card\n1002,,05/03/2023,home appliances,1,89.5,89.5,Paypal\n1003,C003,2023/05/05,Fashion,3,19.99,59.97,Credit card\n1004,C004,May 6 2023,Electronics,1,299.99,,credit card\n1005,C005,2023-05-07,Toys,2,15.0,30.0,Cash\n1006,C006,2023-05-08,Fashion,,25.0,50.0,Credit Card\n1007,C007,2023-5-09,HOMe appliances,1,89.50,89.5,PayPal\n1008,C008,2023-05-10,Toys,1,15.00,,cash\n1009,C009,2023-05-11,Books,5,7.5,37.5,Credit card\n1010,C010,2023-13-12,Books,2,7.5,15.0,Credit Card\n1011,C011,2023-05-13,Fashion,3,19.99,59.97,CreditCard\n1012,C012,2023-05-14,Electronics,1,299.99,299.99,Credit Card", "eda_steps": ["Check and summarize missing values per column", "Standardize the ProductCategory and PaymentMethod columns for consistent capitalization", "Identify rows with invalid or inconsistent date formats in OrderDate", "Compute descriptive statistics (mean, median, std) for Quantity, UnitPrice, and TotalPrice", "Generate value counts for ProductCategory and PaymentMethod", "Calculate total sales per ProductCategory", "Detect rows where TotalPrice does not equal Quantity multiplied by UnitPrice", "Identify top 3 customers by total spending"], "eda_results": {"missing_values": {"CustomerID": 1, "Quantity": 1, "TotalPrice": 2}, "standardized_categories": {"product_categories": ["Electronics", "Home Appliances", "Fashion", "Toys", "Books"], "payment_methods": ["Credit Card", "Paypal", "Cash"]}, "invalid_dates": [10], "summary_stats": {"Quantity": {"mean": 2.18, "median": 2, "std": 1.33}, "UnitPrice": {"mean": 98.33, "median": 25.0, "std": 127.5}, "TotalPrice": {"mean": 151.04, "median": 59.97, "std": 199.42}}, "value_counts": {"ProductCategory": {"Electronics": 3, "Home Appliances": 2, "Fashion": 3, "Toys": 2, "Books": 2}, "PaymentMethod": {"Credit Card": 7, "Paypal": 2, "Cash": 2}}, "total_sales_per_category": {"Electronics": 1199.96, "Home Appliances": 179.0, "Fashion": 169.94, "Toys": 60.0, "Books": 52.5}, "price_mismatch_rows": [4, 7, 8], "top_customers_by_spending": {"C001": 599.98, "C012": 299.99, "C009": 37.5}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across various climate zones to identify data quality issues and preliminary trends.", "raw_table": "Date,Location,Temperature_C,Precipitation_mm,Climate_Zone\n2023-01-01,desert city,25.3,0.0,Arid\n2023-1-15,Tundra Town,-15.6,,Polar\n2023/02/01,Rainforest village,28.4,200.5,Tropical\n2023-02-15,DESERT CITY,27.8,0.0,arid\n2023-3-01,Tundra Town,,5.2,POLAR\n2023-03-15,Rainforest village,29.1,180.0,tropical\n2023-04-01,Mountain Peak,12.0,15.0,Alpine\n2023-04-15,Mountain Peak,11.5,,alpine\n2023-05-01,Desert City,30.0,0.0,ARID\n2023-05-15,Rainforest village,31.2,220.1,tropical\n2023-06-01,Tundra Town,-10.2,3.0,Polar\n2023-06-15,Mountain Peak,13.5,20.0,Alpine\n2023-07-01,Rainforest village,32.0,210.0,tropical\n2023-07-15,DESERT CITY,33.4,0,no_nonsense\n", "eda_steps": ["Check and standardize date formats", "Identify and count missing values per column", "Normalize capitalization in the Location and Climate_Zone columns", "Generate descriptive statistics for Temperature_C and Precipitation_mm", "Create value counts for Climate_Zone", "Calculate mean Temperature_C and total Precipitation_mm by Climate_Zone", "Identify any unusual or unexpected Climate_Zone categories", "Examine correlation between Temperature_C and Precipitation_mm"], "eda_results": {"missing_values": {"Temperature_C": 1, "Precipitation_mm": 3, "Climate_Zone": 0, "Location": 0, "Date": 0}, "standardized_dates": ["2023-01-01", "2023-01-15", "2023-02-01", "2023-02-15", "2023-03-01", "2023-03-15", "2023-04-01", "2023-04-15", "2023-05-01", "2023-05-15", "2023-06-01", "2023-06-15", "2023-07-01", "2023-07-15"], "normalized_locations": ["Desert City", "Tundra Town", "Rainforest Village", "Desert City", "Tundra Town", "Rainforest Village", "Mountain Peak", "Mountain Peak", "Desert City", "Rainforest Village", "Tundra Town", "Mountain Peak", "Rainforest Village", "Desert City"], "normalized_climate_zones": ["Arid", "Polar", "Tropical", "Arid", "Polar", "Tropical", "Alpine", "Alpine", "Arid", "Tropical", "Polar", "Alpine", "Tropical", "No_nonsense"], "summary_stats": {"Temperature_C": {"count": 13, "mean": 18.19, "std_dev": 16.32, "min": -15.6, "max": 33.4}, "Precipitation_mm": {"count": 11, "mean": 65.54, "std_dev": 85.45, "min": 0.0, "max": 220.1}}, "value_counts_climate_zone": {"Arid": 3, "Polar": 3, "Tropical": 5, "Alpine": 3, "No_nonsense": 1}, "mean_temp_by_climate_zone": {"Arid": 29.17, "Polar": -13.47, "Tropical": 30.18, "Alpine": 12.33, "No_nonsense": 33.4}, "total_precip_by_climate_zone": {"Arid": 0.0, "Polar": 8.2, "Tropical": 1010.6, "Alpine": 35.0, "No_nonsense": 0}, "unusual_climate_zones": ["No_nonsense"], "correlations": {"Temperature_C_vs_Precipitation_mm": -0.62}}}
{"purpose": "Explore patient demographics and lab test results to identify patterns related to diabetes diagnosis.", "raw_table": "Patient_ID,Age,Gender,Diagnosis,HbA1c,Cholesterol,Visit_Date\n001,45,Male,Diabetes,7.2,200,2023-01-15\n002,53,female,Pre-Diabetes,6.1,185,15/02/2023\n003,38,M,,5.8,190,2023/03/05\n004,29,Female,diabetes,8.0,,2023-04-10\n005,50,Male,No Diabetes,4.9,210,04-15-2023\n006,,Female,No diabetes,5.2,195,2023-06-01\n007,41,Male,Pre-diabetes,n/a,205,2023-07-20\n008,33,FEMALE,Diabetes,7.5,NaN,2023-08-30\n009,60,male,No Diabetes,5.0,198,2023/09/15\n010,55,Female,Pre-Diabetes,6.3,182,2023-10-05", "eda_steps": ["Check and report missing values for each column", "Standardize the 'Gender' and 'Diagnosis' categorical values for consistency", "Convert 'Visit_Date' to a uniform date format", "Calculate summary statistics for numeric columns: Age, HbA1c, Cholesterol", "Generate value counts for the Diagnosis column", "Identify the number of unique patients", "Compute the mean HbA1c level grouped by Diagnosis", "Examine correlations between Age, HbA1c, and Cholesterol"], "eda_results": {"missing_values": {"Patient_ID": 0, "Age": 1, "Gender": 0, "Diagnosis": 1, "HbA1c": 1, "Cholesterol": 2, "Visit_Date": 0}, "standardized_values": {"Gender": {"Male": 4, "Female": 5}, "Diagnosis": {"Diabetes": 3, "Pre-Diabetes": 3, "No Diabetes": 3, "Missing": 1}}, "summary_stats": {"Age": {"count": 9, "mean": 45.1, "std": 9.7, "min": 29, "max": 60}, "HbA1c": {"count": 9, "mean": 6.44, "std": 1.05, "min": 4.9, "max": 8.0}, "Cholesterol": {"count": 8, "mean": 196.875, "std": 9.1, "min": 182, "max": 210}}, "value_counts": {"Diagnosis": {"Diabetes": 3, "Pre-Diabetes": 3, "No Diabetes": 3, "Missing": 1}}, "unique_patients": 10, "mean_hba1c_by_diagnosis": {"Diabetes": 7.566, "Pre-Diabetes": 6.133, "No Diabetes": 5.033, "Missing": null}, "correlations": {"Age_HbA1c": 0.45, "Age_Cholesterol": 0.12, "HbA1c_Cholesterol": 0.31}}}
{"purpose": "Examine crop yield variations and planting patterns across different farms and crop types.", "raw_table": "Farm_ID,Crop_Type,Planting_Date,Harvest_Date,Yield_kg,Soil_Type,Fertilizer_Used\nF001,Wheat,2023-03-15,2023-08-20,1500,Loamy,Yes\nF002,Corn,03/22/2023,08/28/23,1800,SandY,No\nf003,Rice,2023-04-05,,1200,Clay,Yes\nF004,wheat,2023-03-18,2023-08-19,,Loamy,yes\nF005,Corn,2023/03/25,2023-09-01,1900,Sandy,No\nF006,RICE,04-10-2023,08-30-2023,1300,Clay,yes\nF007,Barley,,2023-08-15,1100,Silty,No\nF008,barley,2023-03-20,2023-08-16,1150,Silty,No\nF009,Corn,March 28 2023,September 05 2023,1850,Sandy,No\nF010,Wheat,2023-03-17,2023-08-21,1550,loamy,YES\nF011,Corn,03-30-2023,09-03-2023,,Sandy,No\nF012,Rice,2023-04-08,2023-09-02,1250,clay,Yes", "eda_steps": ["Standardize crop type capitalization and list unique crop types", "Check for missing values in each column and report percentages", "Calculate descriptive statistics (mean, median, std) for Yield_kg", "Convert all date columns to a consistent date format and compute duration between Planting_Date and Harvest_Date", "Analyze value counts for Soil_Type after standardizing capitalization", "Determine proportion of farms using fertilizer", "Identify farms with missing Harvest_Date or Yield_kg", "Compute correlation between Yield_kg and duration from planting to harvest"], "eda_results": {"crop_types_standardized": ["Wheat", "Corn", "Rice", "Barley"], "missing_values_percent": {"Farm_ID": 0, "Crop_Type": 0, "Planting_Date": 8.33, "Harvest_Date": 8.33, "Yield_kg": 16.67, "Soil_Type": 0, "Fertilizer_Used": 0}, "yield_kg_stats": {"mean": 1450, "median": 1475, "std": 243.8, "count": 10}, "duration_days_stats": {"mean": 156, "median": 156, "std": 4.1, "count": 11}, "soil_type_counts": {"Loamy": 3, "Sandy": 5, "Clay": 3, "Silty": 2}, "fertilizer_usage": {"Yes": 5, "No": 7}, "farms_missing_data": {"Missing_Harvest_Date": ["F003"], "Missing_Yield_kg": ["F004", "F011"]}, "correlation_yield_duration": 0.89}}
{"purpose": "Analyze patient demographics and clinical measurements to identify data quality issues and distribution patterns.", "raw_table": "Patient_ID,Age,Gender,Diagnosis,Blood_Pressure,Heart_Rate,Admission_Date\nP001,45,M,Hypertension,130/85,78,2023-01-15\nP002,38,F,diabetes,120/80,82,01/20/2023\nP003,,female,Hypertension,,88,2023/02/05\nP004,29,Male,Asthma,110/70,75,15-02-2023\nP005,52,F,hypertension,140/90, ,2023-03-01\nP006,60,M,Diabetes,135/95,90,03/10/2023\nP007,47,F,,125/85,80,2023-03-15\nP008,33,Male,asthma,115/75,77,\nP009,55,Female,Hypertension,138/88,85,2023-04-01\nP010,40,m,Diabetes,130/80,83,2023-04-05\n", "eda_steps": ["Check for missing values in each column", "Standardize gender capitalization and categorize missing genders", "Parse and standardize Admission_Date to a consistent date format", "Extract systolic and diastolic values from Blood_Pressure and convert to numeric", "Compute descriptive statistics for Age, systolic and diastolic blood pressure, and Heart_Rate", "Generate value counts for Diagnosis after standardizing to lowercase", "Identify number of unique patients with missing Diagnosis or Blood_Pressure values", "Check correlation between Age and Heart_Rate"], "eda_results": {"missing_values": {"Patient_ID": 0, "Age": 1, "Gender": 0, "Diagnosis": 1, "Blood_Pressure": 1, "Heart_Rate": 1, "Admission_Date": 1}, "gender_counts": {"male": 5, "female": 3, "missing": 0}, "admission_date_standardized": {"min_date": "2023-01-15", "max_date": "2023-04-05", "invalid_dates": 0}, "blood_pressure_parsed": {"systolic": [130, 120, null, 110, 140, 135, 125, 115, 138, 130], "diastolic": [85, 80, null, 70, 90, 95, 85, 75, 88, 80]}, "descriptive_statistics": {"Age": {"count": 9, "mean": 44.9, "min": 29, "max": 60}, "Systolic_BP": {"count": 9, "mean": 127.3, "min": 110, "max": 140}, "Diastolic_BP": {"count": 9, "mean": 83.3, "min": 70, "max": 95}, "Heart_Rate": {"count": 9, "mean": 82.0, "min": 75, "max": 90}}, "diagnosis_counts": {"hypertension": 4, "diabetes": 3, "asthma": 2, "missing": 1}, "patients_missing_critical_info": {"missing_diagnosis": 1, "missing_blood_pressure": 1}, "correlations": {"Age_Heart_Rate": 0.6}}}
{"purpose": "Analyze machine downtime causes and durations to improve maintenance scheduling.", "raw_table": "MachineID,Date,Shift,Downtime_Minutes,Cause,Operator\nM01,2023-03-01,Morning,45,Electrical failure,John\nM02,03/02/2023,Afternoon,30,mechanical jam,Mary\nm03,2023-03-03,night,NA,Overheat,NA\nM01,2023/03/04,Morning,20,Electrical Failure,John\nM02,2023-3-5,Afternoon,15,Power outage,Chris\nM03,03-06-2023,Night,25,Mechanical Jam,mary\nM01,2023-03-07,Morning,,Electrical failure,john\nM02,2023/03/08,,40,Power Outage,Chris\nM03,2023-03-09,Night,35,,Mary\nm01,2023-03-10,Morning,50,Electrical Failure,John\nM02,2023-03-11,Afternoon,NA,Mechanical Jam,Mary\nM03,2023-03-12,Night,30,Overheat,NA\n", "eda_steps": ["Check and summarize missing values for each column", "Standardize date formats to YYYY-MM-DD", "Normalize categorical values for Cause and Operator columns", "Compute descriptive statistics for Downtime_Minutes ignoring missing values", "Generate value counts for Cause and Shift columns", "Identify rows with missing or inconsistent MachineID entries", "Calculate average downtime per MachineID", "Check correlation between Shift and Downtime_Minutes", "List top 2 frequent causes of downtime"], "eda_results": {"missing_values": {"MachineID": 0, "Date": 0, "Shift": 1, "Downtime_Minutes": 3, "Cause": 1, "Operator": 2}, "date_format_standardized": true, "normalized_cause_counts": {"electrical failure": 4, "mechanical jam": 3, "overheat": 2, "power outage": 2, "": 1}, "normalized_operator_counts": {"john": 4, "mary": 3, "chris": 2, "na": 3}, "downtime_stats": {"count": 9, "mean": 31.67, "std": 11.27, "min": 15, "25%": 25, "50%": 30, "75%": 40, "max": 50}, "shift_value_counts": {"morning": 5, "afternoon": 3, "night": 5}, "inconsistent_machine_ids": ["m01", "m03"], "average_downtime_per_machine": {"M01": 38.33, "M02": 28.33, "M03": 30}, "shift_downtime_correlation": 0.12, "top_2_downtime_causes": ["electrical failure", "mechanical jam"]}}
{"purpose": "Analyze customer purchase patterns and product popularity in an e-commerce store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod\n1001,CUST001,2023-01-15,Electronics,2,199.99,Credit Card\n1002,CUST002,15/01/2023,Books,1,15.5,Paypal\n1003,,2023/01/16,Fashion,3,,Credit Card\n1004,CUST004,2023-1-17,home & Garden,5,45.00,Cash\n1005,CUST005,2023-01-18,Electronics,1,199.99,credit card\n1006,CUST006,01-19-2023,Sports,2,85.5,Debit Card\n1007,CUST007,2023.01.20,Books,4,14.75,Paypal\n1008,CUST008,2023-01-21,Fashion,NaN,65.0,Credit Card\n1009,CUST009,2023-01-22,Home & garden,2,50.0,Cash\n1010,CUST010,2023-1-23,Electronics,1,199.99,CREDIT CARD\n1011,CUST011,2023-01-24,Toys,3,25.00,Paypal\n1012,CUST012,,Sports,1,85.5,Debit Card\n1013,CUST013,2023-01-26,Fashion,2,60.00,Credit card\n1014,CUST014,27-01-2023,Toys,,30.00,Cash", "eda_steps": ["Check for missing values in each column", "Standardize the date format in the OrderDate column", "Clean inconsistent capitalization in ProductCategory and PaymentMethod columns", "Compute descriptive statistics for Quantity and UnitPrice", "Generate value counts for ProductCategory and PaymentMethod", "Identify the top 3 most frequently ordered product categories", "Calculate total revenue per product category", "Analyze the distribution of payment methods used"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 1, "ProductCategory": 0, "Quantity": 2, "UnitPrice": 1, "PaymentMethod": 0}, "standardized_dates": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18", "2023-01-19", "2023-01-20", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24", null, "2023-01-26", "2023-01-27"], "cleaned_product_categories": {"Electronics": 3, "Books": 2, "Fashion": 3, "Home & Garden": 2, "Sports": 2, "Toys": 2}, "cleaned_payment_methods": {"Credit Card": 5, "Paypal": 3, "Cash": 3, "Debit Card": 2}, "summary_stats": {"Quantity": {"count": 12, "mean": 2.33, "std": 1.21, "min": 1, "max": 5}, "UnitPrice": {"count": 13, "mean": 86.04, "std": 73.64, "min": 14.75, "max": 199.99}}, "top_categories": ["Electronics", "Fashion", "Books"], "total_revenue_per_category": {"Electronics": 799.96, "Books": 81.5, "Fashion": 255.0, "Home & Garden": 275.0, "Sports": 256.5, "Toys": 165.0}, "payment_method_distribution": {"Credit Card": 35.7, "Paypal": 21.4, "Cash": 21.4, "Debit Card": 14.3, "Missing": 7.1}}}
{"purpose": "Analyze ridership patterns and vehicle issues in a city bus transit system.", "raw_table": "Bus_ID,Route,Date,Passengers,Delay_Minutes,Driver_Name,Vehicle_Type\nB001,Route 12,2023-04-01,45,5,John Doe,Diesel\nB002,route 5,04/01/2023,30,,Jane Smith,Electric\nB003,Rt 7,2023/04/02,NaN,10,mike brown,Diesel\nB004,Route 12,April 3 2023,50,2,susan lee,Hybrid\nb005,Route 5,2023-4-03,27,0,ANNA WHITE,Diesel\nB006,Route 7,2023-04-04,35,3,Bob O'Neil,Electric\nB007,route 12,04-05-2023,,7,Mary-Jane,Hybrid\nB008,Route 5,2023/04/05,28,,Tom Black,Diesel\nB009,Rt 7,2023-04-05,40,5,Chris Green,HYBRID\nB010,Route 12,2023.04.06,48,4,Sarah Connor,Diesel\nB011,Route 5,2023-04-06,32,1,james bond,Electric\nB012,Route 7,2023-04-06,38,,Linda Gray,Diesel", "eda_steps": ["Check for missing values in each column", "Standardize the Route column to consistent naming", "Convert Date column to datetime format", "Compute descriptive statistics for Passengers and Delay_Minutes columns", "Generate value counts for Vehicle_Type and Route columns", "Identify unique drivers and count their occurrences", "Calculate average delay by Vehicle_Type", "Determine correlation between Passengers and Delay_Minutes"], "eda_results": {"missing_values": {"Bus_ID": 0, "Route": 0, "Date": 0, "Passengers": 2, "Delay_Minutes": 3, "Driver_Name": 0, "Vehicle_Type": 0}, "standardized_routes": ["Route 12", "Route 5", "Route 7", "Route 12", "Route 5", "Route 7", "Route 12", "Route 5", "Route 7", "Route 12", "Route 5", "Route 7"], "date_range": {"min_date": "2023-04-01", "max_date": "2023-04-06"}, "summary_stats": {"Passengers": {"count": 10, "mean": 37.8, "std": 7.84, "min": 27, "25%": 31.5, "50%": 38, "75%": 45, "max": 50}, "Delay_Minutes": {"count": 9, "mean": 4.33, "std": 3.04, "min": 0, "25%": 2, "50%": 4, "75%": 5, "max": 10}}, "value_counts": {"Vehicle_Type": {"Diesel": 6, "Electric": 3, "Hybrid": 3}, "Route": {"Route 12": 4, "Route 5": 4, "Route 7": 4}}, "driver_counts": {"John Doe": 1, "Jane Smith": 1, "mike brown": 1, "susan lee": 1, "ANNA WHITE": 1, "Bob O'Neil": 1, "Mary-Jane": 1, "Tom Black": 1, "Chris Green": 1, "Sarah Connor": 1, "james bond": 1, "Linda Gray": 1}, "average_delay_by_vehicle": {"Diesel": 3.67, "Electric": 3.0, "Hybrid": 5.0}, "correlation_passengers_delay": 0.52}}
{"purpose": "Examine patient demographic and clinical characteristics in a small hospital dataset to identify data quality issues and distribution patterns.", "raw_table": "PatientID,Age,Gender,AdmissionDate,Diagnosis,BloodPressure,Cholesterol,Smoker\n001,45,Male,2023-01-15,Hypertension,130/85,200,Yes\n002,thirty,M,15-02-2023,diabetes,120/80,180,No\n003,52,Female,2023/03/10,Hypertension,,220,yes\n004,40,F,2023-04-05,,110/70,,No\n005,67,Male,2023.05.22,Diabetes,140/90,190,NO\n006,,female,2023-06-01,hypertension,135/88,210,Yes\n007,29,Male,2023-07-12,Flu,115/75,NaN,No\n008,55,Female,2023-08-30,Diabetes,145/95,230,No\n009,61,Male,2023-09-15,,138/92,205,yes\n010,48,Male,2023-10-01,Hypertension,130/85,NaN,YES\n011,NA,Female,2023-11-11,Flu,120/80,185,No", "eda_steps": ["Check the data types of each column and identify inconsistencies", "Calculate the percentage of missing values per column", "Summarize statistics for the Age column, ignoring non-numeric entries", "Count unique values and frequency for the Diagnosis column", "Standardize and count unique values in the Gender column", "Parse and standardize AdmissionDate to a consistent date format", "Extract systolic and diastolic values from BloodPressure and summarize them", "Check distribution of Smoker variable after normalizing text case", "Identify rows with outliers or unusual entries in numeric columns"], "eda_results": {"data_types": {"PatientID": "string", "Age": "mixed (numeric and string)", "Gender": "string (inconsistent capitalization)", "AdmissionDate": "string (multiple date formats)", "Diagnosis": "string (missing values, inconsistent capitalization)", "BloodPressure": "string (some missing, mixed formats)", "Cholesterol": "numeric with some missing values and 'NaN'", "Smoker": "string (inconsistent capitalization)"}, "missing_values_percentage": {"PatientID": 0, "Age": 18.18, "Gender": 0, "AdmissionDate": 0, "Diagnosis": 18.18, "BloodPressure": 9.09, "Cholesterol": 18.18, "Smoker": 0}, "age_summary": {"count": 9, "mean": 49.7, "min": 29, "max": 67, "invalid_entries": ["thirty", "NA", ""]}, "diagnosis_value_counts": {"Hypertension": 4, "Diabetes": 3, "Flu": 2, "missing": 2}, "gender_counts_standardized": {"Male": 5, "Female": 5}, "admission_date_standardized": {"min_date": "2023-01-15", "max_date": "2023-11-11", "formats_found": ["YYYY-MM-DD", "DD-MM-YYYY", "YYYY/MM/DD", "YYYY.MM.DD"]}, "blood_pressure_parsed_summary": {"systolic_mean": 129.4, "diastolic_mean": 84.7, "missing_count": 1, "format_issues": 0}, "smoker_distribution_normalized": {"Yes": 5, "No": 6}, "outliers_and_issues": {"age_invalid_entries": ["thirty", "NA", ""], "cholesterol_missing_or_nan": [7, 10], "blood_pressure_missing": [3], "diagnosis_missing": [4, 9]}}}
{"purpose": "Analyze customer purchase patterns and product category distribution in recent ecommerce transactions.", "raw_table": "order_id,customer_id,order_date,product_category,payment_method,order_value,delivery_status\n1001,C123,2023-04-10,Electronics,Credit Card,299.99,delivered\n1002,C124,04/12/2023,Clothing,Paypal,89.5,Delivered\n1003,C123,2023-4-15,home & kitchen,Credit card,45.00,DELIVERED\n1004,C125,2023/04/16,Electronics,,150.0,Shipped\n1005,C126,17-Apr-2023,Books,Credit card,NaN,delivered\n1006,c127,2023-04-18,Clothing,Paypal,120.0,Cancelled\n1007,C128,2023-04-19,beauty,Credit Card,35.5,Delivered\n1008,C129,2023-04-20,Books,Credit Card,20.0,\n1009,C130,2023-04-21,Electronics,Debit Card,499.99,Delivered\n1010,C131,2023-04-22,HOMe & kitchen,Paypal,70,Delivered", "eda_steps": ["Check missing value percentages for each column", "Standardize the capitalization of categorical columns: product_category and delivery_status", "Compute descriptive statistics for order_value", "Generate value counts for product_category", "Identify unique payment methods used", "Count number of orders per customer_id", "Summarize delivery_status distribution"], "eda_results": {"missing_values": {"order_id": 0, "customer_id": 0, "order_date": 0, "product_category": 0, "payment_method": 1, "order_value": 1, "delivery_status": 1}, "standardized_categories": {"product_category": ["Electronics", "Clothing", "Home & Kitchen", "Books", "Beauty"], "delivery_status": ["Delivered", "Shipped", "Cancelled", "Missing"]}, "summary_stats_order_value": {"count": 9, "mean": 143.55, "std": 153.17, "min": 20.0, "25%": 45.0, "50%": 89.5, "75%": 150.0, "max": 499.99}, "value_counts_product_category": {"Electronics": 3, "Clothing": 2, "Home & Kitchen": 2, "Books": 2, "Beauty": 1}, "unique_payment_methods": ["Credit Card", "Paypal", "Debit Card", "Missing"], "orders_per_customer": {"C123": 2, "C124": 1, "C125": 1, "C126": 1, "C127": 1, "C128": 1, "C129": 1, "C130": 1, "C131": 1}, "delivery_status_distribution": {"Delivered": 7, "Shipped": 1, "Cancelled": 1, "Missing": 1}}}
{"purpose": "Analyze streaming platform user engagement by content type and viewing duration.", "raw_table": "User_ID,Content_Type,Watch_Duration_Minutes,Subscription_Type,Watch_Date\n101,Movie,120,Premium,2023/01/15\n102,series,45,,15-02-2023\n103,Documentary,NaN,Basic,2023-03-01\n104,MOVIE,90,Premium,03/05/2023\n105,Series,NaN,Free,2023/04/20\n106,documentary,60,Basic,2023-4-25\n107,movie,,premium,2023/05/10\n108,Series,30,Free,2023/06/01\n109,GameShow,50,Basic,06-15-2023\n110,mOvIe,110,PREMIUM,2023/07/01\n111,series,25,free,2023-07-10\n112,Documentary,70,,2023/07/15\n113,Series,40,BASIC,2023/07/20", "eda_steps": ["Standardize capitalization in 'Content_Type' and 'Subscription_Type' columns", "Convert 'Watch_Date' to consistent date format", "Identify and count missing values in each column", "Compute descriptive statistics for 'Watch_Duration_Minutes'", "Generate value counts for 'Content_Type' and 'Subscription_Type'", "Calculate average watch duration grouped by 'Content_Type'", "Check for duplicate User_ID entries", "Summarize the distribution skewness of watch durations"], "eda_results": {"missing_values": {"User_ID": 0, "Content_Type": 0, "Watch_Duration_Minutes": 3, "Subscription_Type": 2, "Watch_Date": 0}, "value_counts": {"Content_Type": {"Movie": 4, "Series": 5, "Documentary": 3, "GameShow": 1}, "Subscription_Type": {"Premium": 4, "Basic": 4, "Free": 3, "": 1}}, "summary_stats": {"Watch_Duration_Minutes": {"count": 10, "mean": 65, "std": 31.39, "min": 25, "25%": 40, "50%": 60, "75%": 90, "max": 120}}, "average_watch_duration_by_content_type": {"Movie": 106.67, "Series": 35, "Documentary": 65, "GameShow": 50}, "duplicate_user_ids": 0, "watch_duration_skewness": 0.35}}
{"purpose": "Analyze housing market trends and property characteristics in a metropolitan area.", "raw_table": "PropertyID,SaleDate,Location,Price,Size_sqft,Bedrooms,Bathrooms,PropertyType\n1001,2023-01-15,Downtown,350000,850,2,1,Condo\n1002,15/02/2023,suburb,450000,1200,3,2,House\n1003,2023/03/10,DOWNTOWN,,900,2,,Condo\n1004,April 5 2023,Suburb,500000,1300,3,2,house\n1005,2023-05-01,Riverside,600000,1500,4,3,House\n1006,2023-5-15,riverside,NA,1400,4,3,Townhouse\n1007,2023.06.01,Downtown,400000,950,2,1,Condo\n1008,,suburb,475000,1250,3,2,House\n1009,2023-07-20,Riverside,625000,1600,4,3,Townhouse\n1010,2023-08-05,Downtown,390000,870,2,1,condo\n1011,2023-08-15,Suburb,480000,1300,3,2,House\n1012,07/09/2023,DOWNTOWN,405000,920,2,1,Condo", "eda_steps": ["Check for missing values in each column", "Standardize the Location and PropertyType columns capitalization", "Compute descriptive statistics for numeric columns Price and Size_sqft", "Calculate the frequency counts of PropertyType and Location", "Identify entries with inconsistent or missing date formats in SaleDate", "Calculate correlation between Price, Size_sqft, Bedrooms, and Bathrooms", "Find the number of unique PropertyID values and check for duplicates", "Summarize the count of properties by number of Bedrooms"], "eda_results": {"missing_values": {"PropertyID": 0, "SaleDate": 1, "Location": 0, "Price": 2, "Size_sqft": 0, "Bedrooms": 0, "Bathrooms": 1, "PropertyType": 0}, "standardized_categories": {"Location": ["Downtown", "Suburb", "Riverside"], "PropertyType": ["Condo", "House", "Townhouse"]}, "summary_stats": {"Price": {"count": 10, "mean": 477500, "std": 91603, "min": 350000, "25%": 400000, "50%": 475000, "75%": 600000, "max": 625000}, "Size_sqft": {"count": 12, "mean": 1215.8, "std": 260.1, "min": 850, "25%": 900, "50%": 1250, "75%": 1400, "max": 1600}}, "value_counts": {"PropertyType": {"Condo": 5, "House": 5, "Townhouse": 2}, "Location": {"Downtown": 5, "Suburb": 4, "Riverside": 3}}, "date_format_issues": {"Inconsistent_formats": ["15/02/2023", "2023/03/10", "April 5 2023", "2023-5-15", "2023.06.01", "07/09/2023"], "Missing_dates": 1}, "correlations": {"Price_Size_sqft": 0.92, "Price_Bedrooms": 0.89, "Price_Bathrooms": 0.85, "Size_sqft_Bedrooms": 0.88, "Size_sqft_Bathrooms": 0.82}, "unique_PropertyIDs": {"total": 12, "duplicates": 0}, "bedrooms_count": {"2": 5, "3": 4, "4": 3}}}
{"purpose": "Analyze public transportation usage patterns across different city districts to identify service gaps and peak travel times.", "raw_table": "District,Date,Bus_Ridership,Metro_Ridership,Weather,Event\nCentral,2023-01-01,1200,3400,Sunny,New Year Parade\nnorth,01/02/2023,850,2800,Rain, \nSouth,2023/01/03,900,,Cloudy,Local Market\nEast,2023-01-04,700,1500,Sunny,Sports Game\nCENTRAL,2023-1-05,1300,3600,Foggy,Road Construction\nWest,2023-01-06,,2100,rain, \nNorth,2023-01-07,870,2900,Cloudy,Community Meeting\nsouth,2023-01-08,920,3100,Sunny, \nEast,2023-01-09,680,1550,Sunny, \nwest,2023-01-10,750,,Cloudy,Festival\nCentral,13/01/2023,1250,3500,Foggy, \nEast,2023-01-14,720,1600,RAIN, \nSouth,2023-01-15,910,3000,sunny,Parade\nNorth,,860,2850,Cloudy, \nWEST,2023-01-17,740,2200,Foggy, \n", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize the 'District' column to uniform capitalization", "Convert 'Date' column to consistent datetime format, handling irregular formats", "Compute descriptive statistics for 'Bus_Ridership' and 'Metro_Ridership'", "Generate value counts for 'Weather' and 'Event' columns", "Identify the top 2 districts by average total ridership (Bus + Metro)", "Analyze the distribution of ridership under different weather conditions", "Summarize the number of events occurring per district", "Check for correlation between Bus_Ridership and Metro_Ridership"], "eda_results": {"missing_values": {"District": "6.7%", "Date": "6.7%", "Bus_Ridership": "13.3%", "Metro_Ridership": "20%", "Weather": "0%", "Event": "40%"}, "district_standardization": {"unique_districts_before": 8, "unique_districts_after": 4, "districts": ["Central", "North", "South", "East", "West"]}, "date_conversion": {"successful_conversions": 14, "failed_conversions": 1}, "summary_stats": {"Bus_Ridership": {"count": 13, "mean": 906.15, "std": 178.47, "min": 680, "max": 1300}, "Metro_Ridership": {"count": 12, "mean": 2787.5, "std": 690.5, "min": 1500, "max": 3600}}, "value_counts": {"Weather": {"Sunny": 5, "Cloudy": 4, "Foggy": 3, "Rain": 1, "rain": 1, "RAIN": 1}, "Event": {" ": 6, "New Year Parade": 1, "Local Market": 1, "Sports Game": 1, "Road Construction": 1, "Community Meeting": 1, "Festival": 1, "Parade": 1}}, "top_districts_by_avg_total_ridership": {"Central": 4400, "South": 2950}, "ridership_by_weather": {"Sunny": {"avg_bus_ridership": 898, "avg_metro_ridership": 2590}, "Cloudy": {"avg_bus_ridership": 810, "avg_metro_ridership": 2475}, "Foggy": {"avg_bus_ridership": 1030, "avg_metro_ridership": 3100}, "Rain": {"avg_bus_ridership": 850, "avg_metro_ridership": 2800}}, "events_per_district": {"Central": 2, "North": 1, "South": 2, "East": 1, "West": 1}, "correlation_bus_metro": 0.92}}
{"purpose": "Examine temperature and precipitation patterns across different climate zones over several months to identify data quality issues and basic trends.", "raw_table": "Date,Location,Climate_Zone,Temperature_C,Precipitation_mm\n2024/01/15,New York,temperate,3.4,12.0\n15-02-2024,new york,Temperate,1.8,8\n2024-03-20,Los Angeles,Arid,18.5,\n2024-04-10,los angeles,arid,19.2,0\n2024/05/05,Miami,Tropical,28.1,120.5\n2024/06/14,miami,Tropical,30.3,NaN\n06/15/2024,Denver,SubAlpine,12.0,5.5\n2024-07-20,Denver,subalpine,,0\n2024/08/25,Seattle,Temperate,20.1,15\n2024-09-30,seattle,temperate,18.7,NaN\n2024/10/13,Anchorage,Polar,-5.3,3.0\n2024-11-11,ANCHORAGE,polar,-10.1,0\n2024/12/01,Houston,Tropical,,\n", "eda_steps": ["Check and standardize date formats in the Date column", "Normalize capitalization in Location and Climate_Zone columns", "Identify and count missing values in Temperature_C and Precipitation_mm", "Compute descriptive statistics (mean, median, min, max) for Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone", "Analyze temperature distribution by Climate_Zone", "Calculate correlation between Temperature_C and Precipitation_mm where data is available", "Identify rows with inconsistent or unusual data entries"], "eda_results": {"date_format_issues": 3, "standardized_locations": ["New York", "Los Angeles", "Miami", "Denver", "Seattle", "Anchorage", "Houston"], "standardized_climate_zones": ["Temperate", "Arid", "Tropical", "Subalpine", "Polar"], "missing_values": {"Temperature_C": 3, "Precipitation_mm": 4}, "summary_stats": {"Temperature_C": {"mean": 14.7, "median": 15.3, "min": -10.1, "max": 30.3}, "Precipitation_mm": {"mean": 22.8, "median": 8.0, "min": 0, "max": 120.5}}, "value_counts_climate_zone": {"Temperate": 4, "Arid": 2, "Tropical": 3, "Subalpine": 2, "Polar": 2}, "temperature_by_climate_zone": {"Temperate": {"mean": 10.0, "min": 1.8, "max": 20.1}, "Arid": {"mean": 18.85, "min": 18.5, "max": 19.2}, "Tropical": {"mean": 29.2, "min": 28.1, "max": 30.3}, "Subalpine": {"mean": 12.0, "min": 12.0, "max": 12.0}, "Polar": {"mean": -7.7, "min": -10.1, "max": -5.3}}, "correlation_temperature_precipitation": 0.12, "inconsistent_rows_count": 2}}
{"purpose": "Analyze monthly stock trading activity and price patterns for selected companies.", "raw_table": "Date,StockSymbol,Open,Close,Volume,MarketCap\n2023-01-05,AAPL,135.6,137.2,89000000,2.2T\n01/15/2023,GOOGL,89.5,90.1,1500000,1.5T\n2023-02-10,msft,240.3,242.5,27000000,1.9T\n2023/02/18,AMZN,3200,,3000000,1.6T\n3-1-2023,TSLA,700,710,35000000,700B\n2023-03-15,aapl,140.2,142.0,95000000,2.25T\n2023-04-01,GOOGL,95.0,94.1,1400000,1.55T\nApril 10 2023,MSFT,250.8,252.3,28000000,1.95T\n2023-04-20,amzn,3250,3300,3200000,1.65T\n2023-05-05,TSLA,715,705,36000000,720b\n2023-05-15,AAPL,,145.3,90000000,2.3T\n2023-05-22,GOOGL,96.5,97.0,1550000,1.6T\n2023-06-01,MSFT,255.1,256.7,29000000,2.0T", "eda_steps": ["Standardize the StockSymbol column to uppercase", "Parse the Date column into a consistent date format", "Check for and report missing values in all columns", "Compute descriptive statistics for Open, Close, and Volume columns", "Calculate daily price change as Close minus Open and summarize it", "Generate value counts for StockSymbol", "Identify which month had the highest average trading volume", "Compute correlation between Open and Close prices"], "eda_results": {"missing_values": {"Open": 1, "Close": 1, "Volume": 0, "MarketCap": 0, "Date": 0, "StockSymbol": 0}, "value_counts": {"StockSymbol": {"AAPL": 3, "GOOGL": 3, "MSFT": 3, "AMZN": 2, "TSLA": 2}}, "summary_stats": {"Open": {"count": 14, "mean": 804.82, "std": 1185.9, "min": 89.5, "25%": 94.13, "50%": 240.3, "75%": 715, "max": 3250}, "Close": {"count": 14, "mean": 808.11, "std": 1190.15, "min": 90.1, "25%": 94.1, "50%": 242.5, "75%": 710, "max": 3300}, "Volume": {"count": 15, "mean": 31106666, "std": 35362273, "min": 1400000, "25%": 1550000, "50%": 28000000, "75%": 35000000, "max": 95000000}}, "price_change_summary": {"count": 14, "mean": 3.29, "std": 4.56, "min": -10, "max": 20, "median": 1.1}, "month_highest_avg_volume": "March 2023", "correlations": {"Open_Close": 0.998}}}
{"purpose": "Analyze crop yield patterns and field conditions for different farms to identify factors affecting productivity.", "raw_table": "FarmID, Crop, PlantingDate, HarvestDate, FieldSize(ha), SoilType, Yield(tons), Irrigation\nF001, wheat, 2023-03-15, 2023/08/20, 12.5, Loamy, 30.2, YES\nF002, Corn, 15-04-2023, 2023-09-25, thirteen, Sandy, 27.4, no\nF003, Barley, 2023.03.20, 2023-08-18, 10.0, Clay, 22.1, Yes\nf004, WHEAT, 2023/03/18, 20-08-2023, 11.7, loamy, 29.9, y\nF005, Corn, 2023/04/16, 2023/09/26, 13.0, sandY, 28.0, NO\nF006, Barley, 2023-03-19, , 9.5, Clay, , yes\nF007, Wheat, 2023-03-17, 2023-08-19, 12.0, LOAMY, 31.0, No\nF008, corn, 2023-04-14, 2023/09/24, 12.8, sandy, 26.5, n\nF009, Barley, 16/03/2023, 18/08/2023, 10.2, Clay, 21.9, Yes\nF010, wheat, 2023-03-16, 2023-08-21, 12.3, loamy, 30.5, yes", "eda_steps": ["Standardize column names and fix inconsistent capitalization in categorical columns", "Parse and unify date columns into consistent date format", "Convert numeric columns to appropriate types and fix invalid entries", "Check and compute percentage of missing values per column", "Generate descriptive statistics for numeric columns: FieldSize(ha), Yield(tons)", "Perform value counts for Crop, SoilType, and Irrigation columns", "Calculate correlation between FieldSize(ha) and Yield(tons)", "Identify top 2 crops by average yield", "Summarize yield distribution skewness"], "eda_results": {"missing_values": {"PlantingDate": "0%", "HarvestDate": "10%", "FieldSize(ha)": "10%", "SoilType": "0%", "Yield(tons)": "10%", "Irrigation": "0%"}, "value_counts": {"Crop": {"Wheat": 4, "Corn": 3, "Barley": 3}, "SoilType": {"Loamy": 4, "Sandy": 3, "Clay": 3}, "Irrigation": {"Yes": 6, "No": 4}}, "summary_stats": {"FieldSize(ha)": {"count": 9, "mean": 11.9, "std": 1.1, "min": 9.5, "25%": 10.2, "50%": 12.0, "75%": 12.8, "max": 13.0}, "Yield(tons)": {"count": 9, "mean": 27.2, "std": 3.6, "min": 21.9, "25%": 26.5, "50%": 29.9, "75%": 30.5, "max": 31.0}}, "correlations": {"FieldSize_vs_Yield": 0.85}, "top_categories": {"Top 2 Crops by Average Yield": {"Wheat": 30.4, "Corn": 27.3}}, "distribution_skewness": {"Yield(tons)": -0.35}}}
{"purpose": "Explore patient demographics and vital signs to identify data quality issues and distribution patterns in a clinical dataset.", "raw_table": "Patient_ID,Gender,Age,Blood_Pressure,Heart_Rate,Admission_Date,Diagnosis\nP001,Male,45,120/80,72,2023-01-15,Hypertension\nP002,Female,NaN,130/85,88,15/02/2023,diabetes\np003,male,29,110/70,Na,2023/03/05,Asthma\nP004,Female,38,125/82,76,2023-03-20,Hypertension\nP005,,53,140/90,85,2023-04-01,unknown\nP006,Female,44,135/Na,80,04-15-2023,Diabetes\nP007,Male,60,145/95,NaN,2023-04-18,HyPertension\nP008,female,33,118/78,74,2023-04-20,Asthma\nP009,M,47,NaN,78,2023-04-22,Diabetes\nP010,F,41,128/83,79,22 Apr 2023,hypertension", "eda_steps": ["Check and summarize missing values for each column", "Standardize the Gender column to consistent capitalization and categories", "Parse Admission_Date to a uniform date format", "Extract systolic and diastolic values from Blood_Pressure and identify missing or malformed entries", "Compute descriptive statistics (mean, median, standard deviation) for Age, Heart_Rate, systolic and diastolic blood pressure", "Generate value counts for Diagnosis to identify common conditions", "Visualize distribution skewness for Age and Heart_Rate", "Identify any inconsistent or unusual categories in Diagnosis", "Compute correlation between Age, Heart_Rate, and systolic blood pressure"], "eda_results": {"missing_values": {"Patient_ID": 0, "Gender": 1, "Age": 1, "Blood_Pressure": 1, "Heart_Rate": 2, "Admission_Date": 0, "Diagnosis": 0}, "standardized_gender_counts": {"Male": 4, "Female": 4, "Unknown": 1, "M": 1, "F": 1}, "date_parse_issues": 0, "blood_pressure_parsing": {"valid_entries": 9, "missing_or_malformed": 1, "average_systolic": 127.9, "average_diastolic": 82.1}, "age_stats": {"mean": 44.9, "median": 44, "std_dev": 9.6}, "heart_rate_stats": {"mean": 79.1, "median": 79, "std_dev": 5.2}, "diagnosis_value_counts": {"Hypertension": 4, "Diabetes": 3, "Asthma": 2, "unknown": 1}, "diagnosis_inconsistencies": ["HyPertension", "unknown", "diabetes", "Diabetes"], "distribution_skewness": {"Age": 0.15, "Heart_Rate": 0.05}, "correlations": {"Age_Heart_Rate": 0.35, "Age_Systolic_BP": 0.42, "Heart_Rate_Systolic_BP": 0.28}}}
{"purpose": "Examine the characteristics and missing data patterns in patient records for a cardiovascular study.", "raw_table": "Patient_ID,Age,Gender,Blood_Pressure,Cholesterol,Diagnosis,Admission_Date\nP001,54,M,120/80,200,Hypertension,2023-01-05\nP002,47,F,135/85,NA,high blood pressure,05/15/2023\nP003,,male,140/90,180,Hypertension,2023/03/10\nP004,62,F,130/85,210,Hypertensive,2023-04-01\np005,58,F,,195,HYPERTENSION,15-05-2023\nP006,49,M,125/82,205,Hypertension,2023-06-01\nP007,55,,118/78,,No diagnosis,2023-06-05\nP008,50,F,110/70,190,hypertension,2023-07-10\nP009,61,M,140/95,220,High Blood Pressure,07-15-2023\nP010,53,f,130/88,205,hypertension,\n", "eda_steps": ["Check data types and identify inconsistent capitalization in categorical columns", "Calculate the number of missing values per column", "Standardize the 'Gender' column to consistent values", "Parse and standardize 'Admission_Date' to yyyy-mm-dd format", "Generate descriptive statistics (mean, median, std) for numeric columns (Age, Cholesterol)", "Extract systolic and diastolic values from the 'Blood_Pressure' column and compute their means", "Create value counts for the 'Diagnosis' column and unify similar categories", "Identify the number of unique patients", "Assess date range of admissions"], "eda_results": {"missing_values": {"Patient_ID": 0, "Age": 1, "Gender": 1, "Blood_Pressure": 1, "Cholesterol": 2, "Diagnosis": 0, "Admission_Date": 1}, "standardized_gender_values": {"M": 4, "F": 5, "missing": 1}, "standardized_diagnosis_counts": {"Hypertension": 8, "No diagnosis": 1}, "age_stats": {"mean": 54.9, "median": 54, "std": 4.7, "count": 9}, "cholesterol_stats": {"mean": 201.3, "median": 202.5, "std": 13.3, "count": 8}, "blood_pressure_means": {"systolic": 127.8, "diastolic": 85.3, "count": 9}, "unique_patients_count": 10, "admission_date_range": {"min_date": "2023-01-05", "max_date": "2023-07-15", "missing_dates": 1}}}
{"purpose": "Analyze daily electricity consumption patterns across different regions and customer types to identify missing data and consumption trends.", "raw_table": "Date,Region,Customer_Type,Consumption_kWh,Peak_Demand_kW\n2024-01-01,NORTH,Residential,34.5,5.2\n01/02/2024,South,Commercial,58.3,12.1\n2024-01-03,East,industrial,110.7,20.0\n2024-01-04,West,residential,missing,4.8\n2024-01-05,North,Commercial,62.5,missing\n2024/01/06,south,Residential,45.2,6.3\n2024-01-07,EAST,Industrial,115.0,21.5\n2024-01-08,west,commercial,60.1,11.8\n2024-01-09,North,,48.6,7.0\n2024-1-10,South,Residential,47.0,6.0\n2024-01-11,East,Industrial,NA,19.8\n2024-01-12,West,Commercial,59.5,12.0\n2024-01-13,North,Residential,36.8,5.5\n2024-01-14,South,Commercial,61.2,11.9", "eda_steps": ["Check and standardize date formats", "Identify and count missing values in each column", "Normalize Region and Customer_Type capitalization", "Compute descriptive statistics for Consumption_kWh and Peak_Demand_kW", "Generate value counts for Region and Customer_Type", "Calculate correlation between Consumption_kWh and Peak_Demand_kW", "Identify rows with missing Consumption_kWh or Peak_Demand_kW values"], "eda_results": {"missing_values": {"Date": 0, "Region": 1, "Customer_Type": 1, "Consumption_kWh": 3, "Peak_Demand_kW": 2}, "value_counts": {"Region": {"North": 4, "South": 4, "East": 3, "West": 3, "": 1}, "Customer_Type": {"Residential": 5, "Commercial": 5, "Industrial": 3, "": 1}}, "summary_stats": {"Consumption_kWh": {"count": 11, "mean": 62.09, "std": 27.51, "min": 34.5, "25%": 45.2, "50%": 60.1, "75%": 110.7, "max": 115.0}, "Peak_Demand_kW": {"count": 12, "mean": 11.25, "std": 6.88, "min": 4.8, "25%": 5.5, "50%": 7.0, "75%": 12.0, "max": 21.5}}, "correlations": {"Consumption_kWh_vs_Peak_Demand_kW": 0.98}, "rows_with_missing_values": [3, 4, 8, 10], "standardized_regions": ["North", "South", "East", "West"], "standardized_customer_types": ["Residential", "Commercial", "Industrial"]}}
{"purpose": "Analyze user engagement patterns and content types on a social media platform to identify popular post categories and activity trends.", "raw_table": "PostID,UserID,PostType,PostDate,Likes,Comments,Shares\n1,u123,Image,2024/01/05,34,5,2\n2,U124,video,01-07-2024,56,,4\n3,u125,text,2024-1-08,12,1,0\n4,u126,Image,2024/01/09,,3,1\n5,U127,Poll,2024/13/01,8,0,0\n6,u128,Video,2024/01/10,45,7,2\n7,u129,text,,20,2,1\n8,U130,image,2024-01-11,30,,3\n9,u131,Link,2024/01/12,15,1,\n10,u132,Text,2024/01/13,9,0,0\n11,u133,Video,01/14/2024,48,5,3\n12,u134,IMAGE,2024-01-15,27,4,2\n13,u135,Poll,2024-01-16,7,0,0\n14,u136,video,2024-01-17,N/A,6,1", "eda_steps": ["Check the data types of each column and identify inconsistent types", "Calculate the percentage of missing values in each column", "Standardize the PostType column to lowercase for uniformity", "Parse and standardize the PostDate column to a consistent date format, identifying invalid dates", "Compute descriptive statistics (mean, median, min, max) for numeric columns Likes, Comments, and Shares", "Generate value counts for the PostType column to identify the most common post types", "Identify posts with missing or invalid PostDate values", "Analyze correlation between Likes, Comments, and Shares", "Identify the top 3 posts with highest Likes"], "eda_results": {"data_types": {"PostID": "integer", "UserID": "string", "PostType": "string (inconsistent capitalization)", "PostDate": "string (various formats and some missing/invalid)", "Likes": "mixed (integers and string 'N/A', missing values)", "Comments": "numeric with missing values", "Shares": "numeric with missing values"}, "missing_values_percent": {"PostID": 0, "UserID": 0, "PostType": 0, "PostDate": 7.14, "Likes": 14.29, "Comments": 21.43, "Shares": 21.43}, "posttype_value_counts": {"image": 4, "video": 4, "text": 3, "poll": 2, "link": 1}, "invalid_dates": [5, 7], "likes_stats": {"mean": 27.36, "median": 27, "min": 7, "max": 56, "count": 12}, "comments_stats": {"mean": 3.2, "median": 3, "min": 0, "max": 7, "count": 11}, "shares_stats": {"mean": 1.64, "median": 1.5, "min": 0, "max": 4, "count": 11}, "correlations": {"Likes_Comments": 0.83, "Likes_Shares": 0.75, "Comments_Shares": 0.68}, "top_3_posts_by_likes": [{"PostID": 2, "Likes": 56}, {"PostID": 11, "Likes": 48}, {"PostID": 6, "Likes": 45}]}}
{"purpose": "Analyze monthly transactions and customer activity for a retail bank to identify data quality issues and key patterns.", "raw_table": "TransactionID,CustomerID,TransactionDate,TransactionType,Amount,Currency,Branch\nT1001,C001,2023-01-15,deposit,1000,usd,New York\nT1002,C002,15/01/2023,Withdrawal,500,USD,los angeles\nT1003,C003,2023-01-16,Deposit, ,USD,Chicago\nT1004,C004,2023-01-17,transfer,250.75,UsD,New York\nT1005,C002,2023/01/18,Withdrawal,300,,los Angeles\nT1006,C001,01-19-2023,Deposit,1200,USD,BOSTON\nT1007,C005,2023-01-20,WITHDRAWAL,400,usd,boston\nT1008,,2023-01-21,deposit,700,USD,New York\nT1009,C003,2023-01-22,,350,USD,Chicago\nT1010,C006,2023-01-23,Deposit,-100,usd,Miami\nT1011,C007,2023-01-24,Deposit,900,USD,miami\nT1012,C008,2023-01-25,Transfer,500,USD,Chicago", "eda_steps": ["Check for missing values in each column", "Standardize TransactionType and Currency columns capitalization", "Parse TransactionDate into a consistent date format", "Compute descriptive statistics for the Amount column", "Generate value counts for TransactionType and Branch columns", "Identify transactions with negative or zero Amount values", "Compute total transaction amounts per CustomerID", "Analyze distribution skewness of transaction amounts"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 1, "TransactionDate": 0, "TransactionType": 1, "Amount": 1, "Currency": 1, "Branch": 0}, "standardized_categories": {"TransactionType": {"deposit": 5, "withdrawal": 3, "transfer": 2, "missing": 1}, "Currency": {"USD": 11, "missing": 1}}, "date_parsing": {"original_formats": ["2023-01-15", "15/01/2023", "2023/01/18", "01-19-2023"], "all_dates_parsed": true}, "amount_stats": {"count": 12, "mean": 575.48, "std": 420.07, "min": -100, "25%": 350, "50%": 500, "75%": 900, "max": 1200}, "value_counts": {"TransactionType": {"deposit": 5, "withdrawal": 3, "transfer": 2, "missing": 1}, "Branch": {"New York": 3, "Los Angeles": 2, "Chicago": 3, "Boston": 2, "Miami": 2}}, "negative_or_zero_amounts": {"count": 1, "transaction_ids": ["T1010"]}, "total_amount_per_customer": {"C001": 2200, "C002": 800, "C003": 350, "C004": 250.75, "C005": 400, "C006": -100, "C007": 900, "C008": 500, "missing": 700}, "amount_skewness": 0.45}}
{"purpose": "Analyze patient visit patterns and lab results to identify common missing data issues and distribution of diagnoses.", "raw_table": "Patient_ID,Visit_Date,Age,Gender,Diagnosis,Lab_Result,Follow_Up\nP001,2023-01-15,45,Male,Hypertension,140/90,Yes\nP002,15/02/2023,37,Female,Diabetes,7.8,Yes\nP003,2023/03/01,29,Male,hypertension,135/85,No\nP004,,54,Female,Asthma,,Yes\np005,2023-04-20,61,Male,COPD,88,No\nP006,2023-05-05,forty-eight,Female,Diabetes,8.5,\nP007,2023-06-10,33,,Asthma,NaN,No\nP008,2023-07-12,47,Female,Diabetes,7.2,Yes\np009,2023-08-10,52,Male,HypERtension,142/95,No\nP010,2023-09-01,39,Female,Unknown,7.9,Yes", "eda_steps": ["Check the data types of each column and identify inconsistencies", "Calculate the percentage of missing values per column", "Standardize the date formats in the Visit_Date column", "Convert Age to numeric and identify invalid entries", "Generate value counts for the Diagnosis column with case normalization", "Summarize Lab_Result types and handle mixed formats (blood pressure vs numeric values)", "Compute summary statistics for numeric Age and Lab_Result values after cleaning", "Identify the distribution of Gender and presence of missing entries", "Count the number of Follow_Up responses and missing data"], "eda_results": {"missing_values": {"Patient_ID": "0%", "Visit_Date": "10%", "Age": "10%", "Gender": "10%", "Diagnosis": "0%", "Lab_Result": "20%", "Follow_Up": "20%"}, "data_types": {"Patient_ID": "string", "Visit_Date": "string (mixed date formats)", "Age": "mixed (numeric and string)", "Gender": "string with missing", "Diagnosis": "string with inconsistent capitalization", "Lab_Result": "mixed (string, numeric, NaN)", "Follow_Up": "string with missing"}, "diagnosis_value_counts": {"hypertension": 3, "diabetes": 3, "asthma": 2, "copd": 1, "unknown": 1}, "age_conversion": {"invalid_entries": ["forty-eight"], "converted_numeric": [45, 37, 29, 54, 61, 48, 33, 47, 52, 39]}, "lab_result_summary": {"blood_pressure_entries": 3, "numeric_values": [7.8, 8.5, 7.2, 7.9, 88], "missing_or_nan": 2}, "age_statistics": {"mean": 44.3, "median": 45, "min": 29, "max": 61}, "gender_distribution": {"Male": 5, "Female": 4, "Missing": 1}, "follow_up_counts": {"Yes": 6, "No": 3, "Missing": 1}}}
{"purpose": "Evaluate crop yield patterns and soil conditions across different farms to inform agricultural planning.", "raw_table": "Farm_ID,Crop,Planting_Date,Soil_Type,Yield_tonnes_per_hectare,Rainfall_mm\nF001,Corn,2023-04-12,Clay,3.5,120\nF002,WHEAT,04/15/2023,Sandy,4.2,85\nF003,Rice,2023/04/20,Loam,,150\nF004,Barley,2023-04-18,clay,2.9,110\nf005,Corn,Apr 22 2023,Sandy,3.7,NaN\nF006,Soybean,2023-4-25,Loam,3.1,95\nF007,Corn,,Clay,3.6,130\nF008,rice,04-28-2023,Loam,3.9,140\nF009,Barley,2023.05.01,Sandy,,100\nf010,soybean,05/03/2023,Loam,3.0,90", "eda_steps": ["Check for missing values in each column", "Standardize Crop names to title case", "Convert Planting_Date to consistent date format", "Compute descriptive statistics for numeric columns Yield_tonnes_per_hectare and Rainfall_mm", "Generate value counts for Soil_Type and Crop", "Identify rows with missing Yield_tonnes_per_hectare and Planting_Date", "Calculate correlation between Yield_tonnes_per_hectare and Rainfall_mm", "Summarize average yield by Crop"], "eda_results": {"missing_values": {"Farm_ID": 0, "Crop": 0, "Planting_Date": 1, "Soil_Type": 0, "Yield_tonnes_per_hectare": 2, "Rainfall_mm": 1}, "standardized_crop_names": ["Corn", "Wheat", "Rice", "Barley", "Corn", "Soybean", "Corn", "Rice", "Barley", "Soybean"], "converted_planting_dates": ["2023-04-12", "2023-04-15", "2023-04-20", "2023-04-18", "2023-04-22", "2023-04-25", null, "2023-04-28", "2023-05-01", "2023-05-03"], "summary_stats": {"Yield_tonnes_per_hectare": {"count": 8, "mean": 3.49, "std": 0.42, "min": 2.9, "25%": 3.1, "50%": 3.55, "75%": 3.85, "max": 4.2}, "Rainfall_mm": {"count": 9, "mean": 111.67, "std": 22.95, "min": 85, "25%": 95, "50%": 110, "75%": 130, "max": 150}}, "value_counts": {"Soil_Type": {"Clay": 3, "Sandy": 3, "Loam": 4}, "Crop": {"Corn": 3, "Wheat": 1, "Rice": 2, "Barley": 2, "Soybean": 2}}, "rows_with_missing": {"Yield_tonnes_per_hectare": ["F003", "F009"], "Planting_Date": ["F007"]}, "correlations": {"Yield_tonnes_per_hectare vs Rainfall_mm": 0.68}, "average_yield_by_crop": {"Barley": 2.9, "Corn": 3.6, "Rice": 3.9, "Soybean": 3.05, "Wheat": 4.2}}}
{"purpose": "Analyze user engagement and content type distribution on a social media platform over a two-week period.", "raw_table": "Post_ID,User_ID,Post_Date,Content_Type,Likes,Comments,Shares\n001,u123,2023-04-01,Image,150,20,5\n002,U124,4/2/2023,video,200, ,10\n003,u125,2023/04/03,Text,50,5, \n004,u123,April 4, 2023,image,180,15,8\n005,u126,2023-04-05,Poll,,12,3\n006,U127,2023-4-06,Video,220,18,11\n007,u128,2023-04-07,text,75,,2\n008,U129,2023-04-08,IMAGE,130,10,4\n009,u130,2023-04-09,video, ,8,7\n010,u131,04-10-2023,link,90,4,1\n011,u132,2023/04/11,Text,60,6,0\n012,u133,2023-04-12,Poll,40, ,2\n013,u134,2023-04-13,link, ,3,1\n014,u135,April 14 2023,Video,210,20,9", "eda_steps": ["Check for and summarize missing values in each column", "Standardize 'Content_Type' to title case and identify unique categories", "Parse 'Post_Date' into a consistent date format", "Compute descriptive statistics (mean, median, min, max) for numeric engagement metrics (Likes, Comments, Shares)", "Calculate value counts for 'Content_Type'", "Identify posts with zero or missing engagement metrics", "Analyze distribution skewness for Likes", "Determine top 3 users by total likes received", "Summarize correlation between Likes, Comments, and Shares"], "eda_results": {"missing_values": {"Post_ID": 0, "User_ID": 0, "Post_Date": 0, "Content_Type": 0, "Likes": 4, "Comments": 3, "Shares": 2}, "content_type_unique": ["Image", "Video", "Text", "Poll", "Link"], "post_date_parsed": {"format": "YYYY-MM-DD", "earliest_date": "2023-04-01", "latest_date": "2023-04-14"}, "likes_stats": {"mean": 120.7, "median": 90, "min": 40, "max": 220, "missing_count": 4}, "comments_stats": {"mean": 9.4, "median": 8, "min": 3, "max": 20, "missing_count": 3}, "shares_stats": {"mean": 5.4, "median": 5, "min": 0, "max": 11, "missing_count": 2}, "content_type_counts": {"Image": 3, "Video": 4, "Text": 3, "Poll": 2, "Link": 2}, "posts_zero_or_missing_engagement": 5, "likes_skewness": 0.85, "top_users_by_likes": {"u127": 220, "u135": 210, "u124": 200}, "engagement_correlations": {"Likes_Comments": 0.76, "Likes_Shares": 0.68, "Comments_Shares": 0.59}}}
{"purpose": "Analyze monthly sales performance and customer demographics for a retail store.", "raw_table": "OrderID,Product,Category,Quantity,Price,OrderDate,CustomerAge,City\n1001,TV,Electronics,2,399.99,2023-01-15,34,New york\n1002,laptop,Electronics,1,899.99,15/01/2023,28,los Angeles\n1003,Chair,Furniture,4,49.99,2023/01/16,,Chicago\n1004,Desk,Furniture,1,149.99,01-17-2023,45,houston\n1005,Headphones,Electronics,,89.99,2023-01-18,23,New York\n1006,Washing Machine,Home Appliances,1,499.99,2023-01-19,37,DALLas\n1007,Microwave,Home Appliances,2,120.00,2023-1-20,42,Houston\n1008,tV,Electronics,1,399.99,2023-01-21,31,Los angeles\n1009,Sofa,Furniture,1,799.99,2023-01-22,54,,\n1010,Desk,Furniture,3,149.99,2023-01-23,29,Chicago\n1011,laptop,Electronics,2,899.99,2023/01/24,27,New York\n1012,Refrigerator,Home Appliances,1,1200,24-01-2023,40,Dallas\n1013,chair,Furniture,2,49.99,2023-01-25,33,Chicago\n1014,Headphones,Electronics,1,89.99,2023-01-26,22,los angeles\n", "eda_steps": ["Check and summarize missing values in each column", "Standardize and correct inconsistent capitalization in categorical columns", "Parse and unify the date format in the OrderDate column", "Compute descriptive statistics for Quantity, Price, and CustomerAge", "Generate value counts for the Category and City columns", "Identify top 3 selling products by total quantity", "Calculate the average price per category", "Examine correlation between Quantity, Price, and CustomerAge", "Summarize distribution skewness for numeric columns"], "eda_results": {"missing_values": {"OrderID": 0, "Product": 0, "Category": 0, "Quantity": 1, "Price": 0, "OrderDate": 0, "CustomerAge": 1, "City": 1}, "standardized_categories": {"Category": {"electronics": 6, "furniture": 5, "home appliances": 3}, "City": {"new york": 3, "los angeles": 3, "chicago": 3, "houston": 2, "dallas": 2, "": 1}}, "date_format_sample": "All dates converted to YYYY-MM-DD format, e.g. 2023-01-15", "summary_stats": {"Quantity": {"count": 14, "mean": 1.79, "std": 1.05, "min": 1, "25%": 1, "50%": 1.5, "75%": 2, "max": 4}, "Price": {"count": 15, "mean": 386.93, "std": 408.2, "min": 49.99, "25%": 89.99, "50%": 149.99, "75%": 399.99, "max": 1200}, "CustomerAge": {"count": 14, "mean": 33.43, "std": 9.85, "min": 22, "25%": 27, "50%": 33, "75%": 40, "max": 54}}, "value_counts": {"Category": {"Electronics": 6, "Furniture": 5, "Home Appliances": 3}, "City": {"New York": 3, "Los Angeles": 3, "Chicago": 3, "Houston": 2, "Dallas": 2, "": 1}}, "top_selling_products": {"Chair": 6, "Desk": 4, "Laptop": 3}, "average_price_per_category": {"Electronics": 478.99, "Furniture": 259.99, "Home Appliances": 606.66}, "correlations": {"Quantity_Price": -0.12, "Quantity_CustomerAge": 0.05, "Price_CustomerAge": 0.2}, "skewness": {"Quantity": 1.15, "Price": 1.68, "CustomerAge": 0.71}}}
{"purpose": "Identify customer churn patterns and usage behavior in a telecom dataset.", "raw_table": "CustomerID,SignupDate,LastCallDate,PlanType,MonthlyUsageMinutes,Churned,PaymentMethod\n001,2023-01-15,2023-04-20,Basic,350,No,Credit card\n002,15/02/2023,2023-04-18,Premium,NA,yes,bank Transfer\n003,2023/03/01,,STANDARD,500,No,Credit Card\n004,2023-01-28,2023-04-10,premium,450,NO,Cash\n005,2023-02-10,2023/04/22,Basic,abc,Yes,credit card\n006,2023-01-05,2023-04-15,Standard,400,no,Bank transfer\n007,2023-01-20,2023-04-19,,300,Yes,CASH\n008,2023-02-25,2023-04-20,Premium,600,No,Credit Card\n009,2023-01-30,2023-04-21,basic,200,No,Credit card\n010,03/03/2023,2023-04-17,Standard,450,No,bank transfer", "eda_steps": ["Standardize date formats for SignupDate and LastCallDate columns", "Handle missing values in MonthlyUsageMinutes and PlanType columns", "Normalize capitalization in PlanType, Churned, and PaymentMethod columns", "Compute descriptive statistics for MonthlyUsageMinutes", "Calculate value counts for PlanType and Churned columns", "Determine percentage of missing data per column", "Identify correlation between MonthlyUsageMinutes and Churned status", "Find top payment methods used by customers"], "eda_results": {"missing_values": {"CustomerID": 0, "SignupDate": 0, "LastCallDate": 1, "PlanType": 1, "MonthlyUsageMinutes": 2, "Churned": 0, "PaymentMethod": 0}, "standardized_dates": {"SignupDate": ["2023-01-15", "2023-02-15", "2023-03-01", "2023-01-28", "2023-02-10", "2023-01-05", "2023-01-20", "2023-02-25", "2023-01-30", "2023-03-03"], "LastCallDate": ["2023-04-20", "2023-04-18", "NaN", "2023-04-10", "2023-04-22", "2023-04-15", "2023-04-19", "2023-04-20", "2023-04-21", "2023-04-17"]}, "normalized_categories": {"PlanType": ["Basic", "Premium", "Standard", "Premium", "Basic", "Standard", "Unknown", "Premium", "Basic", "Standard"], "Churned": ["No", "Yes", "No", "No", "Yes", "No", "Yes", "No", "No", "No"], "PaymentMethod": ["Credit Card", "Bank Transfer", "Credit Card", "Cash", "Credit Card", "Bank Transfer", "Cash", "Credit Card", "Credit Card", "Bank Transfer"]}, "summary_stats": {"MonthlyUsageMinutes": {"count": 8, "mean": 413.75, "std": 113.91, "min": 200, "25%": 350, "50%": 425, "75%": 475, "max": 600}}, "value_counts": {"PlanType": {"Basic": 3, "Premium": 3, "Standard": 3, "Unknown": 1}, "Churned": {"No": 6, "Yes": 4}}, "correlations": {"MonthlyUsageMinutes_Churned": -0.45}, "top_payment_methods": {"Credit Card": 5, "Bank Transfer": 3, "Cash": 2}}}
{"purpose": "Analyze student performance and attendance patterns in a high school dataset.", "raw_table": "StudentID,Name,Grade,Math_Score,English_Score,Attendance,EnrollmentDate\n101,alice,10,88,92,95,2021/09/01\n102,Bob,EleVen,78,,89,09-03-2021\n103,CHARLIE,10,,85, ,2021-09-02\n104,David,11,92,90,98,2021/9/3\n105,emily,10,85,87,90,09/05/2021\n106,Fiona,11,91, ,93,2021/09/06\n107,George,10,abc,88,85,2021-09-07\n108,Hannah,11,89,91,NaN,09-08-2021\n109,Ian,10,84,83,88,20210909\n110,julia,10,90,88,87,2021/09/10\n111,kyle,11,78,80,92,2021-9-11\n112,Linda,11,85,89,,09/12/2021", "eda_steps": ["Check and count missing values in each column", "Standardize the Grade column to numeric values", "Convert EnrollmentDate to a uniform date format", "Compute summary statistics for Math_Score and English_Score", "Generate value counts for Attendance attendance percentages", "Identify rows with non-numeric scores in Math_Score", "Analyze correlation between Math_Score and English_Score", "Summarize distribution skewness for Attendance"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 0, "Grade": 1, "Math_Score": 2, "English_Score": 2, "Attendance": 3, "EnrollmentDate": 0}, "grade_standardization": {"EleVen": 11, "10": 10, "11": 11}, "enrollment_date_format": {"all_dates_parsed": true, "date_range": "2021-09-01 to 2021-09-12"}, "summary_stats": {"Math_Score": {"count": 10, "mean": 85.0, "std": 5.0, "min": 78, "max": 92}, "English_Score": {"count": 10, "mean": 87.3, "std": 3.2, "min": 80, "max": 92}}, "attendance_value_counts": {"95": 1, "89": 1, " ": 1, "98": 1, "90": 1, "93": 1, "85": 1, "NaN": 1, "88": 1, "87": 1, "92": 1, "": 1}, "non_numeric_math_scores": {"rows": [107], "values": ["abc"]}, "correlations": {"Math_Score_vs_English_Score": 0.72}, "attendance_skewness": 0.1}}
{"purpose": "Explore and summarize key characteristics of recent real estate listings to understand pricing and property features.", "raw_table": "ListingID,DateListed,Location,PropertyType,Bedrooms,Bathrooms,SizeSqFt,PriceUSD,Agent\n001,2023-01-15,DOWNTOWN,Condo,2,1.5,850,450000,John Smith\n002,15/02/2023,Suburb,Single Family,3,2,,550000,Jane doe\n003,2023-03-05,Downtown,condo,2,,900,460000,John smith\n004,2023/04/10,suburb,Townhouse,3,2,1200,580000,Mary Johnson\n005,2023-04-12,Industrial area,Single family,4,3,1500,670000,Unknown\n006,2023-04-15,Suburb,Single Family,3,2,1350,600000,Jane Doe\n007,16-04-2023,Downtown,Condo,1,1,700,380000,John Smith\n008,2023-05-01,Industrial Area,Single Family,4,3,1550,,Mary Johnson\n009,2023-05-03,Suburb,Townhouse,3,,1250,590000,\n010,2023-05-05,downtown,Condo,2,2,875,465000,John Smith\n011,2023-05-07,Suburb,Single family,3,2,1300,605000,Jane Doe\n", "eda_steps": ["Check missing values for each column", "Standardize the capitalization of categorical columns Location, PropertyType, and Agent", "Parse and unify the DateListed column into YYYY-MM-DD format", "Compute descriptive statistics (mean, median, min, max) for numeric columns: Bedrooms, Bathrooms, SizeSqFt, PriceUSD", "Generate value counts for categorical columns Location and PropertyType", "Identify listings with missing SizeSqFt or PriceUSD", "Calculate correlation matrix for numeric columns Bedrooms, Bathrooms, SizeSqFt, and PriceUSD", "Find the top 2 agents with the most listings", "Summarize distributions and check for outliers in PriceUSD"], "eda_results": {"missing_values": {"ListingID": 0, "DateListed": 0, "Location": 0, "PropertyType": 0, "Bedrooms": 0, "Bathrooms": 2, "SizeSqFt": 2, "PriceUSD": 2, "Agent": 1}, "standardized_categories": {"Location": {"Downtown": 5, "Suburb": 5, "Industrial Area": 2}, "PropertyType": {"Condo": 4, "Single Family": 6, "Townhouse": 2}, "Agent": {"John Smith": 4, "Jane Doe": 3, "Mary Johnson": 2, "Unknown": 1, "": 1}}, "date_unification": {"earliest_date": "2023-01-15", "latest_date": "2023-05-07"}, "descriptive_statistics": {"Bedrooms": {"mean": 2.91, "median": 3, "min": 1, "max": 4}, "Bathrooms": {"mean": 1.89, "median": 2, "min": 1, "max": 3}, "SizeSqFt": {"mean": 1076.25, "median": 900, "min": 700, "max": 1550}, "PriceUSD": {"mean": 533750, "median": 580000, "min": 380000, "max": 670000}}, "value_counts": {"Location": {"Downtown": 5, "Suburb": 5, "Industrial Area": 2}, "PropertyType": {"Single Family": 6, "Condo": 4, "Townhouse": 2}}, "missing_critical": {"Listings_missing_SizeSqFt": ["002", "008"], "Listings_missing_PriceUSD": ["008", "002"]}, "correlations": {"Bedrooms-Bathrooms": 0.82, "Bedrooms-SizeSqFt": 0.75, "Bedrooms-PriceUSD": 0.68, "Bathrooms-SizeSqFt": 0.7, "Bathrooms-PriceUSD": 0.65, "SizeSqFt-PriceUSD": 0.87}, "top_agents": {"John Smith": 4, "Jane Doe": 3}, "price_distribution": {"skewness": 0.41, "outliers": ["007"]}}}
{"purpose": "Analyze user engagement patterns and content types on a social media platform to identify trends and data quality issues.", "raw_table": "post_id,user_id,post_date,content_type,likes,comments,shares\n101,U001,2023-01-15,Image,150,20,5\n102,u002,01/20/2023,video,200,,10\n103,U003,2023/01/25,Text,NaN,5,0\n104,U004,,Image,180,25,7\n105,u005,2023-02-01,Video,220,18,12\n106,U006,2023-02-03,text,100,15,\n107,U007,02-05-2023,IMAGE,NaN,10,3\n108,u008,2023-02-10,Poll,50,2,1\n109,U009,2023-02-12,video,300,30,20\n110,U010,2023-02-15,Text,,8,0\n111,U011,2023-02-17,Live,400,50,25\n112,u012,2023-02-20,live,380,45,22", "eda_steps": ["Check and summarize missing values in each column", "Standardize the content_type column to lowercase", "Convert post_date to a uniform date format", "Compute descriptive statistics for likes, comments, and shares columns", "Generate value counts for content_type", "Identify posts with missing likes or shares", "Calculate the average likes, comments, and shares per content type", "Check for duplicate post_id entries", "Analyze the distribution skewness for numeric engagement columns"], "eda_results": {"missing_values": {"post_id": 0, "user_id": 0, "post_date": 1, "content_type": 0, "likes": 3, "comments": 0, "shares": 2}, "content_type_value_counts": {"image": 3, "video": 3, "text": 3, "poll": 1, "live": 2}, "post_date_format_issues": 3, "likes_stats": {"count": 9, "mean": 216.67, "std": 103.41, "min": 50, "25%": 150, "50%": 200, "75%": 300, "max": 400}, "comments_stats": {"count": 12, "mean": 20.33, "std": 14.08, "min": 2, "25%": 8, "50%": 15, "75%": 25, "max": 50}, "shares_stats": {"count": 10, "mean": 10.5, "std": 8.39, "min": 0, "25%": 3, "50%": 7, "75%": 12, "max": 25}, "posts_missing_likes_or_shares": [102, 103, 107, 110, 106], "average_engagement_per_content_type": {"image": {"likes": 165, "comments": 18.3, "shares": 5}, "video": {"likes": 240, "comments": 24, "shares": 14}, "text": {"likes": 100, "comments": 9.3, "shares": 1}, "poll": {"likes": 50, "comments": 2, "shares": 1}, "live": {"likes": 390, "comments": 47.5, "shares": 23.5}}, "duplicate_post_id_count": 0, "engagement_skewness": {"likes": 0.8, "comments": 0.9, "shares": 1.1}}}
{"purpose": "Examine student performance and attendance patterns in a high school to identify potential factors affecting grades.", "raw_table": "StudentID,Name,Grade,Subject,Score,Attendance,Date\n101,alice,10,Math,88,Present,2023-02-01\n102,Bob,10,english,92,Absent,2/1/2023\n103,CHARLIE,11,Math,85,Present,2023/02/01\n104,David,11,Science,,Present,2023-02-01\n105,Eva,10,Math,79,Absent,\n106,Frank,10,English,91,present,2023-02-01\n107,Gina,11,Science,95,Present,01-02-2023\n108,harry,10,science,83,Absent,2023-2-1\n109,Ivy,11,English,87,Present,2023-02-01\n110,jack,10,Math,NaN,Present,2023-02-01\n111,Kate,11,English,90,Absent,2023-02-01\n112,Luke,10,Science,88,Present,2023/02/01\n113,Mia,11,Math,94,Absent,2023-02-01\n114,Nick,10,English,85,Present,2023-02-01", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in categorical columns like Name and Subject", "Convert Date column to a uniform date format", "Compute descriptive statistics for the Score column", "Generate value counts for the Subject and Attendance columns", "Identify students with missing Scores", "Calculate average Score by Grade and Subject", "Examine correlation between Attendance status and Scores"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 0, "Grade": 0, "Subject": 0, "Score": 3, "Attendance": 0, "Date": 1}, "standardized_subjects": {"Math": 5, "English": 5, "Science": 4}, "date_format_uniform": true, "summary_stats": {"Score": {"count": 11, "mean": 87.27, "std": 4.91, "min": 79, "25%": 85, "50%": 88, "75%": 91, "max": 95}}, "value_counts": {"Attendance": {"Present": 8, "Absent": 6}}, "missing_scores_students": ["104", "110", "105"], "average_score_by_grade_subject": {"10": {"Math": 83.5, "English": 88.67, "Science": 85.5}, "11": {"Math": 91.5, "English": 88, "Science": 95}}, "attendance_score_correlation": -0.48}}
{"purpose": "Analyze user engagement patterns and content types on a social media platform.", "raw_table": "post_id,user_id,post_date,content_type,likes,comments,shares\n101,uA12,2024-03-01,Image,150,20,5\n102,ub33,03/02/2024,text,85,,2\n103,UA12,2024-3-03,Video,200,30,10\n104,uC45,2024/03/04,Text,NaN,15,3\n105,UD56,2024-03-05,image,130,22,NaN\n106,uB33,March 6 2024,video,175,25,8\n107,uA12,2024-03-07,IMage,NaN,18,4\n108,uE77,2024-03-08,text,90,10,1\n109,uC45,,Video,160,20,6\n110,uF88,2024-03-10,Poll,50,5,0\n111,uB33,2024-03-11,video,180,28,9\n112,uG99,2024/03/12,text,NaN,NaN,NaN\n113,uH00,2024-3-13,IMage,120,16,3", "eda_steps": ["Check for missing values in each column", "Standardize content_type values to lowercase", "Convert post_date to a consistent date format", "Compute descriptive statistics for likes, comments, and shares", "Generate value counts for content_type", "Identify top 3 users by total likes", "Analyze correlation between likes, comments, and shares", "Summarize the number of posts per day"], "eda_results": {"missing_values": {"post_id": 0, "user_id": 0, "post_date": 1, "content_type": 0, "likes": 4, "comments": 2, "shares": 2}, "content_type_value_counts": {"image": 4, "text": 4, "video": 4, "poll": 1}, "post_date_standardized": {"earliest_date": "2024-03-01", "latest_date": "2024-03-13", "missing_dates_count": 1}, "summary_stats": {"likes": {"count": 11, "mean": 134.55, "median": 130, "min": 50, "max": 200, "std": 48.46}, "comments": {"count": 13, "mean": 17.46, "median": 18, "min": 5, "max": 30, "std": 7.54}, "shares": {"count": 11, "mean": 5.91, "median": 5, "min": 0, "max": 10, "std": 3.32}}, "top_users_by_likes": {"UA12": 350, "UB33": 440, "UC45": 160}, "correlations": {"likes_comments": 0.94, "likes_shares": 0.88, "comments_shares": 0.85}, "posts_per_day": {"2024-03-01": 1, "2024-03-02": 1, "2024-03-03": 1, "2024-03-04": 1, "2024-03-05": 1, "2024-03-06": 1, "2024-03-07": 1, "2024-03-08": 1, "2024-03-10": 1, "2024-03-11": 1, "2024-03-12": 1, "2024-03-13": 1}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones to identify missing data and trends.", "raw_table": "Date,Climate_Zone,Avg_Temperature_C,Precipitation_mm\n01/15/2024,TROPICAL,30.5,120\n2024-02-15,Temperate,18.2,85.4\nMarch 15 2024,arid,,5.2\n04/15/2024,TROPICAL,31.1,NA\n2024-05-15,temperate,20.3,90.1\n06/15/24,ARID,28.4,2.1\nJuly 15, 2024,Tropical,29.9,110.3\n2024/08/15,Temperate,21.0,\n09-15-2024,Arid,27.8,4.7\n10/15/2024,tropical,30.2,115.0\nNov 15 2024,TEMPERATE,19.5,88.9\n12/15/2024,Tropical,31.0,130\n", "eda_steps": ["Check and standardize date formats", "Identify and count missing values in all columns", "Standardize capitalization in Climate_Zone column", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone", "Summarize missing value percentages per column", "Compute correlation between Avg_Temperature_C and Precipitation_mm", "Identify months with highest average temperature"], "eda_results": {"missing_values": {"Date": 0, "Climate_Zone": 0, "Avg_Temperature_C": 1, "Precipitation_mm": 2}, "value_counts": {"Climate_Zone": {"Tropical": 5, "Temperate": 4, "Arid": 3}}, "summary_stats": {"Avg_Temperature_C": {"count": 12, "mean": 27.58, "std": 5.02, "min": 18.2, "25%": 20.15, "50%": 29.95, "75%": 30.85, "max": 31.1}, "Precipitation_mm": {"count": 11, "mean": 73.9, "std": 50.2, "min": 2.1, "25%": 4.7, "50%": 88.9, "75%": 115, "max": 130}}, "missing_percentages": {"Avg_Temperature_C": 8.3, "Precipitation_mm": 16.7}, "correlations": {"Avg_Temperature_C_vs_Precipitation_mm": -0.38}, "highest_avg_temperature_months": ["April 2024", "December 2024"]}}
{"purpose": "Analyze monthly temperature and precipitation trends in various climate zones to identify patterns and data quality issues.", "raw_table": "StationID,Date,Temperature_C,Precipitation_mm,ClimateZone\n101,2023-01-15,5.2,12.3,Temperate\n102,15/02/2023,7.8,8.9,TROPICAL\n103,2023/03/15,NaN,15.4,polar\n104,2023-04-15,12.1,,temperate\n105,2023-05-15,18.3,23.1,Subtropical\n106,2023-06-15,25.7,NaN,Tropical\n107,2023-07-15,29.4,5.0,subtropical\n108,2023-08-15,30.1,0.0,Unknown\n109,2023-09-15,22.3,7.7,Polar\n110,2023-10-15,15.8,11.0,temperate\n111,2023-11-15,,9.9,TROPICAL\n112,2023-12-15,3.4,NaN,Temperate", "eda_steps": ["Check for missing values in each column", "Standardize date format to YYYY-MM-DD", "Compute descriptive statistics (mean, median, std) for Temperature_C and Precipitation_mm", "Generate value counts for ClimateZone", "Identify inconsistent capitalization in ClimateZone and unify", "Calculate correlation between Temperature_C and Precipitation_mm", "Identify rows with missing Temperature_C or Precipitation_mm", "Summarize range of dates covered", "Detect unusual categories in ClimateZone"], "eda_results": {"missing_values": {"StationID": 0, "Date": 0, "Temperature_C": 2, "Precipitation_mm": 3, "ClimateZone": 0}, "standardized_dates": ["2023-01-15", "2023-02-15", "2023-03-15", "2023-04-15", "2023-05-15", "2023-06-15", "2023-07-15", "2023-08-15", "2023-09-15", "2023-10-15", "2023-11-15", "2023-12-15"], "summary_stats": {"Temperature_C": {"mean": 17.04, "median": 17.05, "std": 8.63, "min": 3.4, "max": 30.1, "count": 10}, "Precipitation_mm": {"mean": 10.99, "median": 9.95, "std": 6.22, "min": 0.0, "max": 23.1, "count": 9}}, "value_counts_ClimateZone": {"temperate": 4, "tropical": 4, "polar": 2, "subtropical": 2, "unknown": 1}, "inconsistent_capitalization_fixed": ["TROPICAL -> tropical", "polar -> polar", "temperate -> temperate", "Subtropical -> subtropical", "Unknown -> unknown"], "correlations": {"Temperature_C_vs_Precipitation_mm": -0.28}, "rows_with_missing_values": {"Temperature_C": [103, 111], "Precipitation_mm": [104, 106, 112]}, "date_range": {"start": "2023-01-15", "end": "2023-12-15"}, "unusual_categories": ["unknown"]}}
{"purpose": "Evaluate crop yield patterns and examine factors affecting yields in different farms.", "raw_table": "FarmID,Crop,PlantingDate,HarvestDate,SoilType,Rainfall_mm,Yield_tonnes\nF001,Wheat,2023-03-15,2023/08/20,Loam,250,3.5\nF002,Corn,03/20/2023,2023-09-15,Clay,,4.1\nf003,soybean,2023-04-05,2023-09-30,SAND,180,2.9\nF004,Wheat,,2023-08-18,loam,230,3.7\nF005,Corn,2023-03-22,2023-09-12,Clay,210,four\nF006,Barley,2023-03-30,2023-08-25,Silt,195,3.0\nF007,soybean,2023-04-10,2023-10-01,Sand,175,2.8\nF008,Corn,2023-03-25,2023-09-20,Clay,220,4.3\nF009,Barley,2023-03-28,2023-08-27,Silt,190,3.1\nF010,Wheat,15-03-2023,2023-08-22,loam,240,3.6", "eda_steps": ["Check for missing values in each column", "Standardize and correct inconsistent date formats for PlantingDate and HarvestDate", "Fix inconsistent capitalization in Crop and SoilType columns", "Convert Yield_tonnes column to numeric, handling non-numeric entries", "Compute descriptive statistics for numeric columns: Rainfall_mm and Yield_tonnes", "Generate value counts for Crop and SoilType columns", "Calculate the growing period in days for each farm", "Compute correlation between Rainfall_mm, growing period, and Yield_tonnes", "Identify top-2 crops by average yield"], "eda_results": {"missing_values": {"FarmID": 0, "Crop": 0, "PlantingDate": 1, "HarvestDate": 0, "SoilType": 0, "Rainfall_mm": 1, "Yield_tonnes": 1}, "corrected_dates_sample": {"PlantingDate": ["2023-03-15", "2023-03-20", "2023-04-05", null, "2023-03-22", "2023-03-30", "2023-04-10", "2023-03-25", "2023-03-28", "2023-03-15"], "HarvestDate": ["2023-08-20", "2023-09-15", "2023-09-30", "2023-08-18", "2023-09-12", "2023-08-25", "2023-10-01", "2023-09-20", "2023-08-27", "2023-08-22"]}, "cleaned_categorical_value_counts": {"Crop": {"Wheat": 3, "Corn": 3, "Soybean": 2, "Barley": 2}, "SoilType": {"Loam": 3, "Clay": 3, "Sand": 2, "Silt": 2}}, "yield_tonnes_numeric": {"non_numeric_entries": ["four"], "converted_values": [3.5, 4.1, 2.9, 3.7, null, 3.0, 2.8, 4.3, 3.1, 3.6]}, "descriptive_statistics": {"Rainfall_mm": {"count": 9, "mean": 210.0, "std": 26.74, "min": 175, "25%": 190, "50%": 210, "75%": 230, "max": 250}, "Yield_tonnes": {"count": 9, "mean": 3.32, "std": 0.56, "min": 2.8, "25%": 3.0, "50%": 3.5, "75%": 3.7, "max": 4.3}}, "growing_period_days": {"F001": 158, "F002": 179, "F003": 178, "F004": null, "F005": 174, "F006": 148, "F007": 174, "F008": 179, "F009": 152, "F010": 160}, "correlations": {"Rainfall_mm_vs_Yield_tonnes": 0.79, "Growing_period_vs_Yield_tonnes": 0.45, "Rainfall_mm_vs_Growing_period": 0.1}, "top_crops_by_avg_yield": {"Corn": 4.13, "Wheat": 3.6}}}
{"purpose": "Analyze customer order patterns and product category distribution in an ecommerce dataset.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,Price,PaymentMethod,DeliveryStatus\n1001,C001,2024-01-15,electronics,2,299.99,Credit Card,Delivered\n1002,C002,01/18/2024,Apparel,1,49.99,credit card,Delivered\n1003,c003,2024/01/20,home & kitchen,,89.50,PayPal,Pending\n1004,C002,2024-01-25,Electronics,1,199.99,Credit card,Delivered\n1005,C004,2024-1-26,apparel,3,,Debit Card,Cancelled\n1006,C005,2024-01-27,Books,2,15.00,Cash,Delivered\n1007,c006,27-01-2024,Toys,1,25.00,PayPal,Delivered\n1008,C007,2024-01-28,Home & Kitchen,2,79.99,credit card,Delivered\n1009,C001,2024/01/29,Electronics,1,299.99,Credit Card,Pending\n1010,C008,2024-01-30,Fashion,1,59.99,Debit Card,Delivered\n1011,C009,,Electronics,2,199.99,Credit Card,Delivered\n1012,C010,2024-01-31,Toys,1,,Paypal,Delivered", "eda_steps": ["Check and summarize missing values in each column", "Standardize the date format in the OrderDate column", "Normalize capitalization in ProductCategory and PaymentMethod columns", "Calculate descriptive statistics for Quantity and Price columns", "Generate value counts for ProductCategory and DeliveryStatus columns", "Identify orders with missing Quantity or Price and count them", "Examine correlation between Quantity and Price", "List top 3 most frequent PaymentMethods", "Summarize orders by DeliveryStatus"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 0, "OrderDate": 1, "ProductCategory": 0, "Quantity": 2, "Price": 3, "PaymentMethod": 0, "DeliveryStatus": 0}, "standardized_dates": ["2024-01-15", "2024-01-18", "2024-01-20", "2024-01-25", "2024-01-26", "2024-01-27", "2024-01-27", "2024-01-28", "2024-01-29", "2024-01-30", null, "2024-01-31"], "normalized_product_categories": {"electronics": 4, "apparel": 2, "home & kitchen": 2, "books": 1, "toys": 2, "fashion": 1}, "normalized_payment_methods": {"credit card": 5, "paypal": 3, "debit card": 2, "cash": 1}, "quantity_stats": {"count": 13, "mean": 1.54, "min": 1, "max": 3, "missing": 2}, "price_stats": {"count": 10, "mean": 123.85, "min": 15.0, "max": 299.99, "missing": 3}, "orders_with_missing_quantity_or_price": 4, "correlation_quantity_price": 0.24, "top_payment_methods": ["credit card", "paypal", "debit card"], "delivery_status_counts": {"Delivered": 9, "Pending": 2, "Cancelled": 1}}}
{"purpose": "Analyze customer churn patterns and service usage in a telecom dataset.", "raw_table": "CustomerID,SignupDate,PlanType,MonthlyCharges,TotalCharges,Churn,InternetService\n001,2022-01-15,Basic,29.85,29.85,No,Fiber optic\n002,15/02/2022,Premium,56.95,1889.5,Yes,DSL\n003,03-10-2022,basic,53.85,,No,none\n004,2022/04/01,Standard,42.30,1840.75,No,DSL\n005,2022-05-12,PREMIUM,70.70,3530.6,Yes,Fiber Optic\n006,,Standard,49.95,125.5,No,DSL\n007,2022-07-19,Basic,NaN,NaN,No,\n008,2022-08-22,Premium,89.10,820.5,Yes,Fiber optic\n009,2022-09-10,standard,44.20,1300.0,No,DSL\n010,10/10/2022,basic,29.85,300.0,Yes,None\n011,2022-11-05,BASIC,29.85,100.0,no,Fiber optic\n012,2022-12-01,Standard,49.90,1500.0,No,dsl\n013,2023-01-15,premium,75.25,2100.0,Yes,Fiber Optic", "eda_steps": ["Check for missing values in each column", "Standardize date formats in SignupDate column", "Correct inconsistent capitalization in PlanType and InternetService columns", "Compute descriptive statistics for MonthlyCharges and TotalCharges", "Generate value counts for PlanType, InternetService, and Churn columns", "Identify percentage of customers who churned versus those who stayed", "Calculate correlation between MonthlyCharges and TotalCharges", "Identify any rows with inconsistent or missing key information"], "eda_results": {"missing_values": {"CustomerID": 0, "SignupDate": 1, "PlanType": 0, "MonthlyCharges": 1, "TotalCharges": 2, "Churn": 0, "InternetService": 2}, "standardized_signup_dates": ["2022-01-15", "2022-02-15", "2022-03-10", "2022-04-01", "2022-05-12", null, "2022-07-19", "2022-08-22", "2022-09-10", "2022-10-10", "2022-11-05", "2022-12-01", "2023-01-15"], "corrected_plan_types": {"Basic": 5, "Standard": 4, "Premium": 4}, "corrected_internet_services": {"Fiber optic": 6, "DSL": 5, "None": 2}, "summary_stats": {"MonthlyCharges": {"count": 13, "mean": 51.3, "std": 18.41, "min": 29.85, "25%": 29.85, "50%": 49.95, "75%": 70.7, "max": 89.1}, "TotalCharges": {"count": 11, "mean": 1331.5, "std": 1185.3, "min": 29.85, "25%": 125.5, "50%": 1300.0, "75%": 1840.75, "max": 3530.6}}, "value_counts": {"Churn": {"Yes": 5, "No": 8}}, "churn_percentage": {"Yes": 38.46, "No": 61.54}, "correlations": {"MonthlyCharges_vs_TotalCharges": 0.85}, "rows_with_issues": [3, 6, 7, 10]}}
{"purpose": "Analyze customer purchase patterns and product category performance in an ecommerce store.", "raw_table": "OrderID,CustomerID,ProductCategory,OrderDate,Quantity,PricePerUnit,PaymentMethod\n1001,cust01,Electronics,2023-01-15,2,299.99,Credit Card\n1002,cust02,Home & Garden,15/01/2023,1,89.5,PayPal\n1003,CUST03,eleCtronics,2023/01/16,3,,Credit card\n1004,cust04,Clothing,Jan 17 2023,,49.99,Credit Card\n1005,cust05,TOYS,2023-01-18,1,15.0,cash\n1006,,Clothing,2023-1-19,2,45.99,Credit Card\n1007,cust07,home & garden,01-20-2023,1,99.99,Paypal\n1008,cust08,Toys,2023-01-21,4,14.5,Credit Card\n1009,cust09,Electronics,2023-01-22,1,279.99,Credit Card\n1010,cust10,Books,2023-01-23,5,9.99,Credit Card\n1011,cust11,,2023-01-24,2,19.99,Credit Card\n1012,cust12,Books,2023/01/25,3,10.5,Credit Card\n1013,cust13,clothing,2023-01-26,1,55.0,Debit Card\n1014,cust14,Electronics,,1,299.99,Credit Card", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize the ProductCategory values to consistent capitalization", "Convert OrderDate column to a uniform date format and identify invalid or missing dates", "Calculate summary statistics (mean, median, min, max) for Quantity and PricePerUnit", "Generate value counts for PaymentMethod", "Identify top 3 ProductCategory by total Quantity sold", "Calculate the total revenue per ProductCategory", "Check for duplicate OrderID values"], "eda_results": {"missing_values": {"OrderID": "0%", "CustomerID": "7.1%", "ProductCategory": "7.1%", "OrderDate": "7.1%", "Quantity": "7.1%", "PricePerUnit": "7.1%", "PaymentMethod": "0%"}, "standardized_ProductCategory": {"Electronics": 4, "Home & Garden": 2, "Clothing": 3, "Toys": 2, "Books": 2, "Missing": 1}, "invalid_order_dates": 1, "summary_stats": {"Quantity": {"mean": 1.93, "median": 1.5, "min": 1, "max": 5}, "PricePerUnit": {"mean": 87.06, "median": 49.99, "min": 9.99, "max": 299.99}}, "payment_method_counts": {"Credit Card": 8, "PayPal": 2, "cash": 1, "Debit Card": 1}, "top_3_product_categories_by_quantity": {"Books": 8, "Electronics": 7, "Clothing": 6}, "total_revenue_per_product_category": {"Electronics": 1849.95, "Home & Garden": 189.49, "Clothing": 199.97, "Toys": 74.0, "Books": 68.97, "Missing": 39.98}, "duplicate_order_ids": 0}}
{"purpose": "Analyze production line efficiency and defect rates to identify areas for process improvement.", "raw_table": "BatchID,ProductionDate,Shift,Operator,UnitsProduced,DefectCount,Machine,Temperature\nB001,2024/04/01,Morning,alice,100,5,MX-100,75\nB002,04-02-2024,afternoon,Bob,95,3,mx-100,77\nb003,2024-04-03,NIGHT,Charlie, ,7,MX-101,80\nB004,4/4/24,Morning,alice,105,2,MX-100,missing\nB005,2024-04-05,Afternoon,daniel,98,,MX-101,79\nB006,2024-04-06,Night,Eve,110,4,mx-102,82\nB007,2024/04/07,Morning,Frank,102,6,MX-100,76\nB008,04-08-2024,afternoon,Gina,100,5,mx-101,78\nB009,2024-04-09,NIGHT,henry,103,3,MX-102,83\nB010,4/10/2024,morning,Alice,108,2,MX-100,75\nB011,2024-04-11,Afternoon,Bob,97,4,MX-101,missing\nB012,2024-4-12,Night,Charlie,105,1,MX-102,81", "eda_steps": ["Check for and summarize missing values in each column", "Standardize 'Shift' and 'Operator' column capitalization", "Convert 'ProductionDate' to a consistent date format", "Compute descriptive statistics for 'UnitsProduced', 'DefectCount', and 'Temperature'", "Calculate defect rate (DefectCount / UnitsProduced) for each batch", "Identify top 3 operators by total units produced", "Examine correlation between Temperature and DefectCount", "Summarize value counts for 'Machine' column"], "eda_results": {"missing_values": {"BatchID": 0, "ProductionDate": 0, "Shift": 0, "Operator": 0, "UnitsProduced": 1, "DefectCount": 2, "Machine": 0, "Temperature": 2}, "standardized_categories": {"Shift": ["Morning", "Afternoon", "Night"], "Operator": ["Alice", "Bob", "Charlie", "Daniel", "Eve", "Frank", "Gina", "Henry"]}, "date_format_consistency": "All dates converted to ISO format (YYYY-MM-DD)", "summary_stats": {"UnitsProduced": {"count": 14, "mean": 102.71, "std": 5.04, "min": 95, "25%": 98, "50%": 102, "75%": 105, "max": 110}, "DefectCount": {"count": 12, "mean": 3.92, "std": 1.87, "min": 1, "25%": 2, "50%": 4, "75%": 5, "max": 7}, "Temperature": {"count": 12, "mean": 78.83, "std": 3.09, "min": 75, "25%": 76, "50%": 79, "75%": 81, "max": 83}}, "defect_rates": {"B001": 0.05, "B002": 0.0316, "B003": null, "B004": 0.019, "B005": null, "B006": 0.036, "B007": 0.0588, "B008": 0.05, "B009": 0.0291, "B010": 0.0185, "B011": 0.0412, "B012": 0.0095}, "top_operators_by_units": {"Alice": 313, "Charlie": 210, "Bob": 192}, "correlation_temperature_defects": 0.45, "machine_value_counts": {"MX-100": 5, "MX-101": 4, "MX-102": 4}}}
{"purpose": "Analyze customer purchase behavior and product category preferences in a retail store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,ProductName,Quantity,UnitPrice,PaymentMethod\n1001,C123,2023-01-15,Electronics,Smartphone,2,699.99,Credit Card\n1002,c124,15-01-2023,home appliances,Microwave,1,89.5,Cash\n1003,C125,2023/01/16,Electronics,Laptop, ,1200.00,credit card\n1004,C126,17 Jan 2023,Fashion,T-shirt,3,19.99,Debit Card\n1005,C127,2023-01-18,Fashion,Sunglasses,1,,Cash\n1006,C128,2023-01-18,Home Appliances,Refrigerator,1,999.99,Credit card\n1007,C129,,Fashion,Jacket,2,79.99,Debit Card\n1008,C130,2023-1-19,electronics,Headphones,5,49.99,Cash\n1009,C131,2023-01-20,Home Appliances,,1,150.00,Credit Card\n1010,C132,2023-01-20,FASHION,Jeans,1,39.99,Debit Card\n1011,C133,2023-01-21,Toys,Action Figure,2,15.00,Cash\n1012,C134,2023-01-22,Toys,Board Game,,29.99,Cash\n1013,C135,01/23/2023,Electronics,Smartwatch,1,199.99,Credit Card\n1014,C136,2023/01/23,Home Appliances,Vacuum Cleaner,1,120.0,Cash", "eda_steps": ["Check for missing values in each column", "Standardize and unify the ProductCategory values", "Convert OrderDate to a consistent date format", "Compute descriptive statistics for Quantity and UnitPrice", "Generate value counts for PaymentMethod", "Identify top 3 most purchased ProductCategories by total Quantity", "Calculate the average UnitPrice per ProductCategory", "Check for duplicate OrderID entries", "Summarize the distribution skewness for Quantity"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 0, "OrderDate": 1, "ProductCategory": 0, "ProductName": 1, "Quantity": 2, "UnitPrice": 1, "PaymentMethod": 0}, "standardized_categories": {"Electronics": 5, "Home Appliances": 4, "Fashion": 4, "Toys": 2}, "order_date_formats_converted": "All dates converted to ISO format YYYY-MM-DD except 1 missing entry", "summary_stats": {"Quantity": {"count": 12, "mean": 1.92, "std": 1.45, "min": 1, "25%": 1, "50%": 1.5, "75%": 2.75, "max": 5, "skewness": 1.15}, "UnitPrice": {"count": 13, "mean": 362.77, "std": 450.54, "min": 15, "25%": 29.99, "50%": 79.99, "75%": 699.99, "max": 1200, "skewness": 1.19}}, "value_counts_payment_method": {"Cash": 5, "Credit Card": 5, "Debit Card": 3}, "top_3_categories_by_quantity": {"Electronics": 9, "Fashion": 7, "Home Appliances": 4}, "average_unit_price_per_category": {"Electronics": 449.19, "Home Appliances": 339.87, "Fashion": 46.66, "Toys": 22.5}, "duplicate_order_ids": 0}}
{"purpose": "Examine temperature and precipitation patterns across different climate zones and months to identify data quality issues and basic trends.", "raw_table": "Station_ID,Date,Climate_Zone,Avg_Temperature_C,Precipitation_mm\nST001,2023-01-15,Tropical,29.5,120.3\nst002,15/02/2023,temperate,18.2,45.0\nST003,2023-03-10,Arid,22.1,NaN\nSt004,2023-04-20,Subtropical,NaN,78.9\nST005,2023/05/18,TROPICAL,31.0,130.5\nST006,2023-06-25,Temperate,20.0,55.8\nst007,07-07-2023,Arid,24.3,10.2\nST008,2023-08-15,Subtropical,27.8,NaN\nST009,2023-09-10,Unknown,21.5,60.0\nST010,,tropical,30.2,140.7\nST011,2023-11-05,Temperate,17.5,50.1\nST012,2023-12-01,Arid,23.0,12.3", "eda_steps": ["Check and report missing values for each column", "Standardize the Date column to ISO format YYYY-MM-DD", "Normalize Climate_Zone entries to consistent capitalization", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone", "Identify records with unknown or unusual Climate_Zone values", "Calculate correlation between Avg_Temperature_C and Precipitation_mm", "Summarize the range of measurement dates", "Identify rows with missing Avg_Temperature_C or Precipitation_mm"], "eda_results": {"missing_values": {"Station_ID": 0, "Date": 1, "Climate_Zone": 0, "Avg_Temperature_C": 1, "Precipitation_mm": 2}, "date_standardization": "All dates converted to ISO format except 1 missing date", "climate_zone_normalized": {"Tropical": 4, "Temperate": 3, "Arid": 3, "Subtropical": 2, "Unknown": 1}, "descriptive_statistics": {"Avg_Temperature_C": {"count": 13, "mean": 23.46, "std": 4.78, "min": 17.5, "25%": 20.0, "50%": 23.0, "75%": 27.8, "max": 31.0}, "Precipitation_mm": {"count": 11, "mean": 70.9, "std": 47.4, "min": 10.2, "25%": 45.0, "50%": 60.0, "75%": 120.3, "max": 140.7}}, "value_counts_climate_zone": {"Tropical": 4, "Temperate": 3, "Arid": 3, "Subtropical": 2, "Unknown": 1}, "unusual_climate_zone_records": [{"Station_ID": "ST009", "Climate_Zone": "Unknown"}], "correlation_AvgTemp_Precipitation": -0.34, "date_range": {"min_date": "2023-01-15", "max_date": "2023-12-01"}, "rows_with_missing_temperature_or_precipitation": [{"Station_ID": "ST004", "missing": ["Avg_Temperature_C"]}, {"Station_ID": "ST003", "missing": ["Precipitation_mm"]}, {"Station_ID": "ST008", "missing": ["Precipitation_mm"]}, {"Station_ID": "ST010", "missing": ["Date"]}]}}
{"purpose": "Analyze student performance and attendance patterns in a high school semester.", "raw_table": "StudentID,Name,Grade,Math_Score,English_Score,Attendance,Enrollment_Date\n1001,Alice,10,88,92,95%,2023/01/15\n1002,bob,11,76,85,89%,15-01-2023\n1003,CHARLIE,10,,78,91%,2023-01-16\n1004,Diana,11,90,NA,87%,01/17/2023\n1005,edward,12,85,88,missing,2023/1/18\n1006,Fiona,10,95,94,98%,2023/01/19\n1007,George,12,82,80,93%,2023-01-20\n1008,Helen,11,NA,91,90%,Jan 21 2023\n1009,Ian,10,78,75,85%,2023/01/22\n1010,Jane,12,88,90,92%,2023/01/23", "eda_steps": ["Check and summarize missing values in each column", "Standardize the capitalization of the 'Name' column", "Convert 'Attendance' from percentage strings to numeric values", "Parse and standardize 'Enrollment_Date' to YYYY-MM-DD format", "Compute descriptive statistics for 'Math_Score' and 'English_Score'", "Generate value counts for 'Grade' column", "Identify students with missing scores", "Compute correlation between Math_Score and English_Score", "Find average attendance rate by grade"], "eda_results": {"missing_values": {"Math_Score": 2, "English_Score": 2, "Attendance": 1}, "name_capitalization_standardized": ["Alice", "Bob", "Charlie", "Diana", "Edward", "Fiona", "George", "Helen", "Ian", "Jane"], "attendance_numeric": [95, 89, 91, 87, null, 98, 93, 90, 85, 92], "enrollment_dates_standardized": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18", "2023-01-19", "2023-01-20", "2023-01-21", "2023-01-22", "2023-01-23"], "summary_stats": {"Math_Score": {"count": 8, "mean": 86.0, "std": 6.4, "min": 76, "max": 95}, "English_Score": {"count": 8, "mean": 86.6, "std": 6.5, "min": 75, "max": 94}}, "value_counts_Grade": {"10": 4, "11": 3, "12": 3}, "students_missing_scores": [{"StudentID": 1003, "Math_Score": null}, {"StudentID": 1004, "English_Score": null}, {"StudentID": 1005, "Attendance": null}, {"StudentID": 1008, "Math_Score": null}], "correlations": {"Math_Score_vs_English_Score": 0.85}, "average_attendance_by_grade": {"10": 87.75, "11": 88.67, "12": 89.67}}}
{"purpose": "Analyze user engagement patterns and content type popularity on a social media platform.", "raw_table": "User_ID,Post_Time,Content_Type,Likes,Comments,Shares\nU001,2023-04-01 14:30,Photo,120,15,5\nU002,04/02/2023 9:15 AM,video,98,10,,\nU003,2023/04/03 21:45,Text,45,2,1\nu004,2023-04-04T17:00,Live,missing,8,3\nU005,4/5/23 08:20,PHOTO,130,12,7\nU006,2023-04-06 13:10,Video,,5,2\nU007,2023-04-07 19:00,text,60,missing,0\nU008,Apr 8 2023 10:30,Poll,20,1,1\nU009,2023-04-09 22:00,VIDEO,110,,6\nU010,2023-4-10 15:00,Live,80,7,missing\n", "eda_steps": ["Parse the Post_Time column into a consistent datetime format", "Standardize Content_Type values to lowercase", "Identify and count missing values in Likes, Comments, and Shares columns", "Compute descriptive statistics for Likes, Comments, and Shares", "Generate value counts for Content_Type", "Calculate the average Likes, Comments, and Shares per Content_Type", "Identify top 2 most popular Content_Type by average Likes", "Check the distribution skewness for Likes", "Summarize the number of posts per day"], "eda_results": {"missing_values": {"Likes": 2, "Comments": 2, "Shares": 2}, "content_type_value_counts": {"photo": 2, "video": 3, "text": 2, "live": 2, "poll": 1}, "descriptive_stats": {"Likes": {"count": 8, "mean": 83.5, "std": 36.7, "min": 20, "25%": 52.5, "50%": 80, "75%": 110, "max": 130}, "Comments": {"count": 8, "mean": 7.5, "std": 4.6, "min": 1, "25%": 3.5, "50%": 7, "75%": 11.25, "max": 15}, "Shares": {"count": 8, "mean": 3.125, "std": 2.34, "min": 0, "25%": 1.25, "50%": 3, "75%": 5, "max": 7}}, "average_engagement_per_content_type": {"photo": {"avg_likes": 125, "avg_comments": 13.5, "avg_shares": 6}, "video": {"avg_likes": 104, "avg_comments": 7.5, "avg_shares": 4}, "text": {"avg_likes": 52.5, "avg_comments": 2, "avg_shares": 0.5}, "live": {"avg_likes": 80, "avg_comments": 7.5, "avg_shares": 1.5}, "poll": {"avg_likes": 20, "avg_comments": 1, "avg_shares": 1}}, "top_content_types_by_avg_likes": ["photo", "video"], "likes_skewness": 0.85, "posts_per_day": {"2023-04-01": 1, "2023-04-02": 1, "2023-04-03": 1, "2023-04-04": 1, "2023-04-05": 1, "2023-04-06": 1, "2023-04-07": 1, "2023-04-08": 1, "2023-04-09": 1, "2023-04-10": 1}}}
{"purpose": "Analyze customer churn patterns and usage behavior in a telecom dataset.", "raw_table": "CustomerID,JoinDate,PlanType,MonthlyUsageMinutes,Churn,City\n001,2023-01-15,Basic,350,No,New york\n002,15/02/2023,Premium,450,yes,los Angeles\n003,2023/03/10,Standard,NaN,No,Chicago\n004,2023-04-01,basic,200,No,Houston\n005,2023-4-15,PREMIUM,600,YES,phoenix\n006,,Standard,300,No,PHOENIX\n007,2023-06-20,Basic,400,,Chicago\n008,06-25-2023,standard,abc,No,los Angeles\n009,2023-07-30,Premium,550,Yes,New York\n010,2023/08/05,Basic,250,No,Houston\n011,2023-08-15,Basic,275,no,San Francisco\n012,2023-08-30,premium,500,,Los Angeles\n013,2023-09-05,Standard,350,No,CHICAGO\n014,2023-09-10,BASIC,NaN,Yes,San francisco", "eda_steps": ["Check missing value percentages for each column", "Standardize the PlanType and City column capitalization", "Convert JoinDate to a consistent date format", "Identify and handle invalid MonthlyUsageMinutes values", "Generate value counts for the Churn column", "Compute descriptive statistics for MonthlyUsageMinutes", "Identify top 3 cities by number of customers", "Check correlation between MonthlyUsageMinutes and Churn", "Summarize the number of customers per PlanType"], "eda_results": {"missing_values": {"CustomerID": 0, "JoinDate": 1, "PlanType": 0, "MonthlyUsageMinutes": 3, "Churn": 2, "City": 0}, "standardized_values": {"PlanType": ["Basic", "Premium", "Standard"], "City": ["New York", "Los Angeles", "Chicago", "Houston", "Phoenix", "San Francisco"]}, "invalid_usage_entries": ["abc", "NaN", "NaN"], "churn_value_counts": {"Yes": 5, "No": 7, "Missing": 2}, "monthly_usage_stats": {"count": 11, "mean": 395.45, "median": 350, "min": 200, "max": 600, "std_dev": 123.67}, "top_cities_by_customers": {"Chicago": 3, "Los Angeles": 3, "New York": 2}, "correlation_usage_churn": -0.45, "customers_per_plan": {"Basic": 6, "Premium": 4, "Standard": 4}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones.", "raw_table": "Date,Climate_Zone,Avg_Temperature_C,Precipitation_mm,Weather_Condition\n2023-01-15,TROPICAL,28.5,150,Sunny\n2023/02/15,Tropical,,200,Rainy\n2023-03-15,subtropical,22.1,85,Partly cloudy\n2023-04-15,SubTropical,23.4,NaN,Rain\n2023-05-15,temperate,18.2,55,Cloudy\n2023-06-15,Temperate,19.5,60,clear\n2023-07-15,polar,5.2,10,Snow\n2023-08-15,Polar,4.8,,snowy\n2023-09-15,subtropical,21.0,75,Clear\n2023-10-15,,15.6,40,Fog\n2023-11-15,temperate,16.8,50,cloudy\n2023-12-15,tropical,27.9,180,rAIN\n", "eda_steps": ["Check for missing values in each column", "Standardize the Climate_Zone column to consistent capitalization", "Convert Date column to a uniform date format", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone and Weather_Condition", "Identify rows with missing or inconsistent Weather_Condition entries", "Calculate correlation between Avg_Temperature_C and Precipitation_mm", "Summarize distribution skewness for numeric columns"], "eda_results": {"missing_values": {"Avg_Temperature_C": 1, "Precipitation_mm": 2, "Climate_Zone": 1, "Weather_Condition": 0, "Date": 0}, "value_counts": {"Climate_Zone": {"tropical": 3, "subtropical": 3, "temperate": 3, "polar": 2, "": 1}, "Weather_Condition": {"rainy": 2, "sunny": 1, "partly cloudy": 1, "rain": 1, "cloudy": 2, "clear": 2, "snow": 1, "snowy": 1, "fog": 1}}, "descriptive_statistics": {"Avg_Temperature_C": {"count": 14, "mean": 18.8, "std": 7.5, "min": 4.8, "25%": 15.6, "50%": 18.2, "75%": 23.4, "max": 28.5}, "Precipitation_mm": {"count": 12, "mean": 83.3, "std": 60.7, "min": 10, "25%": 40, "50%": 57.5, "75%": 150, "max": 200}}, "correlations": {"Avg_Temperature_C_vs_Precipitation_mm": -0.3}, "skewness": {"Avg_Temperature_C": -0.45, "Precipitation_mm": 0.95}, "data_issues": {"inconsistent_capitalization_Climate_Zone": true, "missing_Weather_Condition": false, "inconsistent_Weather_Condition_labels": ["rainy", "Rain", "rAIN", "snow", "snowy", "clear", "Clear"], "date_format_variations": ["2023-01-15", "2023/02/15"]}}}
{"purpose": "Examine production line efficiency and defect rates in manufacturing batches.", "raw_table": "BatchID,ProductName,StartDate,EndDate,UnitsProduced,DefectRate,Shift\n101,WidgetA,2023-01-05,2023/01/07,1000,0.02,morning\n102,widgetb,01-10-2023,2023-01-12,950,N/A,NIGHT\n103,WidgetA,2023-01-15,,1100,0.015,Morning\n104,wIdgetc,2023-01-18,2023-01-20,870,0.03,afternoon\n105,widgetB,2023/01/22,2023-01-24,920,0.025,Night\n106,WidgetC,2023-01-25,2023/01/27,880,,Afternoon\n107,widgetA,2023-01-28,2023-01-30,1050,0.01,MORNING\n108,WidgetC,,2023-02-02,900,0.02,Afternoon\n109,WidgetB,2023-02-03,2023-02-05,930,0.03,Night\n110,widgeta,2023-02-06,2023-02-08,1080,0.015,Morning", "eda_steps": ["Check for missing values and their percentages in each column", "Standardize the ProductName and Shift columns to consistent capitalization", "Parse and unify StartDate and EndDate into a consistent date format", "Calculate the duration of each batch production in days", "Compute descriptive statistics for UnitsProduced and DefectRate", "Generate value counts for ProductName and Shift", "Identify batches with missing EndDate or DefectRate", "Analyze correlation between UnitsProduced and DefectRate"], "eda_results": {"missing_values": {"BatchID": 0, "ProductName": 0, "StartDate": 1, "EndDate": 1, "UnitsProduced": 0, "DefectRate": 2, "Shift": 0}, "standardized_categories": {"ProductName": {"WidgetA": 4, "WidgetB": 3, "WidgetC": 3}, "Shift": {"Morning": 4, "Night": 3, "Afternoon": 3}}, "date_parsing_issues": {"StartDate": ["BatchID 108 missing"], "EndDate": ["BatchID 103 missing"]}, "batch_duration_days": {"mean": 2, "min": 2, "max": 2, "missing": 1}, "summary_stats": {"UnitsProduced": {"count": 11, "mean": 973.64, "std": 86.0, "min": 870, "25%": 900, "50%": 930, "75%": 1050, "max": 1100}, "DefectRate": {"count": 9, "mean": 0.0194, "std": 0.0076, "min": 0.01, "25%": 0.015, "50%": 0.02, "75%": 0.025, "max": 0.03}}, "value_counts": {"ProductName": {"WidgetA": 4, "WidgetB": 3, "WidgetC": 3}, "Shift": {"Morning": 4, "Night": 3, "Afternoon": 3}}, "batches_with_missing_values": {"EndDate": [103], "DefectRate": [102, 106]}, "correlations": {"UnitsProduced_vs_DefectRate": -0.45}}}
{"purpose": "Explore movie dataset to understand rating distributions, genre popularity, and missing data patterns.", "raw_table": "MovieID,Title,Genre,ReleaseDate,Rating,Duration,Director\n1,The Last Hero,Action,2020-05-10,8.2,130,John Smith\n2,romantic twilight,Romance,2019/11/01,7.4,115,Emily Zhao\n3,Galaxy Quest,Sci-fi,,8.7,140,Mark Thompson\n4,The Last Hero,action,2020-05-10,8.3,130,john smith\n5,Lost in Space,Sci-Fi,2018-07-22,Missing,125,Mark Thompson\n6,Happy Days,Comedy,2017-02-30,6.5,90,Sarah O'Neil\n7,romantic twilight,Romance,2019/11/01,7.8,,Emily Zhao\n8,Shadow Realm,Horror,05-12-2021,5.9,110,David King\n9,The Last HERO,Action,2020-05-10,8.1,130,John Smith\n10,Galaxy Quest,Sci-Fi,2018-07-22,8.6,140,Mark Thompson\n11,Unknown Film,Drama,2021-13-01,6.8,100,Anna Lee\n12,Bright Future,Sci-fi,2019-08-15,7.9,135,Mark thompson", "eda_steps": ["Check and count missing values in each column", "Identify unique genres and their frequencies", "Standardize genre capitalization and find top 3 genres", "Analyze rating distribution including mean and median", "Check for duplicate movie titles with varying cases", "Calculate average movie duration by genre", "Validate and parse release dates, identifying invalid entries"], "eda_results": {"missing_values": {"MovieID": 0, "Title": 0, "Genre": 0, "ReleaseDate": 2, "Rating": 1, "Duration": 1, "Director": 0}, "value_counts": {"Genre_raw": {"Action": 1, "action": 1, "Romance": 2, "Sci-fi": 1, "Sci-Fi": 3, "Comedy": 1, "Horror": 1, "Drama": 1}}, "top_genres": {"sci-fi": 4, "romance": 2, "action": 3}, "rating_distribution": {"mean_rating": 7.5, "median_rating": 7.8, "min_rating": 5.9, "max_rating": 8.7, "ratings_count": 10}, "duplicate_titles": {"The Last Hero": 3, "romantic twilight": 2, "Galaxy Quest": 2}, "average_duration_by_genre": {"action": 130, "romance": 115, "sci-fi": 135, "comedy": 90, "horror": 110, "drama": 100}, "invalid_release_dates": ["2017-02-30", "2021-13-01"]}}
{"purpose": "Analyze sales performance and customer demographics for retail transactions.", "raw_table": "TransactionID,CustomerID,ProductCategory,SaleAmount,PurchaseDate,CustomerState,PaymentMethod\n1001,cust01,Electronics,299.99,2023-01-15,CA,Credit Card\n1002,cust02,clothing,89.5,15/01/2023,ca,credit card\n1003,cust03,Home & Kitchen,45,,NY,PayPal\n1004,CUST04,electronics,199.95,2023-01-17,TX,Credit card\n1005,cust05,Toys,25.00,2023/01/18,Fl,Cash\n1006,cust06,Clothing,NaN,01-20-2023,NY,Credit Card\n1007,cust07,Books,12.99,2023-1-21,TX,Paypal\n1008,cust08,Toys,35,2023/01/22,FL,Cash\n1009,cust09,Books,NaN,2023-01-22,TX,CREDIT CARD\n1010,cust10,Home & kitchen,60,01/23/2023,NY,Cash\n1011,cust11,Clothing,100.0,2023-01-24,CA,credit Card\n1012,cust12,Electronics,NaN,2023-01-25,CA,Cash\n1013,cust13,Toys,20.0,2023/01/25,fl,Cash\n1014,cust14,Books,15.0,2023-01-26,TX,PayPal", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization of categorical columns: ProductCategory, CustomerState, PaymentMethod", "Convert PurchaseDate to a consistent datetime format", "Compute descriptive statistics for SaleAmount", "Calculate value counts for ProductCategory and PaymentMethod", "Identify the number of unique customers", "Find average SaleAmount by ProductCategory", "Count transactions per state"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 0, "ProductCategory": 0, "SaleAmount": 3, "PurchaseDate": 1, "CustomerState": 0, "PaymentMethod": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home & Kitchen", "Toys", "Books"], "CustomerState": ["CA", "NY", "TX", "FL"], "PaymentMethod": ["Credit Card", "PayPal", "Cash"]}, "purchase_date_range": {"min_date": "2023-01-15", "max_date": "2023-01-26"}, "saleamount_stats": {"count": 11, "mean": 79.0, "median": 60.0, "min": 12.99, "max": 299.99, "std_dev": 87.6}, "value_counts": {"ProductCategory": {"Electronics": 3, "Clothing": 3, "Home & Kitchen": 2, "Toys": 3, "Books": 3}, "PaymentMethod": {"Credit Card": 5, "PayPal": 3, "Cash": 5}}, "unique_customers": 14, "avg_saleamount_by_category": {"Electronics": 249.97, "Clothing": 94.75, "Home & Kitchen": 52.5, "Toys": 26.67, "Books": 12.66}, "transactions_per_state": {"CA": 4, "NY": 3, "TX": 4, "FL": 3}}}
{"purpose": "Analyze monthly sales performance and customer demographics for retail stores.", "raw_table": "Store_ID,Store_Name,Date_of_Sale,Product_Category,Units_Sold,Unit_Price,Customer_Age,Customer_Gender\n101,Main St Outlet,2023-01-15,Electronics,5,299.99,34,M\n102,Suburb Outlet,15/02/2023,furnITure,2,499.50,28,f\n103,Downtown,2023/03/01,clothing,10,,45,M\n104,Main St Outlet,2023-03-05,Electronics,,299.99,22,F\n105,suburb outlet,2023-04-10,Clothing,7,39.99,NA,M\n106,Downtown,2023-04-22,Furniture,1,450.00,38,F\n107,Main St Outlet,2023-05-03,electronics,3,299.99,30,M\n108,,2023-05-15,Clothing,8,35.00,27,F\n109,Suburb Outlet,2023-06-01,Electronics,4,310.00,31,f\n110,Downtown,2023-06-15,clothing,6,40.00,29,M", "eda_steps": ["Check and summarize missing values per column", "Standardize 'Product_Category' and 'Store_Name' capitalization", "Convert 'Date_of_Sale' to consistent date format", "Compute descriptive statistics for numeric columns: Units_Sold, Unit_Price, Customer_Age", "Generate value counts for 'Product_Category' and 'Customer_Gender'", "Identify stores with the highest total sales revenue", "Calculate total sales revenue per store and per product category", "Analyze average customer age by product category", "Check for correlation between Units_Sold and Unit_Price"], "eda_results": {"missing_values": {"Store_ID": 0, "Store_Name": 1, "Date_of_Sale": 0, "Product_Category": 0, "Units_Sold": 1, "Unit_Price": 1, "Customer_Age": 1, "Customer_Gender": 0}, "standardized_categories": {"Product_Category": ["Electronics", "Furniture", "Clothing"], "Store_Name": ["Main St Outlet", "Suburb Outlet", "Downtown"]}, "date_range": {"min": "2023-01-15", "max": "2023-06-15"}, "summary_stats": {"Units_Sold": {"count": 14, "mean": 5.43, "std": 2.67, "min": 1, "max": 10}, "Unit_Price": {"count": 13, "mean": 274.07, "std": 183.72, "min": 35, "max": 499.5}, "Customer_Age": {"count": 14, "mean": 31.43, "std": 7.42, "min": 22, "max": 45}}, "value_counts": {"Product_Category": {"Electronics": 4, "Clothing": 5, "Furniture": 3}, "Customer_Gender": {"M": 7, "F": 5, "f": 2}}, "total_sales_revenue_per_store": {"Main St Outlet": 2999.9, "Suburb Outlet": 1860, "Downtown": 1150}, "total_sales_revenue_per_category": {"Electronics": 3779.93, "Furniture": 1949.5, "Clothing": 556.93}, "average_customer_age_by_category": {"Electronics": 29, "Furniture": 33, "Clothing": 33.6}, "correlation_units_sold_unit_price": 0.12}}
{"purpose": "Analyze crop yield and environmental factors for different farm plots to identify patterns affecting productivity.", "raw_table": "Plot_ID,Crop_Type,Planting_Date,Harvest_Date,Yield_kg,Soil_PH,Rainfall_mm,Fertilizer_Type\nP01,Corn,2023-03-15,2023/09/20,1200,6.5,300,Organic\nP02,Wheat,15-Mar-2023,2023-08-25,850,,250,Chemical\nP03,soybean,2023-03-20,Sept 30 2023,950,5.8,280,organic\np04,Corn,2023/03/18,2023-09-22,,6.7,310,None\nP05,Rice,03-16-2023,2023-10-05,1100,6.0,NA,Chemical\nP06,Wheat,2023-03-17,2023-08-28,900,6.3,260,chemical\nP07,Soybean,2023-03-22,2023-10-01,1000,5.9,285,Organic\nP08,corn,2023-03-19,2023-09-21,1150,6.4,295,None\nP09,Rice,2023-03-16,2023-10-04,1050,6.1,270,Chemical\nP10,Wheat,,2023-08-27,870,6.2,255,chemical", "eda_steps": ["Inspect data types and convert dates to a standard format", "Check for and summarize missing values in each column", "Standardize capitalization in categorical columns like Crop_Type and Fertilizer_Type", "Compute descriptive statistics for numeric columns such as Yield_kg, Soil_PH, and Rainfall_mm", "Generate value counts for Crop_Type and Fertilizer_Type", "Calculate the correlation matrix for numeric variables", "Identify top 2 crops by average yield", "Summarize the distribution skewness of Yield_kg", "Analyze average yield by Fertilizer_Type"], "eda_results": {"missing_values": {"Plot_ID": 0, "Crop_Type": 0, "Planting_Date": 1, "Harvest_Date": 0, "Yield_kg": 1, "Soil_PH": 1, "Rainfall_mm": 1, "Fertilizer_Type": 0}, "value_counts": {"Crop_Type": {"Corn": 3, "Wheat": 3, "Soybean": 2, "Rice": 2}, "Fertilizer_Type": {"Organic": 3, "Chemical": 4, "None": 2}}, "summary_stats": {"Yield_kg": {"count": 9, "mean": 1006.67, "std": 129.96, "min": 850, "25%": 900, "50%": 1000, "75%": 1100, "max": 1200}, "Soil_PH": {"count": 9, "mean": 6.19, "std": 0.3, "min": 5.8, "25%": 6.0, "50%": 6.2, "75%": 6.4, "max": 6.7}, "Rainfall_mm": {"count": 9, "mean": 277.78, "std": 19.52, "min": 250, "25%": 260, "50%": 280, "75%": 295, "max": 310}}, "correlations": {"Yield_kg": {"Soil_PH": 0.78, "Rainfall_mm": 0.66}, "Soil_PH": {"Rainfall_mm": 0.4}}, "top_categories": {"Top_2_Crops_By_Yield": {"Corn": 1150, "Rice": 1075}}, "distribution_skewness": {"Yield_kg": -0.35}, "average_yield_by_fertilizer": {"Organic": 1050, "Chemical": 918, "None": 1175}}}
{"purpose": "Analyze ridership patterns and trip characteristics for urban bus transportation data.", "raw_table": "Trip_ID,Route,Start_Time,End_Time,Passenger_Count,Fare,Driver_ID\nT001,10A,2023-03-15 08:00,2023-03-15 08:45,23,2.50,D001\nT002,10a,15-03-2023 09:00 AM,2023/03/15 09:42,19,2.5,D002\nT003,22B,2023-03-15 10:15,2023-03-15 10:55,NaN,3.00,D001\nT004,22b,2023/03/15 11:00,15-03-2023 11:45,15,,D003\nT005,15C,2023-03-15 12-00,2023-03-15 12:45,8,2.00,D002\nT006,15c,2023-03-15 13:10,2023-03-15 13:55,12,2.00,d002\nT007,10A,03/15/2023 14:00,03/15/2023 14:45,20,2.50,D001\nT008,22B,,2023-03-15 15:40,18,3.00,D003\nT009,unknown,2023-15-03 16:00,2023-03-15 16:50,10,2.50,D004\nT010,15C,2023-03-15 17:05,2023-03-15 17:45,NaN,2.00,D002\nT011,10A,2023-03-15 18:10,2023-03-15 18:55,25,2.75,D001\nT012,22B,2023-03-15 19:20,2023-03-15 19:55,22,,D003", "eda_steps": ["Check for missing values in each column", "Standardize route names to consistent capitalization", "Parse and unify date and time formats for Start_Time and End_Time", "Calculate trip duration in minutes for each trip", "Compute descriptive statistics (mean, median, std) for Passenger_Count and Fare", "Generate value counts for the Route and Driver_ID columns", "Identify trips with missing or invalid Passenger_Count values", "Calculate correlation between Passenger_Count and Fare", "Determine the top 2 most frequent routes by trip count"], "eda_results": {"missing_values": {"Trip_ID": 0, "Route": 1, "Start_Time": 1, "End_Time": 0, "Passenger_Count": 2, "Fare": 3, "Driver_ID": 0}, "standardized_routes": ["10A", "10A", "22B", "22B", "15C", "15C", "10A", "22B", "unknown", "15C", "10A", "22B"], "trip_durations_minutes": {"T001": 45, "T002": 42, "T003": 40, "T004": 45, "T005": 45, "T006": 45, "T007": 45, "T008": null, "T009": 50, "T010": 40, "T011": 45, "T012": 35}, "passenger_count_stats": {"mean": 17.9, "median": 18.0, "std_dev": 5.5}, "fare_stats": {"mean": 2.44, "median": 2.5, "std_dev": 0.33}, "value_counts_route": {"10A": 4, "22B": 4, "15C": 3, "unknown": 1}, "value_counts_driver": {"D001": 4, "D002": 3, "D003": 3, "D004": 1}, "invalid_passenger_count_trips": ["T003", "T010"], "correlation_passenger_fare": 0.58, "top_routes": ["10A", "22B"]}}
{"purpose": "Analyze monthly electricity consumption patterns across different regions to identify data quality issues and consumption trends.", "raw_table": "Region,Month,Electricity_Consumption_kWh,Customer_Type,Report_Date\nNorth,Jan-2024,3500,Residential,2024/01/31\nsouth,Feb 2024,4200,Commerical,2024-02-28\nEast,Mar-2024,,Industrial,28-03-2024\nWEST,Apr-24,3900,residential,2024/04/30\nNorth,May 2024,NaN,Residential,2024-05-31\nEast,Jun-2024,4700,Industrial,2024/06/30\nSouth,Jul-2024,4600,Commercial,2024/07/31\nwest,Aug-2024,4300,Residential,31-08-2024\nNorth,Sep-2024,4000,Commerical,2024/09/30\nEAST,Oct-2024,4800,Industrial,2024-10-31\nSouth,Nov-2024,4400,commercial,2024/11/30\nWest,Dec-2024,4200,Residential,2024-12-31", "eda_steps": ["Check and count missing values in each column", "Standardize the capitalization in categorical columns Region and Customer_Type", "Parse and unify the date formats in Report_Date and Month columns", "Compute descriptive statistics for Electricity_Consumption_kWh", "Generate value counts for the Region column", "Identify inconsistent spellings in Customer_Type", "Calculate correlations between Electricity_Consumption_kWh and Month (as numeric)", "Summarize the distribution skewness of Electricity_Consumption_kWh"], "eda_results": {"missing_values": {"Region": 0, "Month": 0, "Electricity_Consumption_kWh": 2, "Customer_Type": 0, "Report_Date": 0}, "standardized_categories": {"Region": {"North": 3, "South": 3, "East": 3, "West": 3}, "Customer_Type": {"Residential": 5, "Commercial": 4, "Industrial": 3}}, "date_formats_unified": true, "descriptive_statistics": {"Electricity_Consumption_kWh": {"count": 12, "mean": 4350, "std_dev": 455.8, "min": 3500, "25%": 4000, "50%": 4300, "75%": 4700, "max": 4800}}, "value_counts_Region": {"North": 3, "South": 3, "East": 3, "West": 3}, "inconsistent_spelling_Customer_Type": {"Commerical": 2, "commercial": 1}, "correlations": {"Electricity_Consumption_kWh_vs_MonthNumber": 0.72}, "distribution_skewness": {"Electricity_Consumption_kWh": 0.15}}}
{"purpose": "Analyze passenger ridership patterns and identify data quality issues in a city's bus transportation dataset.", "raw_table": "RouteID,Date,Boardings,Alightings,BusType,DriverName\n12,2023-01-01,45,43,standard,John D.\n7,01/02/2023,38,,Mini,alice s\n12,2023-1-03,NaN,40,Standard,John D.\n5,2023/01/04,29,31,standard,Mark T\n7,2023-01-05,40,39,mini,Alice S\n5,2023-01-06,32,35,STANDARD,mark t\n12,2023-1-07,48,46,Standard,\n7,2023-01-08,37,36,Mini,alice S\n5,,30,33,Standard,Mark T\n12,2023-01-10,50,49,standard,JOHN D.\n7,2023/01/11,35,34,,Alice s\n5,2023-01-12,31,NaN,standard,Mark t", "eda_steps": ["Check for missing values across all columns", "Standardize the BusType and DriverName columns (capitalize consistently)", "Convert Date column to a uniform date format and identify missing dates", "Compute descriptive statistics for Boardings and Alightings", "Generate value counts for RouteID and BusType", "Identify rows with inconsistent or missing BusType values", "Calculate the correlation between Boardings and Alightings", "Identify top drivers by total boardings", "Analyze ridership trends over the dates"], "eda_results": {"missing_values": {"RouteID": 0, "Date": 1, "Boardings": 1, "Alightings": 2, "BusType": 1, "DriverName": 1}, "standardized_categories": {"BusType": ["Standard", "Mini"], "DriverName": ["John D.", "Alice S", "Mark T", null]}, "date_issues": {"missing_dates": 1, "unique_dates": 11, "date_format_standardized": true}, "summary_stats": {"Boardings": {"count": 13, "mean": 38.77, "std": 7.03, "min": 29, "max": 50}, "Alightings": {"count": 12, "mean": 38.08, "std": 6.53, "min": 31, "max": 49}}, "value_counts": {"RouteID": {"12": 5, "7": 4, "5": 4}, "BusType": {"Standard": 9, "Mini": 4, "missing": 1}}, "inconsistent_bus_type_rows": 1, "correlations": {"Boardings_Alightings": 0.99}, "top_drivers_by_boardings": {"John D.": 183, "Mark T": 122, "Alice S": 150, "missing": 48}, "ridership_trends": {"highest_boardings_date": "2023-01-10", "lowest_boardings_date": "2023-01-04"}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones to identify missing data and data quality issues.", "raw_table": "Date,Climate_Zone,Avg_Temperature_C,Precipitation_mm\n2024-01-15,Tropical,29.5,120.2\n15-Feb-2024,Temperate,13.2,85.3\n2024/03/15,Arid,22.1,\n2024-04-15,TROPICAL,30.0,110.0\n2024-05-15,temperate,16.5,NaN\n2024-06-15,Arid,25.3,10.5\n07-2024-07,Tropical,31.1,130.4\n2024-08-15,temperate,18.0,90.7\n2024-09-15,Arid,21.0,5\n2024-10-15,Polar,-5.2,15.0\n2024-11-15,polar,-3.8,20.0\n2024-12-15,Polar,-7.0,NaN\n2024-13-15,Tropical,28.9,125.5", "eda_steps": ["Check and standardize date formats in the Date column", "Identify and normalize inconsistencies in the Climate_Zone categories", "Detect and quantify missing values in Avg_Temperature_C and Precipitation_mm", "Compute basic descriptive statistics for Avg_Temperature_C and Precipitation_mm", "Generate value counts for the Climate_Zone column", "Identify any invalid date entries", "Analyze correlation between Avg_Temperature_C and Precipitation_mm where data is available"], "eda_results": {"missing_values": {"Avg_Temperature_C": 0, "Precipitation_mm": 3, "Date": 1}, "invalid_dates": ["2024-13-15"], "standardized_climate_zones": {"Tropical": 4, "Temperate": 3, "Arid": 3, "Polar": 3}, "summary_stats": {"Avg_Temperature_C": {"count": 14, "mean": 17.79, "std_dev": 13.27, "min": -7.0, "max": 31.1}, "Precipitation_mm": {"count": 11, "mean": 73.7, "std_dev": 52.5, "min": 5.0, "max": 130.4}}, "value_counts_Climate_Zone": {"tropical": 4, "temperate": 3, "arid": 3, "polar": 3}, "correlation": {"Avg_Temperature_C_vs_Precipitation_mm": 0.42}}}
{"purpose": "Analyze hourly energy consumption patterns and identify data quality issues in smart meter readings.", "raw_table": "MeterID,Timestamp,Energy_kWh,DeviceType,Region\n1001,2024/04/01 00:00,1.2,heater,North\n1002,04-01-2024 01:00,0.8,AC,South\n1003,2024-04-01 02:00,,fridge,East\n1004,April 1, 2024 03:00,1.0,AC,west\n1005,2024-04-01 04:00,1.5,Heater,North\n1006,2024-04-01 05:00,1.3,heater,Unknown\n1007,2024-04-01 06:00,abc,Fridge,East\n1008,2024-04-01 07:00,0.9,AC,South\n1009,2024-04-01 08:00,1.1,Heater,West\n1010,2024-04-01 09:00,1.0,Fridge,East\n1011,2024/04/01 10:00,1.2,AC,South\n1012,2024-04-01 11:00,1.4,heater,North\n1013,2024-04-01 12:00,1.3,heater,North\n1014,2024-04-01 13:00,1.0,AC,South", "eda_steps": ["Parse the Timestamp column into a consistent datetime format", "Identify and count missing values in each column", "Convert Energy_kWh to numeric, coercing errors to NaN", "Compute descriptive statistics for Energy_kWh", "Generate value counts for DeviceType and Region columns", "Check for inconsistent capitalization in categorical columns", "Identify rows with unknown or unusual categories", "Calculate the number of unique MeterIDs", "Plot histogram of Energy_kWh values to observe distribution", "Examine correlation between Energy_kWh and time of day"], "eda_results": {"missing_values": {"MeterID": 0, "Timestamp": 0, "Energy_kWh": 2, "DeviceType": 0, "Region": 1}, "value_counts": {"DeviceType": {"heater": 5, "AC": 5, "fridge": 3}, "Region": {"North": 4, "South": 4, "East": 3, "West": 2, "Unknown": 1}}, "inconsistent_capitalization": {"DeviceType": ["heater", "Heater", "AC", "Fridge", "fridge"], "Region": ["North", "South", "East", "west", "Unknown", "West"]}, "descriptive_stats_Energy_kWh": {"count": 12, "mean": 1.15, "std": 0.21, "min": 0.8, "25%": 1.0, "50%": 1.15, "75%": 1.3, "max": 1.5}, "unique_MeterIDs": 14, "rows_with_unknown_categories": [{"MeterID": 1006, "Region": "Unknown"}], "timestamp_parsing_notes": "Multiple formats detected: 'YYYY/MM/DD HH:mm', 'MM-DD-YYYY HH:mm', 'YYYY-MM-DD HH:mm', and 'Month D, YYYY HH:mm', standardized to ISO format", "energy_kwh_distribution_observation": "Energy_kWh values mostly between 0.8 and 1.5 with two missing and one invalid entry", "correlation_energy_time": "Slight positive correlation observed between Energy_kWh and hour of day (r ~ 0.3)"}}
{"purpose": "Analyze customer purchase behavior and product category popularity in a retail store.", "raw_table": "OrderID,CustomerName,ProductCategory,Quantity,PricePerUnit,OrderDate\n1001,john smith,Electronics,2,199.99,2023/01/15\n1002,Mary J,Home & kitchen,1,,15-02-2023\n1003,ALICE,eleCtRonics,3,89.5,2023-03-05\n1004,Bob,clothing,NaN,29.99,03/22/2023\n1005,carol,Clothing,2,25.0,2023-04-01\n1006,,Sports,4,49.99,2023-04-15\n1007,David,home & Kitchen,1,99.99,April 20, 2023\n1008,Emma,Electronics,5,NaN,2023-05-02\n1009,Fred,TOYS,2,20,2023-05-10\n1010,Gina,Toys,1,18,2023-05-15\n1011,Hank,,3,10.5,20230520\n1012,Ivy,Clothing,2,27.5,05/25/2023\n1013,Jack,Sports,1,55.0,2023-05-30\n1014,Kate,home & Kitchen,NaN,35.0,2023-06-01", "eda_steps": ["Check for missing values and their percentages in each column", "Standardize the ProductCategory names to consistent capitalization", "Convert the OrderDate column to datetime format", "Calculate descriptive statistics for Quantity and PricePerUnit", "Compute value counts for ProductCategory", "Identify orders with missing Quantity or PricePerUnit and count them", "Calculate total revenue per order as Quantity multiplied by PricePerUnit", "Find the top 3 ProductCategory by total revenue", "Summarize unique customers and missing CustomerName counts"], "eda_results": {"missing_values": {"OrderID": "0%", "CustomerName": "7.1%", "ProductCategory": "7.1%", "Quantity": "14.3%", "PricePerUnit": "21.4%", "OrderDate": "0%"}, "product_category_standardized_counts": {"Electronics": 3, "Home & Kitchen": 3, "Clothing": 3, "Sports": 2, "Toys": 2}, "orderdate_range": {"min": "2023-01-15", "max": "2023-06-01"}, "quantity_stats": {"count": 12, "mean": 2.25, "std": 1.44, "min": 1, "25%": 1.25, "50%": 2, "75%": 3, "max": 5}, "priceperunit_stats": {"count": 11, "mean": 56.13, "std": 62.14, "min": 10.5, "25%": 20, "50%": 29.99, "75%": 89.5, "max": 199.99}, "missing_quantity_or_price_orders": 4, "total_revenue_per_order": {"1001": 399.98, "1002": null, "1003": 268.5, "1004": null, "1005": 50, "1006": 199.96, "1007": 99.99, "1008": null, "1009": 40, "1010": 18, "1011": 31.5, "1012": 55, "1013": 55, "1014": null}, "top_3_product_categories_by_revenue": {"Electronics": 668.48, "Sports": 254.96, "Home & Kitchen": 134.99}, "unique_customers_count": 13, "missing_customer_names_count": 1}}
{"purpose": "Analyze student performance and attendance patterns to identify areas for academic support.", "raw_table": "Student_ID,Name,Grade,Math_Score,English_Score,Attendance,Enrollment_Date\nS001,alice,10,85,78,95%,2023/01/15\nS002,Bob,10,NA,88,89%,15-01-2023\nS003,Charlie,11,92,NA,92%,2023.01.16\nS004,diana,11,85,80,,01/17/2023\nS005,Eva,10,78,85,88%,2023-01-18\nS006,Frank,12,88,91,93%,January 19, 2023\nS007,Gina,11,90,87,NA,2023-01-20\nS008,henry,12,75,82,90%,2023/01/21\nS009,Ian,12,NA,79,85%,2023/01/22\nS010,julia,10,82,84,92%,2023-01-23", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in the 'Name' column", "Convert 'Enrollment_Date' to a uniform date format", "Calculate descriptive statistics for Math_Score and English_Score", "Generate value counts for the 'Grade' column", "Analyze attendance percentage distribution", "Identify students missing scores in Math or English", "Calculate correlation between Math_Score, English_Score, and Attendance"], "eda_results": {"missing_values": {"Student_ID": 0, "Name": 0, "Grade": 0, "Math_Score": 2, "English_Score": 2, "Attendance": 2, "Enrollment_Date": 0}, "standardized_names": ["Alice", "Bob", "Charlie", "Diana", "Eva", "Frank", "Gina", "Henry", "Ian", "Julia"], "enrollment_date_format": "All dates converted to YYYY-MM-DD", "summary_stats": {"Math_Score": {"count": 8, "mean": 84.375, "std_dev": 5.48, "min": 75, "max": 92}, "English_Score": {"count": 8, "mean": 83.5, "std_dev": 4.43, "min": 78, "max": 91}}, "value_counts_grade": {"10": 4, "11": 3, "12": 3}, "attendance_distribution": {"mean": 90.5, "min": 85, "max": 95, "missing": 2}, "students_missing_scores": {"Math_Score": ["S002", "S009"], "English_Score": ["S003", "S004"]}, "correlations": {"Math_Score vs English_Score": 0.68, "Math_Score vs Attendance": 0.42, "English_Score vs Attendance": 0.51}}}
{"purpose": "Examine crop yield variations and planting area distributions across different farms and crop types.", "raw_table": "Farm_ID,Crop_Type,Planting_Date,Yield_kg,Area_ha,Soil_pH,Fertilizer_Used\nF001,Corn,2023-04-15,1200,2.5,6.5,Nitrogen\nF002,wheat,15/04/2023,950,3.0,7.0,phosphorous\nF003,Soybean,2023/04/16,NA,1.8,6.8,Nitrogen\nF004,Corn,04-17-2023,1100,2.7,NA,None\nf005,Wheat,2023-04-15,980,3.1,7.1,Potassium\nF006,soybean,2023-04-16,850,1.9,6.7,phosphorous\nF007,Corn,2023-4-15,1150,2.6,6.6,nitrogen\nF008,Rice,2023-04-15,700,2.0,6.4,Phosphorous\nF009,RICE,2023/04/15,720,NA,6.3,none\nF010,corn,2023-04-15,1180,2.8,6.5,Nitrogen", "eda_steps": ["Check and summarize missing values in each column", "Standardize Crop_Type values to consistent capitalization", "Parse and unify Planting_Date into YYYY-MM-DD format", "Compute descriptive statistics for numeric columns: Yield_kg, Area_ha, Soil_pH", "Generate value counts for Crop_Type and Fertilizer_Used columns", "Calculate correlation matrix for numeric variables Yield_kg, Area_ha, Soil_pH", "Identify top 3 crops by average yield", "Summarize fertilizer usage frequency across all farms"], "eda_results": {"missing_values": {"Yield_kg": 1, "Area_ha": 1, "Soil_pH": 1}, "standardized_Crop_Type_counts": {"Corn": 4, "Wheat": 2, "Soybean": 2, "Rice": 2}, "date_format_unified": true, "summary_stats": {"Yield_kg": {"count": 9, "mean": 1013.33, "std_dev": 178.59, "min": 700, "max": 1200}, "Area_ha": {"count": 9, "mean": 2.56, "std_dev": 0.47, "min": 1.8, "max": 3.1}, "Soil_pH": {"count": 9, "mean": 6.68, "std_dev": 0.27, "min": 6.3, "max": 7.1}}, "value_counts": {"Fertilizer_Used": {"Nitrogen": 4, "Phosphorous": 3, "Potassium": 1, "None": 2}}, "correlations": {"Yield_kg_Area_ha": 0.89, "Yield_kg_Soil_pH": 0.12, "Area_ha_Soil_pH": -0.08}, "top_3_crops_by_avg_yield": {"Corn": 1157.5, "Wheat": 965, "Rice": 710}, "fertilizer_usage_frequency": {"Nitrogen": 4, "Phosphorous": 3, "Potassium": 1, "None": 2}}}
{"purpose": "Analyze machine downtime patterns and identify frequent causes of delays in production.", "raw_table": "MachineID,Date,Shift,DowntimeMinutes,Cause,Operator\nM01,2023/01/05,Day,45,Maintenance,John\nM02,2023-01-06,Night,30,Operator Error,Mary\nm03,01-07-2023,day,NA,Material shortage,Bob\nM01,2023/01/08,Night,15,MAINTENANCE,Ann\nM02,2023-01-09,Day,,operator error,Mary\nM03,2023/1/10,Night,60,Breakdown,Charlie\nM01,2023-01-11,Day,20,Setup,John\nm02,2023/01/12,Night,50,Material Shortage,Mary\nM03,,day,25,breakdown,bob\nM01,2023/01/14,NIGHT,35,Maintenance,\nM02,2023/01/15,Day,40,Operator error,Mary", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization in categorical columns", "Compute descriptive statistics for DowntimeMinutes", "Generate value counts for Cause and Shift columns", "Identify unique operators and count their records", "Analyze date formats and count missing dates"], "eda_results": {"missing_values": {"MachineID": 0, "Date": 1, "Shift": 0, "DowntimeMinutes": 2, "Cause": 0, "Operator": 1}, "standardized_categories": {"Shift": {"Day": 5, "Night": 5}, "Cause": {"Maintenance": 4, "Operator Error": 3, "Material Shortage": 2, "Breakdown": 2, "Setup": 1}, "Operator": {"John": 2, "Mary": 4, "Bob": 2, "Ann": 1, "Charlie": 1, "": 1}}, "summary_stats": {"DowntimeMinutes": {"count": 11, "mean": 34.55, "median": 35, "min": 15, "max": 60, "std_dev": 14.87}}, "value_counts": {"Cause": {"Maintenance": 4, "Operator Error": 3, "Material Shortage": 2, "Breakdown": 2, "Setup": 1}, "Shift": {"Day": 5, "Night": 5}}, "operator_counts": {"John": 2, "Mary": 4, "Bob": 2, "Ann": 1, "Charlie": 1, "Unknown": 1}, "date_format_analysis": {"formats_detected": ["YYYY/MM/DD", "YYYY-MM-DD", "MM-DD-YYYY", "YYYY/M/D", "Missing"], "missing_dates": 1}}}
{"purpose": "Analyze daily energy consumption patterns across different facility types and identify data quality issues.", "raw_table": "Date,Facility_Type,Energy_Consumed_kWh,Peak_Hour_Consumption_kWh,Region\n2024/01/01,Office,3500,550,North\n01-02-2024,Warehouse,4200,NA,South\n2024-01-03,office,3700,600,North\n2024-01-04,Manufacturing,8800,1200,East\n2024/01/05,Office,,580,North\n01-06-2024,Warehouse,4100,590,South\n2024-01-07,manufacturing,8650,1150,East\n2024-01-08,Office,3650,575,\n2024-01-09,Warehouse,4300,620,South\n2024/01/10,Office,3600,590,North\n2024-01-11,Manufacturing,,1180,East\n2024-01-12,Warehouse,4150,600,South", "eda_steps": ["Standardize date formats to YYYY-MM-DD", "Normalize Facility_Type capitalization", "Check and report missing values per column", "Compute descriptive statistics for Energy_Consumed_kWh and Peak_Hour_Consumption_kWh", "Generate value counts for Facility_Type and Region columns", "Identify rows with missing Energy_Consumed_kWh and Peak_Hour_Consumption_kWh", "Calculate correlation between Energy_Consumed_kWh and Peak_Hour_Consumption_kWh", "Determine top facility type by average energy consumption", "Summarize any unusual or missing Region entries"], "eda_results": {"missing_values": {"Date": 0, "Facility_Type": 0, "Energy_Consumed_kWh": 2, "Peak_Hour_Consumption_kWh": 1, "Region": 1}, "value_counts": {"Facility_Type": {"Office": 4, "Warehouse": 4, "Manufacturing": 3}, "Region": {"North": 4, "South": 4, "East": 3, "": 1}}, "summary_stats": {"Energy_Consumed_kWh": {"count": 11, "mean": 5136.36, "std": 2366.05, "min": 3500, "25%": 3700, "50%": 4150, "75%": 4300, "max": 8800}, "Peak_Hour_Consumption_kWh": {"count": 12, "mean": 718.33, "std": 246.29, "min": 550, "25%": 590, "50%": 600, "75%": 1150, "max": 1200}}, "correlations": {"Energy_Consumed_kWh_Peak_Hour_Consumption_kWh": 0.98}, "top_categories": {"Facility_Type_by_avg_energy": {"Manufacturing": 8816.67, "Warehouse": 4187.5, "Office": 3612.5}}, "data_quality_notes": "Date formats standardized from mixed formats. Facility_Type capitalization normalized. One missing Region entry found and one Peak_Hour_Consumption_kWh marked as 'NA'. Two missing Energy_Consumed_kWh values detected."}}
{"purpose": "Analyze machine downtime and defect rates in a manufacturing plant to identify potential issues.", "raw_table": "MachineID,OperationDate,DowntimeMinutes,DefectCount,Shift,Operator\nM101,2023-04-01,45,2,morning,John Doe\nM102,2023/04/01,,0,Evening,jane smith\nm103,04-02-2023,30,1,MOrning,alice j\nM101,2023-04-02,60,,night,John Doe\nM104,2023-04-02,25,3,afternoon,Bob K\nM102,2023/04/03,50,,evening,jane smith\nM103,2023-04-03,40,0,NIGHT,Alice J\nM105,2023-04-04,15,1,morning,Chris P\nM104,,35,2,Afternoon,bob k\nM101,2023-04-04,55,4,morning,John Doe\nM105,2023-04-04,abc,1,Morning,Chris P\nM102,2023-04-05,20,0,Evening,JANE SMITH", "eda_steps": ["Check for missing values in all columns", "Standardize date formats in OperationDate column", "Correct inconsistent capitalization in MachineID, Shift, and Operator columns", "Convert DowntimeMinutes and DefectCount to numeric and handle invalid entries", "Compute descriptive statistics for DowntimeMinutes and DefectCount", "Calculate value counts for Shift and Operator columns", "Identify total downtime and defect count per MachineID", "Compute correlation between DowntimeMinutes and DefectCount"], "eda_results": {"missing_values": {"MachineID": 0, "OperationDate": 1, "DowntimeMinutes": 2, "DefectCount": 2, "Shift": 0, "Operator": 0}, "standardized_dates": ["2023-04-01", "2023-04-01", "2023-04-02", "2023-04-02", "2023-04-02", "2023-04-03", "2023-04-03", "2023-04-04", null, "2023-04-04", "2023-04-04", "2023-04-05"], "cleaned_machine_ids": ["M101", "M102", "M103", "M101", "M104", "M102", "M103", "M105", "M104", "M101", "M105", "M102"], "cleaned_shifts": ["morning", "evening", "morning", "night", "afternoon", "evening", "night", "morning", "afternoon", "morning", "morning", "evening"], "cleaned_operators": ["John Doe", "Jane Smith", "Alice J", "John Doe", "Bob K", "Jane Smith", "Alice J", "Chris P", "Bob K", "John Doe", "Chris P", "Jane Smith"], "numeric_conversions": {"DowntimeMinutes": [45, null, 30, 60, 25, 50, 40, 15, 35, 55, null, 20], "DefectCount": [2, 0, 1, null, 3, null, 0, 1, 2, 4, 1, 0]}, "summary_stats": {"DowntimeMinutes": {"count": 10, "mean": 37.5, "std": 15.1, "min": 15, "25%": 27.5, "50%": 37.5, "75%": 50, "max": 60}, "DefectCount": {"count": 10, "mean": 1.4, "std": 1.4, "min": 0, "25%": 0.75, "50%": 1, "75%": 2.75, "max": 4}}, "value_counts": {"Shift": {"morning": 5, "evening": 3, "night": 2, "afternoon": 2}, "Operator": {"John Doe": 3, "Jane Smith": 3, "Alice J": 2, "Bob K": 2, "Chris P": 2}}, "total_by_machine": {"M101": {"total_downtime": 160, "total_defects": 6}, "M102": {"total_downtime": 70, "total_defects": 0}, "M103": {"total_downtime": 70, "total_defects": 1}, "M104": {"total_downtime": 60, "total_defects": 5}, "M105": {"total_downtime": 15, "total_defects": 2}}, "correlations": {"Downtime_vs_DefectCount": 0.68}}}
{"purpose": "Analyze crop yield and pesticide usage patterns across different farms to identify data quality issues and trends.", "raw_table": "FarmID,Crop,Planting_Date,Harvest_Date,Yield_kg,Pesticide_Used,Pesticide_Amount_litres\nF001,Wheat,2023-03-15,2023/08/20,1000,Yes,15\nf002,Corn,03/20/2023,08-25-2023,850,No,0\nF003,Rice,2023-03-18,,900,yes,12\nF004,Barley,2023-03-22,2023-08-30,NaN,NO,5\nF005,Wheat,March 25 2023,2023-09-01,1100,Yes,abc\nF006,corn,2023/03/27,08/29/2023,870,No,\nF007,Rice,2023-03-30,2023-09-05,920,Yes,10\nF008,barley,,2023/09/03,800,No,4\nF009,Wheat,2023-03-28,2023-09-02,1050,YES,14\nF010,Corn,2023-03-29,2023-09-06,880,no,0\n", "eda_steps": ["Check and count missing values for each column", "Standardize Crop names to consistent capitalization", "Convert Planting_Date and Harvest_Date to datetime objects, handling inconsistent formats", "Calculate the duration between Planting_Date and Harvest_Date in days", "Compute descriptive statistics for Yield_kg and Pesticide_Amount_litres after cleaning", "Generate value counts for Pesticide_Used", "Identify rows with invalid or missing numeric values like 'NaN' or 'abc' in Yield_kg and Pesticide_Amount_litres", "Compute correlation between Yield_kg and Pesticide_Amount_litres", "Find top 2 crops by average yield"], "eda_results": {"missing_values": {"FarmID": 0, "Crop": 0, "Planting_Date": 1, "Harvest_Date": 1, "Yield_kg": 1, "Pesticide_Used": 0, "Pesticide_Amount_litres": 2}, "standardized_crops": {"Wheat": 3, "Corn": 3, "Rice": 2, "Barley": 2}, "date_conversion_errors": {"Planting_Date": 0, "Harvest_Date": 0}, "duration_days": {"mean": 160, "min": 152, "max": 170, "missing": 1}, "descriptive_stats": {"Yield_kg": {"count": 9, "mean": 945.56, "std": 102.67, "min": 800, "max": 1100}, "Pesticide_Amount_litres": {"count": 8, "mean": 8.75, "std": 5.09, "min": 0, "max": 15}}, "value_counts_pesticide_used": {"Yes": 4, "No": 6}, "invalid_numeric_rows": {"Yield_kg": ["F004"], "Pesticide_Amount_litres": ["F005", "F006"]}, "correlations": {"Yield_kg_vs_Pesticide_Amount_litres": 0.68}, "top_crops_by_avg_yield": {"Wheat": 1050, "Rice": 910}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different cities to identify data quality issues and seasonal trends.", "raw_table": "City,Date,Avg_Temperature_C,Precipitation_mm,Weather_Condition\nNew york,2023-01-15,3.2,25.4,Rainy\nLos Angeles,15/01/2023,18.5,0,Sunny\nChicago,2023-02-20,-5.0,,Snowy\nhouston,2023/03/10,20.1,5.6,cloudy\nPhoenix,2023-03-15,25.6,0,Sunny\nNew york,2023-04-10,12.3,45.0,rainy\nlos angeles,2023-04-12,19.0,NaN,Sunny\nChicago,2023-04-25,10.2,10.2,Cloudy\nHouston,2023-05-05,23.5,2.0,Sunny\nPhoenix,2023-05-15,30.0,0,Sunny\nNew York,2023-06-10,,0,Sunny\nLOS ANGELES,2023-06-15,22.0,0,Sunny\nChicago,2023-06-20,15.0,15.0,Sunny\nhouston,2023-06-25,28.5,NaN,Sunny\nPhoenix,2023-06-30,35.2,-1,Sunny", "eda_steps": ["Check and standardize date formats", "Identify and count missing values per column", "Standardize city names capitalization", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Weather_Condition", "Check for invalid precipitation values (e.g., negative numbers)", "Calculate correlation between Avg_Temperature_C and Precipitation_mm", "Identify months with highest average temperature per city"], "eda_results": {"missing_values": {"Avg_Temperature_C": 1, "Precipitation_mm": 3, "Weather_Condition": 0, "City": 0, "Date": 0}, "standardized_cities": {"New York": 3, "Los Angeles": 3, "Chicago": 3, "Houston": 3, "Phoenix": 3}, "date_formats_standardized": true, "descriptive_stats": {"Avg_Temperature_C": {"count": 14, "mean": 18.72, "std": 12.17, "min": -5.0, "25%": 10.2, "50%": 19.0, "75%": 28.5, "max": 35.2}, "Precipitation_mm": {"count": 11, "mean": 12.64, "std": 16.68, "min": -1, "25%": 0, "50%": 0, "75%": 15.0, "max": 45.0}}, "weather_condition_counts": {"Sunny": 9, "Rainy": 2, "cloudy": 1, "Cloudy": 1, "Snowy": 1}, "invalid_precipitation_values": {"negative_values": 1}, "temperature_precipitation_correlation": -0.32, "highest_avg_temp_month_per_city": {"New York": "April", "Los Angeles": "June", "Chicago": "June", "Houston": "June", "Phoenix": "June"}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones.", "raw_table": "Date,Location,Climate_Zone,Avg_Temperature_C,Precipitation_mm\n2024-01-15,Denver,Temperate,3.5,12\n2024/02/15,boston,temperate,1.2,25\n2024-03-15,miami,Tropical,24.1,85\n15-04-2024,Seattle,Temperate,,30\n2024-05-15,los angeles,Arid,19.3,0\n2024-06-15,PHOENIX,arid,33.2,2\n2024-07-15,Anchorage,Subarctic,-5.0,15\n2024-08-15,Anchorage,subarctic,-3.2,18\n2024-09-15,Mexico City,TROPICAL,18.0,45\n2024-10-15,boston,temperate,10.3,\n2024/11/15,Denver,Temperate,0.0,5\n2024-12-15,los angeles,arid,14.1,1\n2024-12-32,Seattle,Temperate,7.0,20\n2024-13-01,miami,tropical,25.0,90", "eda_steps": ["Check and correct inconsistent date formats", "Standardize capitalization for Location and Climate_Zone columns", "Identify and count missing values in each column", "Compute descriptive statistics (mean, median, std) for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone", "Calculate correlations between Avg_Temperature_C and Precipitation_mm", "Identify rows with invalid dates", "Summarize temperature distribution by Climate_Zone", "List top 3 locations with highest average temperature"], "eda_results": {"missing_values": {"Date": 2, "Location": 0, "Climate_Zone": 0, "Avg_Temperature_C": 1, "Precipitation_mm": 2}, "invalid_dates": ["2024-12-32", "2024-13-01"], "standardized_columns": {"Location": ["Denver", "Boston", "Miami", "Seattle", "Los Angeles", "Phoenix", "Anchorage", "Mexico City"], "Climate_Zone": ["Temperate", "Tropical", "Arid", "Subarctic"]}, "value_counts_climate_zone": {"Temperate": 5, "Tropical": 4, "Arid": 3, "Subarctic": 2}, "summary_stats": {"Avg_Temperature_C": {"mean": 11.7, "median": 10.3, "std_dev": 12.4, "min": -5.0, "max": 33.2}, "Precipitation_mm": {"mean": 26.4, "median": 15, "std_dev": 29.3, "min": 0, "max": 90}}, "correlations": {"Avg_Temperature_C_vs_Precipitation_mm": -0.25}, "temperature_by_climate_zone": {"Temperate": {"mean": 4.4, "std_dev": 3.1}, "Tropical": {"mean": 21.3, "std_dev": 3.4}, "Arid": {"mean": 22.2, "std_dev": 9.7}, "Subarctic": {"mean": -4.1, "std_dev": 1.3}}, "top_3_locations_highest_avg_temp": ["Phoenix (33.2 C)", "Miami (24.1 C)", "Mexico City (18.0 C)"]}}
{"purpose": "Examine public transportation usage patterns and service types across different city districts.", "raw_table": "District,Service_Type,Date,Passengers,Revenue,On_Time_Percentage\nDowntown,Bus,2023/01/15,1200,2400,95\nMidtown,Subway,15-01-2023,850,1700,88\nUptown,Bus,,600,1200,90\nDowntown,TrAm,2023-01-15,400,800,85\nmidtown,BuS,2023/1/16,NaN,1500,92\nUptown,Subway,16/01/2023,700,,89\nDowntown,Bus,2023/01/16,1300,2600,96\nEastside,Bus,2023-01-15,300,600,80\nEastside,Subway,2023/1/15,450,900,83\nWESTSIDE,Bus,2023/01/15,NaN,500,78\nWestside,tram,2023-01-16,200,400,82\nMidtown,Tram,2023/01/16,500,1000,87\nUptown,bus,2023/01/17,650,1300,91\nDowntown,Subway,17/01/2023,1000,2000,94", "eda_steps": ["Standardize the capitalization of categorical variables 'District' and 'Service_Type'.", "Identify and count missing values in each column.", "Convert 'Date' column to a consistent date format and parse invalid dates.", "Compute descriptive statistics for numeric columns: Passengers, Revenue, and On_Time_Percentage.", "Generate value counts for 'District' and 'Service_Type'.", "Calculate the correlation matrix between numeric variables.", "Identify top 2 districts by total passenger numbers.", "Summarize missing data impact on revenue and passengers."], "eda_results": {"missing_values": {"District": 0, "Service_Type": 0, "Date": 1, "Passengers": 2, "Revenue": 2, "On_Time_Percentage": 0}, "value_counts": {"District": {"Downtown": 4, "Midtown": 3, "Uptown": 4, "Eastside": 2, "Westside": 2}, "Service_Type": {"Bus": 6, "Subway": 4, "Tram": 3}}, "summary_stats": {"Passengers": {"count": 12, "mean": 712.5, "std": 355.4, "min": 200, "25%": 450, "50%": 650, "75%": 1000, "max": 1300}, "Revenue": {"count": 13, "mean": 1446.15, "std": 722.27, "min": 400, "25%": 900, "50%": 1300, "75%": 2000, "max": 2600}, "On_Time_Percentage": {"count": 14, "mean": 88.21, "std": 5.33, "min": 78, "25%": 83, "50%": 89, "75%": 92, "max": 96}}, "correlations": {"Passengers_vs_Revenue": 0.998, "Passengers_vs_On_Time_Percentage": -0.23, "Revenue_vs_On_Time_Percentage": -0.19}, "top_categories": {"Top_2_Districts_By_Passengers": {"Downtown": 3900, "Uptown": 1950}}, "date_parsing": {"Invalid_or_missing_dates_corrected": 1, "Date_range_start": "2023-01-15", "Date_range_end": "2023-01-17"}}}
{"purpose": "Analyze customer purchase behavior and product category performance in a retail store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,TotalPrice,PaymentMethod\n1001,Cust01,2023-01-12,electronics,2,299.99,599.98,Credit Card\n1002,cust02,01/15/2023,Fashion,1,49.95,49.95,cash\n1003,,2023/01/18,Electronics,1,,299.99,credit card\n1004,Cust03,2023-01-20,Home & Garden,3,25.50,76.5,Debit Card\n1005,Cust04,2023-1-22,Fashion,2,49.95,99.9,Cash\n1006,Cust05,2023-01-25,beauty,1,15.00,15.0,creditCard\n1007,Cust06,2023-01-27,Electronics,2,299.99,599.98,Credit card\n1008,Cust07,01-28-2023,home & garden,1,25.50,25.5,Debit card\n1009,Cust08,2023/01/30,TOYS,5,9.99,49.95,Cash\n1010,Cust09,2023-02-01,Fashion,,49.95,,Credit card\n1011,Cust10,2023-02-03,sports,2,79.99,159.98,Credit Card\n1012,Cust11,2023-02-05,Beauty,3,15.00,45.0,CREDIT CARD\n1013,Cust12,2023-02-07,Toys,2,9.99,19.98,cash\n1014,Cust13,2023-02-10,Fashion,1,49.95,49.95,Credit Card", "eda_steps": ["Check for and summarize missing values in each column", "Standardize capitalization for categorical columns such as ProductCategory and PaymentMethod", "Convert OrderDate entries to a consistent date format", "Compute descriptive statistics for numeric columns Quantity, UnitPrice, and TotalPrice", "Generate value counts for PaymentMethod and ProductCategory after cleaning", "Identify any inconsistent or unusual categories in ProductCategory", "Calculate the total sales (sum of TotalPrice) per ProductCategory", "Analyze the distribution of Quantity purchased", "Check for correlation between Quantity, UnitPrice, and TotalPrice"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 0, "ProductCategory": 0, "Quantity": 2, "UnitPrice": 1, "TotalPrice": 2, "PaymentMethod": 0}, "cleaned_categories": {"ProductCategory": ["Electronics", "Fashion", "Home & Garden", "Beauty", "Toys", "Sports"], "PaymentMethod": ["Credit Card", "Cash", "Debit Card"]}, "value_counts": {"PaymentMethod": {"Credit Card": 7, "Cash": 4, "Debit Card": 2}, "ProductCategory": {"Fashion": 4, "Electronics": 3, "Home & Garden": 2, "Beauty": 2, "Toys": 2, "Sports": 1}}, "descriptive_statistics": {"Quantity": {"count": 13, "mean": 1.92, "std": 1.3, "min": 1, "25%": 1, "50%": 2, "75%": 2, "max": 5}, "UnitPrice": {"count": 13, "mean": 89.9, "std": 127.99, "min": 9.99, "25%": 15.0, "50%": 49.95, "75%": 299.99, "max": 299.99}, "TotalPrice": {"count": 12, "mean": 164.89, "std": 222.04, "min": 15.0, "25%": 49.95, "50%": 76.5, "75%": 99.9, "max": 599.98}}, "total_sales_per_category": {"Electronics": 1499.95, "Fashion": 299.7, "Home & Garden": 102.0, "Beauty": 60.0, "Toys": 69.93, "Sports": 159.98}, "quantity_distribution": {"1": 7, "2": 4, "3": 2, "5": 1}, "correlations": {"Quantity_UnitPrice": -0.12, "Quantity_TotalPrice": 0.85, "UnitPrice_TotalPrice": 0.88}}}
{"purpose": "Analyze stock trading patterns and identify anomalies in transaction volumes and prices.", "raw_table": "Trade_ID,Trade_Date,Stock_Symbol,Trade_Volume,Trade_Price,Trade_Type\nT001,2023-01-15,APPL,100,150.25,buy\nT002,15/01/2023,aapl,200,,SELL\nT003,2023/01/16,GOOGL,150,2800.5,buy\nT004,01-17-2023,msft,,305.0,BUY\nT005,2023-01-18,TSLA,300,900.1,Sell\nT006,2023-01-19,googl,100,2785.0,Buy\nT007,2023-01-19,MSFT,250,310.5,sell\nT008,2023-01-20,AAPL,NaN,152.0,buy\nT009,2023-01-20,TSLA,400,890.4,BUY\nT010,20-01-2023,TSLA,350,NaN,sell\nT011,,MSFT,100,307.0,buy\nT012,2023-01-22,GOOGL,,2820.0,Sell\nT013,2023-01-22,aapl,150,153.2,Buy\nT014,01/23/2023,TSLA,200,895.5,SELL", "eda_steps": ["Check and summarize missing values in each column", "Standardize Trade_Date column to a consistent date format", "Normalize capitalization in Stock_Symbol and Trade_Type columns", "Compute descriptive statistics for Trade_Volume and Trade_Price", "Generate value counts for Trade_Type and Stock_Symbol columns", "Calculate correlation between Trade_Volume and Trade_Price", "Identify trades with missing or zero Trade_Volume or Trade_Price", "Summarize unique trade dates after cleaning"], "eda_results": {"missing_values": {"Trade_ID": 0, "Trade_Date": 1, "Stock_Symbol": 0, "Trade_Volume": 3, "Trade_Price": 2, "Trade_Type": 0}, "standardized_dates": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18", "2023-01-19", "2023-01-19", "2023-01-20", "2023-01-20", "2023-01-20", null, "2023-01-22", "2023-01-22", "2023-01-23"], "normalized_categories": {"Stock_Symbol": ["AAPL", "GOOGL", "MSFT", "TSLA"], "Trade_Type": ["BUY", "SELL"]}, "summary_stats": {"Trade_Volume": {"count": 11, "mean": 218.18, "std": 99.86, "min": 100, "25%": 150, "50%": 200, "75%": 300, "max": 400}, "Trade_Price": {"count": 12, "mean": 879.33, "std": 1151.34, "min": 150.25, "25%": 305, "50%": 307, "75%": 900.1, "max": 2820}}, "value_counts": {"Trade_Type": {"BUY": 7, "SELL": 7}, "Stock_Symbol": {"AAPL": 4, "GOOGL": 3, "MSFT": 3, "TSLA": 4}}, "correlations": {"Trade_Volume_Trade_Price": -0.18}, "anomalies": {"missing_trade_volume": ["T004", "T008", "T012"], "missing_trade_price": ["T002", "T010"]}, "unique_trade_dates_count": 9}}
{"purpose": "Analyze customer call patterns and service usage to identify potential churn indicators.", "raw_table": "CustomerID,CallDuration,CallDate,ServicePlan,DataUsageGB,Churn\n1001,300,2023/01/05,premium,5.2,No\n1002,,01-07-2023,Standard,3.1,Yes\n1003,450,2023-01-09,PREMIUM,NaN,no\n1004,200,1/10/23,basic,1.0,No\n1005,120,2023/01/11,Basic,0.8,yes\n1006,350,2023-13-01,standard,2.7,No\n1007,NaN,2023/01/12,Premium,4.5,No\n1008,180,01/13/2023,standard,,Yes\n1009,240,2023/01/14,basic,1.2,No\n1010,210,2023/01/15,PREMIUM,5.0,Yes\n1011,260,2023-01-16,Standard,3.0,No\n1012,NaN,01/17/2023,basic,0.5,No", "eda_steps": ["Check missing value percentages for each column", "Standardize the ServicePlan and Churn columns to consistent capitalization", "Parse and unify CallDate to a single date format", "Compute descriptive statistics for CallDuration and DataUsageGB", "Generate value counts for ServicePlan and Churn", "Identify the top 2 ServicePlans by customer count", "Calculate correlation between CallDuration and DataUsageGB", "Analyze average CallDuration grouped by Churn status", "Summarize distribution skewness for CallDuration"], "eda_results": {"missing_values": {"CustomerID": 0, "CallDuration": 3, "CallDate": 1, "ServicePlan": 0, "DataUsageGB": 2, "Churn": 0}, "standardized_columns": {"ServicePlan_unique_values": ["premium", "standard", "basic"], "Churn_unique_values": ["yes", "no"]}, "date_format_issues": {"invalid_dates_found": ["2023-13-01"]}, "summary_stats": {"CallDuration": {"count": 9, "mean": 258.89, "std": 96.22, "min": 120, "25%": 200, "50%": 240, "75%": 300, "max": 450, "skewness": 0.42}, "DataUsageGB": {"count": 11, "mean": 2.81, "std": 1.77, "min": 0.5, "25%": 1.0, "50%": 2.7, "75%": 5.0, "max": 5.2}}, "value_counts": {"ServicePlan": {"basic": 4, "standard": 4, "premium": 3}, "Churn": {"no": 7, "yes": 5}}, "top_categories": {"top_2_ServicePlans": ["basic", "standard"]}, "correlations": {"CallDuration_vs_DataUsageGB": 0.87}, "grouped_analysis": {"average_CallDuration_by_Churn": {"yes": 225, "no": 280.71}}, "distribution_skewness": {"CallDuration": 0.42}}}
{"purpose": "Explore patient demographics and clinical measurements to identify data quality issues and summarize key statistics in a cardiology outpatient dataset.", "raw_table": "PatientID,Age,Gender,BloodPressure,Cholesterol,VisitDate,Diagnosis\n001,45,Male,120/80,200,2023-01-15,Hypertension\n002,52,FEMALE,130/85,NA,15/02/2023,hyperTension\n003,38,M,115/75,180,2023/03/01,Normal\n004,,female,140/90,220,2023-03-10, Prehypertension\n005,60,Male,NA,250,2023-04-05,Hypertension\n006,47,female,125/82,190,2023-04-15,\n007,55,,135/88,210,04-20-2023,Hypertension\n008,43,Female,118/78,195,2023-04-22,Normal\n009,50,Male,130/85,,2023-04-30,hyperTension\n010,59,Female,142/95,230,2023-05-02,Hypertension\n011,46,male,128/84,205,2023-05-05,Prehypertension\n012,41,Female,NA,185,2023-05-10,Normal", "eda_steps": ["Check for missing values in each column", "Standardize the Gender column values to a consistent format", "Convert VisitDate to a uniform date format", "Split BloodPressure into systolic and diastolic numeric columns", "Compute descriptive statistics for Age, systolic and diastolic blood pressure, and Cholesterol", "Generate value counts for Diagnosis after standardizing the labels", "Identify rows with inconsistent or missing patient demographics", "Calculate the percentage of patients diagnosed with Hypertension or related conditions", "Plot the distribution of Age grouped by Diagnosis category"], "eda_results": {"missing_values": {"PatientID": 0, "Age": 1, "Gender": 1, "BloodPressure": 2, "Cholesterol": 2, "VisitDate": 0, "Diagnosis": 1}, "standardized_gender_counts": {"Male": 5, "Female": 6, "Unknown": 1}, "visit_date_range": {"min": "2023-01-15", "max": "2023-05-10"}, "blood_pressure_split_sample": {"Systolic": [120, 130, 115, 140, null, 125, 135, 118, 130, 142, 128, null], "Diastolic": [80, 85, 75, 90, null, 82, 88, 78, 85, 95, 84, null]}, "summary_stats": {"Age": {"count": 11, "mean": 49.5, "min": 38, "max": 60}, "SystolicBP": {"count": 10, "mean": 128.3, "min": 115, "max": 142}, "DiastolicBP": {"count": 10, "mean": 83.2, "min": 75, "max": 95}, "Cholesterol": {"count": 10, "mean": 206.5, "min": 180, "max": 250}}, "diagnosis_value_counts": {"Hypertension": 5, "Prehypertension": 2, "Normal": 3, "Unknown": 1}, "data_quality_issues": {"missing_age": ["004"], "missing_gender": ["007"], "missing_blood_pressure": ["005", "012"], "missing_cholesterol": ["002", "009"], "missing_diagnosis": ["006"]}, "hypertension_related_percentage": 58.3}}
{"purpose": "Analyze ridership patterns and operational delays across different bus routes in a metropolitan area.", "raw_table": "Route,Date,Passengers,Delay_minutes,Driver,Bus_Type\n12A,2023/02/01,45,5,john smith,Standard\n7b,02-02-2023,NA,0,MARY JONES,Express\n12a,2023-02-03,50,seven,John Smith,standard\n7B,2023/02/04,38,3,MARY jones,Express\n15C,02/05/2023,42,,Alice Cooper,MiniBus\n15c,2023-02-06,missing,2,Alice cooper,minibus\n7b,2023/02/07,40,1,Mary Jones,Express\n12A,2023-2-08,48,4,John smith,Standard\n15C,02-09-2023,43,0,Alice Cooper,miniBus\n7b,2023/02/10,39,NA,MARY jones,Express\n", "eda_steps": ["Check for and count missing values in each column", "Standardize date formats to YYYY-MM-DD", "Normalize categorical columns: Route, Driver, and Bus_Type for consistent capitalization", "Convert 'Passengers' and 'Delay_minutes' to numeric, handling non-numeric and missing values", "Generate descriptive statistics for numeric columns: Passengers and Delay_minutes", "Calculate value counts for the Route and Bus_Type columns", "Identify unique drivers and count trips per driver", "Calculate average delay per route", "Find correlation between Passengers and Delay_minutes"], "eda_results": {"missing_values": {"Route": 0, "Date": 0, "Passengers": 2, "Delay_minutes": 2, "Driver": 0, "Bus_Type": 0}, "standardized_dates": ["2023-02-01", "2023-02-02", "2023-02-03", "2023-02-04", "2023-02-05", "2023-02-06", "2023-02-07", "2023-02-08", "2023-02-09", "2023-02-10"], "normalized_categories": {"Route": ["12a", "7b", "15c"], "Driver": ["john smith", "mary jones", "alice cooper"], "Bus_Type": ["standard", "express", "minibus"]}, "passengers_stats": {"count": 8, "mean": 43.625, "std": 4.271, "min": 38, "25%": 40, "50%": 43, "75%": 48, "max": 50}, "delay_minutes_stats": {"count": 8, "mean": 2.5, "std": 2.16, "min": 0, "25%": 0.75, "50%": 2, "75%": 4.25, "max": 7}, "value_counts": {"Route": {"7b": 4, "12a": 3, "15c": 3}, "Bus_Type": {"express": 4, "standard": 3, "minibus": 3}}, "driver_trip_counts": {"john smith": 3, "mary jones": 4, "alice cooper": 3}, "average_delay_per_route": {"7b": 1.0, "12a": 5.33, "15c": 1.0}, "correlation_passengers_delay": -0.12}}
{"purpose": "Evaluate the quality control and production output of manufacturing batches over time.", "raw_table": "BatchID,Production_Date,Shift,Operator,Defective_Items,Total_Items,Machine_Status\nB001,2023-01-15,Morning,john doe,5,100,Running\nB002,15/01/2023,Evening,Jane Smith,NA,105,RUNNING\nb003,2023/01/16,NIGHT,alice,j,95,Stopped\nB004,2023-01-17,Morning,Bob Lee,3,100,running\nB005,01-18-2023,morning,Carol,0,100,Running\nB006,2023-01-18,,dan,2,100,Running\nB007,2023-01-19,Evening,jane smith,4,100,STOPPED\nB008,2023-01-20,Night,ALICE,1,,Running\nB009,2023-01-21,Night,John Doe,0,100,Running\nB010,,Morning,Carol,3,100,Running", "eda_steps": ["Standardize date formats in the Production_Date column", "Fill or identify missing values in Defective_Items, Total_Items, Shift, and Production_Date columns", "Normalize capitalization in Operator and Machine_Status columns", "Compute descriptive statistics for Defective_Items and Total_Items columns", "Generate value counts for Shift, Machine_Status, and Operator columns", "Calculate the defect rate (Defective_Items / Total_Items) for each batch where possible", "Identify batches with missing or inconsistent data", "Analyze correlation between defect rate and Machine_Status", "Summarize counts of defective items by shift"], "eda_results": {"missing_values": {"Production_Date": 1, "Shift": 1, "Defective_Items": 2, "Total_Items": 1}, "value_counts": {"Shift": {"Morning": 4, "Evening": 2, "Night": 3, "": 1}, "Machine_Status": {"Running": 7, "Stopped": 2}, "Operator": {"John Doe": 2, "Jane Smith": 2, "Alice": 2, "Bob Lee": 1, "Carol": 2, "Dan": 1}}, "summary_stats": {"Defective_Items": {"count": 8, "mean": 2.25, "std": 1.89, "min": 0, "25%": 0.75, "50%": 2.5, "75%": 3.0, "max": 5}, "Total_Items": {"count": 9, "mean": 99.44, "std": 3.11, "min": 95, "25%": 98.75, "50%": 100, "75%": 100, "max": 105}}, "defect_rates": {"B001": 0.05, "B002": null, "B003": null, "B004": 0.03, "B005": 0.0, "B006": 0.02, "B007": 0.04, "B008": null, "B009": 0.0, "B010": 0.03}, "correlations": {"defect_rate_vs_machine_status": {"Running": 0.02, "Stopped": 0.035}}, "defects_by_shift": {"Morning": 10, "Evening": 4, "Night": 1, "Missing": 0}, "data_quality_issues": {"Defective_Items_non_numeric": ["B003"], "Missing_Defective_Items": ["B002"], "Missing_Total_Items": ["B008"], "Missing_Production_Date": ["B010"], "Missing_Shift": ["B006"]}}}
{"purpose": "Analyze monthly transaction patterns and customer segments for a retail bank.", "raw_table": "TransactionID,CustomerID,TransactionDate,TransactionType,Amount,Branch,CustomerSegment\n1001,C001,2023-01-05,Deposit,500.00,New York,Retail\n1002,c002,01/12/2023,withdrawal,200,los angeles,Corporate\n1003,C003,2023/01/15,DEPOSIT,1500.75,Chicago,Retail\n1004,C004,2023-1-20,Payment,,San Francisco,retail\n1005,C005,15-Jan-2023,Withdrawal,350.5,NEW york,SME\n1006,C006,,Deposit,1000.00,Chicago,corporate\n1007,c007,2023-01-22,Deposit,abc,Los Angeles,Retail\n1008,C008,2023-01-25,withdrawal,700,San francisco,SME\n1009,C009,2023-01-30,Payment,450.25,New york,Retail\n1010,C010,2023-02-01,Deposit,800,Chicago,Retail\n1011,C011,2023-02-05,Withdrawal,400,los Angeles,Corporate\n1012,C012,2023-02-10,Payment,300,San Francisco,Retail\n1013,C013,,deposit,2500,Chicago,SME\n1014,C014,2023-02-15,Withdrawal,600,,Corporate\n", "eda_steps": ["Check for missing values in each column", "Standardize the date format in TransactionDate column", "Convert Amount to numeric and identify non-numeric entries", "Generate value counts for TransactionType and CustomerSegment", "Calculate descriptive statistics for Amount", "Identify number of transactions per Branch", "Analyze transaction counts per month", "Check correlations between Amount and CustomerSegment categories"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 0, "TransactionDate": 2, "TransactionType": 0, "Amount": 2, "Branch": 1, "CustomerSegment": 0}, "standardized_dates": ["2023-01-05", "2023-01-12", "2023-01-15", "2023-01-20", "2023-01-15", null, "2023-01-22", "2023-01-25", "2023-01-30", "2023-02-01", "2023-02-05", "2023-02-10", null, "2023-02-15"], "non_numeric_amount_entries": [{"TransactionID": 1007, "Amount": "abc"}, {"TransactionID": 1004, "Amount": ""}], "value_counts": {"TransactionType": {"Deposit": 6, "Withdrawal": 5, "Payment": 3}, "CustomerSegment": {"Retail": 7, "Corporate": 4, "SME": 3}}, "summary_stats_amount": {"count": 12, "mean": 741.56, "std": 652.12, "min": 200, "25%": 400, "50%": 600, "75%": 1000, "max": 2500}, "transactions_per_branch": {"New York": 3, "Los Angeles": 3, "Chicago": 4, "San Francisco": 3, "": 1}, "transactions_per_month": {"2023-01": 9, "2023-02": 5}, "correlations": {"Amount and CustomerSegment": {"Retail": 620.18, "Corporate": 550.0, "SME": 1150.42}}}}
{"purpose": "Analyze customer purchase behavior and order trends in an ecommerce store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod,DeliveryStatus\n1001,C123,2023-01-15,Electronics,2,299.99,Credit Card,Delivered\n1002,C124,15/01/2023,Home & garden,1,49.50,PayPal,delivered\n1003,C125,,Books,3,15.00,CREDIT CARD,Pending\n1004,C126,2023-01-18,Clothing,NaN,25.00,Cash,Delivered\n1005,c127,2023-01-20,Electronics,1,NaN,credit card,Cancelled\n1006,C128,2023/01/21,Toys,4,19.99,Paypal,Delivered\n1007,C129,01-22-2023,Books,2,15.00,Cash,delivered\n1008,,2023-01-23,Electronics,1,299.99,Credit card,Pending\n1009,C131,2023-01-24,HOME & GARDEN,2,49.50,Paypal,Delivered\n1010,C132,2023-01-25,Clothing,3,25.00,,Delivered\n1011,C133,2023-01-26,Toys,NaN,19.99,Credit Card,Cancelled\n1012,C134,2023-01-27,Books,1,15.00,Credit Card,Delivered\n1013,C135,2023-01-28,,2,100.00,Credit Card,Delivered", "eda_steps": ["Check for and summarize missing values in each column", "Standardize date formats in OrderDate column", "Clean and unify capitalization in ProductCategory and PaymentMethod columns", "Compute descriptive statistics for Quantity and UnitPrice columns", "Generate value counts for ProductCategory and DeliveryStatus columns", "Identify unique customers and count their orders", "Calculate total sales amount per order (Quantity * UnitPrice)", "Summarize payment methods distribution", "Check correlation between Quantity and UnitPrice"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 1, "ProductCategory": 1, "Quantity": 2, "UnitPrice": 1, "PaymentMethod": 1, "DeliveryStatus": 0}, "standardized_dates": ["2023-01-15", "2023-01-15", null, "2023-01-18", "2023-01-20", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24", "2023-01-25", "2023-01-26", "2023-01-27", "2023-01-28"], "cleaned_product_categories": {"Electronics": 3, "Home & Garden": 2, "Books": 4, "Clothing": 2, "Toys": 2, "Unknown": 1}, "cleaned_payment_methods": {"Credit Card": 6, "PayPal": 3, "Cash": 2, "Unknown": 1}, "quantity_stats": {"count": 11, "mean": 2.09, "min": 1, "max": 4, "missing": 2}, "unit_price_stats": {"count": 12, "mean": 84.66, "min": 15.0, "max": 299.99, "missing": 1}, "product_category_counts": {"Books": 4, "Electronics": 3, "Home & Garden": 2, "Clothing": 2, "Toys": 2, "Unknown": 1}, "delivery_status_counts": {"Delivered": 8, "Pending": 2, "Cancelled": 2}, "unique_customers": 12, "orders_per_customer": {"1": 11, "2": 1}, "total_sales_per_order": {"1001": 599.98, "1002": 49.5, "1003": null, "1004": null, "1005": null, "1006": 79.96, "1007": 30.0, "1008": 299.99, "1009": 99.0, "1010": 75.0, "1011": null, "1012": 15.0, "1013": 200.0}, "payment_method_distribution": {"Credit Card": 46.15, "PayPal": 23.08, "Cash": 15.38, "Unknown": 7.69, "Missing": 7.69}, "correlation_quantity_unitprice": -0.12}}
{"purpose": "Examine citizen service request patterns and identify common issues reported to a city government office.", "raw_table": "Request_ID,Request_Type,Date_Received,Status,Priority,Department,Response_Time_days\n1001,Pothole,2023-01-15,Closed,High,Public Works,3\n1002,streetlight outage,15/01/2023,Closed,medium,public Works,5\n1003,Graffiti,2023-02-03,Open,LOW,Community Affairs,\n1004,Blocked sewer,02-10-2023,Closed,High,Public works,2\n1005,Pothole,2023/02/15,closed,Medium,Public Works,4\n1006,Trash Pickup,2023-02-20,Open,,Sanitation, \n1007,Water Leak,2023-02-22,Closed,High,Water Services,1\n1008,STREETLIGHT OUTAGE,2023-02-25,Closed,Medium,Public Works,6\n1009,Graffiti,,Open,Low,Community affairs, \n1010,Trash pickup,02/28/2023,Closed,Medium,Sanitation,3\n1011,Blocked Sewer,2023-03-01,Closed,High,Public Works,2\n1012,Water Leak,03-05-2023,Open,High,Water Services, \n1013,Pothole,2023-03-07,Closed,High,Public Works,3\n1014,graffiti,2023/03/10,Closed,Low,Community Affairs,7", "eda_steps": ["Standardize capitalization in 'Request_Type' and 'Department' columns", "Parse 'Date_Received' into consistent date format and identify missing dates", "Check for missing values in all columns and calculate percentages", "Compute descriptive statistics for 'Response_Time_days' including mean and median", "Generate value counts for 'Request_Type' and 'Status'", "Identify top 3 departments by number of requests", "Analyze the distribution of 'Priority' levels", "Calculate average response time per 'Request_Type'", "Summarize count of open vs closed requests over time"], "eda_results": {"missing_values": {"Request_ID": 0, "Request_Type": 0, "Date_Received": 1, "Status": 0, "Priority": 2, "Department": 0, "Response_Time_days": 3}, "value_counts": {"Request_Type": {"Pothole": 4, "Streetlight Outage": 2, "Graffiti": 3, "Blocked Sewer": 2, "Trash Pickup": 2, "Water Leak": 2}, "Status": {"Closed": 10, "Open": 4}}, "top_departments": {"Public Works": 7, "Community Affairs": 3, "Sanitation": 2, "Water Services": 2}, "priority_distribution": {"High": 7, "Medium": 5, "Low": 3, "Missing": 2}, "response_time_stats": {"mean_response_time_days": 3.57, "median_response_time_days": 3, "response_time_missing_count": 3}, "average_response_time_by_request_type": {"Pothole": 3.0, "Streetlight Outage": 5.5, "Graffiti": 7.0, "Blocked Sewer": 2.0, "Trash Pickup": 3.0, "Water Leak": 1.0}, "date_received_issues": {"unique_date_formats_found": 4, "missing_dates": 1}, "open_vs_closed_over_time": {"Closed_requests": 10, "Open_requests": 4}}}
{"purpose": "Analyze sales performance and customer purchasing patterns for different product categories over recent months.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod\n1001,C123,2023-01-05,Electronics,2,199.99,Credit Card\n1002,c124,01/15/2023,clothing,1,49.5,credit card\n1003,C125,2023/01/20,Home & Kitchen,,89.99,PayPal\n1004,C126,2023-02-05,electronics,3,199.99,CASH\n1005,C127,,Clothing,2,NaN,PayPal\n1006,C128,2023-02-18,Toys,5,15.0,credit card\n1007,C129,2023-02-20,home & kitchen,1,69.99,cash\n1008,C130,2023-03-01,Toys,NaN,15.0,Paypal\n1009,C131,03-05-2023,Electronics,1,199.99,Credit Card\n1010,C132,2023-03-07,clothing,2,49.50,Cash\n1011,C133,2023-03-10,Books,3,9.99,Credit card\n1012,C134,2023-03-12,books,1,9.99,credit card\n1013,C135,2023-03-15,TOYS,4,15.0,Cash", "eda_steps": ["Check for missing values in all columns", "Standardize capitalization in ProductCategory and PaymentMethod columns", "Convert OrderDate to a consistent date format", "Calculate total sales amount per order (Quantity * UnitPrice)", "Generate descriptive statistics for Quantity, UnitPrice, and total sales", "Compute value counts for ProductCategory", "Identify the most frequently used PaymentMethod", "Analyze sales trends over months based on OrderDate"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 0, "OrderDate": 1, "ProductCategory": 0, "Quantity": 2, "UnitPrice": 1, "PaymentMethod": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home & Kitchen", "Toys", "Books"], "PaymentMethod": ["Credit Card", "Cash", "PayPal"]}, "date_conversion_issues": 0, "descriptive_statistics": {"Quantity": {"count": 11, "mean": 2.27, "std": 1.48, "min": 1, "max": 5}, "UnitPrice": {"count": 12, "mean": 74.49, "std": 81.76, "min": 9.99, "max": 199.99}, "TotalSales": {"count": 10, "mean": 194.14, "std": 192.85, "min": 9.99, "max": 599.97}}, "value_counts": {"ProductCategory": {"Electronics": 3, "Clothing": 3, "Home & Kitchen": 2, "Toys": 3, "Books": 2}, "PaymentMethod": {"Credit Card": 5, "Cash": 4, "PayPal": 3}}, "top_payment_method": "Credit Card", "sales_trends": {"2023-01": 449.48, "2023-02": 469.95, "2023-03": 655.92}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones to identify data quality issues and basic statistics.", "raw_table": "Date,Climate_Zone,Avg_Temperature_C,Precipitation_mm\n2023-01-01,Tropical,30.5,120\n2023-01-15,Temperate, 15.2,45\n2023/02/01,Arid,28,NA\n2023-02-15,TROPICAL,,130\nMarch 5, 2023,Temperate,13.8,50.5\n2023-03-20,Subtropical,22.1,80\n2023-04-01,Arid,27,10\n2023-04-15,subtropical,missing,90\n2023-05-01,Tropical,31.2,110\n2023-05-15,Temperate,16,55\n2023-06-01,Arid,29,5\n2023-06-15,Tropical,30.8,115\n2023-07-01,Subtropical,23,85\n2023-07-15,Temperate,17.5,60\n2023-08-01,TROPICAL,29.9,125", "eda_steps": ["Check and report missing values in each column", "Standardize date format to YYYY-MM-DD", "Normalize Climate_Zone capitalization and identify unique categories", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm ignoring missing values", "Generate value counts for Climate_Zone", "Identify rows with non-numeric or missing temperature values", "Calculate correlation between Avg_Temperature_C and Precipitation_mm", "Summarize the range of dates covered in the dataset"], "eda_results": {"missing_values": {"Date": 0, "Climate_Zone": 0, "Avg_Temperature_C": 2, "Precipitation_mm": 1}, "unique_climate_zones": ["Tropical", "Temperate", "Arid", "Subtropical"], "value_counts_climate_zone": {"Tropical": 5, "Temperate": 4, "Arid": 3, "Subtropical": 3}, "date_range": {"min_date": "2023-01-01", "max_date": "2023-08-01"}, "descriptive_stats": {"Avg_Temperature_C": {"count": 13, "mean": 23.77, "std_dev": 6.03, "min": 13.8, "max": 31.2}, "Precipitation_mm": {"count": 14, "mean": 74.64, "std_dev": 44.06, "min": 5, "max": 130}}, "rows_with_invalid_temperature": [7, 4], "correlation": {"Avg_Temperature_C_vs_Precipitation_mm": -0.15}}}
{"purpose": "Analyze customer purchase behavior and product category distribution for a retail store.", "raw_table": "OrderID,CustomerID,ProductCategory,Quantity,UnitPrice,PurchaseDate,PaymentMethod\n1001,C001,Electronics,2,299.99,2023-02-15,Credit card\n1002,c002,Clothing,1,49.5,15/02/2023,CASH\n1003,C003,Home & Garden,3,NaN,2023/02/16,credit Card\n1004,C004,clothing,NaN,25.0,2023-02-17,Debit Card\n1005,C002,Electronics,1,199.99,2023-2-18,Cash\n1006,C005,Toys,5,15.99,2023-02-18,credit card\n1007,c006,Electronics,2,299.99,02-19-2023,Debit card\n1008,C007,TOYS,NaN,15.99,2023-02-20,Credit Card\n1009,C008,Home & Garden,1,89.99,2023-02-20,Credit card\n1010,C001,Clothing,3,49.5,2023-2-21,Cash\n1011,C009,Unknown,1,0,2023-02-22,Credit Card\n1012,C010,Home & garden,2,85.0,2023-02-23,Debit card", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization in ProductCategory and PaymentMethod columns", "Compute descriptive statistics for Quantity and UnitPrice", "Calculate total sales per ProductCategory", "Identify the number of unique customers", "Generate value counts for PaymentMethod", "Analyze date formats and standardize PurchaseDate into YYYY-MM-DD", "Calculate the correlation between Quantity and UnitPrice"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 0, "ProductCategory": 0, "Quantity": 3, "UnitPrice": 1, "PurchaseDate": 0, "PaymentMethod": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home & Garden", "Clothing", "Electronics", "Toys", "Electronics", "Toys", "Home & Garden", "Clothing", "Unknown", "Home & Garden"], "PaymentMethod": ["Credit Card", "Cash", "Credit Card", "Debit Card", "Cash", "Credit Card", "Debit Card", "Credit Card", "Credit Card", "Cash", "Credit Card", "Debit Card"]}, "descriptive_stats": {"Quantity": {"count": 9, "mean": 2.22, "std": 1.25, "min": 1, "25%": 1.5, "50%": 2, "75%": 3, "max": 5}, "UnitPrice": {"count": 11, "mean": 110.53, "std": 127.83, "min": 0, "25%": 15.99, "50%": 49.5, "75%": 199.99, "max": 299.99}}, "total_sales_per_category": {"Electronics": 1799.93, "Clothing": 248.25, "Home & Garden": 348.99, "Toys": 79.95, "Unknown": 0}, "unique_customers": 10, "payment_method_counts": {"Credit Card": 6, "Cash": 3, "Debit Card": 3}, "purchase_date_format_standardized": true, "correlation_quantity_unitprice": 0.35}}
{"purpose": "Analyze customer call behavior and service usage patterns in a telecom dataset to identify potential issues and popular services.", "raw_table": "CustomerID,CallDuration,CallType,ServicePlan,CallDate,DataUsageMB,Region\n1001,  12, Local, Basic, 2023-03-15, 50, north\n1002,5,international,PREMIUM,15/03/2023, ,South\n1003,,Local,Basic,2023/03/16, 20, EAST\n1004,30,Local,,March 17 2023,40,north\n1005,22,Local,Premium,2023-03-18,35,South\n1006,NA,INTERNATIONAL,basic,2023-3-19,10,west\n1007,8,Local,Basic,2023-03-20,NA,West\n1008,25,International,PREMIUM,03-21-2023,80,East\n1009,18,local,Premium,2023-03-22,,south\n1010,10,,Basic,2023-03-23,15,north", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize capitalization in categorical columns: CallType, ServicePlan, and Region", "Parse and unify CallDate into a consistent date format", "Compute descriptive statistics for numeric columns: CallDuration and DataUsageMB", "Generate value counts for CallType and ServicePlan", "Identify the top 2 Regions by number of calls", "Calculate correlation between CallDuration and DataUsageMB where data is available"], "eda_results": {"missing_values": {"CustomerID": "0%", "CallDuration": "20%", "CallType": "10%", "ServicePlan": "10%", "CallDate": "0%", "DataUsageMB": "30%", "Region": "0%"}, "standardized_categories": {"CallType": {"Local": 6, "International": 3, "Missing": 1}, "ServicePlan": {"Basic": 4, "Premium": 4, "Missing": 1}, "Region": {"North": 3, "South": 3, "East": 2, "West": 2}}, "date_range": {"min_date": "2023-03-15", "max_date": "2023-03-23"}, "summary_stats": {"CallDuration": {"count": 8, "mean": 15.0, "median": 14.0, "min": 5, "max": 30}, "DataUsageMB": {"count": 7, "mean": 35.7, "median": 35, "min": 10, "max": 80}}, "value_counts": {"CallType": {"Local": 6, "International": 3, "Missing": 1}, "ServicePlan": {"Basic": 4, "Premium": 4, "Missing": 1}}, "top_regions": {"North": 3, "South": 3}, "correlations": {"CallDuration_vs_DataUsageMB": 0.86}}}
{"purpose": "Analyze student performance and attendance patterns to identify potential factors affecting grades.", "raw_table": "StudentID,Name,Grade,Attendance%,EnrollmentDate,Major,Extracurricular\n1001,john doe,88,95%,2023-01-15,Computer Science,football\n1002,Jane Smith,92,,15/01/2023,computer science,Basketball\n1003,Alice Johnson,85,87%,2023/01/16,Biology,Soccer\n1004,Bob Lee,missing,80%,01-17-2023,biology,Debate\n1005,Chris O'Neil,78,70%,2023-01-18,Engineering,\n1006,Diana Prince,90,90%,2023/1/19,ENGINEERING,Football\n1007,Edgar Allan,82,75%,2023-01-20,computer science,Basketball\n1008,Fiona Glenanne,,85%,2023-01-21,Biology,Chess\n1009,George Clark,88,88%,2023-01-22,engineering,BASEBALL\n1010,Hannah Lee,91,92%,2023-01-22,Computer science,debate", "eda_steps": ["Check missing values in each column", "Standardize and clean categorical columns for Major and Extracurricular", "Convert EnrollmentDate to consistent date format", "Compute descriptive statistics for Grade and Attendance%", "Generate value counts for Major", "Identify students with missing Grade or Attendance%", "Compute correlation between Grade and Attendance%", "Summarize unique counts of Extracurricular activities"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 0, "Grade": 2, "Attendance%": 1, "EnrollmentDate": 0, "Major": 0, "Extracurricular": 1}, "value_counts": {"Major": {"Computer Science": 4, "Biology": 3, "Engineering": 3}, "Extracurricular": {"Football": 2, "Basketball": 2, "Soccer": 1, "Debate": 2, "": 1, "Chess": 1, "Baseball": 1}}, "descriptive_stats": {"Grade": {"count": 8, "mean": 86.75, "std_dev": 5.03, "min": 78, "max": 92}, "Attendance%": {"count": 9, "mean": 85.78, "std_dev": 7.17, "min": 70, "max": 95}}, "correlations": {"Grade_Attendance%": 0.67}, "cleaned_dates_sample": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18"], "students_with_missing": {"Grade": ["1004", "1008"], "Attendance%": ["1002"], "Extracurricular": ["1005"]}, "unique_extracurricular_count": 7}}
{"purpose": "Analyze user engagement patterns and post characteristics on a social media platform.", "raw_table": "post_id,user_id,post_date,post_type,likes,comments,shares,content_length\n1,U123,2023-01-15,Image,25,3,5,120\n2,u124,15-01-2023,video,50,7,,300\n3,U125,2023/01/16,Text,15,,2,85\n4,U126,,IMAGE,40,5,10,150\n5,u127,2023-01-17,Video,NaN,8,3,400\n6,U128,2023-1-18,text,10,1,0,60\n7,u129,2023-01-18,Image,35,,7,130\n8,U130,01/19/2023,Video,45,6,4,310\n9,u131,2023-01-20,Poll,12,0,0,40\n10,U132,2023-01-21,text,8,1,1,75\n11,u133,2023-01-22,image,30,4,6,110\n12,U134,2023-01-22,text,NaN,2,1,50\n13,U135,,Video,55,9,8,320\n14,u136,2023-01-23,IMAGE,28,3,2,140", "eda_steps": ["Check for missing values in all columns", "Standardize post_type values to lowercase", "Convert post_date to a consistent date format", "Compute descriptive statistics for numeric columns: likes, comments, shares, content_length", "Generate value counts for post_type", "Identify posts with missing post_date", "Calculate average likes, comments, and shares by post_type", "Find the post with the longest content_length", "Check correlation between likes, comments, and shares"], "eda_results": {"missing_values": {"post_id": 0, "user_id": 0, "post_date": 2, "post_type": 0, "likes": 2, "comments": 2, "shares": 1, "content_length": 0}, "post_type_value_counts": {"image": 5, "video": 5, "text": 4, "poll": 1}, "posts_missing_post_date": [4, 13], "descriptive_statistics": {"likes": {"count": 12, "mean": 29.5, "std": 14.7, "min": 8, "25%": 15, "50%": 30, "75%": 45, "max": 55}, "comments": {"count": 12, "mean": 4.0, "std": 2.8, "min": 0, "25%": 2, "50%": 3.5, "75%": 6, "max": 9}, "shares": {"count": 13, "mean": 4.0, "std": 3.3, "min": 0, "25%": 1, "50%": 4, "75%": 6, "max": 10}, "content_length": {"count": 14, "mean": 152.9, "std": 97.9, "min": 40, "25%": 75, "50%": 130, "75%": 310, "max": 400}}, "average_engagement_by_post_type": {"image": {"likes": 31.6, "comments": 3.8, "shares": 6.0}, "video": {"likes": 48.0, "comments": 7.5, "shares": 5.0}, "text": {"likes": 11.0, "comments": 1.5, "shares": 1.0}, "poll": {"likes": 12.0, "comments": 0.0, "shares": 0.0}}, "post_with_longest_content": {"post_id": 5, "content_length": 400}, "correlations": {"likes_comments": 0.85, "likes_shares": 0.75, "comments_shares": 0.68}}}
{"purpose": "Analyze customer call patterns and service usage to identify data quality issues and usage trends.", "raw_table": "CustomerID,CallDate,CallDuration,ServiceType,Region,PaymentMethod\n001,2024-01-10,300,voice,North,credit card\n002,01/15/2024,NA,DATA,South,Cash\n003,2024/01/18,180,Voice,East,credit card\n004,2024-01-20,240,Voice,north,Cash\n005,,200,Data,West,credit card\n006,2024-01-22,abc,voice,South,credit card\n007,2024-01-25,150,Data,East,cash\n008,2024-1-28,210,VOICE,West,credit Card\n009,2024-02-01,230,,North,Credit card\n010,02-03-2024,220,voice,South,Credit Card\n011,2024-02-05,190,Voice,East,CASH\n012,2024-02-07,250,data,west,Credit Card\n", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in 'ServiceType' and 'Region' columns", "Convert 'CallDate' to a consistent date format", "Identify and handle non-numeric values in 'CallDuration' column", "Compute descriptive statistics for 'CallDuration'", "Generate value counts for 'ServiceType' and 'PaymentMethod'", "Summarize records with missing 'CallDate' or 'ServiceType'", "Analyze distribution of calls by 'Region'", "Compute correlation between 'CallDuration' and 'Region' (encoded numerically)"], "eda_results": {"missing_values": {"CustomerID": 0, "CallDate": 1, "CallDuration": 1, "ServiceType": 1, "Region": 0, "PaymentMethod": 0}, "standardized_categories": {"ServiceType": ["voice", "data", "NA"], "Region": ["North", "South", "East", "West"]}, "call_date_format_consistency": "All dates converted to YYYY-MM-DD format except 1 missing", "call_duration_clean": {"non_numeric_entries": ["abc"], "missing_after_cleaning": 2}, "summary_stats": {"CallDuration": {"count": 11, "mean": 212.73, "std": 43.95, "min": 150, "25%": 190, "50%": 220, "75%": 240, "max": 300}}, "value_counts": {"ServiceType": {"voice": 7, "data": 4, "NA": 1}, "PaymentMethod": {"credit card": 7, "cash": 4}}, "missing_summary": {"rows_missing_CallDate": [5], "rows_missing_ServiceType": [9]}, "region_distribution": {"North": 3, "South": 3, "East": 3, "West": 3}, "correlations": {"CallDuration_vs_RegionEncoded": 0.12}}}
{"purpose": "Analyze sales performance and customer demographics for a retail store over a two-week period.", "raw_table": "OrderID,CustomerName,ProductCategory,Quantity,Price,OrderDate,Region\n1001,john doe,Electronics,2,399.99,2023-04-01,North\n1002,Jane Smith,Fashion,1,59.99,4/2/2023,South\n1003,jim beam,Electronics,,199.99,2023/04/03,East\n1004,ANNA KAREN,Home & Garden,3,29.99,04-04-2023,west\n1005,,fashion,2,49.99,2023-04-05,South\n1006,Chris P,Electronics,1,abc,2023-04-06,North\n1007,Linda Lee,Fashion,5,39.99,2023-4-07,East\n1008,Mark Z,Home & garden,1,89.99,04/08/2023,West\n1009,Sara K,Fashion,2,59.99,2023-04-09,South\n1010,Tommy H,Electronics,4,299.99,2023/04/10,North\n1011,Emma W,Home & Garden,NaN,39.99,2023-04-11,West\n1012,Bob T,FASHION,3,49.99,2023-04-12,South\n1013,Lucy P,Electronics,2,199.99,4-13-2023,East\n1014,NaN,Fashion,1,59.99,2023-04-14,South", "eda_steps": ["Check for missing values in each column", "Standardize ProductCategory values and count unique categories", "Convert OrderDate to a consistent date format", "Calculate total sales amount per order (Quantity x Price)", "Generate descriptive statistics for Quantity, Price, and total sales", "Count number of orders per Region", "Identify orders with invalid or missing Quantity or Price", "Find the top 3 most sold products categories by total quantity"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerName": 2, "ProductCategory": 0, "Quantity": 2, "Price": 1, "OrderDate": 0, "Region": 0}, "standardized_categories": {"Electronics": 5, "Fashion": 6, "Home & Garden": 3}, "date_format_conversion": "All dates successfully converted to YYYY-MM-DD format", "invalid_entries": {"Quantity_missing_or_invalid": [1003, 1011], "Price_missing_or_invalid": [1006]}, "descriptive_statistics": {"Quantity": {"count": 12, "mean": 2.58, "min": 1, "max": 5}, "Price": {"count": 13, "mean": 89.22, "min": 29.99, "max": 399.99}, "TotalSales": {"count": 12, "mean": 159.24, "min": 29.99, "max": 799.98}}, "orders_per_region": {"North": 3, "South": 5, "East": 3, "West": 3}, "top_3_categories_by_quantity": {"Fashion": 12, "Electronics": 9, "Home & Garden": 4}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones to identify data quality issues and basic statistical summaries.", "raw_table": "Date,ClimateZone,Temperature_C,Precipitation_mm\n2023-01-15,Tropical,29.5,150\n2023/02/15,temperate,12.3,85\n2023-03-15,Arctic,-15.2,5.2\n2023-04-15,Temperate,14.1,NaN\n2023-05-15,TROPICAL,31.0,200\n2023-06-15,arctic,-12.5,3.1\n2023-07-15,Temperate,17.0,90\n2023-08-15,tropical,30.2,180\n2023-09-15,Temperate,,70\n2023-10-15,Arctic,-10.0,2.5\n15-11-2023,Tropical,28.7,160\n2023-12-15,Temperate,10.5,missing\n", "eda_steps": ["Standardize the ClimateZone values to consistent capitalization.", "Convert Date column to a uniform date format.", "Check and report the number and percentage of missing values in each column.", "Calculate summary statistics (mean, median, min, max) for Temperature_C and Precipitation_mm.", "Generate value counts for the ClimateZone categories.", "Identify rows with non-numeric or missing precipitation values.", "Calculate the correlation between Temperature_C and Precipitation_mm where data is complete.", "List top 2 months with highest precipitation in the Tropical zone."], "eda_results": {"missing_values": {"Date": 0, "ClimateZone": 0, "Temperature_C": 1, "Precipitation_mm": 2}, "value_counts": {"ClimateZone": {"Tropical": 4, "Temperate": 5, "Arctic": 3}}, "summary_stats": {"Temperature_C": {"mean": 14.47, "median": 14.1, "min": -15.2, "max": 31.0}, "Precipitation_mm": {"mean": 94.64, "median": 87.5, "min": 2.5, "max": 200}}, "data_quality_issues": {"Precipitation_mm": ["Row 4 has NaN", "Row 11 has 'missing'"], "Temperature_C": ["Row 9 missing value"]}, "correlations": {"Temperature_C_vs_Precipitation_mm": 0.45}, "top_precipitation_tropical_months": [{"Date": "2023-05-15", "Precipitation_mm": 200}, {"Date": "2023-08-15", "Precipitation_mm": 180}]}}
{"purpose": "Assess quality control issues and production delays in a manufacturing assembly line.", "raw_table": "BatchID,Production_Date,Operator,Machine_ID,Defect_Count,Shift,Production_Time_Minutes\nB101,2024-01-15,mary,MX1001,3,Day,120\nB102,15/01/2024,John,MX1002,0,Night,115\nb103,2024/01/16,mary,MX1001,,Day,118\nB104,2024-01-16,ALICE,MX1003,2,day,130\nB105,01-17-2024,John,MX1002,1,Night,not recorded\nb106,2024-01-18,Mary,MX1001,4,DAY,125\nB107,,alice,MX1003,0,Night,110\nB108,2024-1-19,John,MX1002,2,night,117\nB109,2024-01-20,Mary,MX1001,1,Day,123\nB110,2024-01-20,Alice,MX1003,3,NIGHT,112\nB111,2024-01-21,John,MX1002,0,day,119\nB112,2024-01-21,Mary,,2,Day,121\nB113,2024-01-22,Alice,MX1003,1,night,118", "eda_steps": ["Check the data types and convert dates to a consistent format", "Identify and quantify missing values in each column", "Standardize categorical columns: Operator and Shift", "Compute descriptive statistics for numeric columns: Defect_Count and Production_Time_Minutes", "Generate value counts for the Operator and Shift columns", "Analyze the distribution of Defect_Count by Machine_ID", "Check for outliers in Production_Time_Minutes", "Calculate correlation between Defect_Count and Production_Time_Minutes", "Identify batches with missing or inconsistent Production_Date", "Summarize counts of unique Machine_IDs"], "eda_results": {"missing_values": {"BatchID": 0, "Production_Date": 1, "Operator": 0, "Machine_ID": 1, "Defect_Count": 1, "Shift": 0, "Production_Time_Minutes": 1}, "value_counts": {"Operator": {"Mary": 4, "John": 4, "Alice": 4}, "Shift": {"Day": 6, "Night": 6}}, "summary_stats": {"Defect_Count": {"count": 13, "mean": 1.62, "std": 1.39, "min": 0, "25%": 0, "50%": 1, "75%": 3, "max": 4}, "Production_Time_Minutes": {"count": 13, "mean": 118.77, "std": 6.15, "min": 110, "25%": 115, "50%": 118, "75%": 123, "max": 130}}, "defects_by_machine": {"MX1001": {"mean_defects": 2.0, "count": 5}, "MX1002": {"mean_defects": 0.75, "count": 4}, "MX1003": {"mean_defects": 1.5, "count": 4}, "missing": 1}, "outliers_in_production_time": {"lower_bound": 95.36, "upper_bound": 141.42, "outliers": []}, "correlations": {"Defect_Count_vs_Production_Time_Minutes": -0.15}, "inconsistent_dates": ["B107"], "unique_machine_ids_count": 3}}
{"purpose": "Analyze customer call patterns and service usage in a telecom dataset to identify data quality issues and usage trends.", "raw_table": "CustomerID,CallDate,CallDuration,ServiceType,Region,CustomerAge\nC001,2023-01-05,300,Voice,North,34\nc002,01/15/2023,NaN,DATA,South,28\nC003,2023/01/20,120,voice,East,NA\nC004,2023-01-22,45,VOICE,west,42\nc005,,180,Data,North,25\nC006,2023-1-30,60,Voice,South,Thirty\nC007,2023-02-01,200,Video,East,31\nc008,2/5/2023,NaN,data,West,29\nC009,2023-02-07,90,VOiCe,North,40\nC010,2023-02-10,150,,South,35\nC011,2023-02-15,85,Voice,unknown,38\nC012,2023-02-18,NaN,Video,East,44", "eda_steps": ["Check and report missing values in each column", "Standardize the ServiceType column to lowercase", "Parse and unify CallDate into yyyy-mm-dd format", "Convert CustomerAge to numeric, handling non-numeric entries", "Generate descriptive statistics for CallDuration and CustomerAge", "Count the frequency of each ServiceType", "Identify unique regions and count their occurrences", "Summarize the distribution of call durations by service type", "Find correlation between CustomerAge and CallDuration where applicable"], "eda_results": {"missing_values": {"CustomerID": 0, "CallDate": 1, "CallDuration": 3, "ServiceType": 1, "Region": 1, "CustomerAge": 2}, "service_type_standardized_counts": {"voice": 6, "data": 3, "video": 2, "": 1}, "regions_counts": {"north": 3, "south": 3, "east": 3, "west": 2, "unknown": 1}, "call_duration_stats": {"count": 9, "mean": 130, "std_dev": 73.2, "min": 45, "max": 300}, "customer_age_stats": {"count": 10, "mean": 34.4, "std_dev": 5.6, "min": 25, "max": 44}, "call_duration_by_service": {"voice": {"count": 6, "mean": 149, "min": 45, "max": 300}, "data": {"count": 2, "mean": 180, "min": 180, "max": 180}, "video": {"count": 1, "mean": 200, "min": 200, "max": 200}}, "correlation_age_duration": 0.55}}
{"purpose": "Analyze sales performance and customer purchasing patterns over a two-week period.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod\n1001,C001,2023-03-01,Electronics,2,299.99,Credit Card\n1002,c002,03/02/2023,home Appliances,1,89.5,credit card\n1003,C003,2023/03/03,Electronics,NaN,199.99,PayPal\n1004,C004,3-4-2023,Clothing,3,25.0,Debit Card\n1005,C005,2023-03-05,Furniture,1,two hundred,Credit Card\n1006,C001,2023-3-06,Electronics,1,299.99,Credit Card\n1007,C006,,Sports,4,49.99,Paypal\n1008,C007,2023-03-08,clothing,2,30,Debit Card\n1009,C008,2023-03-09,Home appliances,1,90.0,Credit Card\n1010,C009,2023-March-10,Electronics,1,299.99,Credit Card\n1011,C010,2023-03-11,Furniture,1,210.0,Credit Card\n1012,C002,2023-03-12,Toys,NaN,15.0,Credit card\n1013,C011,03/13/2023,Clothing,2,27.5,Debit card\n1014,C012,2023-03-14,Sports,1,50,Paypal\n", "eda_steps": ["Check and summarize missing values in each column", "Standardize the capitalization of categorical columns (ProductCategory, PaymentMethod)", "Parse OrderDate into a consistent date format", "Compute descriptive statistics for Quantity and UnitPrice columns", "Generate value counts for ProductCategory and PaymentMethod columns", "Identify rows with invalid or non-numeric UnitPrice values", "Calculate total sales amount per order (Quantity * UnitPrice) and summarize", "Analyze the distribution of orders over the dates", "Identify top 3 ProductCategories by number of orders"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 0, "OrderDate": 1, "ProductCategory": 0, "Quantity": 2, "UnitPrice": 1, "PaymentMethod": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Home Appliances", "Electronics", "Clothing", "Furniture", "Electronics", "Sports", "Clothing", "Home Appliances", "Electronics", "Furniture", "Toys", "Clothing", "Sports"], "PaymentMethod": ["Credit Card", "Credit Card", "PayPal", "Debit Card", "Credit Card", "Credit Card", "PayPal", "Debit Card", "Credit Card", "Credit Card", "Credit Card", "Credit Card", "Debit Card", "PayPal"]}, "parsed_dates": {"earliest": "2023-03-01", "latest": "2023-03-14", "missing_count": 1}, "descriptive_stats": {"Quantity": {"count": 12, "mean": 1.75, "std": 1.05, "min": 1, "25%": 1, "50%": 1.5, "75%": 2.5, "max": 4}, "UnitPrice": {"count": 13, "mean": 129.91, "std": 113.82, "min": 15.0, "25%": 27.5, "50%": 89.5, "75%": 299.99, "max": 299.99}}, "value_counts": {"ProductCategory": {"Electronics": 5, "Clothing": 3, "Home Appliances": 2, "Furniture": 2, "Sports": 2, "Toys": 1}, "PaymentMethod": {"Credit Card": 7, "Debit Card": 3, "PayPal": 3}}, "invalid_unitprice_rows": [{"OrderID": "1005", "UnitPrice": "two hundred"}], "total_sales_summary": {"count": 12, "mean": 254.91, "min": 15.0, "max": 599.98, "sum": 3058.9}, "order_distribution_by_date": {"2023-03-01": 1, "2023-03-02": 1, "2023-03-03": 1, "2023-03-04": 1, "2023-03-05": 1, "2023-03-06": 1, "2023-03-08": 1, "2023-03-09": 1, "2023-03-10": 1, "2023-03-11": 1, "2023-03-12": 1, "2023-03-13": 1, "2023-03-14": 1}, "top_3_product_categories": {"Electronics": 5, "Clothing": 3, "Home Appliances": 2}}}
{"purpose": "Analyze real estate listing data to understand property characteristics and identify data quality issues.", "raw_table": "Listing_ID,Price,Location,Property_Type,Bedrooms,Bathrooms,Area_sqft,Date_Listed\n101,350000,New york,Apartment,2,1,850,2023-05-01\n102,450000,los angeles,House,3,2,1200,05/15/2023\n103,,Chicago,Apartment,,1,900,2023-06-01\n104,550000,Houston,Townhouse,4,3,1500,2023-05-20\n105,480000,new york,House,3,,1300,2023/05/25\n106,380000,los angeles,apartment,2,1,870,May 30, 2023\n107,NA,Miami,Condo,2,2,1100,2023-06-05\n108,600000,CHICAGO,House,4,3,1600,2023-06-07\n109,420000,houston,Townhouse,3,2,,2023-05-18\n110,375000,miami,Apartment,2,1,850,06-01-2023\n111,520000,New York,House,3,2,1400,2023-05-28\n112,440000,los angeles,Condo,2,2,1000,2023-05-22\n113,460000,Chicago,house,3,2,1250,2023/06/03\n114,390000,MIAmi,Apartment,2,1,880,2023-06-02\n", "eda_steps": ["Check missing value percentages for each column", "Standardize capitalization for Location and Property_Type columns", "Compute descriptive statistics for numeric columns: Price, Bedrooms, Bathrooms, Area_sqft", "Generate value counts for Property_Type and Location", "Identify inconsistent date formats in Date_Listed and standardize them", "Calculate correlation matrix between numeric features", "Identify top 3 most common Property_Type categories", "Summarize number of listings per Location"], "eda_results": {"missing_values": {"Listing_ID": "0%", "Price": "7.1% (1 missing, 1 'NA')", "Location": "0%", "Property_Type": "0%", "Bedrooms": "7.1% (1 missing)", "Bathrooms": "14.3% (2 missing)", "Area_sqft": "14.3% (2 missing)", "Date_Listed": "0%"}, "value_counts": {"Property_Type": {"Apartment": 5, "House": 5, "Townhouse": 2, "Condo": 2}, "Location": {"new york": 3, "los angeles": 3, "chicago": 3, "houston": 2, "miami": 3}}, "descriptive_statistics": {"Price": {"count": 12, "mean": 457916.67, "std": 74626.72, "min": 350000, "25%": 380000, "50%": 450000, "75%": 520000, "max": 600000}, "Bedrooms": {"count": 13, "mean": 2.92, "std": 0.75, "min": 2, "25%": 2, "50%": 3, "75%": 3, "max": 4}, "Bathrooms": {"count": 12, "mean": 1.75, "std": 0.62, "min": 1, "25%": 1, "50%": 2, "75%": 2, "max": 3}, "Area_sqft": {"count": 12, "mean": 1187.5, "std": 287.4, "min": 850, "25%": 870, "50%": 1200, "75%": 1400, "max": 1600}}, "date_format_issues": ["05/15/2023", "2023/05/25", "May 30, 2023", "2023/06/03", "06-01-2023"], "correlations": {"Price-Bedrooms": 0.85, "Price-Bathrooms": 0.79, "Price-Area_sqft": 0.92, "Bedrooms-Bathrooms": 0.88, "Bedrooms-Area_sqft": 0.83, "Bathrooms-Area_sqft": 0.78}, "top_categories": {"Property_Type": ["Apartment", "House", "Townhouse"]}, "listings_per_location": {"new york": 3, "los angeles": 3, "chicago": 3, "houston": 2, "miami": 3}}}
{"purpose": "Examine recent temperature and precipitation patterns across different climate zones to identify data quality issues and seasonal trends.", "raw_table": "Date,Location,Climate_Zone,Temperature_C,Precipitation_mm\n2023-01-15,Tahoe,Temperate,3.5,12\n2023/02/20,tahoe,temperate,4.1,7\n2023-03-10,Tahoe,,7.8,0\n2023-04-05,Death Valley,Arid,35.2,0\n2023-05-11,Death valley,arid,40.1,2\n2023-06-20,Amazon,Tropical,29.5,150\n2023-07-15,Amazon,tropical,31,missing\n07-25-2023,amazon,TROPICAL,30.1,200\n2023-08-30,Antarctica,Polar,-25.3,\n2023-09-12,antarctica,polar,-20.7,0\n2023-10-01,Antarctica,Polar,-15.6,1\n2023-11-15,Sahara,Arid,42,0\n2023-12-05,sahara,Arid,39.8,0\n", "eda_steps": ["Standardize the date format to YYYY-MM-DD", "Normalize capitalization for Location and Climate_Zone columns", "Check and report missing values in each column", "Calculate descriptive statistics for Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone", "Identify rows with inconsistent or missing Climate_Zone entries", "Examine correlation between Temperature_C and Precipitation_mm", "Analyze seasonal temperature averages per Climate_Zone", "Detect and handle 'missing' string values in numeric columns"], "eda_results": {"missing_values": {"Date": 0, "Location": 0, "Climate_Zone": 1, "Temperature_C": 0, "Precipitation_mm": 2}, "value_counts": {"Climate_Zone": {"Temperate": 2, "Arid": 4, "Tropical": 3, "Polar": 3, "": 1}}, "summary_stats": {"Temperature_C": {"count": 14, "mean": 20.83, "std": 21.17, "min": -25.3, "25%": 3.5, "50%": 7.8, "75%": 35.15, "max": 42}, "Precipitation_mm": {"count": 12, "mean": 30.25, "std": 63.47, "min": 0, "25%": 0, "50%": 1, "75%": 12, "max": 200}}, "inconsistent_climate_zone_rows": [3], "correlations": {"Temperature_C_Precipitation_mm": -0.42}, "seasonal_temperature_averages": {"Temperate": {"Winter": 3.8, "Spring": 7.8}, "Arid": {"Spring": 37.65, "Winter": 40.9}, "Tropical": {"Summer": 30.2}, "Polar": {"Summer": -17.15, "Winter": -25.3}}}}
{"purpose": "Analyze daily energy consumption patterns and identify missing data issues in household electricity usage.", "raw_table": "Date,Household_ID,Energy_Consumed_kWh,Energy_Source,Day_Type\n2024-01-01,H001,35.2,solar,Weekday\n01/02/2024,h002,42.1,Wind,Weekday\n2024/01/03,H003,,solar,Weekend\n2024-01-04,H001,38.5,wind,Weekday\n05-01-2024,H002,40.0,Solar,Weekday\n2024-01-06,H003,NaN,coal,Weekend\n2024-01-07,H001,37.8,Coal,Weekend\n2024-1-8,h002,44.3,solar,Weekday\n2024-01-09,H003,39.5,Wind,Weekday\n2024-01-10,H001,41.0,wind,Weekday\n2024-01-11,H002,invalid,solar,Weekend\n2024-01-12,H003,38.7,Coal,Weekday", "eda_steps": ["Parse and standardize the Date column into a consistent date format", "Check for missing or invalid values in the Energy_Consumed_kWh column", "Compute descriptive statistics for Energy_Consumed_kWh", "Generate value counts for Energy_Source and Day_Type columns", "Identify inconsistent capitalization in categorical columns and standardize them", "Calculate the number of missing values per column", "Analyze the distribution of energy consumption by Energy_Source", "Check for any outliers or invalid numeric entries in Energy_Consumed_kWh", "Summarize energy consumption averages for Weekday vs Weekend"], "eda_results": {"missing_values": {"Date": 0, "Household_ID": 0, "Energy_Consumed_kWh": 3, "Energy_Source": 0, "Day_Type": 0}, "value_counts": {"Energy_Source": {"solar": 5, "wind": 4, "coal": 3}, "Day_Type": {"Weekday": 8, "Weekend": 4}}, "summary_stats": {"Energy_Consumed_kWh": {"count": 9, "mean": 39.9, "std_dev": 2.8, "min": 35.2, "max": 44.3}}, "invalid_entries": {"Energy_Consumed_kWh": ["NaN", "", "invalid"]}, "energy_consumption_by_day_type": {"Weekday_avg_kWh": 40.2, "Weekend_avg_kWh": 37.7}}}
{"purpose": "Analyze housing market characteristics and identify data quality issues in property listings.", "raw_table": "PropertyID,ListingDate,Price,Area_sqft,Bedrooms,Location,PropertyType,AgentName\n101,2023-01-15,350000,1200,3,Downtown,Condo,John Smith\n102,15/02/2023,450000,1500,4,Uptown,House,Mary-Jane\n103,2023/03/01,NaN,1100,3,midtown,Condo,ANNA\n104,2023-03-10,500000,1600,4,,Apartment,David\n105,03-20-2023,NaN,1400,3,Suburb,House,Chris\n106,2023-04-01,375000,NaN,2,Downtown,condo,\n107,2023-04-15,420000,1300,3,Suburb,House,John Smith\n108,2023-04-25,NaN,1250,3,Uptown,House,Mary-Jane\n109,2023-05-01,390000,1150,3,Downtown,Apartment,Anna\n110,2023-05-10,460000,1500,4,Uptown,house,David\n111,,480000,1700,4,Suburb,House,Chris\n", "eda_steps": ["Check missing value percentages for each column", "Standardize capitalization in Location and PropertyType columns", "Compute descriptive statistics for numeric columns Price and Area_sqft", "Generate value counts for categorical columns Location and PropertyType", "Identify top 2 agents by number of listings", "Summarize distribution skewness for Price", "Check for inconsistencies in ListingDate formats and count unique formats"], "eda_results": {"missing_values": {"PropertyID": 0, "ListingDate": 1, "Price": 3, "Area_sqft": 1, "Bedrooms": 0, "Location": 1, "PropertyType": 0, "AgentName": 1}, "standardized_categories": {"Location": ["Downtown", "Uptown", "Midtown", "Suburb", null], "PropertyType": ["Condo", "House", "Apartment"]}, "summary_stats": {"Price": {"count": 8, "mean": 427500, "std": 44915.62, "min": 350000, "25%": 375000, "50%": 420000, "75%": 460000, "max": 500000}, "Area_sqft": {"count": 10, "mean": 1375, "std": 183.58, "min": 1100, "25%": 1200, "50%": 1300, "75%": 1500, "max": 1700}}, "value_counts": {"Location": {"Downtown": 3, "Uptown": 3, "Suburb": 3, "Midtown": 1, "null": 1}, "PropertyType": {"House": 6, "Condo": 3, "Apartment": 2}}, "top_agents": {"John Smith": 2, "Mary-Jane": 2}, "price_skewness": 0.15, "listing_date_formats": {"YYYY-MM-DD": 8, "DD/MM/YYYY": 1, "YYYY/MM/DD": 1, "MM-DD-YYYY": 1, "missing": 1}}}
{"purpose": "Analyze monthly transaction patterns and customer segments in a retail banking dataset.", "raw_table": "Transaction_ID,Customer_ID,Transaction_Date,Transaction_Amount,Account_Type,Region\nT001,C101,2023-01-15,250.50,checking,North\nT002,C102,15/02/2023,,- savings ,south\nT003,C103,2023/03/10,800.00,CREDIT,East\nT004,C104,2023-04-22,1200,Checking,west\nT005,C105,2023-05-05,,credit,North\nT006,C106,06-15-2023,450.75,SAVINGS,South\nT007,C107,2023-07-01,300.00,checking,East\nT008,C108,2023-08-20,NaN,Credit,West\nT009,C109,2023-9-10,670,Savings,north\nT010,C110,2023-10-05,1000,checking,SOUTH\nT011,C111,2023-11-15,500,credit,east\nT012,C112,12/12/2023,350,CHECKING,west", "eda_steps": ["Check for missing values in each column", "Standardize the 'Account_Type' and 'Region' columns to uniform capitalization and spacing", "Parse 'Transaction_Date' into a consistent date format", "Compute descriptive statistics for 'Transaction_Amount'", "Generate value counts for 'Account_Type' and 'Region'", "Identify transactions with missing or invalid 'Transaction_Amount' and count them", "Calculate the number of transactions per month", "Compute correlation between 'Transaction_Amount' and month of transaction"], "eda_results": {"missing_values": {"Transaction_ID": 0, "Customer_ID": 0, "Transaction_Date": 0, "Transaction_Amount": 3, "Account_Type": 0, "Region": 0}, "standardized_categories": {"Account_Type": {"checking": 5, "savings": 3, "credit": 4}, "Region": {"north": 3, "south": 3, "east": 3, "west": 3}}, "transaction_date_format": "All dates converted to YYYY-MM-DD", "summary_stats": {"Transaction_Amount": {"count": 9, "mean": 619.94, "std": 321.11, "min": 250.5, "25%": 350, "50%": 500, "75%": 800, "max": 1200}}, "value_counts": {"Account_Type": {"checking": 5, "savings": 3, "credit": 4}, "Region": {"north": 3, "south": 3, "east": 3, "west": 3}}, "missing_or_invalid_amount_count": 3, "transactions_per_month": {"2023-01": 1, "2023-02": 1, "2023-03": 1, "2023-04": 1, "2023-05": 1, "2023-06": 1, "2023-07": 1, "2023-08": 1, "2023-09": 1, "2023-10": 1, "2023-11": 1, "2023-12": 1}, "correlations": {"Transaction_Amount_vs_Month": 0.25}}}
{"purpose": "Analyze real estate property listings to understand price distributions, missing data, and popular property types.", "raw_table": "ListingID,Price,PropertyType,Bedrooms,Bathrooms,SquareFeet,YearBuilt,Location,DateListed\n1,350000,Condo,2,1,900,2010,Downtown,2023-01-15\n2,480000,Single Family,3,2,1500,1998,Suburb,15/02/2023\n3,,Townhouse,3,,1200,2005,suburb,2023-03-01\n4,220000,condo,1,1,700,,DOWNTOWN,2023/04/10\n5,580000,Single family,4,3,2000,2015,Suburb,2023-03-20\n6,NaN,Apartment,1,1,650,2018,Uptown,03-25-2023\n7,310000,Townhouse,2,2,1100,2007,Uptown,2023-02-28\n8,425000,single family,3,2,1400,2000,Suburb,2023-04-01\n9,275000,Condo,2,1,850,2012,Downtown,2023-01-30\n10,NaN,Apartment,,1,700,2019,Uptown,2023-04-05\n11,500000,Single Family,3,2,1600,1995,suburb,2023-03-15\n12,360000,Condo,2,1,950,2011,Downtown,2023-02-20", "eda_steps": ["Check missing value percentages for each column", "Standardize the capitalization of PropertyType and Location columns", "Compute descriptive statistics for numeric columns: Price, Bedrooms, Bathrooms, SquareFeet, YearBuilt", "Generate value counts for PropertyType and Location", "Analyze the distribution of Price by PropertyType", "Examine the date formats in DateListed and standardize them", "Compute correlation matrix between numeric columns", "Identify top 2 most frequent PropertyType categories"], "eda_results": {"missing_values": {"ListingID": "0%", "Price": "16.67%", "PropertyType": "0%", "Bedrooms": "8.33%", "Bathrooms": "8.33%", "SquareFeet": "0%", "YearBuilt": "8.33%", "Location": "0%", "DateListed": "0%"}, "standardized_categories": {"PropertyType": ["Condo", "Single Family", "Townhouse", "Apartment"], "Location": ["Downtown", "Suburb", "Uptown"]}, "summary_stats": {"Price": {"count": 10, "mean": 386500, "std": 109733, "min": 220000, "25%": 310000, "50%": 360000, "75%": 480000, "max": 580000}, "Bedrooms": {"count": 11, "mean": 2.36, "std": 0.9, "min": 1, "25%": 2, "50%": 2, "75%": 3, "max": 4}, "Bathrooms": {"count": 11, "mean": 1.64, "std": 0.64, "min": 1, "25%": 1, "50%": 2, "75%": 2, "max": 3}, "SquareFeet": {"count": 12, "mean": 11708, "std": 427.91, "min": 650, "25%": 850, "50%": 1100, "75%": 1500, "max": 2000}, "YearBuilt": {"count": 11, "mean": 2005.18, "std": 7.84, "min": 1995, "25%": 2000, "50%": 2007, "75%": 2011, "max": 2018}}, "value_counts": {"PropertyType": {"Condo": 4, "Single Family": 4, "Townhouse": 2, "Apartment": 2}, "Location": {"Suburb": 5, "Downtown": 4, "Uptown": 3}}, "price_distribution_by_property_type": {"Condo": {"mean_price": 301250, "median_price": 317500, "count": 4}, "Single Family": {"mean_price": 496250, "median_price": 490000, "count": 4}, "Townhouse": {"mean_price": 310000, "median_price": 310000, "count": 2}, "Apartment": {"mean_price": null, "median_price": null, "count": 2}}, "date_format_standardization": {"original_formats": ["YYYY-MM-DD", "DD/MM/YYYY", "YYYY/MM/DD", "MM-DD-YYYY"], "standardized_format": "YYYY-MM-DD"}, "correlations": {"Price_Bedrooms": 0.86, "Price_Bathrooms": 0.82, "Price_SquareFeet": 0.91, "Price_YearBuilt": 0.35}, "top_categories": {"PropertyType": ["Condo", "Single Family"]}}}
{"purpose": "Analyze customer usage patterns and identify data quality issues in telecom service records.", "raw_table": "CustomerID,CallDuration,DataUsage_MB,PlanType,SubscriptionDate,Churn\n12345,300,1024,Premium,2023-01-15,No\n12346,85, ,basic,15-02-2023,yes\n12347,,512,Standard,2023/03/10,No\n12348,120,256,PREMIUM,2023-04-01,No\n12349,NaN,128,standard,April 5 2023,No\n12350,60,abc,Basic,2023-05-20,Yes\n12351,30,64,Standard,2023-06-15,no\n12352,200,2048,premium,2023-07-01,NO\n12353,45,512,unknown,2023-07-10,Yes\n12354,100,,Basic,,No\n12355,NaN,1024,STANDARD,2023-08-01,yes", "eda_steps": ["Check missing value percentages for each column", "Compute descriptive statistics for numeric columns CallDuration and DataUsage_MB", "Convert SubscriptionDate to a consistent datetime format and identify parsing errors", "Generate value counts for categorical columns PlanType and Churn", "Identify and count unusual or unknown categories in PlanType", "Calculate correlation between CallDuration and DataUsage_MB where data is valid", "Summarize the distribution skewness of CallDuration", "List customers with missing or invalid numeric data"], "eda_results": {"missing_values": {"CustomerID": 0, "CallDuration": 2, "DataUsage_MB": 2, "PlanType": 0, "SubscriptionDate": 1, "Churn": 0}, "summary_stats": {"CallDuration": {"count": 11, "mean": 107.27, "std": 85.02, "min": 30, "25%": 45, "50%": 85, "75%": 200, "max": 300, "skewness": 0.83}, "DataUsage_MB": {"count": 11, "mean": 821.82, "std": 704.61, "min": 64, "25%": 128, "50%": 512, "75%": 1024, "max": 2048, "skewness": 1.05}}, "date_parsing_issues": {"InvalidDates": ["", "April 5 2023"]}, "value_counts": {"PlanType": {"Premium": 3, "Standard": 4, "Basic": 3, "unknown": 1}, "Churn": {"No": 5, "Yes": 4}}, "unusual_categories": {"PlanType": ["unknown"]}, "correlations": {"CallDuration_vs_DataUsage_MB": 0.87}, "invalid_numeric_data_customers": [12347, 12350, 12355]}}
{"purpose": "Explore patient demographic and diagnosis data to identify patterns and data quality issues.", "raw_table": "Patient_ID,Age,Sex,Diagnosis,Admission_Date,Length_of_stay,Discharge_Status\n001,45,Male,Diabetes,2023-01-15,5,Recovered\n002,38,Female,Hypertension,15/02/2023,3,Recovered\n003,,female,diabetes,2023-03-01,7,Deceased\n004,29,Male,Asthma,2023-03-12,NA,recovered\n005,52,Female,Hypertension,,10,Recovered\n006,47,Male,diabetes,2023-04-05,4,Recovered\n007,33,F,email,2023-04-10,2,Recovered\n008,41,Male,Asthma,04-15-2023,3,\n009,59,Female,Hypertension,2023/04/20,5,Recovered\n010,NaN,M,Diabetes,2023-04-25,6,Recovered\n011,44,Female,Asthma,2023-05-01,,Recovered\n012,50,Male,Hypertension,2023-05-03,8,Deceased\n013,27,Female,Flu,2023-05-07,1,Recovered\n014,61,Male,Diabetes,2023-05-10,7,Recovered", "eda_steps": ["Check for missing values and their percentages per column", "Standardize 'Sex' and 'Diagnosis' column capitalization", "Convert 'Admission_Date' to a uniform date format", "Compute descriptive statistics for numeric columns: Age and Length_of_stay", "Generate value counts for the 'Diagnosis' and 'Discharge_Status' columns", "Identify rows with inconsistent or invalid 'Sex' entries", "Calculate correlation between Age and Length_of_stay", "Summarize unique patient counts"], "eda_results": {"missing_values": {"Patient_ID": "0%", "Age": "2/14 (~14.3%)", "Sex": "1/14 (~7.1%)", "Diagnosis": "1/14 (~7.1%)", "Admission_Date": "1/14 (~7.1%)", "Length_of_stay": "3/14 (~21.4%)", "Discharge_Status": "1/14 (~7.1%)"}, "standardized_categories": {"Sex": {"male": 6, "female": 7, "invalid": 1}, "Diagnosis": {"diabetes": 5, "hypertension": 4, "asthma": 3, "flu": 1, "email": 1}}, "date_conversion": {"successful_conversions": 13, "failed_conversions": 1}, "summary_stats": {"Age": {"count": 12, "mean": 44.8, "std": 10.8, "min": 27, "25%": 33, "50%": 44, "75%": 52, "max": 61}, "Length_of_stay": {"count": 11, "mean": 5.0, "std": 2.3, "min": 1, "25%": 3, "50%": 5, "75%": 6, "max": 10}}, "value_counts": {"Diagnosis": {"diabetes": 5, "hypertension": 4, "asthma": 3, "flu": 1, "email": 1}, "Discharge_Status": {"Recovered": 10, "Deceased": 2, "recovered": 1, "": 1}}, "inconsistent_sex_entries": ["Row 7 has 'f' instead of 'female' or 'male'"], "correlations": {"Age_vs_Length_of_stay": 0.42}, "unique_patients": 14}}
{"purpose": "Analyze student performance and attendance patterns in a middle school dataset.", "raw_table": "StudentID,Name,Grade,Math_Score,English_Score,Attendance_Percentage,Enrollment_Date\n101,alice,8,85,,92.5,2023-09-01\n102,Bob,Seventh,78,88,85.0,09/03/2023\n103,charlie,8,NaN,70,80,2023/09/02\n104,David,7,90,82,,2023-9-05\n105,Eva,8,95,89,98.0,2023-09-03\n106,Fiona,7,65,75,72.5,2023.09.04\n107,George,,88,85,90,2023-09-01\n108,henry,7,80,NaN,NaN,09-06-2023\n109,Ivy,8,92,95,99.0,2023-09-07\n110,Jack,7,70,68,85.5,2023-09-08\n111,Kate,8,84,90,95.0,2023-09-01", "eda_steps": ["Check missing value percentages for each column", "Standardize the Grade column to numeric values", "Convert Enrollment_Date to a consistent date format", "Compute descriptive statistics for Math_Score and English_Score", "Generate value counts for Grade", "Identify students with attendance below 80%", "Compute correlation between Math_Score, English_Score, and Attendance_Percentage", "Summarize average scores by Grade"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 0, "Grade": 1, "Math_Score": 1, "English_Score": 2, "Attendance_Percentage": 2, "Enrollment_Date": 0}, "grade_value_counts": {"7": 5, "8": 5}, "attendance_below_80_count": 2, "descriptive_stats": {"Math_Score": {"count": 10, "mean": 82.2, "std": 9.81, "min": 65, "max": 95}, "English_Score": {"count": 9, "mean": 81.44, "std": 9.64, "min": 68, "max": 95}}, "average_scores_by_grade": {"7": {"Math_Score": 76.6, "English_Score": 74.6, "Attendance_Percentage": 82.1}, "8": {"Math_Score": 88.8, "English_Score": 86.8, "Attendance_Percentage": 95.1}}, "correlations": {"Math_Score_vs_English_Score": 0.84, "Math_Score_vs_Attendance_Percentage": 0.62, "English_Score_vs_Attendance_Percentage": 0.59}}}
{"purpose": "Analyze customer call usage patterns and identify data quality issues in the telecom dataset.", "raw_table": "CustomerID,CallDate,CallDuration,CallType,NetworkProvider,DataUsedMB\n1001,2024-01-05,300,Voice,Verizon,50\n1002,01/08/2024,,SMS,AT&T,NA\n1003,2024/01/10,60,voice,verizon,15\n1004,2024-1-12,180,VoIP,Sprint,20\n1005,13-01-2024,120,Voice,AT&T,25\n1006,2024-01-14,Null,SMS,sprint,0\n1007,2024-01-15,90,VOICE,Verizon,30\n1008,Jan 16 2024,45,VoIP,T-Mobile,10\n1009,2024-01-17,200,voice,T-MOBILE,40\n1010,,75,SMS,AT&T,5\n1011,2024-01-19,150,,Verizon,20\n1012,2024-01-20,85,Voice,verizon,NaN\n1013,2024-01-21,NaN,VoIP,Sprint,15", "eda_steps": ["Check for missing values in each column and compute their percentages", "Standardize the date format in the CallDate column", "Convert CallDuration and DataUsedMB to numeric types and handle missing values", "Normalize the capitalization in CallType and NetworkProvider columns", "Generate value counts for CallType and NetworkProvider", "Compute descriptive statistics for CallDuration and DataUsedMB", "Identify any correlations between CallDuration and DataUsedMB", "Find top 3 most frequent CallTypes", "Summarize distribution skewness for CallDuration"], "eda_results": {"missing_values": {"CustomerID": "0%", "CallDate": "8.3%", "CallDuration": "16.7%", "CallType": "8.3%", "NetworkProvider": "0%", "DataUsedMB": "8.3%"}, "standardized_dates": ["2024-01-05", "2024-01-08", "2024-01-10", "2024-01-12", "2024-01-13", "2024-01-14", "2024-01-15", "2024-01-16", "2024-01-17", null, "2024-01-19", "2024-01-20", "2024-01-21"], "value_counts": {"CallType": {"voice": 5, "sms": 3, "voip": 3, "null": 1}, "NetworkProvider": {"verizon": 5, "at&t": 3, "sprint": 3, "t-mobile": 2}}, "summary_stats": {"CallDuration": {"count": 10, "mean": 118.5, "std": 74.6, "min": 45, "25%": 75, "50%": 90, "75%": 180, "max": 300, "skewness": 0.92}, "DataUsedMB": {"count": 11, "mean": 21.8, "std": 14.2, "min": 0, "25%": 10, "50%": 20, "75%": 30, "max": 50}}, "correlations": {"CallDuration_vs_DataUsedMB": 0.67}, "top_categories": {"CallType": ["voice", "sms", "voip"]}}}
{"purpose": "Analyze temperature and precipitation patterns across various climate zones over several months.", "raw_table": "Date,Location,Climate_Zone,Temperature_C,Precipitation_mm,Wind_Speed_kmh\n\"2023-01-05\",New york,Temperate,3.5,12,15\n2023/02/10,los angeles,Mediterranean,18.2,,8\n2023-03-15,Chicago,CONTINENTAL,7.1,25,20\n2023-04-20,Houston,Subtropical,24.5,35,NA\n05-25-2023,Phoenix,Desert,33.2,0,10\n2023-06-10,Seattle,Temperate,16.7,45,12\n2023-07-15,Miami,subtropical,29.1,80,18\n2023-08-20,Denver,continental,22.0,5,25\n2023-09-25,Boston,Temperate,15.0,,14\n2023-10-30,San Francisco,Mediterranean,17.8,10,9\n2023-11-15,Anchorage,Subarctic,-5.3,30,22\n2023-12-20,Anchorage,subarctic,-8.0,40,19\n2024-01-05,New York,temperate,1.0,10,16", "eda_steps": ["Standardize date formats to YYYY-MM-DD", "Normalize capitalization in Location and Climate_Zone columns", "Compute descriptive statistics for Temperature_C and Precipitation_mm", "Check missing value percentages for each column", "Generate value counts for Climate_Zone", "Calculate average Wind_Speed_kmh by Climate_Zone", "Identify correlation between Temperature_C and Precipitation_mm", "Summarize min and max Temperature_C per Location"], "eda_results": {"missing_values": {"Date": 0, "Location": 0, "Climate_Zone": 0, "Temperature_C": 0, "Precipitation_mm": 2, "Wind_Speed_kmh": 1}, "value_counts": {"Climate_Zone": {"Temperate": 4, "Mediterranean": 2, "Continental": 2, "Subtropical": 2, "Desert": 1, "Subarctic": 2}}, "summary_stats": {"Temperature_C": {"count": 13, "mean": 14.03, "std": 13.16, "min": -8.0, "25%": 3.5, "50%": 15.0, "75%": 22.0, "max": 33.2}, "Precipitation_mm": {"count": 11, "mean": 25.6, "std": 25.3, "min": 0, "25%": 5, "50%": 12, "75%": 35, "max": 80}}, "avg_wind_speed_by_climate_zone": {"Temperate": 14.25, "Mediterranean": 8.5, "Continental": 22.5, "Subtropical": 18.5, "Desert": 10.0, "Subarctic": 20.5}, "correlations": {"Temperature_C_Precipitation_mm": -0.34}, "temperature_range_per_location": {"New York": {"min": 1.0, "max": 3.5}, "Los Angeles": {"min": 18.2, "max": 18.2}, "Chicago": {"min": 7.1, "max": 7.1}, "Houston": {"min": 24.5, "max": 24.5}, "Phoenix": {"min": 33.2, "max": 33.2}, "Seattle": {"min": 16.7, "max": 16.7}, "Miami": {"min": 29.1, "max": 29.1}, "Denver": {"min": 22.0, "max": 22.0}, "Boston": {"min": 15.0, "max": 15.0}, "San Francisco": {"min": 17.8, "max": 17.8}, "Anchorage": {"min": -8.0, "max": -5.3}}}}
{"purpose": "Analyze customer churn patterns and identify key usage trends in a telecom dataset.", "raw_table": "CustomerID,SubscriptionType,MonthlySpendGB,LastLoginDate,ChurnStatus,CustomerAge,DeviceType\nC001,Premium,15.2,2023-01-15,Yes,34,Smartphone\nc002,standard,8.5,15-02-2023,No,29,Laptop\nC003,,12.0,2023/03/05,No,45,Tablet\nC004,Premium,NaN,2023-03-15,yes,38,Smartphone\nC005,Standard,9.7,2023-04-01,No,,smartphone\nc006,Premium,18.1,2023-02-28,No,41,\nC007,standard,7.5,03/20/2023,Yes,27,Tablet\nC008,PREMIUM,20.0,2023-04-10,No,33,Smartphone\nC009,standard,,2023-04-05,No,24,Laptop\nc010,Premium,16.4,2023-04-15,Yes,39,Smartphone", "eda_steps": ["Check and summarize missing values in each column", "Standardize the SubscriptionType and ChurnStatus columns to consistent capitalization", "Compute descriptive statistics for MonthlySpendGB and CustomerAge", "Generate value counts for SubscriptionType, ChurnStatus, and DeviceType", "Analyze date formats in LastLoginDate and convert them to a standard format", "Identify customers with missing DeviceType and MonthlySpendGB", "Calculate the average MonthlySpendGB grouped by SubscriptionType", "Determine the percentage of customers who have churned", "Examine correlation between CustomerAge and MonthlySpendGB"], "eda_results": {"missing_values": {"SubscriptionType": 1, "MonthlySpendGB": 2, "LastLoginDate": 0, "ChurnStatus": 0, "CustomerAge": 1, "DeviceType": 1}, "value_counts": {"SubscriptionType": {"Premium": 5, "Standard": 3, "standard": 2}, "ChurnStatus": {"Yes": 4, "No": 6}, "DeviceType": {"Smartphone": 5, "Laptop": 2, "Tablet": 2, "": 1}}, "standardized_columns": {"SubscriptionType": {"Premium": 5, "Standard": 5}, "ChurnStatus": {"Yes": 4, "No": 6}}, "descriptive_statistics": {"MonthlySpendGB": {"count": 13, "mean": 13.84, "std": 4.55, "min": 7.5, "25%": 9.7, "50%": 15.2, "75%": 16.4, "max": 20.0}, "CustomerAge": {"count": 14, "mean": 34.0, "std": 6.59, "min": 24, "25%": 29, "50%": 34, "75%": 39, "max": 45}}, "average_monthly_spend_by_subscription": {"Premium": 16.18, "Standard": 8.57}, "percentage_churned": 40.0, "correlation_age_spend": 0.65, "last_login_date_standardized": true, "missing_device_customers": ["c006"], "missing_monthly_spend_customers": ["C004", "C009"]}}
{"purpose": "Explore the characteristics and data quality of recent real estate listings to understand pricing and property features.", "raw_table": "ListingID,Location,Price,Area_sqft,Num_Bedrooms,Num_Bathrooms,Date_Listed,Property_Type\n101,Downtown,350000,950,2,1,2023/05/10,Condo\n102,suburbs,450000,1200,3,2,15-06-2023,Single Family\n103,Downtown,,850,2,,2023-07-01,Condo\n104,Rural,200000,1500,3,2,07/20/2023,Single family\n105,Suburbs,missing,1100,four,2,2023/06/25,Townhouse\n106,Downtown,375000,900,2,1,06/30/2023,condo\n107,Rural,180000,1400,3,2,2023.07.05,Single Family\n108,Suburbs,425000,1150,3,2,2023-06-28,TownHouse\n109,Downtown,360000,900,2,1,,Condo\n110,Rural,195000,1450,three,2,2023/07/10,Single family\n111,Suburbs,430000,1150,3,Two,20/06/2023,Townhouse\n112,Downtown,355000,950,2,1,2023-06-15,Condo\n113,Suburbs,440000,1200,3,2,2023/06/18,Townhouse", "eda_steps": ["Check for missing values in each column", "Standardize the 'Property_Type' and 'Location' columns capitalization", "Convert 'Price' column to numeric, handling non-numeric values", "Convert 'Num_Bedrooms' and 'Num_Bathrooms' to numeric where possible", "Parse 'Date_Listed' into consistent date format", "Compute descriptive statistics for numeric columns: Price, Area_sqft, Num_Bedrooms, Num_Bathrooms", "Generate value counts for 'Property_Type' and 'Location'", "Identify listings with missing prices", "Calculate the average price by 'Property_Type'", "Detect any outliers in Price using simple IQR method"], "eda_results": {"missing_values": {"ListingID": 0, "Location": 0, "Price": 2, "Area_sqft": 0, "Num_Bedrooms": 2, "Num_Bathrooms": 2, "Date_Listed": 1, "Property_Type": 0}, "standardized_categories": {"Property_Type": {"condo": 5, "single family": 4, "townhouse": 4}, "Location": {"Downtown": 5, "Suburbs": 5, "Rural": 4}}, "price_numeric_conversion": {"converted_count": 13, "non_convertible_rows": [105, 103]}, "bedrooms_numeric_conversion": {"converted_count": 11, "non_convertible_rows": [105, 110]}, "bathrooms_numeric_conversion": {"converted_count": 11, "non_convertible_rows": [105, 111]}, "dates_parsed": {"successful_parses": 14, "failed_parses": 1}, "summary_stats": {"Price": {"count": 13, "mean": 355769.23, "std": 84044.65, "min": 180000, "25%": 350000, "50%": 360000, "75%": 430000, "max": 450000}, "Area_sqft": {"count": 14, "mean": 1082.14, "std": 202.17, "min": 850, "25%": 900, "50%": 1150, "75%": 1200, "max": 1500}, "Num_Bedrooms": {"count": 11, "mean": 2.73, "std": 0.65, "min": 2, "25%": 2, "50%": 3, "75%": 3, "max": 4}, "Num_Bathrooms": {"count": 11, "mean": 1.73, "std": 0.46, "min": 1, "25%": 1, "50%": 2, "75%": 2, "max": 2}}, "value_counts": {"Property_Type": {"condo": 5, "single family": 4, "townhouse": 4}, "Location": {"Downtown": 5, "Suburbs": 5, "Rural": 4}}, "listings_missing_price": [103, 105], "average_price_by_property_type": {"condo": 359000, "single family": 193750, "townhouse": 431250}, "price_outliers": {"lower_bound": 225000, "upper_bound": 555000, "outliers": []}}}
{"purpose": "Examine patient demographics and lab test results to identify data quality issues and key statistics in a small medical dataset.", "raw_table": "PatientID,Age,Gender,Diagnosis,LabTestDate,Cholesterol,Glucose\n001,45,Male,Hypertension,2023-02-15,210,95\n002,38,Female,diabetes,15/03/2023,NaN,110\n003,52,Female,Hypertension,2023/04/10,195,NaN\n004,29,Male,Asthma,04-22-2023,180,85\n005,,female,Diabetes,,230,130\n006,41,Male,Hypertension,2023-06-01,NaN,100\n007,37,FEMALE,COPD,2023-06-07,205,NaN\n008,49,Male,Asthma,2023-05-20,190,105\n009,55,male,unknown,2023-06-15,215,115\n010,34,Female,Diabetes,2023/05/01,220,120", "eda_steps": ["Check for missing values in each column and calculate the percentage missing", "Normalize the Gender column to standard capitalization", "Standardize the Diagnosis column capitalization", "Parse LabTestDate into a consistent date format", "Compute descriptive statistics (mean, median, min, max) for Age, Cholesterol, and Glucose", "Generate value counts for Diagnosis and Gender columns", "Identify the number of unique patients and duplicate PatientIDs", "Visualize distribution skewness for Cholesterol and Glucose levels"], "eda_results": {"missing_values": {"PatientID": "0%", "Age": "10%", "Gender": "0%", "Diagnosis": "0%", "LabTestDate": "10%", "Cholesterol": "20%", "Glucose": "30%"}, "normalized_gender_counts": {"Female": 5, "Male": 5}, "standardized_diagnosis_counts": {"Hypertension": 3, "Diabetes": 3, "Asthma": 2, "COPD": 1, "Unknown": 1}, "lab_test_date_standardized": ["2023-02-15", "2023-03-15", "2023-04-10", "2023-04-22", null, "2023-06-01", "2023-06-07", "2023-05-20", "2023-06-15", "2023-05-01"], "age_stats": {"mean": 43.0, "median": 41.0, "min": 29, "max": 55}, "cholesterol_stats": {"mean": 204.3, "median": 205, "min": 180, "max": 230}, "glucose_stats": {"mean": 106.43, "median": 110, "min": 85, "max": 130}, "unique_patients": 10, "duplicate_patient_ids": 0, "cholesterol_skewness": 0.4, "glucose_skewness": 0.2}}
{"purpose": "Analyze user engagement patterns on social media posts to identify trends and data quality issues.", "raw_table": "post_id,user_id,post_date,post_type,likes,comments,shares\n101,u001,2023-01-15,Photo,120,15,5\n102,U002,15/01/2023,video,85,,3\n103,u003,2023/01/16,Text,NaN,7,0\n104,u004,2023-01-17,photo,200,20,10\n105,u005,01-18-2023,Link,90,12,2\n106,u006,2023-01-18,VIDEO,110,NaN,4\n107,u007,,text,50,5,1\n108,u008,2023-01-20,Photo,NaN,8,\n109,u009,2023-01-21,Link,70,,2\n110,U010,2023-01-21,video,95,10,3", "eda_steps": ["Check and report missing values count per column", "Standardize post_date to YYYY-MM-DD format and identify parsing issues", "Normalize post_type to consistent capitalization", "Compute descriptive statistics for likes, comments, and shares", "Generate value counts for post_type", "Identify posts with zero or missing engagement metrics", "Calculate correlation matrix between likes, comments, and shares"], "eda_results": {"missing_values": {"post_id": 0, "user_id": 0, "post_date": 1, "post_type": 0, "likes": 2, "comments": 3, "shares": 2}, "date_parsing_issues": {"unparsed_dates": 0, "standardized_dates": 9}, "normalized_post_type_counts": {"Photo": 3, "Video": 3, "Text": 2, "Link": 2}, "summary_stats": {"likes": {"count": 8, "mean": 102.5, "std": 45.0, "min": 50, "max": 200}, "comments": {"count": 7, "mean": 11.0, "std": 5.1, "min": 5, "max": 20}, "shares": {"count": 8, "mean": 3.5, "std": 2.8, "min": 0, "max": 10}}, "posts_with_zero_or_missing_engagement": 4, "correlations": {"likes_comments": 0.87, "likes_shares": 0.78, "comments_shares": 0.65}}}
{"purpose": "Examine patient demographics and lab test results to identify data quality issues and summarize key statistics.", "raw_table": "Patient_ID,Age,Gender,Diagnosis,Admission_Date,Discharge_Date,Creatinine_Level,Heart_Rate\nP001,45,Male,Diabetes,2023-01-15,2023/01/20,1.2,88\nP002,52,Female,hypertension,15-Jan-2023,2023-01-22,1.8,102\nP003,,female,COPD,2023/02/01,2023-02-10,,95\nP004,38,M,Diabetes,2023-03-05,2023-03-12,1.0,85\nP005,60,Female,Asthma,2023-03-15,,1.4,90\nP006,29,Male,diabetes,03/20/2023,03/27/2023,0.9,NaN\nP007,70,F,Hypertension,2023/04/01,2023/04/08,2.3,110\nP008,55,Male,CKD,2023-04-10,2023-04-18,3.1,120\nP009,48,Female,Asthma,2023/04/15,2023/04/20,1.1,100\nP010,65,,COPD,2023-05-01,2023/05/10,2.0,112\n", "eda_steps": ["Check for missing values and compute their percentages per column", "Standardize and count unique values in the Gender column", "Convert Admission_Date and Discharge_Date to consistent date format and calculate length of stay", "Generate descriptive statistics for Age, Creatinine_Level, and Heart_Rate", "Count unique diagnoses and list top diagnosis categories", "Identify patients with missing discharge dates", "Analyze correlation between Creatinine_Level and Heart_Rate", "Summarize age distribution by Gender"], "eda_results": {"missing_values": {"Patient_ID": "0%", "Age": "10%", "Gender": "10%", "Diagnosis": "0%", "Admission_Date": "0%", "Discharge_Date": "10%", "Creatinine_Level": "10%", "Heart_Rate": "10%"}, "gender_counts": {"Male": 4, "Female": 4, "M": 1, "F": 1, "": 1}, "diagnosis_counts": {"Diabetes": 3, "Hypertension": 2, "COPD": 2, "Asthma": 2, "CKD": 1}, "top_diagnoses": ["Diabetes", "Hypertension", "COPD"], "date_conversion_warnings": "Admission_Date and Discharge_Date had mixed formats; all converted to ISO format where possible.", "length_of_stay_stats": {"mean_days": 7.4, "min_days": 5, "max_days": 10, "missing_discharge_dates": ["P005"]}, "summary_stats": {"Age": {"count": 13, "mean": 51.8, "std": 13.3, "min": 29, "max": 70}, "Creatinine_Level": {"count": 12, "mean": 1.57, "std": 0.64, "min": 0.9, "max": 3.1}, "Heart_Rate": {"count": 12, "mean": 100.0, "std": 11.4, "min": 85, "max": 120}}, "correlations": {"Creatinine_HeartRate": 0.68}, "age_by_gender": {"Male": {"count": 4, "mean_age": 41.75, "min_age": 29, "max_age": 55}, "Female": {"count": 4, "mean_age": 51.25, "min_age": 45, "max_age": 60}}}}
{"purpose": "Analyze viewer ratings and genre distribution for recent movies to identify trends and data quality issues.", "raw_table": "MovieID,Title,Genre,ReleaseDate,ViewerRating,BoxOfficeMillion\n1,The Last Saga,Action,2023-05-12,8.2,150\n2,love in paris,Romance,05/20/2023,7.5,85\n3,Haunted Nights,Horror,,6.1,40\n4,Future Quest,Sci-Fi,2023/07/01,9.0,200\n5,Comedy Hour,comedy,2023-06-15,NaN,70\n6,Drama Queen,Drama,2023-06-30,7,65\n7,The Last Saga,Action,2023-05-12,8.3,152\n8,Unknown Realms,FANTASY,Jun 22 2023,7.8,NaN\n9,Love in Paris,romance,05-20-2023,7.6,88\n10,Space Oddity,Sci-Fi,2023/07/01,Not Rated,210\n11,Comedy Hour,Comedy,2023-06-15,6.8,68\n12,,Drama,2023-06-30,7.1,60\n13,Haunted Nights,Horror,2023-04-28,6.3,42", "eda_steps": ["Check for missing values in each column", "Standardize the Genre column to title case", "Identify duplicate movie entries based on Title and ReleaseDate", "Analyze the distribution of ViewerRating values and handle non-numeric entries", "Calculate descriptive statistics for numeric columns ViewerRating and BoxOfficeMillion", "Count the number of movies per Genre", "Check inconsistencies in ReleaseDate formatting and convert all dates to ISO format", "Find the top 3 movies by BoxOfficeMillion", "Summarize unique movie titles after deduplication"], "eda_results": {"missing_values": {"MovieID": 0, "Title": 1, "Genre": 0, "ReleaseDate": 1, "ViewerRating": 2, "BoxOfficeMillion": 1}, "standardized_genres": ["Action", "Romance", "Horror", "Sci-Fi", "Comedy", "Drama", "Fantasy"], "duplicate_entries": [{"Title": "The Last Saga", "ReleaseDate": "2023-05-12", "count": 2}, {"Title": "Love in Paris", "ReleaseDate": "2023-05-20", "count": 2}, {"Title": "Comedy Hour", "ReleaseDate": "2023-06-15", "count": 2}, {"Title": "Haunted Nights", "ReleaseDate": "2023-04-28", "count": 2}], "viewer_rating_distribution": {"valid_ratings_count": 11, "non_numeric_entries": 1, "missing_entries": 1, "mean_rating": 7.3, "min_rating": 6.1, "max_rating": 9.0}, "descriptive_statistics": {"ViewerRating": {"mean": 7.3, "median": 7.5, "min": 6.1, "max": 9.0, "std_dev": 0.82, "count": 11}, "BoxOfficeMillion": {"mean": 95.5, "median": 70, "min": 40, "max": 210, "std_dev": 55.7, "count": 12}}, "genre_counts": {"Action": 2, "Romance": 2, "Horror": 2, "Sci-Fi": 2, "Comedy": 2, "Drama": 2, "Fantasy": 1}, "release_date_format_issues": 3, "top_3_movies_by_box_office": [{"Title": "Space Oddity", "BoxOfficeMillion": 210}, {"Title": "Future Quest", "BoxOfficeMillion": 200}, {"Title": "The Last Saga", "BoxOfficeMillion": 152}], "unique_movie_titles_after_deduplication": 9}}
{"purpose": "Examine temperature and precipitation patterns across different climate zones to identify data quality issues and trends.", "raw_table": "Date,Location,Climate_Zone,Temperature_C,Precipitation_mm\n2024-01-15,Denver,temperate,5.6,0\n01/16/2024,boston,Temperate,3.2,1.4\n2024/01/17,New Orleans,tropical,16.5,N/A\n2024-01-18,Houston,tropical,,5.2\n2024-01-19,Anchorage,Arctic,-12.3,0\n2024-01-20,anchorage,arctic,-15.0,0.1\n2024-01-21,Miami,tropical,22.4,10.5\n2024-01-22,Boston,Temperate,,2.3\n2024-01-23,Denver,Temperate,6.1,0\n2024-01-24,Houston,TROPICAL,18.0,7.8\n2024-01-25,Miami,Tropical,21.8,12.7\n01-26-2024,New Orleans,tropical,17.2,8.1\n2024-01-27,Denver,Temperate,4.9,0\n2024-01-28,Anchorage,Arctic,-10.5,0\n2024-01-29,BOSTON,temperate,2.9,3.0", "eda_steps": ["Standardize and parse Date column into consistent datetime format", "Convert all Climate_Zone values to lowercase for consistency", "Check and report missing values in Temperature_C and Precipitation_mm", "Calculate descriptive statistics (mean, median, std) for Temperature_C and Precipitation_mm by Climate_Zone", "Generate value counts for Location and Climate_Zone columns", "Identify unique date formats and count their occurrences", "Calculate correlation between Temperature_C and Precipitation_mm where applicable", "Summarize top 3 locations with highest average precipitation"], "eda_results": {"missing_values": {"Temperature_C": 2, "Precipitation_mm": 1}, "value_counts": {"Location": {"Denver": 3, "Boston": 3, "New Orleans": 2, "Houston": 2, "Anchorage": 3, "Miami": 2}, "Climate_Zone": {"temperate": 7, "tropical": 7, "arctic": 3}}, "date_format_counts": {"YYYY-MM-DD": 12, "MM/DD/YYYY": 1, "YYYY/MM/DD": 1, "MM-DD-YYYY": 1}, "summary_stats_by_climate_zone": {"temperate": {"Temperature_C": {"mean": 4.54, "median": 4.9, "std": 1.57}, "Precipitation_mm": {"mean": 1.36, "median": 0, "std": 1.45}}, "tropical": {"Temperature_C": {"mean": 19.18, "median": 17.2, "std": 2.49}, "Precipitation_mm": {"mean": 8.56, "median": 8.1, "std": 3.89}}, "arctic": {"Temperature_C": {"mean": -12.6, "median": -12.3, "std": 2.28}, "Precipitation_mm": {"mean": 0.03, "median": 0, "std": 0.06}}}, "correlations": {"Temperature_vs_Precipitation": -0.12}, "top_locations_by_avg_precipitation": {"Miami": 11.6, "New Orleans": 8.05, "Houston": 6.5}}}
{"purpose": "Analyze daily ride-sharing trip characteristics to understand usage patterns and data quality issues.", "raw_table": "Trip_ID,Start_Time,End_Time,Distance_km,Passenger_Count,Payment_Method,Driver_Rating\n1,2024-04-01 08:15,2024-04-01 08:45,12.5,2,Cash,4.5\n2,4/1/2024 09:00 AM,4/1/2024 09:22 AM,8.2,1,Credit Card,5\n3,2024-04-01 10:30,,15.3,3,,3.8\n4,2024-04-01 11:00,2024-04-01 11:30,NaN,2,credit card,4.2\n5,2024-4-01 12:15,2024-4-01 12:45,7.8,1,CASH,4.9\n6,2024/04/01 13:00,2024/04/01 13:30,10.0,,Paypal,4.7\n7,2024-04-01 14:00,2024-04-01 14:22,11.1,2,Credit card,NaN\n8,2024-04-01 15:15,2024-04-01 15:45,9.3,1,Cash,4.0\n9,April 1 2024 16:00,April 1 2024 16:25,13.0,4,Cash,4.6\n10,2024-04-01 17:30,2024-04-01 18:00,NaN,1,Credit Card,4.8\n11,2024-04-01 18:15,2024-04-01 18:45,14.0,2,PayPal,4.4\n12,2024-04-01 19:00,2024-04-01 19:30,10.5,2,Credit card,4.1\n13,2024-04-01 20:00,2024-04-01 20:30,NaN,1,,4.3\n14,2024-04-01 21:00,2024-04-01 21:20,12.0,3,Cash,4.9", "eda_steps": ["Check and summarize missing values per column", "Standardize and parse date/time columns for Start_Time and End_Time", "Compute descriptive statistics for numeric columns: Distance_km, Passenger_Count, Driver_Rating", "Generate value counts for Payment_Method", "Calculate trip duration in minutes and summarize its distribution", "Identify any inconsistent capitalizations in categorical columns and unify them"], "eda_results": {"missing_values": {"Trip_ID": 0, "Start_Time": 0, "End_Time": 1, "Distance_km": 3, "Passenger_Count": 1, "Payment_Method": 2, "Driver_Rating": 2}, "standardized_dates_sample": {"Start_Time_first_3": ["2024-04-01 08:15:00", "2024-04-01 09:00:00", "2024-04-01 10:30:00"], "End_Time_first_3": ["2024-04-01 08:45:00", "2024-04-01 09:22:00", null]}, "summary_stats": {"Distance_km": {"count": 11, "mean": 11.07, "std": 2.43, "min": 7.8, "max": 15.3}, "Passenger_Count": {"count": 13, "mean": 2.0, "std": 1.0, "min": 1, "max": 4}, "Driver_Rating": {"count": 12, "mean": 4.43, "std": 0.39, "min": 3.8, "max": 5.0}}, "value_counts": {"Payment_Method": {"Cash": 5, "Credit Card": 5, "Paypal": 2, "missing/unknown": 2}}, "trip_duration_minutes": {"count": 13, "mean": 29.2, "std": 4.9, "min": 20, "max": 45}, "capitalization_unification": {"Payment_Method_unique_before": ["Cash", "Credit Card", "credit card", "CASH", "Paypal", "PayPal", ""], "Payment_Method_unique_after": ["Cash", "Credit Card", "Paypal", "missing/unknown"]}}}
{"purpose": "Analyze crop yield and pesticide usage patterns across different farms during the 2023 growing season.", "raw_table": "FarmID,Crop,PlantingDate,HarvestDate,Yield_kg,PesticideUsed,PesticideAmount_l,SoilQuality\nF001,Wheat,2023-03-15,2023/09/20,1200,Yes,5.5,High\nF002,Corn,03/20/2023,09-25-2023,1500,No,,medium\nF003,Rice,2023.04.01,2023-10-01,1100,yes,3.0,Low\nf004,wheat,2023-03-18,2023-09-19,NaN,Yes,4.0,High\nF005,Corn,2023/03/22,2023/09/27,1600,No,0,Medium\nF006,Rice,,2023-10-03,1050,No,,low\nF007,Wheat,2023-03-16,2023-09-21,1250,YES,5.0,High\nF008,Corn,2023-03-19,2023-09-26,1550,yes,2.5,Medium\nF009,Rice,2023-04-02,2023-10-02,NaN,No,,Low\nf010,Wheat,2023-03-17,2023-09-20,1190,Yes,4.8,High", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in categorical columns Crop, PesticideUsed, and SoilQuality", "Convert PlantingDate and HarvestDate to consistent date format", "Compute descriptive statistics for numeric columns Yield_kg and PesticideAmount_l", "Generate value counts for categorical columns Crop, PesticideUsed, SoilQuality", "Calculate the average yield per crop type", "Analyze correlation between PesticideAmount_l and Yield_kg", "Identify farms with missing planting dates", "Examine distribution skewness for Yield_kg"], "eda_results": {"missing_values": {"FarmID": 0, "Crop": 0, "PlantingDate": 1, "HarvestDate": 0, "Yield_kg": 2, "PesticideUsed": 0, "PesticideAmount_l": 3, "SoilQuality": 0}, "value_counts": {"Crop": {"Wheat": 4, "Corn": 3, "Rice": 3}, "PesticideUsed": {"Yes": 5, "No": 5}, "SoilQuality": {"High": 4, "Medium": 3, "Low": 3}}, "descriptive_stats": {"Yield_kg": {"count": 8, "mean": 1325, "std": 210, "min": 1050, "25%": 1192.5, "50%": 1220, "75%": 1550, "max": 1600}, "PesticideAmount_l": {"count": 7, "mean": 3.6, "std": 1.4, "min": 0, "25%": 2.5, "50%": 4.0, "75%": 5.0, "max": 5.5}}, "average_yield_per_crop": {"Wheat": 1212.5, "Corn": 1550, "Rice": 1075}, "correlations": {"PesticideAmount_l_vs_Yield_kg": 0.75}, "farms_missing_planting_date": ["F006"], "distribution_skewness": {"Yield_kg": 0.68}}}
{"purpose": "Analyze monthly sales performance and customer demographics for a retail store chain.", "raw_table": "OrderID,CustomerName,ProductCategory,OrderDate,Quantity,UnitPrice,TotalAmount,PaymentMethod\n1001, alice smith,Electronics,2023-01-15,2,299.99,599.98,Credit Card\n1002,Bob Johnson,home & garden,2023-1-18,1,89.50,89.50,credit card\n1003,CHARLES W.,Electronics,01/20/2023,3,299.99,899.97,Cash\n1004,Diane Lee,Toys,2023-02-05,,15.99,,Credit card\n1005,Emily Davis,HOME & Garden,2023/02/10,4,89.50,358.00,PayPal\n1006,Fred M,Electronics,2023-02-12,1,299.99,299.99,CASH\n1007,Gina K,Toys,2023-02-13,5,15.99,79.95,credit Card\n1008,,Electronics,2023-02-14,2,299.99,599.98,Cash\n1009,Hank P,Clothing,02-15-2023,3,49.99,149.97,Credit Card\n1010,Ian O,Clothing,2023-02-16,2,49.99,99.98,Credit card\n1011,James Q,Toys,2023/02/18,1,15.99,15.99,Paypal\n1012,Karen T,Clothing,2023-02-20,1,,49.99,Credit Card\n1013,Lisa M,Home & Garden,2023-02-21,3,89.50,268.50,CREDIT CARD\n1014,Mike N,Electronics,2023-02-22,2,299.99,599.98,Paypal", "eda_steps": ["Check and summarize missing values for each column", "Standardize the capitalization of 'ProductCategory' and 'PaymentMethod'", "Parse and standardize 'OrderDate' to a consistent date format", "Compute descriptive statistics (mean, median, min, max) for numeric columns: Quantity, UnitPrice, TotalAmount", "Generate value counts for 'ProductCategory' and 'PaymentMethod'", "Identify orders with missing Quantity or UnitPrice and investigate impact on TotalAmount", "Calculate total sales by ProductCategory", "Calculate correlation between Quantity, UnitPrice, and TotalAmount", "Summarize number of unique customers and missing customer names"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerName": 1, "ProductCategory": 0, "OrderDate": 0, "Quantity": 1, "UnitPrice": 1, "TotalAmount": 1, "PaymentMethod": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Home & Garden", "Toys", "Clothing"], "PaymentMethod": ["Credit Card", "Cash", "PayPal"]}, "order_date_range": {"earliest": "2023-01-15", "latest": "2023-02-22"}, "descriptive_statistics": {"Quantity": {"mean": 2.27, "median": 2, "min": 1, "max": 5}, "UnitPrice": {"mean": 139.99, "median": 89.5, "min": 15.99, "max": 299.99}, "TotalAmount": {"mean": 320.62, "median": 149.97, "min": 15.99, "max": 899.97}}, "value_counts": {"ProductCategory": {"Electronics": 5, "Home & Garden": 3, "Toys": 4, "Clothing": 3}, "PaymentMethod": {"Credit Card": 6, "Cash": 3, "PayPal": 3}}, "missing_quantity_unitprice_orders": [1004, 1012], "total_sales_by_category": {"Electronics": 2999.9, "Home & Garden": 716.0, "Toys": 111.88, "Clothing": 299.94}, "correlations": {"Quantity_UnitPrice": 0.12, "Quantity_TotalAmount": 0.89, "UnitPrice_TotalAmount": 0.96}, "customer_summary": {"unique_customers": 13, "missing_customer_names": 1}}}
{"purpose": "Analyze production line efficiency and defect rates over a two-week period in a manufacturing plant.", "raw_table": "Date,Product_ID,Production_Line,Units_Produced,Defects,Operator_Name,Shift\n2024-05-01, A123,line1, 1000, 5, John Doe, Morning\n05/02/2024,a123,Line1, 950,  , jane smith,Afternoon\n2024/05/03,A124,LINE2, 1100, 7, , Morning\n2024-05-04,A124,line2, 1150,3, Mike O'Neil,night\nMay 5 2024,A125,line3, NineHundred, 4, Anna Lee, Afternoon\n2024-05-06,A125,Line3, 920, 2, Anna lee, Morning\n2024-05-07,A123,line1, 980, 6, John Doe, afternoon\n2024-05-08,A126,Line2, 1050, 0, Sarah Connor, Night\n2024-05-09,A126,Line2, 1075,, Sarah Connor, Morning\n2024-5-10,A124,line2, 1120, 5, Mike O'Neil, Night\n2024-05-11,A123,line1, 1000, 4, John doe, Morning\n2024-05-12,A125,line3, 910, 3, Anna Lee, Afternoon\n2024-05-13,A126,Line2, 1080, 1, , Night\n05-14-2024,A124,line2, 1130, 2, Mike O'Neil, Afternoon\n", "eda_steps": ["Check and summarize missing values for each column", "Standardize and correct inconsistent capitalization in categorical columns", "Convert 'Units_Produced' to numeric, handling non-numeric entries", "Compute descriptive statistics for 'Units_Produced' and 'Defects'", "Generate value counts for 'Production_Line' and 'Shift'", "Identify unique operators and count entries per operator", "Analyze defect rates per production line", "Summarize production trends over time by date"], "eda_results": {"missing_values": {"Date": 0, "Product_ID": 0, "Production_Line": 0, "Units_Produced": 1, "Defects": 2, "Operator_Name": 2, "Shift": 0}, "value_counts": {"Production_Line": {"line1": 4, "line2": 7, "line3": 3}, "Shift": {"Morning": 5, "Afternoon": 4, "Night": 4}}, "standardized_operators": {"John Doe": 4, "Jane Smith": 1, "Mike O'Neil": 4, "Anna Lee": 3, "Sarah Connor": 2, "Missing": 2}, "units_produced_stats": {"count": 14, "mean": 1027.86, "median": 1037.5, "min": 900, "max": 1150}, "defects_stats": {"count": 12, "mean": 3.92, "median": 4, "min": 0, "max": 7}, "defect_rate_by_line": {"line1": 4.75, "line2": 3.57, "line3": 3.0}, "production_trend": {"earliest_date": "2024-05-01", "latest_date": "2024-05-14", "units_produced_total": 14390}}}
{"purpose": "Analyze customer purchase behavior and product category trends in an ecommerce store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,UnitsSold,UnitPrice,PaymentMethod,DeliveryStatus\n1001,C001,2023/01/15,Electronics,2,299.99,CreditCard,delivered\n1002,C002,01-18-2023,Home & Kitchen,1,89.5,paypal,Delivered\n1003,C003,2023-01-20,Toys,3,,CreditCard,shipped\n1004,C001,2023/1/25,electronics,1,299.99,CREDITcard,delivered\n1005,C004,2023-01-28,Books,NaN,15.0,Cash,Returned\n1006,,2023-02-01,Home & kitchen,2,89.5,paypal,delivered\n1007,C005,02/05/2023,Toys,5,19.99,CreditCard,DELIVERED\n1008,C006,2023-02-10,books,1,15.0,Cash,delivered\n1009,C007,2023-02-12,Electronics,NaN,299.99,CreditCard,shipped\n1010,C002,2023/02/15,Home & Kitchen,2,89.5,paypal,\n1011,C008,2023-02-18,Toys,1,19.99,CreditCard,delivered\n1012,C009,2023-02-20,,3,49.99,Cash,delivered\n1013,C010,02-22-2023,Electronics,1,abc,CreditCard,returned\n1014,C011,2023/02/25,Books,2,15.0,Paypal,delivered", "eda_steps": ["Standardize the ProductCategory column to consistent capitalization and correct misspellings", "Parse and unify the OrderDate column to a single date format", "Identify and count missing values in each column", "Calculate descriptive statistics (mean, median) for UnitsSold and UnitPrice", "Generate value counts for PaymentMethod and DeliveryStatus", "Identify top 3 ProductCategory by total UnitsSold", "Check for any inconsistent or invalid numeric entries in UnitsSold and UnitPrice", "Summarize number of unique customers", "Analyze correlation between UnitsSold and UnitPrice"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 0, "ProductCategory": 1, "UnitsSold": 3, "UnitPrice": 1, "PaymentMethod": 0, "DeliveryStatus": 1}, "value_counts": {"PaymentMethod": {"CreditCard": 7, "paypal": 3, "Paypal": 1, "Cash": 3, "CREDITcard": 1}, "DeliveryStatus": {"delivered": 7, "Delivered": 2, "shipped": 2, "Returned": 1, "returned": 1, "": 1, "DELIVERED": 1}}, "summary_stats": {"UnitsSold": {"mean": 2.14, "median": 2, "invalid_entries": 0}, "UnitPrice": {"mean": 102.85, "median": 89.5, "invalid_entries": 1}}, "top_categories": {"Electronics": 5, "Home & Kitchen": 5, "Toys": 9, "Books": 3}, "unique_customers": 11, "correlations": {"UnitsSold_UnitPrice": -0.14}}}
{"purpose": "Analyze customer churn patterns and service usage in a telecom dataset to identify potential risk factors.", "raw_table": "CustomerID,JoinDate,PlanType,MonthlyCharge,DataUsageGB,Churned,CustomerRegion\n001,2022-01-15,standard,45.99,12.5,No,North\n002,15/02/2022,Premium,89.5,45.2,yes,South\n003,,BASIC,30,8.1,No,East\n004,2022-03-05,standard,,15,No,west\n005,2022.04.10,Premium,99.99,60.1,YES,North\n006,2022-02-28,preMIum,75.5,NaN,No,Unknown\n007,2022-01-30,basic,25,,No,South\n008,2022-03-15,Standard,50,20.3,No,East\n009,March 20 2022,Premium,85,50.5,Yes,North\n010,2022/04/01,Basic,28,7.9,no,west\n011,2022-01-25,standard,48,18.7,,South\n012,2022-02-14,,55,25.1,No,East\n013,14-03-2022,Standard,NA,17,yes,North\n014,2022-03-22,PREMIUM,95,55.0,No,South", "eda_steps": ["Check for missing values in each column", "Standardize 'PlanType' capitalization and handle missing values", "Parse and standardize 'JoinDate' into a consistent date format", "Calculate descriptive statistics for 'MonthlyCharge' and 'DataUsageGB'", "Generate value counts for 'Churned' and 'CustomerRegion'", "Identify rows with inconsistent or unusual entries and count them", "Compute correlation between 'MonthlyCharge' and 'DataUsageGB'", "Determine the percentage of customers who have churned by 'PlanType'", "Summarize the distribution skewness for numeric columns"], "eda_results": {"missing_values": {"CustomerID": 0, "JoinDate": 1, "PlanType": 1, "MonthlyCharge": 2, "DataUsageGB": 3, "Churned": 1, "CustomerRegion": 1}, "value_counts": {"Churned": {"No": 8, "Yes": 5, "": 1}, "CustomerRegion": {"North": 5, "South": 4, "East": 3, "west": 2, "Unknown": 1}}, "plan_type_standardized_counts": {"Basic": 4, "Standard": 5, "Premium": 5, "Missing": 1}, "join_date_issues": 1, "monthly_charge_stats": {"count": 13, "mean": 59.45, "std_dev": 23.56, "min": 25, "max": 99.99, "skewness": 0.75}, "data_usage_stats": {"count": 11, "mean": 26.7, "std_dev": 18.6, "min": 7.9, "max": 60.1, "skewness": 1.05}, "correlation_monthly_charge_data_usage": 0.92, "churn_rate_by_plan": {"Basic": "25%", "Standard": "20%", "Premium": "60%", "Missing": "0%"}, "inconsistent_entries_count": 3}}
{"purpose": "Analyze customer purchase behavior and identify trends in product categories and order timing.", "raw_table": "OrderID,CustomerID,ProductCategory,OrderDate,Quantity,UnitPrice,PaymentMethod\n1001,C123,Electronics,2023/01/15,2,299.99,Credit card\n1002,C124,Clothing,15-01-2023,1,49.5,PayPal\n1003,C125,home appliances,2023-01-16, ,199.95,Credit Card\n1004,C126,Electronics,01/17/2023,3,,credit card\n1005,C127,fashion,01/18/23,2,35.00,Cash\n1006,C128,Clothing,2023-01-18,1,49.5,PayPal\n1007,C129,Toys,2023-1-19,4,15.99,Cash\n1008,C130,Toys,,2,15.99,Credit card\n1009,C131,Electronics,2023-01-20,1,299.99,Credit Card\n1010,C132,Fashion,20-01-2023,1,35.00,paypal\n1011,C133,Home Appliances,2023/01/21,1,199.95,Credit Card\n1012,C134,Clothing,2023-01-22, ,49.5,Credit card\n1013,C135,Electronics,01-23-2023,2,299.99,Credit Card", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization of categorical columns (ProductCategory, PaymentMethod)", "Parse OrderDate into a consistent date format", "Compute descriptive statistics for Quantity and UnitPrice", "Generate value counts for ProductCategory and PaymentMethod", "Identify orders with missing Quantity or UnitPrice and examine their distribution", "Calculate total sales per ProductCategory (Quantity * UnitPrice)", "Find the correlation between Quantity and UnitPrice", "Determine the number of orders per day"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 0, "ProductCategory": 0, "OrderDate": 1, "Quantity": 3, "UnitPrice": 1, "PaymentMethod": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home Appliances", "Fashion", "Toys"], "PaymentMethod": ["Credit Card", "Paypal", "Cash"]}, "date_parsing_errors": 0, "summary_stats": {"Quantity": {"count": 12, "mean": 1.75, "min": 1, "max": 4, "missing": 3}, "UnitPrice": {"count": 12, "mean": 109.98, "min": 15.99, "max": 299.99, "missing": 1}}, "value_counts": {"ProductCategory": {"Electronics": 4, "Clothing": 3, "Home Appliances": 2, "Fashion": 2, "Toys": 2}, "PaymentMethod": {"Credit Card": 7, "Paypal": 3, "Cash": 2}}, "orders_with_missing_qty_or_price": 4, "total_sales_per_category": {"Electronics": 2099.93, "Clothing": 148.5, "Home Appliances": 199.95, "Fashion": 105.0, "Toys": 95.94}, "correlation_quantity_unitprice": -0.12, "orders_per_day": {"2023-01-15": 2, "2023-01-16": 1, "2023-01-17": 1, "2023-01-18": 2, "2023-01-19": 1, "2023-01-20": 1, "2023-01-21": 1, "2023-01-22": 1, "2023-01-23": 1, "missing_date": 1}}}
{"purpose": "Examine crop yield patterns and field characteristics to improve farm productivity.", "raw_table": "Field_ID,Crop_Type,Planting_Date,Harvest_Date,Yield_kg,Soil_Type,Moisture_Level,pesticide_used\nF001,WHEAT,2023-03-15,2023/08/20,1500,Loamy,30,Yes\nF002,Corn,15-Mar-2023,2023-08-22,NaN,Clay,45,No\nF003,wheat,2023-03-20,2023-08-19,1400,loamy,28,yes\nF004,Rice,2023/03/10,2023-09-01,1100,Sandy,,No\nF005,CORN,2023-03-18,2023-08-25,1350,Clay,50,Yes\nF006,Rice,,2023-09-05,1150,Sandy,40,no\nF007,Barley,2023-03-22,2023-08-30,900,Loamy,35,No\nF008,barley,2023/03/25,2023/08/29,950,loamy,33,Yes\nF009,wheat,March 17 2023,2023-08-21,1450,LOAMY,31,No\nF010,Corn,2023-03-19,2023-08-23,1300,clay,47,Yes", "eda_steps": ["Check for missing values and their percentages in each column", "Standardize Crop_Type capitalization and summarize unique crops", "Convert Planting_Date and Harvest_Date to a uniform date format", "Calculate the duration between Planting_Date and Harvest_Date for each record", "Compute descriptive statistics for numeric columns: Yield_kg, Moisture_Level, and planting-to-harvest duration", "Generate value counts for Soil_Type and pesticide_used columns", "Identify any correlations between Moisture_Level and Yield_kg", "Summarize which Crop_Type has the highest average yield", "Detect any outliers or inconsistent entries in Yield_kg"], "eda_results": {"missing_values": {"Field_ID": "0%", "Crop_Type": "0%", "Planting_Date": "10%", "Harvest_Date": "0%", "Yield_kg": "10%", "Soil_Type": "0%", "Moisture_Level": "10%", "pesticide_used": "0%"}, "standardized_crops": {"Wheat": 4, "Corn": 3, "Rice": 2, "Barley": 2}, "date_conversion_success": "100%", "planting_to_harvest_days_stats": {"mean": 158, "min": 153, "max": 165, "std_dev": 4.5}, "numeric_summary_stats": {"Yield_kg": {"count": 13, "mean": 1221.54, "std_dev": 230.11, "min": 900, "max": 1500}, "Moisture_Level": {"count": 12, "mean": 37.25, "std_dev": 7.7, "min": 28, "max": 50}}, "value_counts": {"Soil_Type": {"Loamy": 5, "Clay": 3, "Sandy": 2}, "pesticide_used": {"Yes": 5, "No": 5}}, "correlations": {"Moisture_Level_vs_Yield_kg": 0.62}, "crop_average_yield": {"Wheat": 1450, "Corn": 1316.7, "Rice": 1125, "Barley": 925}, "yield_outliers": {"None_detected": true}}}
{"purpose": "Analyze customer purchase behavior and product categories in recent ecommerce transactions.", "raw_table": "OrderID,CustomerID,Product,Category,Quantity,Price,OrderDate,PaymentMethod\n1001,C123,wireless mouse,Electronics,2,15.99,2023-01-15,Credit Card\n1002,C124,Office CHair,Furniture,1,89.50,15/01/2023,credit card\n1003,C125,usb-c Cable,electronics,3,7.5,2023-1-16,Paypal\n1004,C126,,Furniture,1,,2023/01/17,CASH\n1005,C127,Desk Lamp,Home & garden,2,22.0,2023-01-18,credit Card\n1006,C128,wireless Mouse,Electronics,1,16,18-01-2023,PayPal\n1007,C129,Notebook,,5,2.5,2023-01-19,Cash\n1008,C130,office chair,Furniture,1,85.00,2023-01-20,Credit card\n1009,C131,Desk lamp,Home & Garden,1,21.5,2023-01-21,Credit Card\n1010,C132,USB-C Cable,Electronics,,7.5,2023-01-22,Paypal\n1011,C133,wireless mouse,Electronics,2,16.0,,credit card\n1012,C134,Desk Lamp,Home & Garden,1,22.0,2023-01-23,Credit Card", "eda_steps": ["Check for missing values in each column", "Standardize the Category and PaymentMethod columns capitalization", "Convert OrderDate to a consistent date format", "Compute descriptive statistics for Quantity and Price", "Identify unique products and their frequency", "Calculate total revenue per product", "Summarize payment method usage counts", "Find orders with missing Quantity or Price values"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 0, "Product": 1, "Category": 1, "Quantity": 2, "Price": 1, "OrderDate": 1, "PaymentMethod": 0}, "standardized_categories": {"electronics": 5, "furniture": 3, "home & garden": 3, "missing": 1}, "standardized_payment_methods": {"Credit Card": 6, "Paypal": 3, "Cash": 2}, "date_range": {"earliest_order": "2023-01-15", "latest_order": "2023-01-23", "missing_dates": 1}, "quantity_stats": {"count": 13, "mean": 1.92, "min": 1, "max": 5}, "price_stats": {"count": 14, "mean": 23.0, "min": 2.5, "max": 89.5}, "product_frequencies": {"wireless mouse": 3, "office chair": 2, "usb-c cable": 2, "desk lamp": 3, "notebook": 1, "missing": 1}, "total_revenue_per_product": {"wireless mouse": 95.97, "office chair": 174.5, "usb-c cable": 37.5, "desk lamp": 87.5, "notebook": 12.5, "missing": 0}, "orders_missing_quantity_or_price": [1004, 1010]}}
{"purpose": "Examine monthly transaction patterns and customer segmentation in retail banking.", "raw_table": "Transaction_ID,Customer_ID,Transaction_Date,Transaction_Amount,Account_Type,Transaction_Type\nT001,C001,2023-01-15,250.00,Checking,Deposit\nT002,C002,1/18/2023,,-Savings,Withdrawal\nT003,C003,2023-02-05,1000.50,CHECKING,Deposit\nT004,C004,2023/02/20,200,Checking,withdrawal\nT005,C002,2023-03-01,,Savings,Deposit\nT006,C005,15-03-2023,500.00,savings,Deposit\nT007,C001,2023-03-20,-150,Checking,Withdrawal\nT008,C006,2023.04.01,300.25,Savings,Deposit\nT009,C007,,400.00,checking,Deposit\nT010,C008,2023-04-15,NaN,Checking,Withdrawal\nT011,C009,2023-04-20,700.00,Savings,Withdrawal\nT012,C010,2023-05-01,250.75,Savings,Deposit\nT013,C011,2023-05-07,,-Checking,Deposit\nT014,C002,2023-05-15,100.00,Savings,Withdrawal", "eda_steps": ["Check and count missing values in each column", "Standardize date formats in Transaction_Date column", "Convert Transaction_Amount to numeric, handling missing and invalid entries", "Analyze the distribution of Account_Type ignoring case sensitivity", "Generate value counts for Transaction_Type", "Compute summary statistics for Transaction_Amount", "Identify transactions with negative or zero amounts", "Summarize number of transactions per Customer_ID"], "eda_results": {"missing_values": {"Transaction_ID": 0, "Customer_ID": 0, "Transaction_Date": 1, "Transaction_Amount": 4, "Account_Type": 0, "Transaction_Type": 0}, "date_standardization": {"formats_detected": ["yyyy-mm-dd", "m/d/yyyy", "dd-mm-yyyy", "yyyy/mm/dd", "yyyy.mm.dd"], "missing_dates": 1}, "transaction_amount_conversion": {"converted_to_numeric": 10, "missing_or_invalid": 4, "negative_values_count": 1}, "account_type_distribution": {"checking": 6, "savings": 7, "mixed_case_inconsistencies": 3}, "transaction_type_counts": {"Deposit": 8, "Withdrawal": 6}, "transaction_amount_summary": {"count": 10, "mean": 375.95, "std_dev": 299.42, "min": -150, "25_percentile": 200, "median": 275.38, "75_percentile": 500.13, "max": 1000.5}, "negative_or_zero_transactions": 1, "transactions_per_customer": {"C001": 2, "C002": 3, "C003": 1, "C004": 1, "C005": 1, "C006": 1, "C007": 1, "C008": 1, "C009": 1, "C010": 1, "C011": 1}}}
{"purpose": "Analyze temperature and precipitation patterns across different cities to identify data quality issues and seasonal trends.", "raw_table": "Date,City,Temperature_C,Precipitation_mm,Weather_Condition\n2023/01/15,New york,5.2,12.5,Rain\n15-02-2023,los Angeles,18.3,,Sunny\n2023-03-10,CHICAGO,-2.0,5.0,Snow\n2023-04-05,New York,12.1,0,clear\n2023-05-20,los angeles,20.5,N/A,sunny\n2023/06/18,Chicago,25.0,0,Clear\n2023-07-22,New york,,7.8,Rain\n2023-08-30,LOS ANGELES,28.4,0,Sunny\n2023-09-15,chicago,18.2,,cloudy\n2023/10/10,new york,10.0,3.2,Fog\n2023-11-01,Los angeles,16.7,0,Sunny\n2023-12-25,CHICAGO,-5.5,15.3,Snow\n2023-13-01,New York,3.0,5.0,Rain", "eda_steps": ["Parse and standardize the Date column to a uniform date format", "Normalize City names to consistent capitalization", "Identify and quantify missing values in each column", "Compute descriptive statistics for Temperature_C and Precipitation_mm", "Generate value counts for the Weather_Condition column", "Check for invalid dates or outliers in the Date column", "Analyze temperature variation by City", "Identify rows with inconsistent or unusual Weather_Condition entries"], "eda_results": {"missing_values": {"Date": 0, "City": 0, "Temperature_C": 1, "Precipitation_mm": 3, "Weather_Condition": 0}, "value_counts": {"Weather_Condition": {"Sunny": 4, "Rain": 3, "Clear": 2, "Snow": 2, "Fog": 1, "cloudy": 1}}, "invalid_dates": ["2023-13-01"], "temperature_stats": {"mean": 12.68, "median": 12.1, "min": -5.5, "max": 28.4, "count": 12}, "precipitation_stats": {"mean": 5.4, "median": 3.2, "min": 0, "max": 15.3, "count": 9}, "city_temperature_means": {"New York": 7.575, "Los Angeles": 20.0, "Chicago": 11.9}, "weather_condition_issues": ["cloudy (inconsistent capitalization compared to others)", "N/A in Precipitation_mm column is treated as missing"]}}
{"purpose": "Analyze city public transportation usage and service satisfaction to identify key areas for improvement.", "raw_table": "City,route_id,date,passenger_count,satisfaction_rating,service_type,issues_reported\nNew york,12,2023-04-01,320,4,Bus,delays\nlos angeles,7,04/02/2023,215,3,Train,\nChicago,5,2023-04-03,NaN,5,Bus,crowding\nHouston,3,2023/04/04,150,2,Bus,delays\nPhoenix,8,2023-4-05,180,NaN,Bus,\nphiladelphia,2,2023-04-06,200,3,Tram,maintenance\nSan Antonio,6,2023-04-07,NaN,4,Bus,\nSan Diego,1,2023-04-08,110,NaN,Train,delays\nDallas,9,,90,2,Bus,crowding\nSan Jose,4,2023-04-10,130,5,Tram,\nAustin,11,2023-04-11,175,4,Bus,delays\nJacksonville,10,2023-4-12,155,3,train,\nfort worth,13,2023-04-13,NaN,2,Bus,maintenance\nColumbus,14,2023-04-14,140,4,Bus,delays\nCharlotte,15,2023-04-15,100,NaN,TrAm,", "eda_steps": ["Check missing value percentages for each column", "Standardize city names capitalization", "Parse and unify date column format", "Compute descriptive statistics for passenger_count and satisfaction_rating", "Generate value counts for service_type", "Identify top 3 cities by total passenger_count", "Summarize common issues_reported frequency", "Calculate correlation between passenger_count and satisfaction_rating"], "eda_results": {"missing_values": {"City": 0, "route_id": 0, "date": 1, "passenger_count": 4, "satisfaction_rating": 4, "service_type": 0, "issues_reported": 5}, "standardized_cities": ["New York", "Los Angeles", "Chicago", "Houston", "Phoenix", "Philadelphia", "San Antonio", "San Diego", "Dallas", "San Jose", "Austin", "Jacksonville", "Fort Worth", "Columbus", "Charlotte"], "date_range": {"min_date": "2023-04-01", "max_date": "2023-04-15", "missing_dates_count": 1}, "summary_stats": {"passenger_count": {"count": 11, "mean": 165.45, "std": 69.18, "min": 90, "25%": 130, "50%": 175, "75%": 200, "max": 320}, "satisfaction_rating": {"count": 11, "mean": 3.45, "std": 1.15, "min": 2, "25%": 3, "50%": 4, "75%": 4, "max": 5}}, "service_type_counts": {"Bus": 9, "Train": 3, "Tram": 3}, "top_cities_by_passenger_count": {"New York": 320, "Los Angeles": 215, "Philadelphia": 200}, "issues_reported_counts": {"delays": 4, "crowding": 2, "maintenance": 2, "": 7}, "correlations": {"passenger_count_vs_satisfaction_rating": 0.28}}}
{"purpose": "Examine crop yield variation and planting dates in different soil types to inform planting strategies.", "raw_table": "Farm_ID,Crop,Planting_Date,Soil_Type,Area_ha,Yield_tonnes,Harvest_Date\nF001,wheat,2023-03-15,Loamy,10.5,32.1,2023-08-20\nF002,Corn,03/20/2023,Sandy,8,25.4,2023-09-10\nF003,Rice,2023-04-01,Clay,12,,2023-09-15\nF004,Wheat,2023-03-18,loamy,9.7,30.0,2023-08-25\nF005,Corn,April 2 2023, SANDY,7.5,24.8,2023-09-12\nF006,Rice,,Clay,11,29.5,2023-09-18\nF007,Barley,2023/03/22,Peaty,6,18.2,2023-07-30\nF008,barley,2023-03-24,peaty,6.2,19.1,2023-08-02\nF009,Wheat,2023-03-16,Loamy,10,,2023-08-21\nF010,Corn,2023-03-21,sandy,,26.0,2023-09-11\nF011,Rice,2023-04-03,clay,13,31.0,2023-09-20\nF012,Barley,2023-03-23,Peaty,6.5,18.8,2023-08-01\nF013,Corn,03-19-2023,SandY,7.9,25.0,2023-09-09\nF014,Wheat,2023-03-17,LOAMY,10.1,31.5,2023-08-22", "eda_steps": ["Standardize crop names and soil type categories to consistent capitalization", "Check and report missing values per column", "Convert Planting_Date and Harvest_Date to date format", "Calculate descriptive statistics (mean, median, std) for numeric columns Area_ha and Yield_tonnes", "Generate value counts for Crop and Soil_Type", "Analyze yield distribution by Soil_Type", "Calculate correlation between Area_ha and Yield_tonnes", "Identify records with missing Planting_Date or Yield_tonnes"], "eda_results": {"missing_values": {"Planting_Date": 1, "Yield_tonnes": 2, "Area_ha": 1}, "value_counts": {"Crop": {"Wheat": 4, "Corn": 4, "Rice": 3, "Barley": 3}, "Soil_Type": {"Loamy": 4, "Sandy": 4, "Clay": 3, "Peaty": 3}}, "summary_stats": {"Area_ha": {"mean": 8.8, "median": 8.75, "std": 2.22}, "Yield_tonnes": {"mean": 26.9, "median": 25.4, "std": 5.08}}, "yield_by_soil_type": {"Loamy": 31.2, "Sandy": 25.3, "Clay": 30.25, "Peaty": 18.7}, "correlations": {"Area_ha vs Yield_tonnes": 0.62}, "records_missing_critical": {"Planting_Date": ["F006"], "Yield_tonnes": ["F003", "F009"]}}}
{"purpose": "Analyze monthly sales performance and customer demographics for retail transactions.", "raw_table": "TransactionID,ProductCategory,SaleAmount,CustomerAge,PurchaseDate,StoreLocation\n1001,Electronics,299.99,34,2023-2-5,New york\n1002,clothing,49.99,28,2023/02/07,Los Angeles\n1003,Home & Garden,,45,2-10-2023,los angeles\n1004,Electronics,199.95,NaN,2023-02-12,NEW YORK\n1005,Clothing,39.99,23,2023-02-15,Chicago\n1006,Toys,15.99,37,2023/2/18,chicago\n1007,Home & garden,89.50,41,2023-02-21,New York\n1008,clothing,59.99,35,2023-02-23,LOS ANGELES\n1009,Electronics,NaN,29,2023-02-26,Chicago\n1010,Toys,19.99,NaN,2023-02-28,new york\n1011,Clothing,49.99,33,2023-03-01,Chicago\n1012,,75.00,40,2023-03-03,New York\n1013,Electronics,299.99,38,2023-03-05,los angeles\n1014,Home & Garden,120.00,39,,Chicago", "eda_steps": ["Check for missing values across all columns", "Standardize capitalization in 'ProductCategory' and 'StoreLocation' columns", "Parse and unify 'PurchaseDate' into consistent date format", "Compute descriptive statistics for 'SaleAmount' and 'CustomerAge'", "Generate value counts for 'ProductCategory' and 'StoreLocation'", "Calculate number of transactions per month", "Identify top 2 product categories by total sales amount", "Examine correlation between 'SaleAmount' and 'CustomerAge'"], "eda_results": {"missing_values": {"TransactionID": 0, "ProductCategory": 1, "SaleAmount": 2, "CustomerAge": 2, "PurchaseDate": 1, "StoreLocation": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home & Garden", "Toys", "Unknown"], "StoreLocation": ["New York", "Los Angeles", "Chicago"]}, "parsed_dates": {"earliest_date": "2023-02-05", "latest_date": "2023-03-05"}, "summary_stats": {"SaleAmount": {"count": 13, "mean": 110.83, "std": 104.75, "min": 15.99, "25%": 49.99, "50%": 59.99, "75%": 199.95, "max": 299.99}, "CustomerAge": {"count": 12, "mean": 34.75, "std": 6.38, "min": 23, "25%": 29, "50%": 35, "75%": 38.5, "max": 45}}, "value_counts": {"ProductCategory": {"Electronics": 4, "Clothing": 4, "Home & Garden": 3, "Toys": 2, "Unknown": 1}, "StoreLocation": {"New York": 5, "Los Angeles": 4, "Chicago": 5}}, "monthly_transactions": {"2023-02": 10, "2023-03": 4}, "top_categories_by_sales": {"Electronics": 799.92, "Home & Garden": 209.5}, "correlations": {"SaleAmount_vs_CustomerAge": -0.12}}}
{"purpose": "Analyze ridership patterns and delays for a city's bus transit system over a two-week period.", "raw_table": "route_id,date,day_of_week,riders,delay_minutes,driver_name,weather_condition\n12,2024-04-01,Monday,120,5,John Doe,Sunny\n07,2024/04/02,tuesday,85,,Jane Smith,Overcast\n15,04-03-2024,Wed,NaN,7,Bob Johnson,Rain\n12,2024-04-04,Thursday,130,3,john doe,Sunny\n07,2024-04-05,Friday,95,NaN,Jane Smith,Cloudy\n15,2024-04-06,Saturday,110,10,Bob johnson,rain\n12,2024-04-07,Sunday,125,2,John Doe,Sunny\n07,2024-4-08,Monday,90,4,Jane Smith,Overcast\n15,2024-04-09,Tuesday,105,,Bob Johnson,Rain\n12,2024-04-10,Wednesday,,6,John Doe,sunny\n07,2024-04-11,thursday,88,5,jane smith,Overcast\n15,2024-04-12,Friday,100,8,Bob Johnson,Rain\n12,2024-04-13,Saturday,115,NaN,John doe,Sunny", "eda_steps": ["Check missing value percentages for each column", "Standardize date formatting to YYYY-MM-DD", "Normalize day_of_week values to title case full names", "Compute descriptive statistics for riders and delay_minutes columns", "Generate value counts for route_id and weather_condition columns", "Identify average delay_minutes per route_id", "Find the top 2 drivers by total ridership", "Examine correlation between riders and delay_minutes", "Summarize ridership totals by day_of_week"], "eda_results": {"missing_values": {"route_id": 0, "date": 0, "day_of_week": 0, "riders": 1, "delay_minutes": 4, "driver_name": 0, "weather_condition": 0}, "standardized_dates": ["2024-04-01", "2024-04-02", "2024-04-03", "2024-04-04", "2024-04-05", "2024-04-06", "2024-04-07", "2024-04-08", "2024-04-09", "2024-04-10", "2024-04-11", "2024-04-12", "2024-04-13"], "normalized_day_of_week": ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"], "summary_stats": {"riders": {"count": 12, "mean": 105.83, "std": 15.27, "min": 85, "25%": 90, "50%": 105, "75%": 120, "max": 130}, "delay_minutes": {"count": 9, "mean": 5.56, "std": 2.41, "min": 2, "25%": 4, "50%": 5, "75%": 7, "max": 10}}, "value_counts": {"route_id": {"12": 5, "07": 4, "15": 4}, "weather_condition": {"Sunny": 5, "Overcast": 3, "Rain": 4, "Cloudy": 1}}, "average_delay_per_route": {"12": 4.0, "07": 4.67, "15": 8.33}, "top_drivers_by_ridership": {"John Doe": 490, "Bob Johnson": 415}, "correlation_riders_delay": 0.58, "ridership_by_day_of_week": {"Monday": 210, "Tuesday": 190, "Wednesday": 105, "Thursday": 218, "Friday": 195, "Saturday": 225, "Sunday": 125}}}
{"purpose": "Analyze sales performance and customer demographics for a retail store to identify trends and data quality issues.", "raw_table": "OrderID,CustomerID,ProductCategory,Quantity,Price,OrderDate,CustomerAge,CustomerRegion\n1001,C001,electronics,2,399.99,2023-01-15,34,North\n1002,C002,Clothing,1,29.99,15/01/2023,28,South\n1003,C003,Home & kitchen,,89.50,2023/01/16,45,East\n1004,C004,clothing,3,25.00,2023-01-17,NaN,west\n1005,,Electronics,1,199.99,01-18-2023,39,North\n1006,C006,Books,5,9.99,2023.01.19,23,South\n1007,C007,Home & Kitchen,2,85.00,2023-1-20,51,East\n1008,C008,Clothing,NaN,35.00,2023-01-20,30,NORTH\n1009,C009,Electronics,1,NaN,2023-01-21,44,East\n1010,C010,books,3,12.50,2023-01-22,27,South\n1011,C011,Clothing,2,27.00,2023-01-23,29,South\n1012,C012,Home & kitchen,4,NaN,2023-01-24,50,East\n1013,C013,Toys,1,15.00,2023-01-25,22,West", "eda_steps": ["Check the number and percentage of missing values in each column", "Standardize the ProductCategory and CustomerRegion columns to consistent capitalization", "Compute descriptive statistics (mean, median, std) for Quantity, Price, and CustomerAge", "Generate value counts for ProductCategory and CustomerRegion", "Identify orders with missing or inconsistent OrderDate formats", "Calculate the average order price per ProductCategory", "Check for correlations between Quantity, Price, and CustomerAge", "Find the top 3 most frequent ProductCategory entries"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "ProductCategory": 0, "Quantity": 2, "Price": 3, "OrderDate": 0, "CustomerAge": 1, "CustomerRegion": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home & Kitchen", "Books", "Toys"], "CustomerRegion": ["North", "South", "East", "West"]}, "summary_stats": {"Quantity": {"count": 13, "mean": 2.31, "median": 2, "std": 1.43}, "Price": {"count": 12, "mean": 104.29, "median": 27.0, "std": 138.99}, "CustomerAge": {"count": 14, "mean": 34.14, "median": 31, "std": 9.96}}, "value_counts": {"ProductCategory": {"Clothing": 4, "Electronics": 3, "Home & Kitchen": 3, "Books": 2, "Toys": 1}, "CustomerRegion": {"South": 4, "East": 4, "North": 3, "West": 2}}, "inconsistent_order_dates": {"formats_found": ["YYYY-MM-DD", "DD/MM/YYYY", "YYYY/MM/DD", "MM-DD-YYYY", "YYYY.MM.DD", "YYYY-M-D"], "rows_with_nonstandard_format": [1002, 1003, 1005, 1006, 1007]}, "average_price_per_category": {"Electronics": 299.99, "Clothing": 29.0, "Home & Kitchen": 87.25, "Books": 11.25, "Toys": 15.0}, "correlations": {"Quantity_Price": 0.68, "Quantity_CustomerAge": -0.12, "Price_CustomerAge": 0.05}, "top_3_product_categories": ["Clothing", "Electronics", "Home & Kitchen"]}}
{"purpose": "Analyze housing listing details to understand data quality and feature distributions for pricing insights.", "raw_table": "ListingID,DateListed,Price,Location,Bedrooms,Bathrooms,SquareFeet,PropertyType,YearBuilt\n1001,2023-01-15,450000,downtown,3,2,1500,Condo,2005\n1002,01/20/2023,NA,Suburbs,4,,2000,Single Family,1998\n1003,2023/01/25,550000,suburbs,3,2,1800,townhouse,2010\n1004,2023-02-01,620000,DOWNTOWN,4,3,2300,Single family,NA\n1005,2/5/2023,700000,Suburbs,5,3,2500,Single Family,2015\n1006,2023-02-10,NA,downtown,2,1,,Condo,2000\n1007,2023-02-15,480000,Suburbs,3,2,1600,TownHouse,2008\n1008,02/18/2023,530000,Downtown,3,,1700,Condo,2007\n1009,2023-02-20,750000,suburbs,5,4,2700,Single family,2018\n1010,2023-02-25,NA,,4,3,2200,Single Family,2012\n1011,2023-02-28,460000,Suburbs,3,2,1650,,2011\n1012,03/01/2023,670000,Downtown,4,3,2100,Condo,2009\n", "eda_steps": ["Check missing value percentages for all columns", "Standardize and unify capitalization for categorical columns Location and PropertyType", "Convert DateListed into a consistent date format", "Compute descriptive statistics for numeric columns Price, Bedrooms, Bathrooms, SquareFeet, and YearBuilt", "Generate value counts for categorical columns Location and PropertyType", "Identify listings with missing Price values", "Compute correlation matrix between numeric features", "Find the top 2 most common PropertyType categories", "Summarize the range of listing dates"], "eda_results": {"missing_values": {"ListingID": 0, "DateListed": 0, "Price": 3, "Location": 1, "Bedrooms": 0, "Bathrooms": 3, "SquareFeet": 1, "PropertyType": 1, "YearBuilt": 1}, "standardized_categories": {"Location": {"Downtown": 5, "Suburbs": 6, "": 1}, "PropertyType": {"Condo": 5, "Single Family": 6, "Townhouse": 2, "": 1}}, "date_range": {"earliest_listing": "2023-01-15", "latest_listing": "2023-03-01"}, "summary_stats": {"Price": {"count": 9, "mean": 580000, "min": 450000, "max": 750000, "std": 103923.05}, "Bedrooms": {"count": 12, "mean": 3.83, "min": 2, "max": 5, "std": 0.98}, "Bathrooms": {"count": 9, "mean": 2.44, "min": 1, "max": 4, "std": 0.94}, "SquareFeet": {"count": 11, "mean": 19618, "min": 1500, "max": 2700, "std": 407.06}, "YearBuilt": {"count": 11, "mean": 2008.7, "min": 1998, "max": 2018, "std": 6.33}}, "value_counts": {"Location": {"Downtown": 5, "Suburbs": 6, "": 1}, "PropertyType": {"Single Family": 6, "Condo": 5, "Townhouse": 2, "": 1}}, "listings_missing_price": [1002, 1006, 1010], "correlations": {"Price_Bedrooms": 0.89, "Price_Bathrooms": 0.85, "Price_SquareFeet": 0.92, "Price_YearBuilt": 0.35}, "top_categories": {"PropertyType": [{"category": "Single Family", "count": 6}, {"category": "Condo", "count": 5}]}}}
{"purpose": "Examine citizen complaints data to identify common complaint types and assess data quality issues.", "raw_table": "Complaint_ID, Submission_Date, Department, Complaint_Type, Resolution_Status, Response_Time_Days, Citizen_Age\n001, 2023-01-15, sanitation, Noise, Resolved, 3, 34\n002, 15/02/2023, Transportation, noise, Pending, , 28\n003,, HEALTH, Water Supply, Resolved, 5, 45\n004, 2023-03-10, Sanitation, Trash COLLECTION, Resolved, 2, 51\n005, 03-25-2023, transportation, Noise, Resolved, 4, \n006, 2023/04/01, Health, Water supply, Pending, 7, 38\n007, 2023-04-15, Sanitation, Noise, Resolved, 1, 40\n008, 2023-04-20, TRANSPORTATION, Traffic, Resolved, 6, 29\n009, 2023-04-22, sanitation, Garbage, Pending, , 60\n010, 2023-05-01, Health, water supply, resolved, 3, 50\n011, 2023-05-05, Transportation, Noise, Resolved, 2, 33\n012, 2023.05.10, Health, Noise, Pending, 8, 42\n013, 2023-05-15, sanitation, Traffic, resolved, 2, 36", "eda_steps": ["Check the total number of rows and columns", "Identify missing values and their percentages per column", "Standardize and clean the Department and Complaint_Type columns", "Generate descriptive statistics for Response_Time_Days and Citizen_Age", "Count unique categories and their frequencies in Department and Complaint_Type", "Calculate the number of complaints per Resolution_Status category", "Analyze the distribution of Response_Time_Days for resolved complaints", "Identify complaints with missing Response_Time_Days", "Explore correlation between Citizen_Age and Response_Time_Days"], "eda_results": {"summary_stats": {"Response_Time_Days": {"count": 11, "mean": 3.91, "std": 2.31, "min": 1, "25%": 2, "50%": 3, "75%": 5, "max": 8}, "Citizen_Age": {"count": 12, "mean": 40.75, "std": 9.23, "min": 28, "25%": 34, "50%": 38.5, "75%": 45, "max": 60}}, "missing_values": {"Complaint_ID": 0, "Submission_Date": 1, "Department": 0, "Complaint_Type": 0, "Resolution_Status": 0, "Response_Time_Days": 3, "Citizen_Age": 1}, "value_counts": {"Department": {"Sanitation": 5, "Transportation": 4, "Health": 4}, "Complaint_Type": {"Noise": 6, "Water Supply": 3, "Trash Collection": 1, "Traffic": 2, "Garbage": 1}, "Resolution_Status": {"Resolved": 8, "Pending": 5}}, "top_categories": {"Complaint_Type": [{"Noise": 6}, {"Water Supply": 3}], "Department": [{"Sanitation": 5}, {"Transportation": 4}]}, "response_time_missing_complaints": ["002", "009", "005"], "correlations": {"Citizen_Age_vs_Response_Time_Days": 0.21}, "complaints_per_status": {"Resolved": 8, "Pending": 5}}}
{"purpose": "Analyze municipal public transportation usage trends and identify data quality issues.", "raw_table": "Date,Route,Passenger_Count,Ticket_Type,Delay_Minutes\n2024-01-01,Route A,150,Regular,5\n01/02/2024,route b, 130,Regular ,0\n2024/01/03,Route A,,Student,3\n2024-01-04,Route C, ninety,Regular,10\n2024-01-05,Route B,120,student,NA\n2024-01-06,Route C,110,Regular,2\n2024-01-07,Route A,140,regular,1\n2024-01-08,route b,135,Student,0\n2024-01-09,Route C,115,regular,4\n2024-01-10,Route B,125,,5\n", "eda_steps": ["Parse dates into consistent datetime format", "Standardize route names to consistent capitalization", "Convert Passenger_Count to numeric, handling invalid entries", "Compute descriptive statistics for Passenger_Count and Delay_Minutes", "Check missing value percentages for all columns", "Generate value counts for Route and Ticket_Type columns", "Identify top 2 routes by average passenger count", "Assess distribution skewness of Passenger_Count", "Summarize delay times average and max by route"], "eda_results": {"missing_values": {"Date": 0, "Route": 0, "Passenger_Count": 1, "Ticket_Type": 1, "Delay_Minutes": 1}, "value_counts": {"Route": {"Route A": 3, "Route B": 3, "Route C": 3, "route b": 1}, "Ticket_Type": {"Regular": 4, "Student": 3, "student": 1, "": 1}}, "summary_stats": {"Passenger_Count": {"count": 9, "mean": 126.67, "std": 11.55, "min": 110, "25%": 120, "50%": 125, "75%": 135, "max": 150}, "Delay_Minutes": {"count": 9, "mean": 3.33, "std": 3.36, "min": 0, "25%": 0, "50%": 3, "75%": 5, "max": 10}}, "top_categories": {"Top 2 Routes by Average Passenger Count": {"Route A": 145, "Route B": 126.67}}, "distribution_skewness": {"Passenger_Count": 0.05}, "delay_summary_by_route": {"Route A": {"average_delay": 3, "max_delay": 5}, "Route B": {"average_delay": 3.33, "max_delay": 5}, "Route C": {"average_delay": 5.33, "max_delay": 10}}}}
{"purpose": "Analyze the characteristics and conditions of recent real estate listings to identify data quality issues and summary statistics.", "raw_table": "ListingID,Price,SqFt,Bedrooms,Bathrooms,Neighborhood,DateListed,Condition\n101,350000,1500,3,2,Maple Ridge,2023-01-15,Good\n102,420000,1750,4,3,maple ridge,15/02/2023,excellent\n103,,1600,3,2,Oakwood,2023-03-01,Fair\n104,380000,NaN,3,,oakwood,03-15-2023,good\n105,295000,1400,2,1,Maple Ridge,2023/04/01,poor\n106,500000,2000,4,3,Pine Hills,2023-04-15,Excellent\n107,450000,1900,4,3,Pine Hills,2023-04-22,\n108,NaN,1700,3,2,Oakwood,April 25 2023,Good\n109,320000,1500,3,2,MAPLE RIDGE,2023-05-01,Fair\n110,400000,1850,4,3,pine Hills,2023-05-10,Good", "eda_steps": ["Check for missing values in each column", "Standardize the 'Neighborhood' column capitalization", "Convert 'DateListed' to a consistent date format", "Compute descriptive statistics for the numeric columns: Price, SqFt, Bedrooms, Bathrooms", "Generate value counts for the 'Condition' categorical column", "Identify top 2 neighborhoods by number of listings", "Calculate correlation matrix for numeric variables", "Summarize missing value percentages", "Analyze distribution skewness for 'Price' and 'SqFt'"], "eda_results": {"missing_values": {"ListingID": 0, "Price": 2, "SqFt": 1, "Bedrooms": 0, "Bathrooms": 2, "Neighborhood": 0, "DateListed": 0, "Condition": 1}, "standardized_neighborhoods": {"Maple Ridge": 4, "Oakwood": 3, "Pine Hills": 3}, "date_format_conversion": {"earliest_date": "2023-01-15", "latest_date": "2023-05-10"}, "summary_stats": {"Price": {"count": 8, "mean": 391250, "std": 68705, "min": 295000, "25%": 337500, "50%": 385000, "75%": 445000, "max": 500000}, "SqFt": {"count": 9, "mean": 17000, "std": 21149, "min": 1400, "25%": 1500, "50%": 1750, "75%": 1900, "max": 2000}, "Bedrooms": {"count": 10, "mean": 3.4, "std": 0.7, "min": 2, "25%": 3, "50%": 3, "75%": 4, "max": 4}, "Bathrooms": {"count": 8, "mean": 2.25, "std": 0.89, "min": 1, "25%": 2, "50%": 2, "75%": 3, "max": 3}}, "value_counts_condition": {"Good": 4, "Excellent": 2, "Fair": 2, "Poor": 1, "missing": 1}, "top_neighborhoods": {"Maple Ridge": 4, "Oakwood": 3}, "correlations": {"Price_SqFt": 0.95, "Price_Bedrooms": 0.86, "Price_Bathrooms": 0.8, "SqFt_Bedrooms": 0.79, "SqFt_Bathrooms": 0.75, "Bedrooms_Bathrooms": 0.88}, "missing_value_percentages": {"Price": 20, "SqFt": 10, "Bathrooms": 20, "Condition": 10}, "skewness": {"Price": 0.12, "SqFt": 0.04}}}
{"purpose": "Analyze patient demographics and lab test results to identify patterns related to diagnosis and treatment outcomes.", "raw_table": "Patient_ID,Age,Gender,Diagnosis,Lab_Result,Visit_Date,Treatment_Status\n001,45,Male,Diabetes,7.8,2023/01/15,Completed\n002,38,female,Hypertension,142,15-02-2023,ongoing\n003,29,F,diabetes,,2023-03-01,Completed\n004,,Male,Asthma,5.6,2023/04/12,Completed\n005,55,Female,COPD,4.2,2023/05/10,Ongoing\n006,60,male,hypertension,150,2023/6/01,completed\n007,47,Female,Diabetes,8.1,06/15/2023,Completed\n008,33,M,Asthma,5.9,2023-07-20,Pending\n009,41,female,,7.2,2023/08/25,Ongoing\n010,50,Female,COPD,4.5,,Completed\n011,39,Male,hypertension,145,2023-09-05,Ongoing\n012,28,Female,Diabetes,7.9,2023/10/12,Completed\n013,44,Male,COPD,4.1,2023/11/30,completed\n014,37,F,Asthma,6.0,2023-12-15,Pending", "eda_steps": ["Check missing value percentages for all columns", "Standardize capitalization in Gender and Diagnosis columns", "Compute descriptive statistics for Age and Lab_Result columns", "Generate value counts for Diagnosis and Treatment_Status columns", "Identify records with missing Diagnosis and Lab_Result", "Check Visit_Date formats and parse into consistent datetime", "Compute average Lab_Result by Diagnosis", "Summarize distribution skewness for Lab_Result"], "eda_results": {"missing_values": {"Patient_ID": 0, "Age": 1, "Gender": 0, "Diagnosis": 1, "Lab_Result": 1, "Visit_Date": 1, "Treatment_Status": 0}, "standardized_categories": {"Gender": {"Male": 6, "Female": 8}, "Diagnosis": {"Diabetes": 5, "Hypertension": 3, "Asthma": 3, "COPD": 3, "Missing": 1}}, "summary_stats": {"Age": {"count": 14, "mean": 41.5, "std": 9.98, "min": 28, "25%": 34.5, "50%": 41, "75%": 47, "max": 60}, "Lab_Result": {"count": 13, "mean": 7.06, "std": 4.54, "min": 4.1, "25%": 4.5, "50%": 6.0, "75%": 7.9, "max": 150}}, "value_counts": {"Treatment_Status": {"Completed": 7, "Ongoing": 4, "Pending": 2}}, "missing_records": {"Missing Diagnosis": ["009"], "Missing Lab_Result": ["003"]}, "visit_date_quality": {"Valid_dates": 13, "Missing_dates": 1, "Date_formats_detected": ["YYYY/MM/DD", "DD-MM-YYYY", "YYYY-MM-DD", "MM/DD/YYYY", "YYYY/M/D"]}, "average_lab_result_by_diagnosis": {"Diabetes": 7.7, "Hypertension": 145.7, "Asthma": 5.83, "COPD": 4.26, "Missing": null}, "lab_result_skewness": 3.9}}
{"purpose": "Analyze quarterly financial performance and transaction patterns of investment accounts.", "raw_table": "AccountID,Date,TransactionType,Amount,AssetType,Region\n1001,2024-01-15,Deposit,5000,Stocks,North America\n1002,15/02/2024,withdrawal,-2000,Bonds,Europe\n1003,2024/03/10,Deposit,7500,real estate,Asia\n1004,2024-02-05,Deposit,,Commodities,South America\n1005,03-01-2024,Withdrawal,-1500,Stocks,north america\n1006,2024-04-20,Deposit,10000,Stocks,Europe\n1007,2024-03-25,Withdrawal,-5000,,Asia\n1008,2024-01-30,deposit,3000,Bonds,Europe\n1009,2024-02-15,Withdrawal,-700,Real Estate,asia\n1010,2024-04-01,Deposit,NaN,Commodities,unknown\n1011,2024-01-20,Withdrawal,-1200,Stocks,North America\n1012,2024-03-05,Deposit,4000,Stocks,South america\n", "eda_steps": ["Check missing value percentages for each column", "Standardize date formats to ISO format (YYYY-MM-DD)", "Normalize capitalization for TransactionType, AssetType, and Region columns", "Compute descriptive statistics for the Amount column", "Generate value counts for TransactionType, AssetType, and Region", "Identify top 3 AssetTypes by total transaction Amount", "Calculate correlation between Amount and numeric encoded TransactionType", "Summarize the number of transactions per quarter"], "eda_results": {"missing_values": {"AccountID": 0, "Date": 0, "TransactionType": 0, "Amount": 2, "AssetType": 1, "Region": 1}, "standardized_dates_sample": ["2024-01-15", "2024-02-15", "2024-03-10"], "normalized_categories_sample": {"TransactionType": ["Deposit", "Withdrawal"], "AssetType": ["Stocks", "Bonds", "Real Estate", "Commodities"], "Region": ["North America", "Europe", "Asia", "South America", "Unknown"]}, "summary_stats_amount": {"count": 13, "mean": 2084.62, "std": 4153.77, "min": -7000, "25%": -1500, "50%": 3000, "75%": 5000, "max": 10000}, "value_counts": {"TransactionType": {"Deposit": 7, "Withdrawal": 6}, "AssetType": {"Stocks": 5, "Bonds": 2, "Real Estate": 2, "Commodities": 2, "Missing": 1}, "Region": {"North America": 3, "Europe": 3, "Asia": 3, "South America": 2, "Unknown": 1}}, "top_asset_types_by_amount": {"Stocks": 17700, "Real Estate": 6800, "Bonds": 1000}, "correlation_amount_transactiontype": -0.85, "transactions_per_quarter": {"Q1 2024": 11, "Q2 2024": 2}}}
{"purpose": "Examine production line efficiency and defect rates across different shifts and machine operators.", "raw_table": "Production_ID,Date,Shift,Operator,Machine,Units_Produced,Defect_Rate,Production_Time\n101,2024/04/01,MornIng,alice,MX100,250,0.02,8.5\n102,04-02-2024,Night,Bob,MX100,230,,8\n103,2024-04-03,Afternoon,CHARLIE,mx200,245,0.01,7.8\n104,4/4/2024,Morning,Alice,MX200,,0.03,8.2\n105,2024/04/05,night,Bob,mx100,220,0.05,7.9\n106,2024-04-06,Afternoon,charlie,MX100,240,0.00,8\n107,04-07-2024,Morning,alice,mx300,260,0.04,8.3\n108,2024/04/08,NIGHT,Bob,MX300,255,0.02,8.1\n109,2024-4-9,Afternoon,Charlie,mx200,235,0.01,7.7\n110,2024/04/10,Morning,Alice,mx100,245,NaN,8.4\n", "eda_steps": ["Standardize the 'Shift' column capitalization", "Check and count missing values for each column", "Convert 'Date' column to consistent date format", "Compute descriptive statistics for 'Units_Produced', 'Defect_Rate', and 'Production_Time'", "Generate value counts for 'Operator' and 'Machine' columns", "Calculate average defect rate by shift", "Identify top 2 operators by total units produced", "Examine correlation between 'Units_Produced' and 'Production_Time'"], "eda_results": {"missing_values": {"Units_Produced": 1, "Defect_Rate": 2, "Production_Time": 0, "Production_ID": 0, "Date": 0, "Shift": 0, "Operator": 0, "Machine": 0}, "standardized_shifts": {"Morning": 4, "Afternoon": 3, "Night": 3}, "date_format_consistency": "All dates converted to YYYY-MM-DD format", "summary_stats": {"Units_Produced": {"count": 14, "mean": 241.4, "std": 13.0, "min": 220, "max": 260}, "Defect_Rate": {"count": 12, "mean": 0.021, "std": 0.017, "min": 0.0, "max": 0.05}, "Production_Time": {"count": 14, "mean": 8.04, "std": 0.25, "min": 7.7, "max": 8.5}}, "value_counts": {"Operator": {"Alice": 4, "Bob": 3, "Charlie": 3}, "Machine": {"MX100": 6, "MX200": 3, "MX300": 2}}, "average_defect_rate_by_shift": {"Morning": 0.025, "Afternoon": 0.007, "Night": 0.035}, "top_2_operators_by_units": {"Alice": 1000, "Charlie": 720}, "correlations": {"Units_Produced_vs_Production_Time": -0.45}}}
{"purpose": "Examine crop yield patterns and factors influencing yield variability across different farms during the 2023 season.", "raw_table": "Farm_ID,Crop,Planting_Date,Harvest_Date,Yield_Tons,Soil_Type,Fertilizer_Used,Rainfall_mm\nF001,Corn,03-15-2023,09/20/2023,12.5,Loam,NPK 10-10-10,450\nF002,wheat,2023/04/02,10-15-2023,9.3,Sandy,Organic,380\nF003,Rice,April 10 2023,10/30/2023,,Clay,NPK 20-10-10,500\nF004,CORN,03/20/2023,09-25-2023,13.1,loam,chemical,480\nF005,Barley,2023-03-25,10/05/2023,8.7,SILTY,organic,420\nF006,Wheat,04-05-23,10/12/23,9.8,Sandy,NPK 10-10-10,395\nF007,Rice,04/11/2023,10/28/2023,11.2,Clay,,510\nF008,Barley,03/28/2023,10/07/2023,8.5,Silty,Organic,415\nF009,corn,15-03-2023,20/09/2023,12.9,Loam,NPK 10-10-10,460\nF010,Wheat,04/03/2023,10/13/2023,9.6,Sandy,chemical,390\nF011,Rice,04-12-2023,10/29/2023,10.8,Clay,NPK 20-10-10,505\nF012,Barley,03-30-2023,10-08-2023,8.4,silty,organic,425\nF013,Corn,03/18/2023,09/22/2023,12.7,Loam,NPK 10-10-10,455", "eda_steps": ["Check and report missing value counts for each column", "Standardize crop names to title case and report unique crops", "Parse and standardize date columns to ISO format (YYYY-MM-DD)", "Compute descriptive statistics (mean, median, std) for Yield_Tons and Rainfall_mm", "Generate value counts for Soil_Type and Fertilizer_Used including inconsistencies", "Calculate correlation between Yield_Tons and Rainfall_mm", "Identify farms with missing Yield_Tons", "Summarize average Yield_Tons by Crop type"], "eda_results": {"missing_values": {"Yield_Tons": 1, "Fertilizer_Used": 1}, "unique_crops": ["Corn", "Wheat", "Rice", "Barley"], "date_standardization_sample": {"Planting_Date_original_examples": ["03-15-2023", "2023/04/02", "April 10 2023", "15-03-2023"], "Planting_Date_standardized_examples": ["2023-03-15", "2023-04-02", "2023-04-10", "2023-03-15"]}, "summary_stats": {"Yield_Tons": {"mean": 10.36, "median": 9.8, "std_dev": 1.81, "count": 14}, "Rainfall_mm": {"mean": 448.2, "median": 455, "std_dev": 40.2, "count": 14}}, "value_counts": {"Soil_Type": {"Loam": 4, "Sandy": 3, "Clay": 4, "Silty": 4}, "Fertilizer_Used": {"NPK 10-10-10": 5, "Organic": 4, "chemical": 2, "NPK 20-10-10": 3, "": 1}}, "correlations": {"Yield_Tons_vs_Rainfall_mm": 0.54}, "farms_missing_yield": ["F003"], "average_yield_by_crop": {"Corn": 12.8, "Wheat": 9.57, "Rice": 10.67, "Barley": 8.53}}}
{"purpose": "Analyze user engagement patterns and content types on a social media platform.", "raw_table": "user_id,post_date,content_type,likes,comments,shares\nU001,2023-3-5,Photo,120,15,5\nU002,2023/03/06,video,250,20,8\nu003,03-07-2023,Text,35,,2\nU004,March 8 2023,photo,80,5,N/A\nU005,2023-03-09,Live Video,150,25,10\nU006,2023/3/10,TEXT,40,3,1\nU007,2023-03-11,video,,7,4\nu008,2023.03.12,Photo,95,12,3\nU009,2023-13-03,photo,70,,2\nU010,2023-03-14,live video,160,30,12\nU011,,Text,50,6,2\nU012,2023-03-16,Photo,110,14,5\n", "eda_steps": ["Check and summarize missing values in each column", "Standardize date formats and identify any invalid dates", "Normalize content_type categories to consistent capitalization", "Compute descriptive statistics for likes, comments, and shares", "Generate value counts for content_type", "Identify posts with missing engagement metrics", "Calculate correlation between likes, comments, and shares", "Identify top 3 most engaged posts based on likes and shares combined"], "eda_results": {"missing_values": {"user_id": 0, "post_date": 1, "content_type": 0, "likes": 2, "comments": 3, "shares": 1}, "date_issues": {"invalid_dates": ["2023-13-03"], "missing_dates": 1}, "content_type_normalized_counts": {"photo": 5, "video": 2, "text": 3, "live video": 2}, "summary_stats": {"likes": {"count": 11, "mean": 97.27, "std": 67.35, "min": 35, "25%": 70, "50%": 95, "75%": 150, "max": 250}, "comments": {"count": 9, "mean": 12.22, "std": 9.08, "min": 3, "25%": 5, "50%": 12, "75%": 15, "max": 30}, "shares": {"count": 11, "mean": 5.55, "std": 3.57, "min": 1, "25%": 2, "50%": 4, "75%": 7, "max": 12}}, "missing_engagement_posts": ["U003 (missing comments)", "U004 (shares marked N/A)", "U007 (missing likes)", "U009 (missing comments)", "U011 (missing post_date)"], "correlations": {"likes_comments": 0.85, "likes_shares": 0.8, "comments_shares": 0.75}, "top_3_posts_by_likes_shares": [{"user_id": "U002", "likes": 250, "shares": 8, "combined": 258}, {"user_id": "U010", "likes": 160, "shares": 12, "combined": 172}, {"user_id": "U005", "likes": 150, "shares": 10, "combined": 160}]}}
{"purpose": "Analyze customer purchase behavior and product category distribution in a retail store.", "raw_table": "OrderID,CustomerID,PurchaseDate,ProductCategory,Quantity,PricePerUnit,TotalAmount,PaymentType\n1001,C001,2023/01/05,Electronics,2,299.99,599.98,Credit Card\n1002,C002,01-07-2023,home appliances,1,159.5,159.5,CASH\n1003,C003,2023-01-08,Fashion,3,49.99,149.97,credit card\n1004,,2023-01-09,Electronics,1,299.99,,Credit Card\n1005,C005,2023/01/09,Fashion,,39.99,79.98,Debit Card\n1006,C006,01/10/2023,Home Appliances,2,,319.0,Cash\n1007,C002,2023-01-11,Fashion,1,39.99,39.99,\n1008,C007,2023-01-11,Books,4,15.99,63.96,Debit card\n1009,C008,2023/01/12,electronics,1,299.99,299.99,Credit Card\n1010,C009,13-01-2023,Books,,15.99,,cash\n1011,C010,2023-01-14,Fashion,2,49.99,99.98,Credit Card\n1012,C011,,toys,1,25.0,25.0,Cash\n1013,C012,2023-01-15,Books,3,15.99,47.97,Credit card\n1014,C013,2023/01/15,Home Appliances,1,159.5,159.5,Debit Card", "eda_steps": ["Check missing values percentages for all columns", "Standardize the ProductCategory names to consistent capitalization", "Convert PurchaseDate to a uniform date format and identify missing dates", "Compute descriptive statistics for Quantity, PricePerUnit, and TotalAmount", "Generate value counts for PaymentType after standardizing capitalization", "Identify top 3 most frequent ProductCategory values", "Calculate total sales (sum of TotalAmount) per ProductCategory", "Examine consistency between Quantity, PricePerUnit, and TotalAmount", "Check for duplicate OrderID entries"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "PurchaseDate": 1, "ProductCategory": 0, "Quantity": 3, "PricePerUnit": 2, "TotalAmount": 3, "PaymentType": 1}, "standardized_product_categories": {"Electronics": 3, "Home Appliances": 3, "Fashion": 4, "Books": 4, "Toys": 1}, "missing_purchase_dates_count": 1, "descriptive_statistics": {"Quantity": {"count": 11, "mean": 1.91, "std": 0.96, "min": 1, "25%": 1, "50%": 2, "75%": 2, "max": 4}, "PricePerUnit": {"count": 12, "mean": 116.08, "std": 125.94, "min": 15.99, "25%": 39.99, "50%": 49.99, "75%": 159.5, "max": 299.99}, "TotalAmount": {"count": 11, "mean": 158.77, "std": 154.68, "min": 25.0, "25%": 63.96, "50%": 99.98, "75%": 159.5, "max": 599.98}}, "payment_type_counts": {"Credit Card": 5, "Cash": 4, "Debit Card": 3}, "top_3_product_categories": ["Fashion", "Books", "Electronics"], "total_sales_by_category": {"Electronics": 899.97, "Home Appliances": 638.5, "Fashion": 369.92, "Books": 159.9, "Toys": 25.0}, "consistency_checks": {"inconsistent_total_amount_rows": [1004, 1006, 1005, 1010]}, "duplicate_order_ids": []}}
{"purpose": "Analyze the production line efficiency and identify potential quality issues based on equipment and operator data.", "raw_table": "BatchID,ProductionDate,Operator,EquipmentID,UnitsProduced,DefectiveUnits,Shift\nB001,2023-01-10,alice,EQ-12,100,2,Morning\nB002,01/11/2023,Bob,eq-12,95,NaN,Evening\nb003,2023/01/12,ALICE,EQ13,110,4,morning\nB004,13-01-2023,Charlie,EQ-12,NaN,3,Night\nB005,2023-01-14,bob,eq-14,105,,Evening\nb006,2023-1-15,Alice,EQ13,98,1,Morning\nB007,01-16-2023,charlie,EQ14,90,0,Night\nB008,2023/01/17,alice,EQ-12,102,NaN,Morning\nb009,18 Jan 2023,Bob,EQ-13,100,2,Evening\nB010,2023-01-19,,eq-14,96,1,Night", "eda_steps": ["Check and standardize date formats in ProductionDate column", "Identify and count missing values per column", "Normalize Operator names to consistent capitalization", "Compute descriptive statistics for UnitsProduced and DefectiveUnits", "Calculate defect rate per batch as DefectiveUnits divided by UnitsProduced", "Generate value counts for EquipmentID and Shift", "Analyze average defect rate by EquipmentID and by Shift", "Check correlation between UnitsProduced and DefectiveUnits"], "eda_results": {"missing_values": {"BatchID": 0, "ProductionDate": 0, "Operator": 1, "EquipmentID": 0, "UnitsProduced": 1, "DefectiveUnits": 3, "Shift": 0}, "normalized_operators": {"Alice": 4, "Bob": 3, "Charlie": 2, "": 1}, "descriptive_stats": {"UnitsProduced": {"count": 14, "mean": 99.4, "std": 6.27, "min": 90, "max": 110}, "DefectiveUnits": {"count": 11, "mean": 1.82, "std": 1.23, "min": 0, "max": 4}}, "defect_rates": [0.02, null, 0.036, null, null, 0.0102, 0, null, 0.02, 0.0104], "value_counts": {"EquipmentID": {"EQ-12": 4, "EQ13": 3, "EQ-14": 3}, "Shift": {"Morning": 4, "Evening": 3, "Night": 3}}, "avg_defect_rate_by_equipment": {"EQ-12": 0.02, "EQ13": 0.022, "EQ-14": 0.01}, "avg_defect_rate_by_shift": {"Morning": 0.02, "Evening": 0.015, "Night": 0.007}, "correlations": {"UnitsProduced_vs_DefectiveUnits": 0.72}}}
{"purpose": "Examine crop yield patterns and field characteristics to inform planting strategies.", "raw_table": "Field_ID,Crop_Type,Yield_kg,Planting_Date,Fertilizer_Used,Soil_pH\nF001,Corn,8500,2023-04-15,Yes,6.5\nf002,wheat,7300,15/04/2023,YES,6.8\nF003,Rice,,April 20 2023,No,7.0\nF004,Corn,9200,2023-04-18,yes,6.4\nF005,barley,6000,2023-4-17,No,NA\nF006,WHEAT,7500,2023/04/16,yes,6.7\nF007,corn,8800,2023-04-14,No,6.3\nF008,Rice,7900,04-19-2023,YES,7.1\nF009,Barley,6200,2023-04-15,No,6.9\nF010,wheat,7000,,Yes,6.6", "eda_steps": ["Standardize Crop_Type capitalization", "Parse and unify Planting_Date format to YYYY-MM-DD", "Check for missing values in all columns", "Compute descriptive statistics for Yield_kg and Soil_pH", "Generate value counts for Crop_Type and Fertilizer_Used", "Calculate average Yield_kg by Crop_Type", "Examine correlation between Soil_pH and Yield_kg", "Identify records with missing Yield_kg or Planting_Date"], "eda_results": {"missing_values": {"Yield_kg": 1, "Planting_Date": 1, "Soil_pH": 1}, "value_counts": {"Crop_Type": {"Corn": 3, "Wheat": 3, "Rice": 2, "Barley": 2}, "Fertilizer_Used": {"Yes": 5, "No": 5}}, "summary_stats": {"Yield_kg": {"count": 9, "mean": 7478.9, "std": 1006.4, "min": 6000, "25%": 7000, "50%": 7300, "75%": 8500, "max": 9200}, "Soil_pH": {"count": 9, "mean": 6.7, "std": 0.28, "min": 6.3, "25%": 6.5, "50%": 6.7, "75%": 6.9, "max": 7.1}}, "average_yield_by_crop": {"Corn": 8833.3, "Wheat": 7266.7, "Rice": 7900, "Barley": 6100}, "correlations": {"Soil_pH_vs_Yield_kg": 0.45}, "records_with_missing": {"Yield_kg": ["F003"], "Planting_Date": ["F010"]}, "note_on_data_cleaning": "Crop_Type values were standardized to title case; Fertilizer_Used values normalized to 'Yes' or 'No'; Planting_Date formats unified to ISO standard."}}
{"purpose": "Analyze citizen complaint data submitted to a city government to identify common complaint types and data quality issues.", "raw_table": "CaseID,ComplaintType,DateReported,Status,ResolutionTimeDays,Department\n001,Noise,2023-05-01,Closed,3,Environmental\n002, illegal dumping,5/3/2023,open,,Waste Management\n003,Noise,2023/05/04,Closed,2,Environmental\n004,Water leak,2023-05-05,Closed,10,Public Works\n005,noise,May 6 2023,closed,1,environmental\n006,Street Light Outage,2023-05-07,Open,,Public Works\n007,Illegal dumping,2023-5-08,Closed,5,waste management\n008,Water leak,2023/05/09,Closed,7,Public works\n009,Street light outage,05-10-2023,closed,4,public Works\n010,,2023-05-11,Closed,6,Public Works\n011,Noise,,Open,,Environmental\n012,Illegal Dumping,2023-05-12,Closed,8,Waste Management\n013,Noise,2023-05-13,Closed,2,Environmental\n014,Water Leak,2023-05-14,Closed,9,Public Works", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization of ComplaintType and Department columns", "Parse DateReported column into a consistent date format", "Compute descriptive statistics (mean, median) for ResolutionTimeDays", "Generate value counts for ComplaintType", "Count the number of complaints by Status", "Identify the average ResolutionTimeDays by Department", "Check for duplicate CaseID entries", "Summarize complaints over time by counting complaints per week"], "eda_results": {"missing_values": {"CaseID": 0, "ComplaintType": 1, "DateReported": 1, "Status": 0, "ResolutionTimeDays": 4, "Department": 0}, "standardized_categories": {"ComplaintType": ["Noise", "Illegal Dumping", "Water Leak", "Street Light Outage", "Missing"], "Department": ["Environmental", "Waste Management", "Public Works"]}, "date_parsing_issues": 0, "resolution_time_stats": {"mean": 5.2, "median": 5}, "value_counts_complaint_type": {"Noise": 5, "Illegal Dumping": 3, "Water Leak": 4, "Street Light Outage": 2, "Missing": 1}, "value_counts_status": {"Closed": 11, "Open": 3}, "avg_resolution_time_by_department": {"Environmental": 2.0, "Waste Management": 6.5, "Public Works": 7.2}, "duplicate_case_ids": 0, "complaints_per_week": {"2023-05-01": 1, "2023-05-02": 0, "2023-05-03": 1, "2023-05-04": 1, "2023-05-05": 1, "2023-05-06": 1, "2023-05-07": 1, "2023-05-08": 1, "2023-05-09": 1, "2023-05-10": 1, "2023-05-11": 1, "2023-05-12": 1, "2023-05-13": 1, "2023-05-14": 1}}}
{"purpose": "Analyze monthly stock trading data to understand price and volume trends and detect missing or inconsistent data.", "raw_table": "Date,Ticker,Open,Close,Volume,Sector\n2024-01-05,AAPL,172.5,174.3,12000000,Technology\n01/12/2024,goog,NR,2805.2,1500000,technology\n2024-01-19,MSFT,310.1,312.5,,Technology\n2024/01/26,AMZN,3340.0,3355.5,2000000,Retail\n2024-02-02,AAPL,175.0,176.1,13000000,Tech\n2024-02-09,GOOG,2820.5,2835.7,1600000,Technology\n2024/02/16,msft,313.0,314.8,18000000,technology\n2024-02-23,amzn,3360,3375.0,2100000,Retail\n2024-03-01,TSLA,900.0,905.5,25000000,Auto\n2024-03-08,tsla,905.3,910.0,24000000,auto\n2024-03-15,AAPL,177.0,,12500000,TECH\n2024-03-22,GOOG,2850.0,2865.0,1550000,Technology\n2024-03-29,MSFT,315.5,N/A,17500000,Technology", "eda_steps": ["Standardize the 'Date' column to a consistent date format", "Normalize 'Ticker' and 'Sector' columns to consistent capitalization", "Identify and count missing values in each column", "Compute descriptive statistics for numeric columns: Open, Close, Volume", "Generate value counts for the 'Sector' and 'Ticker' columns", "Calculate correlation between Open and Close prices", "Identify rows with non-numeric or anomalous values in numeric columns", "Summarize overall data completeness and quality"], "eda_results": {"missing_values": {"Date": 0, "Ticker": 0, "Open": 2, "Close": 2, "Volume": 1, "Sector": 0}, "value_counts": {"Sector": {"Technology": 9, "Retail": 2, "Auto": 2}, "Ticker": {"AAPL": 3, "GOOG": 3, "MSFT": 3, "AMZN": 2, "TSLA": 2}}, "summary_stats": {"Open": {"count": 13, "mean": 1288.68, "std": 1272.15, "min": 172.5, "25%": 310.1, "50%": 315.5, "75%": 2820.5, "max": 3360}, "Close": {"count": 12, "mean": 1212.67, "std": 1233.14, "min": 174.3, "25%": 312.5, "50%": 910.0, "75%": 2835.7, "max": 3375}, "Volume": {"count": 14, "mean": 12364285.7, "std": 7131840.5, "min": 1500000, "25%": 1600000, "50%": 17500000, "75%": 2100000, "max": 25000000}}, "correlations": {"Open_Close": 0.998}, "anomalies": {"non_numeric_open": [1], "non_numeric_close": [12], "missing_volume": [2]}, "data_quality_summary": "Date column is fully populated but has inconsistent formats corrected. Ticker and Sector columns had inconsistent capitalization normalized. Numeric columns contain some missing and non-numeric entries that require cleaning before modeling."}}
{"purpose": "Analyze stock price and trading volume trends for selected companies over a two-week period.", "raw_table": "Date,Stock_Symbol,Open,Close,Volume,Market_Sector\n2024/04/01,AAPL,172.5,174.3,34.5M,Tech\n2024-04-02,GOOGL,2740,2765,1.2e7,tech\n04-03-2024,MSFT,301.2,299.8,,Technology\n2024/4/4,aapl,175.0,176.5,32.4M,Tech\n2024-04-05,GOOGL,2770,,1.0e7,Tech\n04-06-2024,MSFT,300.5,303.2,18M,technology\n2024/04/07,AMZN,3340,3355,2.5e6,Consumer\n2024-04-08,amzn,3355,3370,,consumer\n04-09-2024,TSLA,1100,1125,15.3M,Auto\n2024/04/10,TSLA,1125,1110,14.7M,auto\n2024-04-11,GOOGL,2780,2800,1.3e7,Tech\n2024-04-12,MSFT,,305,19M,Technology\n04-13-2024,AAPL,177.0,178.5,30.2M,TECH\n2024/04/14,TSLA,1110,1130,16M,Auto", "eda_steps": ["Standardize the Market_Sector column capitalization", "Convert Date column to a uniform date format", "Check and report missing values for each column", "Convert Volume to numeric values in millions", "Generate descriptive statistics for Open and Close prices", "Calculate daily price change (Close - Open) and summarize", "Count unique stock symbols and their frequencies", "Identify top Market_Sector by average trading volume", "Compute correlation between Open and Close prices"], "eda_results": {"missing_values": {"Date": 0, "Stock_Symbol": 0, "Open": 1, "Close": 1, "Volume": 3, "Market_Sector": 0}, "volume_millions": [34.5, 12.0, null, 32.4, 10.0, 18.0, 2.5, null, 15.3, 14.7, 13.0, 19.0, 30.2, 16.0], "descriptive_stats": {"Open": {"count": 13, "mean": 1119.57, "std": 1206.94, "min": 172.5, "25%": 299.8, "50%": 301.2, "75%": 1110, "max": 2780}, "Close": {"count": 13, "mean": 1123.8, "std": 1207.31, "min": 174.3, "25%": 299.8, "50%": 303.2, "75%": 1125, "max": 2800}}, "price_change_summary": {"mean_change": 4.23, "median_change": 1.3, "min_change": -15, "max_change": 25.0}, "stock_symbol_counts": {"AAPL": 3, "GOOGL": 3, "MSFT": 3, "AMZN": 2, "TSLA": 3}, "market_sector_standardized_counts": {"Tech": 7, "Technology": 3, "Consumer": 2, "Auto": 3}, "top_market_sector_by_avg_volume": {"Tech": 18.01}, "correlation_open_close": 0.998}}
{"purpose": "Examine monthly stock performance and trading volumes for selected companies to identify trends and data quality issues.", "raw_table": "Ticker,Date,Closing_Price,Volume,Market_Sector\nAAPL,2023-01-15,145.3,1000000,Technology\nMSFT,15/01/2023,299.5,850000,technology\nGOOG,2023/01/15,NA,920000,TECHNOLOGY\nTSLA,2023-01-15,204.2,,Automotive\namzn,2023-01-15,95.1,700000,Consumer Discretionary\nNFLX,01-15-2023,350.0,500000,Communication Services\nFB,2023-01-15,NaN,NaN,communication services\nBRK.A,2023-01-15,470000,100,Financial\nJPM,2023-01-15,135.2,600000,financial\nWMT,2023-1-15,151.3,Three hundred thousand,Consumer Staples\nDIS,2023-01-15,NaN,400000,Consumer discretionary\nNVDA,2023-01-15,280.7,770000,TECHNOLOGY\nXOM,2023-01-15,88.4,680000,Energy\nC,2023-1-15,70.5,450000,financial\nGE,2023-1-15,85.1,500000,Industrials", "eda_steps": ["Standardize date formats to YYYY-MM-DD", "Convert all ticker symbols to uppercase", "Identify and count missing values in Closing_Price and Volume columns", "Convert Volume column to numeric, handling non-numeric entries", "Compute descriptive statistics for Closing_Price and Volume", "Generate value counts for Market_Sector with consistent capitalization", "Calculate correlation between Closing_Price and Volume", "Identify top 3 market sectors by average closing price"], "eda_results": {"missing_values": {"Closing_Price": 3, "Volume": 2}, "volume_conversion_issues": {"WMT": "Three hundred thousand"}, "summary_stats": {"Closing_Price": {"count": 12, "mean": 58747.35, "std_dev": 135365.46, "min": 70.5, "max": 470000}, "Volume": {"count": 13, "mean": 586615, "std_dev": 392065, "min": 100, "max": 1000000}}, "value_counts_market_sector": {"Technology": 4, "Automotive": 1, "Consumer Discretionary": 2, "Communication Services": 2, "Financial": 3, "Consumer Staples": 1, "Energy": 1, "Industrials": 1}, "correlations": {"Closing_Price_vs_Volume": -0.15}, "top_3_sectors_by_avg_closing_price": {"Financial": 22568.57, "Technology": 206.42, "Communication Services": 175.0}}}
{"purpose": "Analyze customer purchase behavior and product popularity in an ecommerce store.", "raw_table": "OrderID,CustomerID,ProductCategory,OrderDate,Quantity,UnitPrice,PaymentMethod,Rating\n1001,C001,Electronics,2023-01-15,2,199.99,Credit Card,4\n1002,C002,home Appliances,01/16/2023,1,89.5,Paypal,5\n1003,C003,Electronics,2023/01/17,,299.99,Credit card,3\n1004,C004,Fashion,17-01-2023,3,29.99,Credit Card,4\n1005,C001,Books,2023-01-18,2,,paypal,5\n1006,,fashion,2023-01-19,1,15.5,Cash,2\n1007,C005,Toys,01-20-2023,5,9.99,Credit Card,\n1008,C006,Home appliances,2023-01-20,2,120.0,Paypal,4\n1009,C007,Books,2023-01-21,1,12.99,Cash,3\n1010,C008,electronics,2023-01-22,4,199.99,Credit card,5\n1011,C009,Toys,2023-01-22,3,9.99,Credit Card,4\n1012,C010,Fashion,2023-01-23,2,,Credit Card,3\n1013,C002,Home Appliances,2023-01-24,1,85.0,Paypal,5", "eda_steps": ["Check for missing values in each column and compute their percentages", "Standardize the ProductCategory names to consistent capitalization", "Parse and standardize OrderDate to a common date format", "Calculate descriptive statistics (mean, median, std) for Quantity and UnitPrice", "Generate value counts for PaymentMethod and ProductCategory", "Identify top 3 product categories by total quantity sold", "Analyze average rating per ProductCategory", "Check for duplicate OrderID entries"], "eda_results": {"missing_values": {"OrderID": "0%", "CustomerID": "7.7%", "ProductCategory": "0%", "OrderDate": "0%", "Quantity": "7.7%", "UnitPrice": "15.4%", "PaymentMethod": "0%", "Rating": "15.4%"}, "standardized_categories": ["Electronics", "Home Appliances", "Fashion", "Books", "Toys"], "order_date_format": "All dates converted to YYYY-MM-DD", "quantity_stats": {"mean": 2.31, "median": 2, "std": 1.42}, "unit_price_stats": {"mean": 106.34, "median": 89.5, "std": 94.17}, "payment_method_counts": {"Credit Card": 7, "Paypal": 4, "Cash": 2}, "product_category_counts": {"Electronics": 3, "Home Appliances": 3, "Fashion": 3, "Books": 2, "Toys": 2}, "top_3_categories_by_quantity": {"Toys": 10, "Electronics": 6, "Fashion": 6}, "average_rating_per_category": {"Electronics": 4.0, "Home Appliances": 4.67, "Fashion": 3.0, "Books": 4.0, "Toys": 4.0}, "duplicate_order_ids": 0}}
{"purpose": "Analyze a dataset of recent real estate listings to understand property characteristics and data quality issues.", "raw_table": "ListingID,Price,Location,PropertyType,Bedrooms,Bathrooms,Area_sqft,DateListed\n001,350000,Downtown,Condo,2,2,850,2023-01-15\n002,450000,suburb,Single Family,3,2,1200,15/01/2023\n003,,Downtown,Townhouse,3,,1100,2023/01/20\n004,250000,Suburb,condo,1,1,600,2023-1-25\n005,Not disclosed,Downtown,Apartment,2,1,800,2023-01-18\n006,375000,Midtown,Single family,3,2,1300,01-22-2023\n007,500000,DOWNTOWN,TOWNHOUSE,4,3,1500,\n008,300000,midtown,Condo,2,2,850,2023-01-19\n009,400000,Suburb,Single Family,Three,2,1250,2023-01-21\n010,275000,Midtown,Apartment,2,,750,2023-01-23\n011,380000,suburb,Single Family,3,2,1350,2023-01-24\n012,290000,Downtown,condo,2,1,700,2023-01-22", "eda_steps": ["Check and report missing values for each column", "Standardize Location and PropertyType text capitalization", "Convert Price to numeric and identify non-numeric entries", "Convert Bedrooms and Bathrooms to numeric, handle text and missing values", "Calculate descriptive statistics for numeric columns: Price, Bedrooms, Bathrooms, Area_sqft", "Generate value counts for PropertyType and Location", "Analyze date formats in DateListed and standardize to YYYY-MM-DD", "Identify listings with missing Price or DateListed", "Compute correlation matrix for numeric features"], "eda_results": {"missing_values": {"ListingID": 0, "Price": 2, "Location": 0, "PropertyType": 0, "Bedrooms": 1, "Bathrooms": 3, "Area_sqft": 0, "DateListed": 1}, "price_non_numeric": ["Not disclosed"], "bedrooms_issues": ["Three"], "standardized_locations": {"Downtown": 5, "Suburb": 4, "Midtown": 3}, "standardized_property_types": {"Condo": 4, "Single Family": 5, "Townhouse": 2, "Apartment": 2}, "price_stats": {"count": 10, "mean": 352500, "std": 85000, "min": 250000, "25%": 290000, "50%": 350000, "75%": 380000, "max": 500000}, "bathrooms_stats": {"count": 9, "mean": 1.78, "std": 0.73, "min": 1, "max": 3}, "bedrooms_stats": {"count": 11, "mean": 2.64, "std": 0.87, "min": 1, "max": 4}, "area_sqft_stats": {"count": 12, "mean": 1033, "std": 285, "min": 600, "max": 1500}, "date_formats_found": ["YYYY-MM-DD", "DD/MM/YYYY", "YYYY/MM/DD", "MM-DD-YYYY", "YYYY-M-D"], "listings_missing_price_or_date": ["003 (missing Price)", "005 (non-numeric Price)", "007 (missing DateListed)"], "correlations": {"Price-Bedrooms": 0.87, "Price-Bathrooms": 0.75, "Price-Area_sqft": 0.92, "Bedrooms-Bathrooms": 0.8, "Bedrooms-Area_sqft": 0.85, "Bathrooms-Area_sqft": 0.7}}}
{"purpose": "Analyze public library usage and demographics to inform resource allocation decisions.", "raw_table": "Library_ID,City,Date_of_Visit,Visitor_Age,Membership_Type,Books_Borrowed,Event_Attended\n101,Springfield,2023-01-15,34,Regular,3,Book Club\n102,shelbyville,15/01/2023,29,Premium,5,\n103,SPRINGFIELD,2023/01/16,,regular,2,Story Time\n104,Ogdenville,2023-1-17,45,Regular,,Author Talk\n105,Shelbyville,2023-01-18,52,PREMIUM,7,book club\n106,ogdenville,,38,Regular,4,\n107,Springfield,2023-01-19,33,Premium,three,Story time\n108,Capital City,2023-01-20,27,Regular,1,Author talk\n109,capital city,20-01-2023,41,Regular,0,\n110,Shelbyville,2023-01-21,36,,2,Book Club", "eda_steps": ["Standardize city names to have consistent capitalization", "Parse and unify date formats in Date_of_Visit column", "Check for missing values and report their percentages per column", "Convert Books_Borrowed to numeric, handling non-numeric entries", "Generate descriptive statistics for numeric columns: Visitor_Age and Books_Borrowed", "Count unique membership types and their frequencies", "Identify the most attended events", "Calculate correlation between Visitor_Age and Books_Borrowed"], "eda_results": {"missing_values": {"Library_ID": "0%", "City": "0%", "Date_of_Visit": "10%", "Visitor_Age": "10%", "Membership_Type": "10%", "Books_Borrowed": "10%", "Event_Attended": "40%"}, "standardized_cities": {"Springfield": 3, "Shelbyville": 3, "Ogdenville": 2, "Capital City": 2}, "books_borrowed_converted": {"non_numeric_entries": ["three"], "converted_missing_to_nan": 1}, "numeric_summary_statistics": {"Visitor_Age": {"count": 12, "mean": 36.25, "std_dev": 7.56, "min": 27, "max": 52}, "Books_Borrowed": {"count": 11, "mean": 3.09, "std_dev": 2.48, "min": 0, "max": 7}}, "membership_type_counts": {"Regular": 6, "Premium": 4, "": 1}, "top_events_attended": {"Book Club": 3, "Story Time": 2, "Author Talk": 2, "": 5}, "correlation_visitor_age_books_borrowed": 0.45}}
{"purpose": "Analyze student performance and attendance patterns to identify data quality issues and key trends.", "raw_table": "StudentID,Name,Grade,Subject,Score,Attendance,ExamDate\n1,alice,10,Math,85,Present,2023-05-12\n2,Bob,10,english,78,Absent,05/13/2023\n3,CHARLIE,11,Math,92,,2023/05/14\n4,David,11,Science,88,Present,14-05-2023\n5,Eva,10,HISTORY,missing,Present,2023-05-15\n6,Fred,11,Math,75,Present,2023.05.16\n7,Grace,10,English,82,Absent,2023-05-17\n8,henry,11,Science,89,Present,May 18, 2023\n9,Ivy,10,Math,95,Present,2023-05-19\n10,Jack,11,History,80,Absent,2023-05-20\n11,Kate,10,Science,missing,missing,2023-05-21\n12,Luke,11,english,87,Present,2023-05-22", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize the capitalization of categorical columns 'Name', 'Subject', and 'Grade'", "Convert 'Score' column to numeric, handling 'missing' and other invalid entries", "Parse 'ExamDate' into a consistent date format", "Compute descriptive statistics for 'Score' after cleaning", "Generate value counts for 'Subject' and 'Attendance'", "Identify number of students with perfect attendance", "Analyze average scores by 'Grade' and 'Subject'", "Detect inconsistencies or anomalies in 'Attendance' entries"], "eda_results": {"missing_values": {"StudentID": "0.0%", "Name": "0.0%", "Grade": "0.0%", "Subject": "0.0%", "Score": "16.7%", "Attendance": "8.3%", "ExamDate": "0.0%"}, "standardized_categories": {"Name_samples": ["Alice", "Bob", "Charlie", "David", "Eva"], "Subject_samples": ["Math", "English", "Science", "History"], "Grade_samples": ["10", "11"]}, "score_conversion": {"valid_scores": 10, "converted_to_numeric": true, "invalid_entries_replaced_with_NaN": 2}, "date_parsing": {"original_formats_detected": ["YYYY-MM-DD", "MM/DD/YYYY", "YYYY/MM/DD", "DD-MM-YYYY", "YYYY.MM.DD", "Month DD, YYYY"], "all_dates_standardized": true}, "score_statistics": {"count": 10, "mean": 85.1, "median": 86.0, "min": 75, "max": 95, "std_dev": 6.3}, "value_counts": {"Subject": {"Math": 4, "English": 3, "Science": 3, "History": 2}, "Attendance": {"Present": 8, "Absent": 3, "missing": 1}}, "perfect_attendance_count": 8, "average_scores_by_grade_subject": {"10": {"Math": 90.0, "English": 80.0, "History": null, "Science": null}, "11": {"Math": 83.5, "English": 87.0, "History": 80.0, "Science": 88.5}}, "attendance_anomalies": {"unexpected_values_detected": false, "missing_values_found": true}}}
{"purpose": "Examine patient demographics and vital signs to identify data quality issues and basic distributions in a small clinical dataset.", "raw_table": "Patient_ID,Age,Gender,Weight_kg,Height_cm,Blood_Pressure,Admission_Date,Diagnosis\nP001,45,M,82,175,120/80,2023-01-12,Hypertension\nP002,38,F,NaN,165,130/85,12-02-2023,diabetes\nP003,,Male,75,180,110/70,2023/03/05,Asthma\nP004,52,Female,68,,125/80,2023-04-01,hypertension\nP005,29,m,NaN,160,118/78,,Unknown\nP006,65,M,90,170,140/90,2023-5-10,Diabetes\nP007,33,F,55,158,115/75,05/15/2023,asthma\nP008,47,female,70.5,172,128/82,2023-06-01,Hypertension\nP009,60,Male,85,NaN,135/88,2023-06-15,Diabetes\nP010,41,F,72,168,NaN,2023-7-20,Hypertension", "eda_steps": ["Check for missing values and their percentages in each column", "Standardize the Gender column values to consistent categories", "Parse and unify Admission_Date into a standard date format", "Calculate summary statistics (mean, median, min, max) for Age, Weight_kg, and Height_cm", "Extract systolic and diastolic values from Blood_Pressure and summarize their distributions", "Count unique diagnoses and their frequencies", "Identify rows with any missing critical patient information"], "eda_results": {"missing_values": {"Age": "10%", "Gender": "0%", "Weight_kg": "30%", "Height_cm": "20%", "Blood_Pressure": "10%", "Admission_Date": "10%", "Diagnosis": "10%"}, "gender_value_counts": {"Male": 4, "Female": 5, "m": 1, "f": 1}, "standardized_gender_counts": {"Male": 5, "Female": 5}, "admission_date_formats": {"YYYY-MM-DD": 6, "DD-MM-YYYY": 1, "MM/DD/YYYY": 1, "YYYY/MM/DD": 1, "Missing": 1}, "age_summary_stats": {"mean": 44.67, "median": 44, "min": 29, "max": 65}, "weight_kg_summary_stats": {"mean": 73.5, "median": 70.5, "min": 55, "max": 90}, "height_cm_summary_stats": {"mean": 168.8, "median": 170, "min": 158, "max": 180}, "blood_pressure_parsed": {"systolic": {"mean": 126.1, "median": 125, "min": 110, "max": 140}, "diastolic": {"mean": 81.3, "median": 80, "min": 70, "max": 90}}, "diagnosis_counts": {"Hypertension": 4, "Diabetes": 3, "Asthma": 2, "Unknown": 1}, "rows_with_missing_critical_info": [3, 5, 9, 10]}}
{"purpose": "Explore patient admission data to identify common admission sources and analyze age distribution in the hospital.", "raw_table": "PatientID,Age,Gender,AdmissionDate,AdmissionSource,Diagnosis,LengthOfStay\n001,45,Male,2023-01-15,ER,diabetes,5\n002,29,Female,15/02/2023,Referral,Hypertension,3\n003,,female,2023/03/05,ER,Asthma,4\n004,67,M,2023-3-12,walk-in,Diabetes,7\n005,54,F,2023.04.10,ER,Hypertension,NaN\n006,38,F,2023-05-08,Referral,asthma,2\n007,72,Male,06-15-2023,ER,Diabetes,8\n008,31,Female,2023-07-20,emergency,hypertension,3\n009,NaN,M,2023-08-05,walk-in,Asthma,5\n010,46,female,2023/08/15,Referral,Diabetes,6\n011,50,Male,2023-09-01,ER,Hypertension,4\n012,44,Female,2023-09-10,Walk-in,diabetes,NaN", "eda_steps": ["Check for missing values in each column", "Standardize and unify the 'Gender' column values", "Parse 'AdmissionDate' into consistent date format", "Compute descriptive statistics for 'Age' and 'LengthOfStay'", "Generate value counts for 'AdmissionSource' and 'Diagnosis'", "Identify percentage of patients admitted from ER vs other sources", "Calculate average length of stay grouped by Diagnosis", "Summarize number of admissions per month", "Check for correlation between Age and LengthOfStay"], "eda_results": {"missing_values": {"PatientID": 0, "Age": 2, "Gender": 0, "AdmissionDate": 0, "AdmissionSource": 0, "Diagnosis": 0, "LengthOfStay": 2}, "standardized_gender_counts": {"Male": 5, "Female": 6}, "value_counts_admission_source": {"ER": 5, "Referral": 3, "Walk-in": 3, "emergency": 1}, "value_counts_diagnosis": {"Diabetes": 5, "Hypertension": 4, "Asthma": 3}, "percentage_er_admissions": 45.45, "average_length_of_stay_by_diagnosis": {"Diabetes": 6.4, "Hypertension": 3.5, "Asthma": 3.67}, "admissions_per_month": {"January": 1, "February": 1, "March": 2, "April": 1, "May": 1, "June": 1, "July": 1, "August": 2, "September": 2}, "correlation_age_length_of_stay": 0.62, "age_descriptive_stats": {"count": 10, "mean": 47.6, "std": 14.1, "min": 29, "25%": 38, "50%": 45.5, "75%": 54, "max": 72}, "length_of_stay_descriptive_stats": {"count": 11, "mean": 4.9, "std": 2.1, "min": 2, "25%": 3, "50%": 4, "75%": 6, "max": 8}}}
{"purpose": "Analyze student performance and attendance patterns in a high school semester.", "raw_table": "StudentID,Name,Grade,Subject,Score,Attendance,ExamDate\n101,john doe,10,math,88,Present,2023/03/15\n102,Jane Smith,10,Math,92,Absent,15-Mar-2023\n103,alex johnson,11,english,85,Present,2023-03-16\n104,MARIA GOMEz,11,English, ,Present,16/03/2023\n105,Chris Lee,12,science,78,Absent,03-17-2023\n106,sam O'neil,12,Science,81,present,2023.03.18\n107,Linda,10,math,90,,2023/03/15\n108,Tom Brown,11,english,87,Present,17 Mar 2023\n109,Anita Patel,12,science,missing,Absent,2023-03-18\n110,Ben,10,Math,84,present,2023/3/15\n111,Sara K.,11,English,88,Present,16-03-2023\n112,jake,12,Science,83,Absent,2023-03-18\n113,KATE WONG,10,Math,91,Present,15/03/23", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in Name and Subject columns", "Convert Score column to numeric and identify non-numeric entries", "Compute descriptive statistics for Score grouped by Grade and Subject", "Calculate attendance counts and percentages", "Standardize and parse ExamDate into a consistent date format", "Identify unique subjects and their frequency", "Analyze correlation between Score and Attendance status where possible", "Identify top performing students based on average Score"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 0, "Grade": 0, "Subject": 0, "Score": 2, "Attendance": 1, "ExamDate": 0}, "standardized_subjects": {"math": 5, "english": 4, "science": 4}, "non_numeric_scores": ["", "missing"], "score_stats": {"10_math": {"count": 5, "mean": 89.0, "min": 84, "max": 92}, "11_english": {"count": 4, "mean": 86.0, "min": 85, "max": 88}, "12_science": {"count": 3, "mean": 80.67, "min": 78, "max": 83}}, "attendance_counts": {"Present": 7, "Absent": 5, "Missing": 1}, "exam_dates_parsed": {"earliest_date": "2023-03-15", "latest_date": "2023-03-18"}, "top_performers": [{"StudentID": 102, "Name": "Jane Smith", "Grade": 10, "Subject": "Math", "Average_Score": 92}, {"StudentID": 113, "Name": "Kate Wong", "Grade": 10, "Subject": "Math", "Average_Score": 91}, {"StudentID": 107, "Name": "Linda", "Grade": 10, "Subject": "Math", "Average_Score": 90}], "attendance_score_crosstab": {"Present": {"average_score": 87.86, "count": 7}, "Absent": {"average_score": 80.0, "count": 5}}}}
{"purpose": "Analyze customer purchase patterns and product category sales in a retail store", "raw_table": "OrderID,CustomerID,Product,Category,Quantity,Price,OrderDate,StoreLocation\n1001,C001,apple,fruits,10,0.5,2023/01/15,new york\n1002,C002,Banana,fruits,5,0.3,15-01-2023,New York\n1003,,Orange,Fruits,8,0.4,2023-01-16,NEW YORK\n1004,C003,Milk,Dairy,2,1.2,2023/1/16,new york\n1005,C004,bread,bakery,,2.5,01/17/2023,Los Angeles\n1006,C001,Eggs,Dairy,12,0.1,2023/01/18,los angeles\n1007,C005,Cheese,dairy,1,3.5,01-18-2023,LOS ANGELES\n1008,C006,Chocolate,Snacks,4,1.0,2023-01-19,Chicago\n1009,C002,Chips,snacks,6,1.5,2023/01/20,chicago\n1010,C007,Banana,Fruits,7,,2023-01-21,Chicago\n1011,C008,bread,Bakery,3,2.5,2023-01-21,los angeles\n1012,C009,Apple,Fruits,5,0.5,2023-01-22,NEW YORK\n1013,C010,Milk,dairy,4,1.3,22/01/2023,New york", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization of categorical columns: Product, Category, StoreLocation", "Convert OrderDate to a consistent date format", "Compute descriptive statistics for Quantity and Price columns", "Generate value counts for Category and StoreLocation columns", "Identify most frequent products purchased", "Calculate total sales amount per row (Quantity * Price) and summarize total sales by Category", "Analyze the number of unique customers", "Check for duplicated OrderIDs"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "Product": 0, "Category": 0, "Quantity": 1, "Price": 1, "OrderDate": 0, "StoreLocation": 0}, "standardized_categories": {"Category": ["Fruits", "Dairy", "Bakery", "Snacks"], "StoreLocation": ["New York", "Los Angeles", "Chicago"]}, "order_date_range": {"min": "2023-01-15", "max": "2023-01-22"}, "summary_stats": {"Quantity": {"count": 14, "mean": 5.93, "std": 3.54, "min": 1, "25%": 3, "50%": 5, "75%": 8, "max": 12}, "Price": {"count": 13, "mean": 1.18, "std": 1.0, "min": 0.1, "25%": 0.4, "50%": 0.5, "75%": 1.5, "max": 3.5}}, "value_counts": {"Category": {"Fruits": 6, "Dairy": 4, "Bakery": 2, "Snacks": 2}, "StoreLocation": {"New York": 5, "Los Angeles": 4, "Chicago": 3}}, "top_products": {"Apple": 2, "Banana": 2, "Bread": 2, "Milk": 2, "Chips": 1, "Cheese": 1, "Chocolate": 1, "Eggs": 1, "Orange": 1}, "total_sales_by_category": {"Fruits": 14.7, "Dairy": 12.6, "Bakery": 12.5, "Snacks": 12.0}, "unique_customers": 9, "duplicated_order_ids": 0}}
{"purpose": "Analyze customer purchase behavior and identify data quality issues in recent ecommerce transactions.", "raw_table": "OrderID,CustomerID,ProductCategory,PurchaseAmount,OrderDate,PaymentMethod,ShipmentStatus\n1001,501,Electronics,299.99,2023/1/15,credit Card,Delivered\n1002,502,home & Kitchen,89.5,15-02-2023,Paypal,Shipped\n1003,,Books,15.0,2023-02-20,credit card,delivered\n1004,504,Electronics,not available,2023/3/5,Credit Card,Pending\n1005,505,Clothing,49.99,2023-03-07,CREDIT CARD,Delivered\n1006,506,Beauty,25.0,2023-03-08,Debit Card,,\n1007,507,BookS,19.99,2023.03.09,Paypal,Delivered\n1008,508,clothing,35,03/10/2023,credit card,Returned\n1009,509,Electronics,199.99,2023-3-11,Debit card,Delivered\n1010,510,Home & kitchen,120,2023/03/12,Credit card,Shipped\n1011,511,,75.0,2023-03-13,Paypal,Delivered\n1012,512,Beauty,30.0,2023/13/03,Debit card,Delivered", "eda_steps": ["Check missing value percentages in each column", "Standardize date format in the OrderDate column", "Correct inconsistent capitalization in ProductCategory and PaymentMethod columns", "Compute descriptive statistics (mean, median, min, max) for PurchaseAmount", "Generate value counts for ProductCategory and ShipmentStatus", "Identify orders with invalid PurchaseAmount entries", "Summarize count of unique customers", "Calculate percentage of orders per PaymentMethod", "Determine number of orders per month"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "ProductCategory": 2, "PurchaseAmount": 1, "OrderDate": 0, "PaymentMethod": 0, "ShipmentStatus": 1}, "standardized_dates": ["2023-01-15", "2023-02-15", "2023-02-20", "2023-03-05", "2023-03-07", "2023-03-08", "2023-03-09", "2023-03-10", "2023-03-11", "2023-03-12", "2023-03-13", "2023-03-13"], "corrected_categories": {"ProductCategory": ["Electronics", "Home & Kitchen", "Books", "Electronics", "Clothing", "Beauty", "Books", "Clothing", "Electronics", "Home & Kitchen", null, "Beauty"], "PaymentMethod": ["Credit Card", "Paypal", "Credit Card", "Credit Card", "Credit Card", "Debit Card", "Paypal", "Credit Card", "Debit Card", "Credit Card", "Paypal", "Debit Card"]}, "purchase_amount_stats": {"count": 11, "mean": 93.62, "median": 75, "min": 15, "max": 299.99}, "value_counts": {"ProductCategory": {"Electronics": 3, "Home & Kitchen": 2, "Books": 2, "Clothing": 2, "Beauty": 2, "null": 1}, "ShipmentStatus": {"Delivered": 6, "Shipped": 2, "Pending": 1, "Returned": 1, "null": 1}}, "invalid_purchase_amount_orders": [1004], "unique_customers_count": 11, "payment_method_percentages": {"Credit Card": 6, "Paypal": 3, "Debit Card": 3}, "orders_per_month": {"2023-01": 1, "2023-02": 2, "2023-03": 9}}}
{"purpose": "Analyze city park maintenance requests to identify common issues and data quality concerns.", "raw_table": "Request_ID,Submission_Date,Park_Name,Issue_Type,Status,Priority,Resolution_Time_days\n001,2023-01-15,central park,Littering,Closed,High,3\n002,01/16/2023,Central Park,graffiti,OPEN,medium,NA\n003,2023/01/17,Riverside PARK,Broken Bench,closed,Low,7\n004,2023-1-18,Highland park,Littering,Closed,High,2\n005,,Downtown Park,Illegal Dumping,Open,Medium,\n006,2023-01-20,central park,Littering,Closed,high,1\n007,2023-01-21,Highland Park,Noise Complaints,open,Medium,NA\n008,2023/01/22,Riverside park,graffiti,Closed,Medium,5\n009,2023-01-23,Downtown park,broken bench,Closed,low,4\n010,2023-01-24,Central Park,Littering,closed,HIGH,2\n011,2023-01-25,Highland Park,Illegal dumping,Open,Medium, \n012,01-26-2023,Riverside Park,Noise complaints,Closed,Medium,6\n013,2023-01-27,central park,Broken bench,Closed,Low,3", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in 'Park_Name', 'Issue_Type', 'Status', and 'Priority' columns", "Convert 'Submission_Date' to a consistent date format", "Calculate descriptive statistics for 'Resolution_Time_days'", "Generate value counts for 'Issue_Type' and 'Status' columns", "Identify the number of requests per park", "Find average resolution time by issue type", "Check for inconsistencies or unusual categories in 'Priority'"], "eda_results": {"missing_values": {"Request_ID": 0, "Submission_Date": 1, "Park_Name": 0, "Issue_Type": 0, "Status": 0, "Priority": 0, "Resolution_Time_days": 3}, "standardized_categories": {"Park_Name": ["Central Park", "Riverside Park", "Highland Park", "Downtown Park"], "Issue_Type": ["Littering", "Graffiti", "Broken Bench", "Illegal Dumping", "Noise Complaints"], "Status": ["Open", "Closed"], "Priority": ["High", "Medium", "Low"]}, "submission_dates_standardized": ["2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18", null, "2023-01-20", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24", "2023-01-25", "2023-01-26", "2023-01-27"], "resolution_time_stats": {"count": 10, "mean": 3.8, "std_dev": 1.9, "min": 1, "max": 7}, "value_counts_issue_type": {"Littering": 4, "Graffiti": 2, "Broken Bench": 3, "Illegal Dumping": 2, "Noise Complaints": 2}, "value_counts_status": {"Closed": 9, "Open": 4}, "requests_per_park": {"Central Park": 5, "Riverside Park": 3, "Highland Park": 4, "Downtown Park": 2}, "average_resolution_time_by_issue": {"Littering": 2.0, "Graffiti": 5.0, "Broken Bench": 4.67, "Illegal Dumping": null, "Noise Complaints": 6.0}, "priority_categories_found": ["High", "Medium", "Low"]}}
{"purpose": "Analyze the characteristics and quality of real estate listings to identify data quality issues and summarize key property features.", "raw_table": "ListingID,Price,Bedrooms,Bathrooms,SqFt,Neighborhood,DateListed,Type\n1001,450000,3,2,1500,Downtown,2023/04/15,Condo\n1002,not disclosed,4,3,2300,Suburbia,15-05-2023,Single Family\n1003,375000,2,,1200,downtown,2023-04-20,townhouse\n1004,600000,5,4,3200,Uptown,2023/4/25,Single Family\n1005,,3,2,1400,suburbia,2023/04/22,Condo\n1006,500000,4,3,NaN,Midtown,04-20-2023,Single Family\n1007,320000,2,1,1100,Midtown,2023/04/18,Apartment\n1008,275000,1,1,850,Uptown,2023-04-19,Apartment\n1009,425000,3,2,1600,Downtown,2023/04/21,Condo\n1010,510000,4,3,2500,Suburbia,,Single Family\n1011,480000,3,2,1550,uptown,2023-04-23,Townhouse\n1012,NaN,3,2,1500,Midtown,2023/04/17,Condo", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization of Neighborhood and Type columns", "Convert Price and SqFt columns to numeric and handle non-numeric entries", "Compute descriptive statistics for Price, Bedrooms, Bathrooms, and SqFt", "Generate value counts for Neighborhood and Type columns", "Analyze the distribution of DateListed and detect inconsistent formats", "Identify listings with missing critical information such as Price or SqFt", "Calculate correlation matrix for numeric variables", "Summarize the top 3 neighborhoods by average listing price"], "eda_results": {"missing_values": {"ListingID": 0, "Price": 2, "Bedrooms": 0, "Bathrooms": 1, "SqFt": 2, "Neighborhood": 0, "DateListed": 1, "Type": 0}, "value_counts": {"Neighborhood": {"Downtown": 3, "Suburbia": 3, "Uptown": 3, "Midtown": 3}, "Type": {"Condo": 4, "Single Family": 4, "Townhouse": 2, "Apartment": 2}}, "standardized_categories": {"Neighborhood": ["Downtown", "Suburbia", "Uptown", "Midtown"], "Type": ["Condo", "Single Family", "Townhouse", "Apartment"]}, "descriptive_statistics": {"Price": {"count": 10, "mean": 440500, "min": 275000, "max": 600000, "median": 435000}, "Bedrooms": {"count": 12, "mean": 3.25, "min": 1, "max": 5, "median": 3}, "Bathrooms": {"count": 11, "mean": 2.36, "min": 1, "max": 4, "median": 2}, "SqFt": {"count": 10, "mean": 1785, "min": 850, "max": 3200, "median": 1525}}, "date_format_issues": {"Formats_detected": ["YYYY/MM/DD", "DD-MM-YYYY", "YYYY-MM-DD", "MM-DD-YYYY", "missing"], "Inconsistent_rows": [1002, 1006, 1010]}, "listings_missing_critical_info": {"Price_missing": [1005, 1012], "SqFt_missing": [1006, 1005], "DateListed_missing": [1010], "Bathrooms_missing": [1003]}, "correlations": {"Price_Bedrooms": 0.85, "Price_Bathrooms": 0.79, "Price_SqFt": 0.91, "Bedrooms_Bathrooms": 0.88, "Bedrooms_SqFt": 0.8, "Bathrooms_SqFt": 0.75}, "top_neighborhoods_by_price": {"Uptown": 425000, "Suburbia": 460000, "Downtown": 383333}}}
{"purpose": "Analyze customer usage patterns and service issues in a telecom dataset to identify data quality problems and usage trends.", "raw_table": "CustomerID,JoinDate,PlanType,MonthlyUsageGB,ServiceIssue,IssueReportedDate\nC101,2022-01-10,Basic,15.5,No,\nC102,2022/02/15,Premium,45.2,Yes,03-01-2022\nc103,15-03-2022,Basic,,no,\nC104,2022-04-05,PREMIUM,55.6,yes,2022/04/20\nC105,,Basic,20.0,No,\nc106,2022-06-10,,30.0,NO,\nC107,2022-07-22,Standard,25.5,Yes,07-25-2022\nC108,2022-08-30,standard,27.3,,\nC109,2022-09-15,Premium,60.1,yes,2022-09-25\nC110,2022-10-01,Basic,18.7,No,\nC111,2022-11-12,Standard,NaN,No,\nC112,2022/12/05,Premium,50.0,YES,12/15/2022", "eda_steps": ["Check for missing values in all columns", "Standardize capitalization in categorical columns PlanType and ServiceIssue", "Parse and standardize date columns JoinDate and IssueReportedDate to consistent date format", "Compute descriptive statistics for MonthlyUsageGB", "Generate value counts for PlanType and ServiceIssue", "Identify records with missing or inconsistent PlanType", "Calculate the percentage of customers reporting service issues", "Find the time difference in days between JoinDate and IssueReportedDate for customers with reported issues"], "eda_results": {"missing_values": {"CustomerID": 0, "JoinDate": 1, "PlanType": 1, "MonthlyUsageGB": 2, "ServiceIssue": 1, "IssueReportedDate": 5}, "standardized_categories": {"PlanType": {"Basic": 4, "Premium": 4, "Standard": 3, "Missing": 1}, "ServiceIssue": {"No": 5, "Yes": 5, "Missing": 1}}, "monthly_usage_stats": {"count": 11, "mean": 33.56, "std": 16.46, "min": 15.5, "25%": 20.0, "50%": 27.3, "75%": 50.0, "max": 60.1}, "plan_type_value_counts": {"Basic": 4, "Premium": 4, "Standard": 3, "Missing": 1}, "service_issue_value_counts": {"Yes": 5, "No": 5, "Missing": 1}, "missing_plan_records": ["C106"], "service_issue_percentage": 45.5, "issue_report_time_diff_days": {"C102": 14, "C104": 15, "C107": 3, "C109": 10, "C112": 10}}}
{"purpose": "Analyze customer purchase behavior and product category popularity in an ecommerce dataset.", "raw_table": "OrderID,CustomerID,Product,Category,Quantity,Price,OrderDate,PaymentMethod\n1001,C001,Wireless Mouse,Electronics,2,25.5,2023-01-15,Credit Card\n1002,C002,coffee mug,Home & Kitchen,1,7.99,15/01/2023,Paypal\n1003,C001,Laptop Stand,OFFICE,1,34.99,2023/01/16,Credit Card\n1004,C003,,electronics,3,,2023-01-17,Cash\n1005,C004,Notebook,Office,5,2.5,2023-1-18,credit card\n1006,C005,Water Bottle,Sports,2,12.0,18-01-2023,Paypal\n1007,C006,Wireless mouse,Electronics,1,25.5,2023-01-19,credit card\n1008,C007,Yoga Mat,Sports,1,20.0,2023-01-20,\n1009,C008,Desk Lamp,Home & kitchen,2,15.0,2023-01-21,Credit Card\n1010,C009,Notebook,office,3,2.5,2023-01-21,Credit card\n1011,,Bluetooth Speaker,Electronics,1,45.0,2023-01-22,Cash\n1012,C010,coffee Mug,home & Kitchen,2,7.99,2023-01-23,Paypal\n1013,C011,Desk Lamp,Home & Kitchen,1,15.0,2023-01-24,Credit Card\n1014,C012,Laptop stand,Office,1,34.99,2023-01-25,Paypal", "eda_steps": ["Check for missing values in each column", "Standardize the 'Category' column to consistent capitalization", "Parse 'OrderDate' into a standard date format", "Generate descriptive statistics for 'Quantity' and 'Price'", "Calculate the total sales per product (Quantity * Price)", "Identify the top 3 most popular product categories by total sales", "Count the frequency of each payment method", "Find duplicate products with inconsistent naming", "Analyze order counts per customer"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "Product": 1, "Category": 0, "Quantity": 0, "Price": 1, "OrderDate": 0, "PaymentMethod": 1}, "standardized_categories": {"Electronics": 4, "Home & Kitchen": 5, "Office": 4, "Sports": 2}, "date_format_consistency": "All dates parsed and standardized to YYYY-MM-DD", "summary_stats": {"Quantity": {"count": 14, "mean": 2.29, "min": 1, "max": 5, "std": 1.28}, "Price": {"count": 13, "mean": 19.65, "min": 2.5, "max": 45.0, "std": 13.43}}, "total_sales_per_product": {"Wireless Mouse": 76.5, "Coffee Mug": 23.97, "Laptop Stand": 69.98, "Notebook": 20.0, "Water Bottle": 24.0, "Yoga Mat": 20.0, "Desk Lamp": 45.0, "Bluetooth Speaker": 45.0}, "top_categories_by_sales": {"Electronics": 166.5, "Home & Kitchen": 83.97, "Office": 90.48, "Sports": 44.0}, "payment_method_counts": {"Credit Card": 5, "Paypal": 4, "Cash": 2, "credit card": 2, "": 1}, "duplicate_products_inconsistent_naming": {"Wireless Mouse": ["Wireless Mouse", "Wireless mouse"], "Coffee Mug": ["coffee mug", "coffee Mug"], "Laptop Stand": ["Laptop Stand", "Laptop stand"], "Notebook": ["Notebook", "Notebook"], "Desk Lamp": ["Desk Lamp", "Desk Lamp"]}, "orders_per_customer": {"C001": 2, "C002": 1, "C003": 1, "C004": 1, "C005": 1, "C006": 1, "C007": 1, "C008": 1, "C009": 1, "C010": 1, "C011": 1, "C012": 1, "": 1}}}
{"purpose": "Analyze viewer ratings and release patterns of popular TV shows to identify trends and data quality issues.", "raw_table": "Show_Title,Genre,Release_Date,Num_Seasons,Avg_Rating,Total_Episodes\nBreaking Bad,Drama,01-20-2008,5,9.5,62\nFriends,comedy,1994/09/22,10,8.9,236\nStranger Things,Sci-Fi,2016-07-15,4,,34\nThe Office,comedy,03/24/2005,9,8.8,201\nGame of Thrones,drama,2011-4-17,8,9.3,73\nThe Mandalorian,Sci-Fi,Nov 12 2019,2,8.7,16\nSherlock,Drama,2010/07/25,4,nine point one,13\nThe Crown,Drama,2016/11/04,5,8.7,50\nRick and Morty,Animation,2013-12-02,,9.2,41\nThe Simpsons,animation,1989-12-17,32,8.7,700\nSeinfeld,Comedy,1989-07-05,9,8.8,180\nWestworld,SCI-FI,2016-10-02,3,8.6,\nFriends,Comedy,1994-09-22,10,8.9,236", "eda_steps": ["Compute descriptive statistics for numeric columns", "Generate value counts for the Genre column", "Check for missing values in all columns", "Standardize and identify inconsistencies in the Genre column", "Parse and standardize Release_Date formats", "Identify duplicate show entries", "Compute correlation matrix between numeric columns", "Identify top 3 TV shows by Avg_Rating", "Summarize distribution skewness for Avg_Rating"], "eda_results": {"summary_stats": {"Num_Seasons": {"count": 13, "mean": 8.15, "std": 8.69, "min": 2, "25%": 4, "50%": 5, "75%": 9, "max": 32}, "Avg_Rating": {"count": 12, "mean": 8.87, "std": 0.28, "min": 8.6, "25%": 8.7, "50%": 8.85, "75%": 9.1, "max": 9.5}, "Total_Episodes": {"count": 12, "mean": 155.8, "std": 199.7, "min": 13, "25%": 34, "50%": 62, "75%": 180, "max": 700}}, "value_counts": {"Genre": {"Drama": 5, "Comedy": 4, "Sci-Fi": 3, "Animation": 2}}, "missing_values": {"Num_Seasons": 1, "Avg_Rating": 2, "Total_Episodes": 1}, "genre_standardization": {"Drama": ["Drama", "drama"], "Comedy": ["comedy", "Comedy"], "Sci-Fi": ["Sci-Fi", "SCI-FI", "Sci-Fi"], "Animation": ["Animation", "animation"]}, "release_date_formats": {"varied_formats": ["MM-DD-YYYY", "YYYY/MM/DD", "YYYY-MM-DD", "YYYY-M-D", "MMM DD YYYY", "MMM DD YYYY"], "standardized_date_range": "1989-07-05 to 2019-11-12"}, "duplicate_entries": {"Friends": 2}, "correlations": {"Num_Seasons_vs_Total_Episodes": 0.95, "Avg_Rating_vs_Num_Seasons": 0.15, "Avg_Rating_vs_Total_Episodes": 0.12}, "top_3_shows_by_rating": [{"Show_Title": "Breaking Bad", "Avg_Rating": 9.5}, {"Show_Title": "Sherlock", "Avg_Rating": 9.1}, {"Show_Title": "Rick and Morty", "Avg_Rating": 9.2}], "avg_rating_skewness": -0.55}}
{"purpose": "Explore real estate listings to understand property characteristics and data quality issues.", "raw_table": "ListingID,Price,Location,Bedrooms,Bathrooms,SquareFeet,DateListed,PropertyType\n001,350000,Downtown,3,2,1500,2023/01/15,Single Family\n002,450000,Suburb,4,,2000,15-02-2023,Townhouse\n003,299999,Downtown,2,1,900,2023-03-01,Condo\n004,,Suburb,3,2,1800,2023/03/15,Single family\n005,525000,suburb,5,3.5,2500,03-20-2023,Single Family\n006,415000,DOWNTOWN,3,2,1600,2023/01/05,condo\n007,NaN,Suburb,,2,1700,2023-02-28,Townhouse\n008,390000,Downtown,3,1.5,1400,01/25/2023,Single Family\n009,480000,Suburb,4,3,2200,2023/02/10,Single family\n010,310000,Downtown,2,1,950,,Condo", "eda_steps": ["Check for missing values in each column", "Standardize 'Location' and 'PropertyType' capitalization", "Compute descriptive statistics for numeric columns: Price, Bedrooms, Bathrooms, SquareFeet", "Generate value counts for categorical columns: Location, PropertyType", "Analyze date formatting consistency in 'DateListed' and convert to a standard format", "Calculate correlation matrix between numeric features", "Identify listings with missing Price or Bedrooms data", "Summarize distribution of property types by average price"], "eda_results": {"missing_values": {"ListingID": 0, "Price": 2, "Location": 0, "Bedrooms": 1, "Bathrooms": 1, "SquareFeet": 0, "DateListed": 1, "PropertyType": 0}, "standardized_categories": {"Location": {"Downtown": 5, "Suburb": 5}, "PropertyType": {"Single Family": 5, "Townhouse": 2, "Condo": 3}}, "summary_stats": {"Price": {"count": 8, "mean": 395625, "min": 299999, "max": 525000, "std": 79757.92}, "Bedrooms": {"count": 9, "mean": 3.22, "min": 2, "max": 5, "std": 1.03}, "Bathrooms": {"count": 9, "mean": 2.22, "min": 1, "max": 3.5, "std": 0.86}, "SquareFeet": {"count": 10, "mean": 1700, "min": 900, "max": 2500, "std": 515.39}}, "date_format_issues": {"Inconsistent formats found": true, "Standardized to ISO 8601": true, "Missing dates": 1}, "correlations": {"Price_Bedrooms": 0.92, "Price_Bathrooms": 0.87, "Price_SquareFeet": 0.95, "Bedrooms_Bathrooms": 0.89, "Bedrooms_SquareFeet": 0.94, "Bathrooms_SquareFeet": 0.88}, "missing_critical_info": {"Listings_missing_Price": ["004", "007"], "Listings_missing_Bedrooms": ["007"]}, "average_price_by_property_type": {"Single Family": 422500, "Townhouse": 450000, "Condo": 341666.67}}}
{"purpose": "Analyze production line defects and downtime causes in a manufacturing plant.", "raw_table": "BatchID,ProductionDate,Line,DefectType,DowntimeMinutes,OperatorShift\n1001,2024-01-05,Line A,Crack,30,Morning\n1002,01/06/2024,line b,Surface flaw,,evening\n1003,2024/01/07,Line A,,15,Morning\n1004,2024-1-08,LINE C,Crack,45,Night\n1005,2024-01-09,line a,Missing Part,20,Morning\n1006,,Line B,Surface Flaw,25,Evening\n1007,2024-01-11,Line C,crack,35,Night\n1008,2024-01-12,Line A,Surface flaw,NA,Morning\n1009,13-01-2024,Line B,Missing part,10,Evening\n1010,2024-01-14,Line C,,40,Night\n1011,2024-01-15,Line A,Crack,50,Morning\n", "eda_steps": ["Check and standardize date formats in the ProductionDate column", "Convert Line and DefectType columns to consistent capitalization", "Identify and count missing values in all columns", "Compute descriptive statistics for DowntimeMinutes", "Generate value counts for DefectType and OperatorShift", "Analyze the distribution of DowntimeMinutes by Line", "Check correlation between DowntimeMinutes and DefectType presence", "Identify top defect types causing the most downtime"], "eda_results": {"missing_values": {"BatchID": 0, "ProductionDate": 1, "Line": 0, "DefectType": 2, "DowntimeMinutes": 2, "OperatorShift": 0}, "summary_stats": {"DowntimeMinutes": {"count": 9, "mean": 30.0, "std": 13.75, "min": 10, "25%": 20, "50%": 30, "75%": 40, "max": 50}}, "value_counts": {"DefectType": {"Crack": 4, "Surface Flaw": 3, "Missing Part": 2, "": 2}, "OperatorShift": {"Morning": 5, "Evening": 3, "Night": 3}}, "line_downtime_distribution": {"Line A": {"mean_downtime": 31.25, "count": 4}, "Line B": {"mean_downtime": 17.5, "count": 4}, "Line C": {"mean_downtime": 40.0, "count": 3}}, "correlations": {"DefectPresence_vs_DowntimeMinutes": 0.65}, "top_defects_by_downtime": {"Crack": 40.0, "Surface Flaw": 26.7, "Missing Part": 15.0}}}
{"purpose": "Analyze trip duration and passenger patterns for urban taxi rides to optimize service efficiency.", "raw_table": "TripID,DriverID,PassengerCount,TripStart,TripEnd,Distance_km,Fare,PaymentMethod\n1001,DR123,2,2023-05-01 08:15,2023-05-01 08:45,12.5,25.60,Cash\n1002,dr124,1,05/01/2023 09:00 AM,05/01/2023 09:20 AM,7.3,15.00,credit\n1003,DR125,,2023-05-01T10:00:00,2023-05-01T10:30:00,15.0,33.50,CARD\n1004,DR126,3,2023/05/01 11:15,2023/05/01 11:50,18.2,40.00,Cash\n1005,dr127,2,2023-5-1 12:00 PM,2023-5-1 12:30 PM,13.7,29.80,Credit card\n1006,DR128,one,01-05-2023 13:00,01-05-2023 13:20,6.5,14.00,Cash\n1007,DR129,4,2023.05.01 14:00,2023.05.01 14:45,22.1,48.00,card\n1008,,3,2023-05-01 15:00,2023-05-01 15:30,16.0,35.00,Cash\n1009,DR131,2,2023-05-01 16:10,2023-05-01 16:40,12.0,27.00,Credit\n1010,DR132,NaN,2023-05-01 17:00,2023-05-01 17:25,10.0,22.50,cash\n1011,DR133,2,2023-05-01 18:15,2023-05-01 18:40,11.2,24.75,Credit Card\n1012,dr134,3,2023-05-01T19:00:00Z,2023-05-01T19:30:00Z,17.3,38.00,CARD\n1013,DR135,2,2023-05-01 20:00,2023-05-01 20:25,9.8,21.00,Credit\n1014,DR136,1,,2023-05-01 21:00,8.0,18.50,Cash", "eda_steps": ["Check and summarize missing values per column", "Standardize and parse inconsistent date/time columns to datetime format", "Convert PassengerCount to numeric and handle non-numeric or missing entries", "Calculate trip duration in minutes from TripStart and TripEnd", "Compute descriptive statistics for numeric columns: Distance_km, Fare, PassengerCount, TripDuration", "Generate value counts for PaymentMethod and DriverID", "Identify top 3 drivers by number of trips", "Examine correlation between Distance_km, Fare, PassengerCount, and TripDuration"], "eda_results": {"missing_values": {"TripID": 0, "DriverID": 1, "PassengerCount": 3, "TripStart": 1, "TripEnd": 0, "Distance_km": 0, "Fare": 0, "PaymentMethod": 0}, "standardized_payment_methods": {"cash": 5, "credit": 3, "card": 3, "credit card": 2}, "passenger_count_cleaned": {"mean": 2.18, "median": 2, "min": 1, "max": 4, "non_numeric_replaced_with_nan_count": 1}, "trip_duration_minutes": {"mean": 29.2, "median": 28, "min": 20, "max": 45}, "descriptive_statistics": {"Distance_km": {"mean": 13.36, "std": 5.07, "min": 6.5, "max": 22.1}, "Fare": {"mean": 27.47, "std": 8.37, "min": 14.0, "max": 48.0}, "PassengerCount": {"mean": 2.18, "std": 1.01, "min": 1, "max": 4}, "TripDuration": {"mean": 29.2, "std": 7.25, "min": 20, "max": 45}}, "value_counts_driverID": {"DR123": 1, "dr124": 1, "DR125": 1, "DR126": 1, "dr127": 1, "DR128": 1, "DR129": 1, "": 1, "DR131": 1, "DR132": 1, "DR133": 1, "dr134": 1, "DR135": 1, "DR136": 1}, "top_3_drivers_by_trip_count": {"DR123": 1, "dr124": 1, "DR125": 1}, "correlations": {"Distance_km_Fare": 0.98, "Distance_km_TripDuration": 0.95, "Fare_TripDuration": 0.96, "PassengerCount_Fare": 0.2, "PassengerCount_TripDuration": 0.18}}}
{"purpose": "Analyze crop yield patterns and farm characteristics to identify factors affecting productivity.", "raw_table": "Farm_ID,Crop_Type,Yield_kg,Planting_Date,Fertilizer_Used,Soil_pH,Rainfall_mm\nF01,wheat,1200,2023-03-15,Yes,6.5,150\nF02,Rice,1450,15-04-2023,yes,6.8,200\nF03,Corn,,2023/03/20,No,7.1,180\nF04,WHEAT,1100,2023-03-18,No,6.4,NA\nF05,Rice,NaN,04/20/2023,yes,6.9,210\nF06,barley,900,2023-03-25,YES,6.7,170\nF07,Corn,1300,2023-03-22,No,seven,160\nF08,Rice,1400,2023-04-10,No,6.6,190\nF09,wheat,1150,03/17/2023,Yes,6.5,\nF10,Corn,1250,2023-03-19,No,6.8,175", "eda_steps": ["Check missing value percentages for each column", "Standardize Crop_Type capitalization", "Convert Planting_Date to a consistent date format", "Identify and handle invalid Soil_pH values", "Compute descriptive statistics for numeric columns Yield_kg, Soil_pH, and Rainfall_mm", "Generate value counts for Fertilizer_Used and Crop_Type", "Analyze correlation between Yield_kg and Soil_pH, Rainfall_mm", "Identify farms with missing Yield_kg and explore related features"], "eda_results": {"missing_values": {"Yield_kg": 2, "Planting_Date": 0, "Fertilizer_Used": 0, "Soil_pH": 1, "Rainfall_mm": 2}, "value_counts": {"Crop_Type": {"wheat": 3, "rice": 3, "corn": 3, "barley": 1}, "Fertilizer_Used": {"yes": 5, "no": 5}}, "soil_pH_issues": {"invalid_entries": ["seven"], "count": 1}, "descriptive_stats": {"Yield_kg": {"count": 8, "mean": 1212.5, "std": 185.6, "min": 900, "25%": 1125, "50%": 1225, "75%": 1350, "max": 1450}, "Soil_pH": {"count": 9, "mean": 6.68, "std": 0.25, "min": 6.4, "25%": 6.5, "50%": 6.65, "75%": 6.85, "max": 7.1}, "Rainfall_mm": {"count": 8, "mean": 176.9, "std": 19.3, "min": 150, "25%": 165, "50%": 175, "75%": 195, "max": 210}}, "correlations": {"Yield_kg_Soil_pH": 0.45, "Yield_kg_Rainfall_mm": 0.52}, "farms_missing_yield": {"F03": {"Crop_Type": "corn", "Planting_Date": "2023-03-20", "Fertilizer_Used": "No", "Soil_pH": 7.1, "Rainfall_mm": 180}, "F05": {"Crop_Type": "rice", "Planting_Date": "2023-04-20", "Fertilizer_Used": "yes", "Soil_pH": 6.9, "Rainfall_mm": 210}}}}
{"purpose": "Analyze the monthly transaction patterns and customer segmentation for a retail bank.", "raw_table": "TransactionID,CustomerID,TransactionDate,Amount,TransactionType,Branch\n1001,CUST001,2024-01-15,1250.50,deposit,New york\n1002,CUST002,15/01/2024,,Withdrawal,los angeles\n1003,CUST003,2024-01-16,300.00,Deposit,NEW YORK\n1004,CUST001,2024/01/17,NaN,withdrawal,Chicago\n1005,CUST004,2024-01-18,500.75,DEPOSIT,Los Angeles\n1006,CUST005,01-19-2024,700,withdrawal,San Francisco\n1007,CUST002,2024-01-20,-150,deposit,CHICAGO\n1008,CUST006,2024-01-21,400,Withdrawal,San francisco\n1009,CUST007,,350,Deposit,New York\n1010,CUST008,2024-1-22,abc,Withdrawal,Los Angeles\n1011,CUST009,2024-01-23,850.00,Deposit,houston\n1012,CUST010,01/24/2024,1200,Deposit,Houston\n1013,CUST011,2024-01-25,550.50,withdrawal,Houston\n1014,CUST012,2024/01/26,NaN,withdrawal,LOS ANGELES", "eda_steps": ["Check the percentage of missing values in each column", "Standardize and parse the TransactionDate column to a consistent datetime format", "Convert the Amount column to numeric, coercing errors and handling missing values", "Normalize the TransactionType and Branch columns to consistent capitalization", "Compute descriptive statistics for the Amount column", "Generate value counts for TransactionType and Branch", "Identify customers with the highest total transaction amounts", "Calculate the correlation between transaction Amount and TransactionType encoded numerically"], "eda_results": {"missing_values": {"TransactionID": "0%", "CustomerID": "0%", "TransactionDate": "7%", "Amount": "14%", "TransactionType": "0%", "Branch": "0%"}, "transaction_date_parsing": {"parsed_dates": 13, "failed_to_parse": 1, "standard_format": "YYYY-MM-DD"}, "amount_conversion": {"non_numeric_entries": 1, "missing_after_conversion": 2, "amount_min": -150, "amount_max": 1250.5, "amount_mean": 646.52, "amount_median": 550.5}, "normalized_categories": {"TransactionType": {"deposit": 6, "withdrawal": 7}, "Branch": {"new york": 3, "los angeles": 4, "chicago": 2, "san francisco": 2, "houston": 3}}, "top_customers_by_total_amount": {"CUST001": 1250.5, "CUST010": 1200, "CUST009": 850, "CUST005": 700, "CUST011": 550.5}, "correlation_amount_transactiontype": {"correlation_coefficient": -0.56, "note": "TransactionType encoded as deposit=1, withdrawal=0"}}}
{"purpose": "Analyze customer purchase behavior and product category distribution in an ecommerce dataset.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod,ShippingCost\n1001,C001,2023-01-15,Electronics,2,299.99,Credit Card,15.00\n1002,c002,15-01-2023,home & kitchen,1,89.50,paypal,5\n1003,C003,2023/01/16,Books,3,15.99,Credit card,0\n1004,C004,01-17-2023,Electronics,,199.99,credit Card,12\n1005,C005,2023-01-18,Toys,5,12.5,CASH,8.5\n1006,C006,2023-01-19,Books,2,16,Credit Card,\n1007,C007,2023-01-20,Home & Kitchen,1,,paypal,7\n1008,C008,2023-01-20,Books,4,15.99,Credit Card,0\n1009,C009,2023-01-21,Toys,3,12.5,Cash,8\n1010,C010,Jan 22 2023,clothing,2,49.99,credit card,10\n1011,C011,2023-01-22,Clothing,1,50,CREDIT CARD,10\n1012,C012,2023-01-23,Electronics,1,299.99,credit card,15\n1013,,2023-01-23,Books,3,15.99,Paypal,0\n1014,C014,2023-01-24,Toys,2,12.5,Credit Card,8.5\n", "eda_steps": ["Check the data types of each column and identify inconsistencies", "Calculate the percentage of missing values per column", "Standardize the 'ProductCategory' and 'PaymentMethod' categorical values", "Convert 'OrderDate' to a consistent date format", "Compute descriptive statistics for numeric columns: Quantity, UnitPrice, ShippingCost", "Generate value counts for 'ProductCategory' and 'PaymentMethod'", "Identify top 3 product categories by total quantity sold", "Calculate correlation between Quantity, UnitPrice, and ShippingCost", "Summarize missing value impact on key columns"], "eda_results": {"data_types": {"OrderID": "integer", "CustomerID": "string", "OrderDate": "string (inconsistent formats)", "ProductCategory": "string", "Quantity": "float (some missing)", "UnitPrice": "float (some missing)", "PaymentMethod": "string", "ShippingCost": "float (some missing)"}, "missing_values_percentage": {"OrderID": 0, "CustomerID": 7.14, "OrderDate": 0, "ProductCategory": 0, "Quantity": 7.14, "UnitPrice": 7.14, "PaymentMethod": 0, "ShippingCost": 7.14}, "standardized_categories": {"ProductCategory": ["Electronics", "Home & Kitchen", "Books", "Toys", "Clothing"], "PaymentMethod": ["Credit Card", "Paypal", "Cash"]}, "order_date_standardization": "All dates converted to YYYY-MM-DD format", "summary_stats": {"Quantity": {"count": 13, "mean": 2.54, "std": 1.26, "min": 1, "max": 5}, "UnitPrice": {"count": 13, "mean": 87.63, "std": 113.25, "min": 12.5, "max": 299.99}, "ShippingCost": {"count": 13, "mean": 8.26, "std": 4.78, "min": 0, "max": 15}}, "value_counts": {"ProductCategory": {"Books": 4, "Electronics": 3, "Toys": 3, "Home & Kitchen": 2, "Clothing": 2}, "PaymentMethod": {"Credit Card": 8, "Paypal": 3, "Cash": 2}}, "top_categories_by_quantity": {"Toys": 10, "Books": 12, "Electronics": 3}, "correlations": {"Quantity_UnitPrice": -0.25, "Quantity_ShippingCost": 0.51, "UnitPrice_ShippingCost": 0.75}, "missing_value_impact": "Key columns Quantity, UnitPrice, and ShippingCost each have one missing entry (7.14%), CustomerID missing in one row (7.14%) which may affect customer-level analysis"}}
{"purpose": "Analyze student performance and attendance patterns in a high school semester.", "raw_table": "Student_ID,Name,Grade,Math_Score,English_Score,Attendance,Enrollment_Date\n101,alice,10,88,92,95%,2023-01-15\n102,Bob,10, ,85,88%,15-01-2023\n103,CHARLIE,11,91,NaN,90%,2023/01/16\n104,Diana,11,85,89,missing,2023-01-17\n105,eVa,12,78,81,85%,01-18-2023\n106,Frank,12,92,95,99%,2023-01-19\n107,Gina,10,85,88,93%,jan 20 2023\n108,Henry,11,NaN,84,87%,2023-01-21\n109,Ian,12,88,NaN,91%,2023-1-22\n110,julia,10,90,87,89%,2023-01-23\n", "eda_steps": ["Check and count missing values in each column", "Standardize capitalization in the Name column", "Parse and standardize Enrollment_Date to YYYY-MM-DD format", "Compute descriptive statistics for Math_Score and English_Score", "Calculate attendance percentages as numeric values", "Generate value counts for Grade", "Identify students with missing test scores", "Calculate correlation between Math_Score, English_Score, and Attendance"], "eda_results": {"missing_values": {"Student_ID": 0, "Name": 0, "Grade": 0, "Math_Score": 2, "English_Score": 2, "Attendance": 1, "Enrollment_Date": 0}, "name_standardization": ["Alice", "Bob", "Charlie", "Diana", "Eva", "Frank", "Gina", "Henry", "Ian", "Julia"], "enrollment_date_standardized": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18", "2023-01-19", "2023-01-20", "2023-01-21", "2023-01-22", "2023-01-23"], "descriptive_stats": {"Math_Score": {"count": 8, "mean": 87.375, "std": 5.03, "min": 78, "25%": 85, "50%": 88, "75%": 90, "max": 92}, "English_Score": {"count": 8, "mean": 87.625, "std": 4.27, "min": 81, "25%": 85, "50%": 87.5, "75%": 91.5, "max": 95}}, "attendance_percent_numeric": [95, 88, 90, null, 85, 99, 93, 87, 91, 89], "value_counts_grade": {"10": 4, "11": 3, "12": 3}, "students_missing_scores": {"Math_Score": ["Bob", "Henry"], "English_Score": ["Charlie", "Ian"], "Attendance": ["Diana"]}, "correlations": {"Math_vs_English": 0.72, "Math_vs_Attendance": 0.56, "English_vs_Attendance": 0.62}}}
{"purpose": "Evaluate crop yield patterns and identify data quality issues in farm production records.", "raw_table": "Farm_ID,Crop_Type,Harvest_Date,Yield_tonnes,Soil_Quality,Weather_Condition\nF001,Corn,2023-09-15,12.5,Good,Sunny\nF002,wheat,15/09/2023,8.3,Fair,Rainy\nF003,RICE,09-14-2023,10.0,,Cloudy\nF004,Corn,2023/09/13,missing,Good,sunny\nf005,Barley,2023-09-16,7.5,Poor,Foggy\nF006,Corn,,13.2,Fair,Sunny\nF007,Rice,2023-09-15,11.0,Good,Sunny\nF008,Wheat,2023-09-15,NaN,good,Sunny\nF009,Barley,2023-09-14,6.8,Poor,Foggy\nF010,Corn,2023-09-15,12.1,GOOD,Sunny", "eda_steps": ["Check and count missing values in each column", "Standardize capitalization in categorical columns Crop_Type, Soil_Quality, and Weather_Condition", "Parse and unify the date format in Harvest_Date to YYYY-MM-DD", "Compute descriptive statistics for Yield_tonnes, ignoring missing or invalid values", "Generate value counts for Crop_Type and Soil_Quality", "Identify rows with inconsistent or missing Yield_tonnes data", "Calculate correlation between Yield_tonnes and Soil_Quality (encoded numerically)", "Summarize distribution skewness of the Yield_tonnes column"], "eda_results": {"missing_values": {"Farm_ID": 0, "Crop_Type": 0, "Harvest_Date": 1, "Yield_tonnes": 3, "Soil_Quality": 1, "Weather_Condition": 0}, "standardized_categories": {"Crop_Type": {"Corn": 4, "Wheat": 2, "Rice": 2, "Barley": 2}, "Soil_Quality": {"Good": 4, "Fair": 2, "Poor": 2, "Missing": 1}, "Weather_Condition": {"Sunny": 6, "Rainy": 1, "Cloudy": 1, "Foggy": 2}}, "date_format_unified": {"Earliest_Harvest_Date": "2023-09-13", "Latest_Harvest_Date": "2023-09-16"}, "summary_stats": {"Yield_tonnes": {"count": 9, "mean": 10.04, "std": 2.22, "min": 6.8, "25%": 7.5, "50%": 11.0, "75%": 12.5, "max": 13.2}}, "inconsistent_yield_rows": ["F004", "F008", "F003"], "value_counts": {"Crop_Type": {"Corn": 4, "Wheat": 2, "Rice": 2, "Barley": 2}, "Soil_Quality": {"Good": 4, "Fair": 2, "Poor": 2, "Missing": 1}}, "correlations": {"Yield_tonnes_Soil_Quality": 0.81}, "skewness": {"Yield_tonnes": -0.45}}}
{"purpose": "Explore patient demographics and diagnosis information to identify common conditions and data quality issues.", "raw_table": "Patient_ID,Name,Age,Gender,Diagnosis,Visit_Date,Blood_Pressure\n001,John Doe,45,Male,Hypertension,2023-01-15,130/85\n002,Jane Smith,38,Female,diabetes,15/02/2023,120/80\n003,,29,F,Asthma,2023/03/10,110/70\n004,Emily Davis,NaN,Female,Hypertension,03-20-2023,135/90\n005,Michael Brown,52,Male,,2023-04-05,145/95\n006,Linda Wilson,47,female,Diabetes,2023-04-12,125/82\n007,Chris Johnson,33,M,asthma,2023-04-18,112/72\n008,Patricia Miller,NaN,Female,Hypertension,2023-04-25,NaN\n009,Robert Garcia,41,Male,Hypertension,April 30 2023,128/84\n010,Susan Martinez,37,Female,DIABETES,2023-05-03,118/76\n", "eda_steps": ["Check for missing values in each column", "Standardize the Gender column values", "Parse Visit_Date into a consistent date format", "Summarize frequency counts of Diagnoses", "Compute descriptive statistics for Age", "Analyze distribution of Blood_Pressure systolic values", "Identify patients with missing or invalid names", "Calculate percentage of missing values per column"], "eda_results": {"missing_values": {"Patient_ID": 0, "Name": 1, "Age": 2, "Gender": 0, "Diagnosis": 1, "Visit_Date": 0, "Blood_Pressure": 1}, "gender_standardized_counts": {"Male": 4, "Female": 5, "Other/Unknown": 0}, "visit_date_parsing_issues": 0, "diagnosis_value_counts": {"Hypertension": 4, "Diabetes": 3, "Asthma": 2, "": 1}, "age_summary_statistics": {"count": 8, "mean": 40.0, "std": 7.6, "min": 29, "25%": 33, "50%": 39, "75%": 46.5, "max": 52}, "blood_pressure_systolic_values": {"mean_systolic": 126.9, "min_systolic": 110, "max_systolic": 145, "missing_count": 1}, "missing_names_count": 1, "missing_value_percentages": {"Name": 10, "Age": 20, "Diagnosis": 10, "Blood_Pressure": 10}}}
{"purpose": "Analyze government employee demographics and department distribution to identify data quality issues and workforce composition.", "raw_table": "Employee_ID,Name,Department,Join_Date,Salary,Employment_Status,Age\n001,John Doe,Health,2020-01-15,55000,Active,34\n002,jane smith,education,15/03/2019,49000,active,29\n003,Bob Johnson,Transport,,60000,Active,45\n004,ALICE BROWN,Health,2018-11-20,not disclosed,Inactive,38\n005,Mike Davis,utilities,2021/05/10,53000,active,missing\n006,Emily Wilson,Education,2017-07-30,47000,Retired,50\n007,Chris Lee,Transport,2019-06-01,58000,ACTIVE,41\n008,Sara O'connor,Health,03-15-2020,NaN,active,33\n009,Tom Clark,Utilities,2020-12-01,51000,Active,28\n010,Linda Green,EDUCATION,2019-02-28,48000,Active,31\n011,David King,Transport,2018-08-15,62000,Inactive,44\n012,,Health,2019-10-10,54000,Active,36\n013,Ann White,Transport,2020-13-01,57500,Active,40\n014,George Harris,Education,,50000,active,27", "eda_steps": ["Check for missing values in all columns and calculate their percentages", "Standardize the casing of categorical columns: Department and Employment_Status", "Parse Join_Date column into consistent date format and identify invalid dates", "Compute descriptive statistics for numeric columns: Salary and Age", "Generate value counts for Department and Employment_Status columns", "Identify entries with inconsistent or unusual values in Salary and Age", "Detect duplicate or missing Employee_IDs or Names", "Summarize the distribution of Join_Date by year", "Calculate the number of Active vs Inactive employees per Department"], "eda_results": {"missing_values": {"Employee_ID": 0, "Name": 1, "Department": 0, "Join_Date": 3, "Salary": 2, "Employment_Status": 0, "Age": 1}, "standardized_categories": {"Department": {"Health": 4, "Education": 4, "Transport": 4, "Utilities": 2}, "Employment_Status": {"Active": 9, "Inactive": 2, "Retired": 1}}, "join_date_issues": {"Invalid_dates": ["2020-13-01"], "Missing_dates_count": 3}, "descriptive_stats": {"Salary": {"count": 12, "mean": 53750, "std": 5121.7, "min": 47000, "max": 62000}, "Age": {"count": 13, "mean": 36.3, "std": 7.5, "min": 27, "max": 50}}, "unusual_values": {"Salary": ["not disclosed", "NaN"], "Age": ["missing"]}, "duplicate_or_missing_ids_names": {"Missing_Names": 1, "Duplicate_Employee_IDs": 0}, "join_date_distribution_by_year": {"2017": 1, "2018": 2, "2019": 4, "2020": 4, "2021": 1, "Invalid": 1, "Missing": 3}, "active_inactive_counts_by_department": {"Health": {"Active": 4, "Inactive": 1}, "Education": {"Active": 3, "Inactive": 0, "Retired": 1}, "Transport": {"Active": 3, "Inactive": 1}, "Utilities": {"Active": 2}}}}
{"purpose": "Analyze crop yields and planting patterns across different farm regions to identify trends and missing data.", "raw_table": "Farm_ID,Region,Crop,Planting_Date,Yield_tons,Soil_Type,Rainfall_mm\nF001,North,Corn,2023-04-10,23.5,Loam,120\nF002,south,Wheat,2023/04/12,18.2,Sand,85\nF003,East,corn,04-15-2023,19.7,Clay,NA\nF004,West,RICE,,22.1,Loam,90\nF005,North,Soybean,2023-04-18,NA,loam,110\nF006,South,Wheat,2023-04-20,20.0,SAND,80\nF007,East,Corn,2023-04-22,21.4,clay,95\nF008,West,Rice,2023/04/24,23.0,Loam,88\nF009,North,soybean,2023-04-25,17.5,Loam,105\nF010,south,Wheat,2023-4-27,19.3,Sand,NA\nF011,East,CORN,2023-04-29,20.1,Clay,100\nF012,West,Rice,2023-04-30,21.8,loam,NA", "eda_steps": ["Standardize region and crop names to consistent capitalization", "Check and summarize missing values per column", "Parse and unify planting date formats", "Compute descriptive statistics for Yield_tons and Rainfall_mm", "Generate value counts for Soil_Type", "Calculate correlation between Yield_tons and Rainfall_mm", "Identify top 2 crops by average yield", "Summarize yields grouped by Region"], "eda_results": {"missing_values": {"Farm_ID": 0, "Region": 0, "Crop": 0, "Planting_Date": 1, "Yield_tons": 1, "Soil_Type": 0, "Rainfall_mm": 3}, "value_counts_soil_type": {"Loam": 6, "Sand": 3, "Clay": 3}, "standardized_regions": ["North", "South", "East", "West"], "standardized_crops": ["Corn", "Wheat", "Rice", "Soybean"], "planting_date_parsing_issues": 0, "summary_stats": {"Yield_tons": {"count": 11, "mean": 20.91, "std_dev": 2.0, "min": 17.5, "max": 23.5}, "Rainfall_mm": {"count": 9, "mean": 98.44, "std_dev": 14.45, "min": 80, "max": 120}}, "correlations": {"Yield_Rainfall": 0.72}, "top_crops_by_avg_yield": {"Rice": 22.3, "Corn": 21.68}, "yield_by_region": {"North": 20.5, "South": 19.17, "East": 20.4, "West": 22.3}}}
{"purpose": "Analyze the quality and production metrics of manufactured parts to identify data issues and production trends.", "raw_table": "PartID,ProductionDate,Shift,MachineID,Operator,DefectCount,ProductionTimeMinutes,MaterialGrade\nP001,2023/4/11,Morning,mach01,John Doe,0,45,Grade A\nP002,2023-04-12,night,MACH02,JANE DOE,1,50,grade B\nP003,04-13-2023,Morning,mach01,John Doe,,48,GRADE A\np004,2023/04/14,Afternoon,Mach03,alice smith,2,55,Grade C\nP005,,night,mach02,jane doe,0,49,Grade B\nP006,2023-04-15,NIGHT,Mach02,Bob Lee,3,60,grade b\nP007,2023/04/16,Morning,mach01,John Doe,0,47,Grade A\nP008,2023-4-17,Afternoon,MACH03,ALICE SMITH,1,54,grade c\nP009,2023/04/18,Morning,Mach01,John Doe,0,46,Grade A\nP010,2023/04/19,Afternoon,mach03,alice smith,,53,Grade C\nP011,2023-04-20,Night,Mach02,bob lee,2,58,Grade B", "eda_steps": ["Check for missing values in all columns", "Standardize the capitalization in categorical columns such as Shift, MachineID, Operator, and MaterialGrade", "Parse and unify the ProductionDate column into a consistent date format", "Compute descriptive statistics for numeric columns: DefectCount and ProductionTimeMinutes", "Generate value counts for the Shift and MaterialGrade columns", "Identify the number of unique Operators and Machines", "Calculate the correlation between DefectCount and ProductionTimeMinutes", "Summarize missing value percentages per column", "Identify top 2 material grades by count"], "eda_results": {"missing_values": {"PartID": 0, "ProductionDate": 1, "Shift": 0, "MachineID": 0, "Operator": 0, "DefectCount": 2, "ProductionTimeMinutes": 0, "MaterialGrade": 0}, "standardized_categoricals": {"Shift": ["Morning", "Night", "Afternoon"], "MachineID": ["Mach01", "Mach02", "Mach03"], "Operator": ["John Doe", "Jane Doe", "Alice Smith", "Bob Lee"], "MaterialGrade": ["Grade A", "Grade B", "Grade C"]}, "production_date_format": "All dates converted to YYYY-MM-DD with one missing value remaining", "summary_stats": {"DefectCount": {"count": 9, "mean": 1.0, "std": 1.1, "min": 0, "25%": 0, "50%": 0, "75%": 2, "max": 3}, "ProductionTimeMinutes": {"count": 11, "mean": 52.6, "std": 5.0, "min": 45, "25%": 47, "50%": 53, "75%": 55, "max": 60}}, "value_counts": {"Shift": {"Morning": 4, "Night": 3, "Afternoon": 4}, "MaterialGrade": {"Grade A": 4, "Grade B": 4, "Grade C": 3}}, "unique_counts": {"Operators": 4, "Machines": 3}, "correlations": {"DefectCount_ProductionTimeMinutes": 0.78}, "top_categories": {"MaterialGrade": ["Grade A", "Grade B"]}}}
{"purpose": "Analyze customer call patterns and service usage to identify potential churn risks.", "raw_table": "CustomerID,CallDate,CallDuration,ServiceType,CallQuality,Region\n001,2023-01-15,300,Voice,Good,North\n002,15/01/2023,NaN,Data,excellent,south\n003,2023-02-01,120,VOICE,Fair,East\n004,2023-02-05,45,,Poor,West\n005,,200,Data,Good,North\n006,2023-02-10,NaN,Voice,Good,South\n007,2023-02-10,180,Data,unknown,East\n008,2023/02/15,150,VOICE,Fair,west\n009,2023-02-18, ,Voice,Good,North\n010,2023-02-20,95,Data,Excellent,South\n011,2023-02-22,100,Voice,,East\n012,02-23-2023,NaN,Voice,Good,North", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize the CallDate column into a consistent date format", "Convert CallDuration to numeric and summarize descriptive statistics", "Normalize ServiceType and CallQuality categories to consistent capitalization", "Generate value counts for ServiceType and Region", "Identify the number of calls per customer", "Analyze distribution of CallQuality ratings", "Compute correlation between CallDuration and CallQuality (encoded numerically)"], "eda_results": {"missing_values": {"CustomerID": "0%", "CallDate": "8.33%", "CallDuration": "25%", "ServiceType": "8.33%", "CallQuality": "16.67%", "Region": "0%"}, "standardized_dates_sample": ["2023-01-15", "2023-01-15", "2023-02-01", "2023-02-05", "missing", "2023-02-10", "2023-02-10", "2023-02-15", "2023-02-18", "2023-02-20", "2023-02-22", "2023-02-23"], "call_duration_stats": {"count": 9, "mean": 141.67, "std": 78.43, "min": 45, "25%": 95, "50%": 120, "75%": 180, "max": 300}, "normalized_service_types": {"Voice": 7, "Data": 4}, "normalized_call_quality": {"Good": 5, "Excellent": 2, "Fair": 2, "Poor": 1, "Unknown": 1}, "value_counts_region": {"North": 4, "South": 3, "East": 3, "West": 2}, "calls_per_customer": {"001": 1, "002": 1, "003": 1, "004": 1, "005": 1, "006": 1, "007": 1, "008": 1, "009": 1, "010": 1, "011": 1, "012": 1}, "call_quality_distribution_percent": {"Good": 41.67, "Excellent": 16.67, "Fair": 16.67, "Poor": 8.33, "Unknown": 8.33, "Missing": 8.33}, "correlation_call_duration_call_quality": 0.58}}
{"purpose": "Analyze customer purchase behavior and identify patterns in order frequency and product category popularity.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod,CustomerRegion\n1001,C001,2023/01/15,Electronics,2,199.99,Credit Card,North\n1002,C002,15-01-2023,home Appliances,1,349.50,Paypal,South\n1003,C003,2023-01-16,electronics,NaN,299.99,Credit card,East\n1004,c004,01/17/2023,Fashion,3,49.99,CreditCard,West\n1005,C005,2023/01/18,Fashion,2,NaN,Cash,South\n1006,C006,,Sports,1,89.99,Credit Card,South\n1007,C007,2023/01/20,Home appliances,5,349.50,Paypal,East\n1008,C008,2023-01-20,Electronics,1,199.99,Cash,\n1009,C009,Jan 21 2023,Fashion,NaN,59.99,Credit Card,North\n1010,C010,2023-01-22,Sports,2,89.99,Paypal,North\n1011,C011,2023/01/22,beauty,1,29.99,Credit Card,East\n1012,C012,2023-01-23,Beauty,2,29.99,Credit card,west\n1013,C013,2023-01-23,Electronics,1,199.99,Cash,South\n1014,C014,2023-01-24,Fashion,3,49.99,Credit Card,North", "eda_steps": ["Check and summarize missing values per column", "Standardize and parse OrderDate into a uniform date format", "Normalize ProductCategory and PaymentMethod capitalization", "Compute descriptive statistics for Quantity and UnitPrice", "Generate value counts for ProductCategory", "Identify unique PaymentMethods and their counts", "Calculate total sales per ProductCategory", "Find top 3 customers by total purchase amount", "Analyze the distribution of orders over CustomerRegion"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 0, "OrderDate": 1, "ProductCategory": 0, "Quantity": 2, "UnitPrice": 1, "PaymentMethod": 0, "CustomerRegion": 1}, "standardized_dates": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18", null, "2023-01-20", "2023-01-20", "2023-01-21", "2023-01-22", "2023-01-22", "2023-01-23", "2023-01-23", "2023-01-24"], "normalized_product_categories": {"Electronics": 5, "Home Appliances": 2, "Fashion": 4, "Sports": 2, "Beauty": 2}, "normalized_payment_methods": {"Credit Card": 8, "Paypal": 3, "Cash": 3}, "descriptive_stats": {"Quantity": {"count": 12, "mean": 2.17, "std": 1.34, "min": 1, "25%": 1.0, "50%": 2.0, "75%": 3.0, "max": 5}, "UnitPrice": {"count": 13, "mean": 134.21, "std": 132.18, "min": 29.99, "25%": 49.99, "50%": 89.99, "75%": 199.99, "max": 349.5}}, "total_sales_per_category": {"Electronics": 1399.94, "Home Appliances": 2097.0, "Fashion": 349.93, "Sports": 269.97, "Beauty": 89.97}, "top_customers_by_purchase": {"C007": 1747.5, "C002": 349.5, "C001": 399.98}, "orders_by_region": {"North": 4, "South": 4, "East": 3, "West": 2, "": 1}}}
{"purpose": "Examine temperature and precipitation patterns across different climate zones to identify data quality issues and seasonal trends.", "raw_table": "Date,Location,Climate_Zone,Avg_Temperature_C,Precipitation_mm\n2023-01-15,New York,TEMPERATE,3.5,20\n15/02/2023,los angeles,Arid,18.7,0\n2023-03-10,Chicago,Temperate,7.2,NA\n2023/04/05,Houston,Tropical,23.1,85.4\n2023-05-12,Phoenix, arid,NA,5.6\n2023-06-18,Miami,Tropical,28.6,120.1\n07-07-2023,Seattle,Temperate,15.2,45\n2023-08-20,Boston,TEMPERATE,22.3,30.5\n2023-09-15,Denver,Alpine,14.7,\n2023-10-01,San Francisco,Arid,17.8,2.1\n2023-11-11,Anchorage,Alpine,-5.6,NA\n2023-12-25,New York,TEMPERATE,0.0,15.2\n,Los Angeles,Arid,19.0,0\n2023-02-30,Miami,Tropical,29.1,110.3", "eda_steps": ["Parse and standardize the date column to a consistent format", "Identify and count missing values in each column", "Normalize capitalization in the Location and Climate_Zone columns", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm, ignoring missing values", "Generate value counts for Climate_Zone categories", "Check for invalid or impossible date entries", "Analyze correlation between Avg_Temperature_C and Precipitation_mm", "List top 3 locations with highest average temperature", "Summarize number of records per month"], "eda_results": {"missing_values": {"Date": 1, "Location": 0, "Climate_Zone": 0, "Avg_Temperature_C": 2, "Precipitation_mm": 3}, "standardized_dates": {"parsed_dates": 13, "unparsable_dates": 1}, "value_counts_Climate_Zone": {"Temperate": 5, "Arid": 4, "Tropical": 4, "Alpine": 2}, "descriptive_stats": {"Avg_Temperature_C": {"count": 12, "mean": 14.18, "std": 11.02, "min": -5.6, "max": 29.1}, "Precipitation_mm": {"count": 11, "mean": 39.18, "std": 44.53, "min": 0, "max": 120.1}}, "invalid_dates": ["2023-02-30"], "correlations": {"Avg_Temperature_C_vs_Precipitation_mm": 0.47}, "top_3_locations_by_avg_temp": [{"Location": "Miami", "Avg_Temperature_C": 28.85}, {"Location": "Los Angeles", "Avg_Temperature_C": 18.85}, {"Location": "San Francisco", "Avg_Temperature_C": 17.8}], "records_per_month": {"January": 2, "February": 2, "March": 1, "April": 1, "May": 1, "June": 1, "July": 1, "August": 1, "September": 1, "October": 1, "November": 1, "December": 1}}}
{"purpose": "Analyze city-level public transportation usage patterns and identify data quality issues.", "raw_table": "City,Date,Ridership,Service_Type,On_Time_Percentage\nNew york,2023-01-15,12500,Bus,89.5\nLos Angeles,01/16/2023,9800,Subway, 92\nChicago,2023/01/17,8700,Bus,87\nhouston,2023-01-15,missing,Bus,85\nPhoenix,2023-1-18,7600,TRAM,NA\nPhiladelphia,2023-01-19,8200,subway,90\nsan Antonio,2023-01-20,missing,Bus,88\nSan Diego,2023-01-21,7400,Bus,\nDallas,2023-01-22,7000,Bus,84.5\nSan Jose,2023/01/23,6900,Subway, 91\nAustin,2023-01-24,6650,Bus,87\nJacksonville,2023-01-25,6200,metro,86\nFort Worth,2023-01-26,6000,Bus,missing", "eda_steps": ["Standardize city names capitalization", "Convert Date column to consistent date format", "Identify and count missing values per column", "Compute descriptive statistics for Ridership and On_Time_Percentage", "Generate value counts for Service_Type and correct inconsistent categories", "Calculate the average ridership by Service_Type", "Analyze the distribution skewness of Ridership", "Check correlation between Ridership and On_Time_Percentage"], "eda_results": {"missing_values": {"City": 0, "Date": 0, "Ridership": 2, "Service_Type": 0, "On_Time_Percentage": 2}, "value_counts": {"Service_Type": {"Bus": 7, "Subway": 3, "Tram": 1, "Metro": 1}}, "summary_stats": {"Ridership": {"count": 13, "mean": 7830.77, "std": 2176.45, "min": 6000, "25%": 6900, "50%": 7400, "75%": 8700, "max": 12500}, "On_Time_Percentage": {"count": 11, "mean": 87.95, "std": 2.39, "min": 84.5, "25%": 86, "50%": 88, "75%": 90, "max": 92}}, "top_categories": {"City": ["New York", "Los Angeles", "Chicago", "Houston", "Phoenix"]}, "correlations": {"Ridership_On_Time_Percentage": 0.42}}}
{"purpose": "Analyze production batch quality and identify patterns in defect rates across different machines and shifts.", "raw_table": "BatchID,Machine,Shift,ProductionDate,UnitsProduced,DefectCount,Operator\nB001,Machine_A,Morning,2024/01/05,1000,5,John Doe\nB002,machine_b,evening,01-06-2024,950,7,jane smith\nB003,Machine_A,Morning,2024-01-07,NaN,3,John Doe\nB004,Machine_C,Night,2024/01/08,1100,,M. Johnson\nB005,machine_b,Evening,2024-01-09,1050,10,jane smith\nB006,Machine_C,Night,01/10/2024,1080,6,M. Johnson\nB007,MACHINE_A,Morning,2024/01/11,1000,4,John Doe\nB008,machine_b,Evening,2024-01-12,1030,NaN,jane Smith\nB009,Machine_C,Night,2024/01/13,1120,8,M. Johnson\nB010,MACHINE_A,Morning,2024-01-14,1005,2,John Doe\nB011,machine_b,Evening,14-01-2024,995,5,jane smith\nB012,Machine_C,Night,2024/01/15,1095,7,M. Johnson", "eda_steps": ["Check for missing values in all columns", "Standardize capitalization in categorical columns: Machine, Shift, Operator", "Convert ProductionDate to a consistent date format", "Compute descriptive statistics for numeric columns UnitsProduced and DefectCount", "Calculate defect rate as DefectCount divided by UnitsProduced for each batch", "Generate value counts for categorical columns Machine, Shift, and Operator", "Identify batches with missing or inconsistent data", "Compute correlation between UnitsProduced and DefectCount", "Summarize average defect rate by Machine and Shift"], "eda_results": {"missing_values": {"BatchID": 0, "Machine": 0, "Shift": 0, "ProductionDate": 0, "UnitsProduced": 1, "DefectCount": 2, "Operator": 0}, "standardized_categories": {"Machine": {"Machine_A": 4, "Machine_B": 4, "Machine_C": 4}, "Shift": {"Morning": 4, "Evening": 4, "Night": 4}, "Operator": {"John Doe": 4, "Jane Smith": 4, "M. Johnson": 4}}, "production_date_range": {"min": "2024-01-05", "max": "2024-01-15"}, "summary_stats": {"UnitsProduced": {"count": 14, "mean": 1035.0, "std": 55.4, "min": 950, "25%": 995, "50%": 1005, "75%": 1080, "max": 1120}, "DefectCount": {"count": 12, "mean": 5.75, "std": 2.5, "min": 2, "25%": 4, "50%": 6, "75%": 7, "max": 10}}, "batches_with_missing_data": ["B003", "B004", "B008"], "correlations": {"UnitsProduced_vs_DefectCount": 0.65}, "average_defect_rate": {"by_Machine": {"Machine_A": 0.0048, "Machine_B": 0.0063, "Machine_C": 0.0064}, "by_Shift": {"Morning": 0.0048, "Evening": 0.0063, "Night": 0.0064}}, "value_counts": {"Machine": {"Machine_A": 4, "Machine_B": 4, "Machine_C": 4}, "Shift": {"Morning": 4, "Evening": 4, "Night": 4}, "Operator": {"John Doe": 4, "Jane Smith": 4, "M. Johnson": 4}}}}
{"purpose": "Explore viewer ratings and genre distribution of recent movies to understand audience preferences.", "raw_table": "MovieID,Title,Genre,ReleaseDate,Duration,IMDB_Rating,BoxOffice_Millions\n1,The Last Night,Action,2023-05-12,130,7.8,150.5\n2,Love in Paris,romance,05/15/2023,95,8.1,88.3\n3,Shadow Realm,Fantasy,2023/06/01,110,,120.2\n4,Galaxy Quest,SCI-FI,2023-6-5,125,7.4,135.0\n5,Haunted Hills,Horror,,100,6.9,45.7\n6,mystic river,Fantasy,2023-05-20,115,7.5,NaN\n7,Urban Legends,Horror,2023-05-25,98,6.8,50.0\n8,The Chef's Table,Documentary,2023-06-10,80,8.3,30.1\n9,Cosmic Drift,SCI-FI,2023-05-30,130,7.9,140.7\n10,Romantic Escape,Romance,2023-06-12,90,7.6,95.2\n", "eda_steps": ["Check for missing values in each column", "Standardize capitalization for the Genre column", "Parse and unify the ReleaseDate format to YYYY-MM-DD", "Compute descriptive statistics for Duration and IMDB_Rating", "Generate value counts for the Genre column", "Identify top 3 movies by BoxOffice_Millions", "Calculate correlation between Duration, IMDB_Rating, and BoxOffice_Millions"], "eda_results": {"missing_values": {"MovieID": 0, "Title": 0, "Genre": 0, "ReleaseDate": 1, "Duration": 0, "IMDB_Rating": 1, "BoxOffice_Millions": 1}, "standardized_genres": {"Action": 1, "Romance": 2, "Fantasy": 2, "Sci-Fi": 2, "Horror": 2, "Documentary": 1}, "release_date_formats_unified": true, "descriptive_statistics": {"Duration": {"count": 10, "mean": 106.3, "std": 17.4, "min": 80, "max": 130}, "IMDB_Rating": {"count": 9, "mean": 7.59, "std": 0.49, "min": 6.8, "max": 8.3}}, "genre_value_counts": {"Romance": 2, "Fantasy": 2, "Horror": 2, "Sci-Fi": 2, "Action": 1, "Documentary": 1}, "top_3_box_office_movies": [{"Title": "The Last Night", "BoxOffice_Millions": 150.5}, {"Title": "Cosmic Drift", "BoxOffice_Millions": 140.7}, {"Title": "Galaxy Quest", "BoxOffice_Millions": 135.0}], "correlations": {"Duration_vs_IMDB_Rating": 0.15, "Duration_vs_BoxOffice": 0.82, "IMDB_Rating_vs_BoxOffice": 0.47}}}
{"purpose": "Analyze TV show ratings and episode counts to understand viewer preferences and identify data inconsistencies.", "raw_table": "Show_ID,Show_Name,Genre,Seasons,Episodes,Average_Rating,First_Air_Date\n101,The Great Escape,Drama,3,30,8.5,2018-01-15\n102,Galaxy Quest,SCI-FI,4,,7.9,15/03/2017\n103,Love & Life,Romance,Two,20,7.2,2019-05-22\n104,Haunted Nights,Horror,3,28,8.1,2017-11-01\n105,THE COMEDY HUB,comedy,5,50,8.8,2016-12-09\n106,Wild Adventures,Adventure,,45,7.5,2018/08/10\n107,Crime Scene,thriller,4,40,8.3,2017-07-30\n108,Space odyssey,SCI-FI,3,30,nan,2018-02-28\n109,Friendly Neighbors,Comedy,2,18,7.0,2019-07-14\n110,Mystery Manor,Mystery,3,NaN,8.0,2018-09-05", "eda_steps": ["Check for missing values in each column", "Standardize Genre column capitalization", "Convert Seasons and Episodes columns to numeric, handling non-numeric values", "Calculate descriptive statistics for Seasons, Episodes, and Average_Rating", "Generate value counts for the Genre column", "Identify shows with missing or inconsistent air date formats", "Find the top 3 shows by Average_Rating", "Summarize the distribution skewness for Average_Rating"], "eda_results": {"missing_values": {"Show_ID": 0, "Show_Name": 0, "Genre": 0, "Seasons": 2, "Episodes": 2, "Average_Rating": 1, "First_Air_Date": 0}, "standardized_genres": {"Drama": 1, "Sci-Fi": 2, "Romance": 1, "Horror": 1, "Comedy": 2, "Adventure": 1, "Thriller": 1, "Mystery": 1}, "data_conversion_issues": {"Seasons_non_numeric": ["Two", null], "Episodes_non_numeric": ["NaN", ""], "Average_Rating_non_numeric": ["nan"]}, "descriptive_statistics": {"Seasons": {"count": 13, "mean": 3.25, "std": 1.1, "min": 2, "max": 5}, "Episodes": {"count": 13, "mean": 32.7, "std": 10.9, "min": 18, "max": 50}, "Average_Rating": {"count": 14, "mean": 7.9, "std": 0.65, "min": 7.0, "max": 8.8}}, "top_genres": [{"Genre": "Comedy", "Count": 2}, {"Genre": "Sci-Fi", "Count": 2}, {"Genre": "Drama", "Count": 1}], "inconsistent_air_dates": ["Galaxy Quest (15/03/2017)", "Wild Adventures (2018/08/10)"], "top_3_shows_by_rating": [{"Show_Name": "THE COMEDY HUB", "Average_Rating": 8.8}, {"Show_Name": "The Great Escape", "Average_Rating": 8.5}, {"Show_Name": "Crime Scene", "Average_Rating": 8.3}], "average_rating_skewness": 0.15}}
{"purpose": "Analyze viewing patterns and ratings for popular TV shows to identify trends and missing data issues.", "raw_table": "ShowID,ShowName,Genre,ReleaseDate,Seasons,AvgRating,TotalViews\n1,Stranger Things,Sci-Fi,2016-07-15,4,8.7,1500000\n2,the crown,Drama,11/04/2016,4,8.6,1100000\n3,Breaking Bad,crime,2008/01/20,5,9.5,2000000\n4,Friends,Comedy,1994-09-22,10,8.9,2500000\n5,GAME OF THRONES,Fantasy,2011-04-17,8,9.3,3200000\n6,The Mandalorian,Sci-Fi,Dec 12, 2019,2,8.8,900000\n7,Westworld,Sci-Fi,2016-10-02,3,missing,700000\n8,The Office,Comedy,2005-03-24,9,8.8,2300000\n9,Sherlock,Crime,2010-07-25,4,9.1,\n10,Black Mirror,Sci-fi,2011-12-04,5,8.8,1300000\n11,The Witcher,Fantasy,2019-12-20,2,8.2,1100000\n12,Lost,Drama,2004-09-22,,8.4,900000\n", "eda_steps": ["Standardize capitalization in ShowName and Genre columns", "Parse ReleaseDate into a consistent date format", "Identify and count missing values in each column", "Compute descriptive statistics for numeric columns Seasons, AvgRating, and TotalViews", "Generate value counts for Genre", "Identify top 3 shows by TotalViews", "Check correlation between Seasons and AvgRating", "Summarize date range of ReleaseDate", "List shows with missing AvgRating or TotalViews"], "eda_results": {"missing_values": {"ShowID": 0, "ShowName": 0, "Genre": 0, "ReleaseDate": 0, "Seasons": 1, "AvgRating": 1, "TotalViews": 1}, "value_counts": {"Genre": {"Sci-Fi": 3, "Drama": 2, "Crime": 2, "Comedy": 2, "Fantasy": 2}}, "summary_stats": {"Seasons": {"count": 11, "mean": 5.18, "min": 2, "max": 10}, "AvgRating": {"count": 11, "mean": 8.77, "min": 8.2, "max": 9.5}, "TotalViews": {"count": 11, "mean": 1631818, "min": 700000, "max": 3200000}}, "top_categories": {"Top3ShowsByViews": [{"ShowName": "Game of Thrones", "TotalViews": 3200000}, {"ShowName": "Friends", "TotalViews": 2500000}, {"ShowName": "The Office", "TotalViews": 2300000}]}, "correlations": {"Seasons_vs_AvgRating": 0.42}, "date_range": {"min": "1994-09-22", "max": "2019-12-20"}, "shows_with_missing_values": {"AvgRating": ["Westworld"], "TotalViews": ["Sherlock"], "Seasons": ["Lost"]}}}
{"purpose": "Analyze monthly temperature and precipitation trends across different climate zones.", "raw_table": "Date,Location,Climate_Zone,Avg_Temperature_C,Precipitation_mm\n2023-01-15,Boston,Temperate,2.5,78\n2023/02/15,boston,TEMPERATE,1.8,56\n2023-03-15,Denver,Alpine,5.2,34\n2023-4-15,Denver,alpine,7.1,NA\n15-May-2023,Miami,Tropical,27.3,112\n2023-06-15,Miami,tropical,29.1,130\n2023-07-15,Anchorage,Subarctic,-5.4,45\n2023-08-15,Anchorage,SubArctic,-3.8,50\n2023-09-15,Miami,,28.4,\n2023-10-15,Denver,Alpine,3.3,25\n2023-11-15,Boston,Temperate,0.4,90\n2023-12-15,Boston,temperate,1.0,85\n2023-13-15,Boston,Temperate,1.2,88\n2023-07-32,Miami,Tropical,30.0,140", "eda_steps": ["Parse and standardize the Date column to a consistent date format", "Identify and count missing values in each column", "Normalize Climate_Zone capitalization and check for unusual or missing categories", "Compute descriptive statistics (mean, median, std) for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Location and Climate_Zone columns", "Check for invalid or outlier dates in the Date column", "Calculate correlation between Avg_Temperature_C and Precipitation_mm", "Summarize the number of records per month"], "eda_results": {"missing_values": {"Date": 0, "Location": 0, "Climate_Zone": 1, "Avg_Temperature_C": 0, "Precipitation_mm": 2}, "normalized_climate_zones": ["Temperate", "Temperate", "Alpine", "Alpine", "Tropical", "Tropical", "Subarctic", "Subarctic", "Unknown", "Alpine", "Temperate", "Temperate", "Temperate", "Tropical"], "value_counts": {"Location": {"Boston": 5, "Denver": 3, "Miami": 5, "Anchorage": 2}, "Climate_Zone": {"Temperate": 5, "Alpine": 3, "Tropical": 4, "Subarctic": 2, "Unknown": 1}}, "descriptive_stats": {"Avg_Temperature_C": {"mean": 8.1, "median": 3.3, "std_dev": 11.2}, "Precipitation_mm": {"mean": 74.1, "median": 65.5, "std_dev": 38.4}}, "invalid_dates": ["2023-13-15", "2023-07-32"], "correlations": {"Avg_Temperature_C_vs_Precipitation_mm": 0.56}, "records_per_month": {"January": 1, "February": 1, "March": 1, "April": 1, "May": 1, "June": 1, "July": 2, "August": 1, "September": 1, "October": 1, "November": 1, "December": 1}}}
{"purpose": "Analyze energy consumption patterns across different city zones and months to identify data quality issues and usage trends.", "raw_table": "Zone,Month,Energy_Consumed_kWh,Peak_Demand_kW,Customer_Type,Reading_Date\nNorth,Jan,1200,15,Residential,2023-01-15\nsouth,FEB,850,,Commercial,15-02-2023\nEast,Mar,NaN,12,Industrial,2023/03/20\nWEST,Apr,950,14,Residential,2023-04-18\nnorth,May,1100,17,Residential,2023-05-16\nSouth,jun,1050,16,Commercial,2023-06-19\nEast,JUL,1250,,Industrial,2023-07-21\nWest,Aug,Not Available,15,Residential,2023-08-17\nNorth,Sep,1300,18,Residential,2023-09-14\nsouth,Oct,1150,16,Commercial,2023-10-12\nEast,Nov,1000,14,Industiral,2023-11-10\nWEST,Dec,1400,19,Residential,2023-12-15", "eda_steps": ["Standardize capitalization for the 'Zone' and 'Customer_Type' columns", "Parse and unify 'Reading_Date' into a consistent date format", "Identify and count missing values in each column", "Compute descriptive statistics for 'Energy_Consumed_kWh' and 'Peak_Demand_kW'", "Generate value counts for 'Zone' and 'Customer_Type'", "Check for incorrect or unusual categories in categorical columns", "Analyze correlation between 'Energy_Consumed_kWh' and 'Peak_Demand_kW'", "Identify rows with non-numeric or invalid entries in numeric columns", "Summarize monthly trends in energy consumption"], "eda_results": {"missing_values": {"Energy_Consumed_kWh": 2, "Peak_Demand_kW": 2}, "value_counts": {"Zone": {"North": 3, "South": 3, "East": 3, "West": 3}, "Customer_Type": {"Residential": 5, "Commercial": 3, "Industrial": 2, "Industiral": 1}}, "incorrect_categories": {"Customer_Type": ["Industiral"]}, "summary_stats": {"Energy_Consumed_kWh": {"count": 11, "mean": 1127.27, "std": 182.37, "min": 850, "25%": 1000, "50%": 1100, "75%": 1250, "max": 1400}, "Peak_Demand_kW": {"count": 10, "mean": 15.2, "std": 1.92, "min": 12, "25%": 14, "50%": 15, "75%": 16.5, "max": 19}}, "correlations": {"Energy_Consumed_kWh_vs_Peak_Demand_kW": 0.89}, "non_numeric_entries": {"Energy_Consumed_kWh": ["NaN", "Not Available"]}, "monthly_trends": {"Jan": 1200, "Feb": 850, "Mar": null, "Apr": 950, "May": 1100, "Jun": 1050, "Jul": 1250, "Aug": null, "Sep": 1300, "Oct": 1150, "Nov": 1000, "Dec": 1400}}}
{"purpose": "Analyze monthly sales performance and customer demographics for a retail store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,CustomerAge,Region\n1001,C123,2023-01-15,Electronics,2,299.99,34,North\n1002,c124,15/01/2023,home appliances,1,89.50,,South\n1003,C125,2023-02-05,Electronics,3,NaN,45,East\n1004,C126,2023-2-20,Fashion,5,49.99,29,west\n1005,C127,2023-02-28,Fashion,,39.99,31,NORTH\n1006,,2023/03/05,Home Appliances,2,95.00,38,South\n1007,C129,03-12-2023,Electronics,1,299.99,27,East\n1008,C130,2023-03-15,Fashion,4,45.00,thirty,West\n1009,C131,2023-03-20,home appliances,2,92.00,40,South\n1010,C132,2023-04-01,Electronics,1,310.00,33,north", "eda_steps": ["Check for missing values in each column", "Standardize capitalization and formatting for ProductCategory and Region columns", "Convert OrderDate to a consistent date format", "Calculate total sales per order (Quantity * UnitPrice)", "Generate descriptive statistics for numeric columns including Quantity, UnitPrice, CustomerAge, and total sales", "Identify and count unique ProductCategory values", "Summarize value counts for Region", "Identify the number of orders with missing or invalid Quantity or UnitPrice", "Compute average CustomerAge by Region"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 0, "ProductCategory": 0, "Quantity": 2, "UnitPrice": 1, "CustomerAge": 2, "Region": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Home Appliances", "Fashion"], "Region": ["North", "South", "East", "West"]}, "order_dates_standardized": ["2023-01-15", "2023-01-15", "2023-02-05", "2023-02-20", "2023-02-28", "2023-03-05", "2023-03-12", "2023-03-15", "2023-03-20", "2023-04-01"], "total_sales_per_order": [599.98, 89.5, null, 249.95, null, 190.0, 299.99, 180.0, 184.0, 310.0], "summary_stats": {"Quantity": {"count": 8, "mean": 2.75, "min": 1, "max": 5}, "UnitPrice": {"count": 9, "mean": 172.55, "min": 39.99, "max": 310.0}, "CustomerAge": {"count": 8, "mean": 34.375, "min": 27, "max": 45}, "TotalSales": {"count": 8, "mean": 238.03, "min": 89.5, "max": 599.98}}, "value_counts": {"ProductCategory": {"Electronics": 4, "Home Appliances": 3, "Fashion": 3}, "Region": {"North": 3, "South": 3, "East": 2, "West": 2}}, "invalid_orders_count": {"Quantity_or_UnitPrice_missing": 3}, "average_customer_age_by_region": {"North": 32.5, "South": 39.0, "East": 36.0, "West": 29.5}}}
{"purpose": "Analyze machine downtime causes and durations to improve maintenance scheduling.", "raw_table": "MachineID,StartDate,EndDate,DowntimeHours,Cause,Operator\nM01,2023/01/15,2023-01-16,5,Electrical failure,John\nm02,15-01-2023,16-01-2023,3,Mechanical Breakdown,alice\nM03,2023-01-17,,4,Electrical Failure,bob\nM04,2023-01-18,2023/01/18,,Overheating,Charlie\nm05,2023-01-19,2023-01-20,2,unknown,Dave\nM06,2023/01/20,2023-01-21,NaN,Mechanical breakdown,\nM07,2023-01-21,2023-01-22,6,Electrical Failure,Ed\nM08,2023-01-22,2023-01-23,3,Overheating,frank\nm09,2023-01-23,2023-01-24,NaN,Mechanical Failure,George\nM10,,2023-01-25,7,Electrical failure,Helen", "eda_steps": ["Check and report missing values per column", "Standardize the 'Cause' column capitalization", "Convert 'DowntimeHours' to numeric and identify non-numeric entries", "Compute descriptive statistics for 'DowntimeHours'", "Generate value counts for 'Cause'", "Identify unique operators and count missing operator entries", "Analyze consistency of 'StartDate' and 'EndDate' formats", "Calculate downtime duration difference where StartDate and EndDate are present"], "eda_results": {"missing_values": {"MachineID": 0, "StartDate": 1, "EndDate": 1, "DowntimeHours": 3, "Cause": 0, "Operator": 1}, "cause_value_counts": {"electrical failure": 4, "mechanical breakdown": 2, "overheating": 2, "unknown": 1, "mechanical failure": 1}, "downtime_hours_numeric_conversion_issues": 0, "downtime_hours_summary_stats": {"count": 8, "mean": 4.5, "std": 1.82, "min": 2, "25%": 3, "50%": 4.5, "75%": 6, "max": 7}, "unique_operators_count": 8, "missing_operator_count": 1, "date_format_inconsistencies": {"StartDate": ["2023/01/15", "15-01-2023", "2023-01-17", "2023-01-18", "2023-01-19", "2023/01/20", "2023-01-21", "2023-01-22", "2023-01-23", null], "EndDate": ["2023-01-16", "16-01-2023", null, "2023/01/18", "2023-01-20", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24", "2023-01-25"]}, "calculated_downtime_days_difference_stats": {"count": 8, "mean_days_difference": 1, "min": 0, "max": 1}}}
{"purpose": "Analyze engagement patterns and content types on a social media platform to identify trends and data quality issues.", "raw_table": "Post_ID,User_ID,Post_Date,Content_Type,Likes,Comments,Shares\n1,U123,2023-01-15T14:30,Image,150,20,5\n2,u124,01/16/2023,video,200,,10\n3,U125,2023-01-17,image,abc,15,3\n4,u126,17-01-2023,text,50,5,0\n5,U127,,Video,300,40,20\n6,U128,2023/01/18,text,70,NaN,1\n7,u129,2023-01-19,image,90,10,NaN\n8,U130,2023-01-20,Poll,20,2,0\n9,u131,2023-1-21,text,30,,2\n10,U132,2023-01-22,VIDEO,400,50,25\n11,U133,2023-01-23,video,NaN,30,15\n12,u134,2023-01-24,Image,120,25,5\n13,U135,2023-01-25,,85,12,3\n14,u136,2023-01-26,text,60,8,4", "eda_steps": ["Check for missing values in each column", "Standardize Content_Type capitalization and fill missing values with 'Unknown'", "Convert Post_Date to a consistent datetime format", "Convert Likes, Comments, and Shares columns to numeric, handling non-numeric and missing entries", "Compute descriptive statistics for numeric engagement metrics (Likes, Comments, Shares)", "Generate value counts for Content_Type", "Identify top 3 posts by Likes", "Calculate correlation matrix between Likes, Comments, and Shares"], "eda_results": {"missing_values": {"Post_ID": 0, "User_ID": 0, "Post_Date": 1, "Content_Type": 1, "Likes": 2, "Comments": 3, "Shares": 2}, "content_type_value_counts": {"Image": 4, "Video": 4, "Text": 4, "Poll": 1, "Unknown": 1}, "post_date_conversion_errors": 0, "numeric_conversion_issues": {"Likes": ["abc"], "Comments": ["NaN", ""], "Shares": ["NaN", ""]}, "descriptive_statistics": {"Likes": {"count": 12, "mean": 137.5, "std": 117.3, "min": 20, "25%": 60, "50%": 90, "75%": 200, "max": 400}, "Comments": {"count": 11, "mean": 19.55, "std": 14.12, "min": 2, "25%": 8, "50%": 15, "75%": 30, "max": 50}, "Shares": {"count": 12, "mean": 8.83, "std": 8.9, "min": 0, "25%": 3, "50%": 5, "75%": 15, "max": 25}}, "top_3_posts_by_likes": [{"Post_ID": 10, "Likes": 400}, {"Post_ID": 5, "Likes": 300}, {"Post_ID": 2, "Likes": 200}], "correlations": {"Likes_Comments": 0.85, "Likes_Shares": 0.79, "Comments_Shares": 0.73}}}
{"purpose": "Analyze monthly temperature and precipitation trends across different climate zones to identify data quality issues and basic statistics.", "raw_table": "Date,Region,Climate_Zone,Avg_Temperature_C,Precipitation_mm\n2023-01-15,Northwest,Temperate,5.6,120\n2023/02/15,NorthWest,Temperate,7.1,NA\n2023-03-15,southeast,Tropical,22.5,200\n2023-04-15,Southeast,TROPICAL,23.0,180\n2023-05-15,Midwest,Continental,15.2,60\n2023-06-15,MidWest,continental,18.6,55\n2023-07-15,Southwest,Desert,30.1,5\n2023-08-15,SouthWest,desert,NA,7\n2023-09-15,Northwest,Temperate,12.3,110\n2023-10-15,Southeast,Tropical,19.8,190\n2023-11-15,Midwest,Continental,10.0,NA\n2023-12-15,SouthWest,Desert,28.5,3\n2023-13-15,Unknown,Unknown,NA,NA", "eda_steps": ["Check and report missing value counts for all columns", "Standardize Climate_Zone categories to consistent capitalization", "Convert Date column to datetime format and identify invalid dates", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Region and Climate_Zone", "Identify rows with inconsistent Region capitalization", "Calculate correlation between Avg_Temperature_C and Precipitation_mm", "Summarize distribution skewness for numeric columns"], "eda_results": {"missing_values": {"Date": 1, "Region": 1, "Climate_Zone": 1, "Avg_Temperature_C": 2, "Precipitation_mm": 3}, "invalid_dates": ["2023-13-15"], "standardized_climate_zones": ["Temperate", "Tropical", "Continental", "Desert", "Unknown"], "value_counts": {"Region": {"Northwest": 3, "Southeast": 3, "Midwest": 3, "Southwest": 3, "Unknown": 1}, "Climate_Zone": {"Temperate": 3, "Tropical": 3, "Continental": 3, "Desert": 3, "Unknown": 1}}, "inconsistent_region_names": ["NorthWest", "MidWest", "SouthWest"], "descriptive_statistics": {"Avg_Temperature_C": {"count": 12, "mean": 16.75, "std": 7.58, "min": 5.6, "25%": 10.0, "50%": 15.2, "75%": 22.5, "max": 30.1}, "Precipitation_mm": {"count": 10, "mean": 98.0, "std": 78.7, "min": 3, "25%": 7, "50%": 60, "75%": 180, "max": 200}}, "correlations": {"Avg_Temperature_C_vs_Precipitation_mm": -0.45}, "skewness": {"Avg_Temperature_C": 0.84, "Precipitation_mm": 0.92}}}
{"purpose": "Analyze customer purchase patterns and product category performance in a retail store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod\n1001,C123,2023-01-15,Electronics,2,399.99,Credit Card\n1002,c124,15/01/2023,home appliances,1,89.50,Cash\n1003,,2023/01/16,Toys,3,19.99,credit card\n1004,C125,2023-01-17,Fashion,5,,Debit\n1005,C123,01-18-2023,fashion,2,49.9,CREDIT\n1006,C126,20230119,Electronics,1,399.99,Paypal\n1007,C127,2023-01-20,Garden,4,15.00,Cash\n1008,C128,2023-1-21,Toys,2,20.0,Debit\n1009,C129,,Electronics,1,399.99,Credit Card\n1010,C130,2023-01-22,Home Appliances,1,N/A,Cash\n1011,C131,2023-01-23,Fashion,3,50.00,credit card\n1012,C132,2023-01-24,garden,2,15.00,Paypal", "eda_steps": ["Check for missing values in all columns", "Standardize the ProductCategory names to title case", "Convert OrderDate to a uniform date format", "Calculate descriptive statistics for Quantity and UnitPrice", "Generate value counts for PaymentMethod and ProductCategory", "Identify orders with missing UnitPrice or CustomerID", "Compute total sales amount per ProductCategory", "Analyze the frequency of orders per CustomerID"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 1, "ProductCategory": 0, "Quantity": 0, "UnitPrice": 2, "PaymentMethod": 0}, "standardized_categories": {"Electronics": 4, "Home Appliances": 2, "Toys": 2, "Fashion": 3, "Garden": 2}, "orderdate_uniform_format": {"earliest_date": "2023-01-15", "latest_date": "2023-01-24"}, "descriptive_statistics": {"Quantity": {"count": 13, "mean": 2.69, "min": 1, "max": 5}, "UnitPrice": {"count": 11, "mean": 121.35, "min": 15.0, "max": 399.99}}, "value_counts": {"PaymentMethod": {"Credit Card": 3, "Cash": 3, "Credit": 1, "Debit": 2, "Paypal": 2}, "ProductCategory": {"Electronics": 4, "Home Appliances": 2, "Toys": 2, "Fashion": 3, "Garden": 2}}, "orders_missing_critical_info": {"missing_UnitPrice_OrderIDs": [1004, 1010], "missing_CustomerID_OrderIDs": [1003]}, "total_sales_per_category": {"Electronics": 1599.96, "Home Appliances": 89.5, "Toys": 99.95, "Fashion": 299.7, "Garden": 45.0}, "orders_per_customer": {"C123": 2, "c124": 1, "C125": 1, "C126": 1, "C127": 1, "C128": 1, "C129": 1, "C130": 1, "C131": 1, "C132": 1}}}
{"purpose": "Analyze user engagement patterns on a social media platform over a week.", "raw_table": "User_ID,Post_Date,Post_Type,Likes,Comments,Shares\n101,2024-04-01,Image,45,10,5\n102,4/2/2024,video,30,,2\n103,2024-04-03,Text,NaN,4,1\n104,2024-4-04,IMAGE,50,12,6\n105,2024/04/05,video,25,7,3\n106,2024-04-06,text,15,3,\n107,,image,40,8,4\n108,2024-04-08,Live,60,20,10\n109,2024-04-09,Video,35,,5\n110,2024-04-10,Text,20,5,2\n111,2024-04-10,podcast,12,2,1\n112,2024-04-11,Text,NaN,,\n", "eda_steps": ["Check and summarize missing values in each column", "Standardize the Post_Type column to lowercase", "Convert Post_Date to a uniform date format and identify invalid or missing dates", "Compute descriptive statistics (mean, median, min, max) for Likes, Comments, and Shares", "Generate value counts for Post_Type", "Identify the number of unique users and their posting frequency", "Examine correlation between Likes, Comments, and Shares", "Find top 3 most engaging post types based on average Likes"], "eda_results": {"missing_values": {"User_ID": 0, "Post_Date": 1, "Post_Type": 0, "Likes": 2, "Comments": 3, "Shares": 2}, "post_type_standardized_counts": {"image": 3, "video": 3, "text": 4, "live": 1, "podcast": 1}, "invalid_dates_count": 1, "likes_stats": {"mean": 31.4, "median": 30, "min": 12, "max": 60}, "comments_stats": {"mean": 7.1, "median": 6, "min": 2, "max": 20}, "shares_stats": {"mean": 3.6, "median": 3, "min": 1, "max": 10}, "unique_users": 12, "average_posts_per_user": 1, "correlations": {"likes_comments": 0.89, "likes_shares": 0.85, "comments_shares": 0.83}, "top_3_engaging_post_types_by_likes": {"live": 60, "image": 45, "video": 30}}}
{"purpose": "Evaluate citizen service request patterns and data quality for a city government department.", "raw_table": "RequestID,RequestType,RequestDate,Status,AssignedDept,Priority\n1001,Trash pickup,2023-01-15,closed,Sanitation,High\n1002,street light repair,1/18/2023,Closed,electrical,medium\n1003,graffiti removal,,OPEN,Public Works,High\n1004,Road repair,2023/02/20,open,Public works,Low\n1005,TRASH PICKUP,02-25-2023,Closed,sanitation,medium\n1006,Water leak report,2023-02-28,closed,Water Dept,High\n1007,Street Light Repair,03/01/2023,OPEN,ELECTRICAL,high\n1008,Graffiti Removal,March 5 2023,Closed,Public Works,Medium\n1009,Road repair,03-10-2023,,Public Works,low\n1010,Trash Pickup,03/12/2023,Closed,Sanitation,high\n1011,Water leak report,2023-3-15,Open,water dept,Medium\n1012,,03-17-2023,Closed,Sanitation,Medium\n1013,graffiti Removal,03/20/23,OPEN,Public Works,Low", "eda_steps": ["Inspect the data types for each column", "Check for missing values and their percentages per column", "Standardize the RequestType and AssignedDept columns for consistent capitalization", "Calculate the frequency counts for each RequestType", "Calculate the frequency counts for each Status category", "Generate descriptive statistics for Priority, considering case inconsistencies", "Parse and standardize the RequestDate column to a uniform date format", "Identify the number of requests per AssignedDept", "Summarize the number of open versus closed requests"], "eda_results": {"data_types": {"RequestID": "integer", "RequestType": "string", "RequestDate": "string", "Status": "string", "AssignedDept": "string", "Priority": "string"}, "missing_values_percent": {"RequestID": 0, "RequestType": 7.7, "RequestDate": 7.7, "Status": 7.7, "AssignedDept": 0, "Priority": 0}, "standardized_RequestType": ["Trash Pickup", "Street Light Repair", "Graffiti Removal", "Road Repair", "Trash Pickup", "Water Leak Report", "Street Light Repair", "Graffiti Removal", "Road Repair", "Trash Pickup", "Water Leak Report", null, "Graffiti Removal"], "standardized_AssignedDept": ["Sanitation", "Electrical", "Public Works", "Public Works", "Sanitation", "Water Dept", "Electrical", "Public Works", "Public Works", "Sanitation", "Water Dept", "Sanitation", "Public Works"], "RequestType_value_counts": {"Trash Pickup": 3, "Street Light Repair": 2, "Graffiti Removal": 3, "Road Repair": 2, "Water Leak Report": 2, "null": 1}, "Status_value_counts": {"Closed": 7, "Open": 5, "": 1}, "Priority_value_counts": {"High": 4, "Medium": 5, "Low": 3}, "RequestDate_parsing_summary": {"earliest_date": "2023-01-15", "latest_date": "2023-03-20", "unparsed_rows": 1}, "AssignedDept_request_counts": {"Sanitation": 4, "Electrical": 2, "Public Works": 5, "Water Dept": 2}, "Open_vs_Closed_requests": {"Open": 5, "Closed": 7, "Missing": 1}}}
{"purpose": "Analyze household electricity consumption patterns and identify missing data issues.", "raw_table": "Household_ID,Date,Energy_Consumption_kWh,Region,Type_of_Home\nH001,2024-01-01,34.5,North,Detached\nH002,01/02/2024,,south,semi-detached\nh003,2024/01/03,28.7,North,Apartment\nH004,2024-1-04,45.2,east,Detached\nH005,2024-01-05,NaN,East,Detached\nH006,2024/01/06,38.0,SOUTH,detached\nH007,7-Jan-2024,41.5,North,Semi-Detached\nH008,2024-01-08,29.9,west,Apartment\nH009,2024-01-09,33.0,West,Apartment\nh010,2024-01-10,invalid,south,detached\nH011,11-01-2024,36.6,East,Detached\nH012,2024/01/12,30.4,North,Apartment", "eda_steps": ["Check for missing and invalid values in all columns", "Standardize date formats to YYYY-MM-DD", "Convert Energy_Consumption_kWh to numeric and handle non-numeric entries", "Compute descriptive statistics of Energy_Consumption_kWh", "Generate value counts for Region and Type_of_Home columns", "Calculate the number of unique households", "Identify any inconsistent capitalization in categorical columns", "Summarize missing value percentages per column"], "eda_results": {"missing_values": {"Household_ID": 0, "Date": 0, "Energy_Consumption_kWh": 2, "Region": 0, "Type_of_Home": 0}, "invalid_entries": {"Energy_Consumption_kWh": ["invalid"]}, "date_format_standardization": {"original_formats_detected": ["YYYY-MM-DD", "DD/MM/YYYY", "YYYY/MM/DD", "D-MMM-YYYY", "DD-MM-YYYY"], "all_dates_standardized_to": "YYYY-MM-DD"}, "energy_consumption_stats": {"count": 13, "mean": 34.27, "std_dev": 5.05, "min": 28.7, "max": 45.2, "median": 34.5}, "value_counts": {"Region": {"North": 4, "South": 3, "East": 3, "West": 2}, "Type_of_Home": {"Detached": 5, "Semi-Detached": 2, "Apartment": 4, "semi-detached": 1, "detached": 1}}, "unique_households": 12, "capitalization_issues": {"Region": ["south", "SOUTH", "west", "West", "east", "East"], "Type_of_Home": ["semi-detached", "Semi-Detached", "detached", "Detached"]}, "missing_value_percentages": {"Energy_Consumption_kWh": "15.38%"}}}
{"purpose": "Analyze customer purchase patterns and product category popularity in an ecommerce store.", "raw_table": "order_id,customer_id,product_category,purchase_date,quantity,price_per_unit,payment_method\n1001,C001,Electronics,2024-03-15,1,299.99,Credit Card\n1002,C002,Fashion,15/03/2024,2,49.99,Paypal\n1003,C001,Home Decor,2024/03/16,1,,credit card\n1004,,electronics,03-17-2024,3,199.99,Credit Card\n1005,C003,Toys,2024-03-18,2,15.00,CASH\n1006,C004,Fashion,March 19 2024,1,59.99,Paypal\n1007,C005,Sports,2024-03-20,1,89.5,credit card\n1008,C006,Electronics,2024-03-21,,399.99,Credit Card\n1009,C007,health & beauty,2024-03-22,1,23.99,Cash\n1010,C002,Fashion,2024-03-23,2,49.99,PayPal\n1011,C008,Toys,03/24/2024,1,15,CREDIT CARD\n1012,C009,Fashion,2024-3-25,1,-,Paypal\n1013,C010,Home decor,2024-03-26,1,120.00,Credit Card\n1014,C011,Electronics,2024.03.27,1,299.99,credit card", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize the 'product_category' column capitalization", "Parse 'purchase_date' into a standard date format", "Compute descriptive statistics for 'quantity' and 'price_per_unit'", "Generate value counts for 'payment_method' and 'product_category'", "Identify orders with missing or zero prices and quantities", "Calculate total purchase amount per order as quantity * price_per_unit", "Summarize top 3 most popular product categories by total quantity sold", "Analyze payment method distribution across orders"], "eda_results": {"missing_values": {"order_id": 0, "customer_id": 1, "product_category": 0, "purchase_date": 0, "quantity": 2, "price_per_unit": 3, "payment_method": 0}, "standardized_product_categories": {"electronics": 4, "fashion": 4, "home decor": 2, "toys": 2, "sports": 1, "health & beauty": 1}, "payment_method_counts": {"credit card": 7, "paypal": 4, "cash": 2}, "quantity_stats": {"count": 13, "mean": 1.38, "min": 1, "max": 3, "missing": 2}, "price_per_unit_stats": {"count": 11, "mean": 139.54, "min": 15.0, "max": 399.99, "missing_or_invalid": 3}, "orders_with_missing_or_zero_values": {"missing_quantity": [1008, 1012], "missing_price": [1003, 1012], "zero_or_invalid_price": [1012]}, "total_purchase_amount_per_order": {"1001": 299.99, "1002": 99.98, "1003": null, "1004": 599.97, "1005": 30.0, "1006": 59.99, "1007": 89.5, "1008": null, "1009": 23.99, "1010": 99.98, "1011": 15.0, "1012": null, "1013": 120.0, "1014": 299.99}, "top_3_product_categories_by_quantity": {"electronics": 6, "fashion": 7, "home decor": 2}, "payment_method_distribution": {"credit card": 50.0, "paypal": 28.57, "cash": 14.29, "missing": 7.14}}}
{"purpose": "Analyze ride-sharing trip data to understand trip duration, distance, and user type distribution.", "raw_table": "trip_id,user_type,start_time,end_time,distance_km,price_usd\nT001,regular,2023-03-15 08:15,2023-03-15 08:40,12.5,18.75\nT002,Premium,3/16/2023 09:05 AM,2023-03-16 09:45,15,25\nT003,regular,2023-03-16 11:00,11:30,9,,\nT004,VIP,2023-03-17 19:20,2023-03-17 19:50,NA,30.5\nT005,regular,,2023-03-18 07:45,7.8,12.4\nT006,premium,2023-03-18 14:10,2023-03-18 14:40,13,22\nT007,Regular,2023-03-19 16:00,2023-03-19 16:25,11.2,17.75\nT008,,2023-03-19 21:30,2023-03-19 21:55,8.7,13.5\nT009,VIP,3/20/2023 10:05 AM,3/20/2023 10:40 AM,14.3,28\nT010,premium,03-21-2023 18:45,03-21-2023 19:20,16,26\n", "eda_steps": ["Check and summarize missing values for each column", "Standardize capitalization for the user_type column", "Parse and standardize date-time columns start_time and end_time", "Compute trip duration in minutes from start_time and end_time", "Generate descriptive statistics for numeric columns: distance_km, price_usd, trip duration", "Count unique user_type categories and their frequencies", "Identify trips with missing or invalid distance or price values", "Analyze correlation between trip distance, duration, and price"], "eda_results": {"missing_values": {"trip_id": 0, "user_type": 1, "start_time": 1, "end_time": 0, "distance_km": 1, "price_usd": 2}, "user_type_value_counts": {"regular": 4, "premium": 3, "vip": 2, "missing": 1}, "trip_duration_minutes": {"mean": 32.5, "min": 25, "max": 40, "missing": 1}, "distance_km_stats": {"mean": 11.57, "min": 7.8, "max": 16, "missing": 1}, "price_usd_stats": {"mean": 20.73, "min": 12.4, "max": 30.5, "missing": 2}, "invalid_or_missing_distance_or_price_trips": ["T003", "T004"], "correlations": {"distance_km_vs_price_usd": 0.97, "distance_km_vs_trip_duration": 0.95, "price_usd_vs_trip_duration": 0.96}}}
{"purpose": "Analyze property listings to understand price distribution and identify common property features in the dataset.", "raw_table": "ListingID,Price,Location,PropertyType,Bedrooms,Bathrooms,Area_sqft,DateListed\n001,350000,Downtown,Apartment,2,1,850,2023/01/15\n002,450000,suburb,Villa,4,3,2500,15-02-2023\n003,,Downtown,apartment,1,,700,2023-03-01\n004,520000,Suburb,Condo,3,2,1300,2023/02/28\n005,275000,Midtown,Apartment,2,1,900,March 5, 2023\n006,430000,Downtown,villa,4,3,2400,2023/03/10\n007,N/A,midtown,Condo,3,2,1250,2023-02-20\n008,390000,Suburb,Apartment,,1,800,2023/01/30\n009,305000,Downtown,Apartment,2,1,850,2023/03/11\n010,500000,Suburb,House,3,2,1500,2023.02.15\n011,NaN,Midtown,Apartment,2,1,850,2023/02/25", "eda_steps": ["Check for missing values in all columns", "Standardize the 'Location' and 'PropertyType' columns to consistent capitalization", "Convert 'Price' column to numeric and handle missing or non-numeric entries", "Parse and standardize 'DateListed' formats to ISO date format", "Compute descriptive statistics for numeric columns: Price, Bedrooms, Bathrooms, Area_sqft", "Generate value counts for 'Location' and 'PropertyType' columns", "Identify the correlation matrix between numeric columns", "Find top 3 most common property types", "Summarize the distribution skewness of the Price column"], "eda_results": {"missing_values": {"ListingID": 0, "Price": 3, "Location": 0, "PropertyType": 0, "Bedrooms": 2, "Bathrooms": 1, "Area_sqft": 0, "DateListed": 0}, "standardized_categories": {"Location": {"Downtown": 4, "Suburb": 4, "Midtown": 3}, "PropertyType": {"Apartment": 6, "Villa": 2, "Condo": 2, "House": 1}}, "price_numeric_stats": {"count": 8, "mean": 401250, "median": 390000, "min": 275000, "max": 520000, "std_dev": 84041.2}, "descriptive_stats": {"Bedrooms": {"count": 9, "mean": 2.44, "min": 1, "max": 4}, "Bathrooms": {"count": 9, "mean": 1.67, "min": 1, "max": 3}, "Area_sqft": {"count": 11, "mean": 1250.0, "min": 700, "max": 2500}}, "correlations": {"Price-Bedrooms": 0.91, "Price-Bathrooms": 0.89, "Price-Area_sqft": 0.95}, "top_categories": {"PropertyType": [{"Apartment": 6}, {"Villa": 2}, {"Condo": 2}], "Location": [{"Downtown": 4}, {"Suburb": 4}, {"Midtown": 3}]}, "price_skewness": 0.15}}
{"purpose": "Analyze household electricity consumption patterns and identify data quality issues.", "raw_table": "Date,Household_ID,Consumption_kWh,Region,Energy_Source\n2023-01-01,HH001,15.2,North,electric\n01/02/2023,hh002,20.5,South,solar\n2023-01-03,HH003,,East,Electric\n2023-1-4,HH004,18.0,west,wind\n2023/01/05,HH005,25.4,North,ELECTRIC\n2023-01-06,hh006,not recorded,South,solar\n2023-01-07,HH007,30.1,East,Wind\n07-Jan-2023,HH008,22.0,West,Electric\n2023-01-09,HH009,19.8,North,solar\n2023-01-10,HH010,21.5,South,electric\n2023-01-11,HH011,17.3,East,wind\n2023-01-12,HH012,23.7,West,SOLAR\n", "eda_steps": ["Check the data types of each column and correct inconsistencies", "Identify and count missing or invalid values in Consumption_kWh", "Standardize the Region and Energy_Source categorical variables", "Calculate basic descriptive statistics for Consumption_kWh", "Generate value counts for Energy_Source and Region columns", "Visualize consumption trends over dates (identify date format inconsistencies)", "Compute correlation between Consumption_kWh and Region if encoded", "Identify top 3 households with highest average consumption"], "eda_results": {"missing_values": {"Consumption_kWh": 1, "Date": 0, "Household_ID": 0, "Region": 0, "Energy_Source": 0}, "value_counts": {"Energy_Source": {"electric": 4, "solar": 4, "wind": 3}, "Region": {"North": 3, "South": 3, "East": 3, "West": 3}}, "summary_stats": {"Consumption_kWh": {"count": 11, "mean": 21.59, "std": 4.61, "min": 15.2, "25%": 18.0, "50%": 21.5, "75%": 23.7, "max": 30.1}}, "data_type_corrections": {"Consumption_kWh": "Converted 'not recorded' to missing value (NaN)", "Region": "Standardized capitalization to Title Case", "Energy_Source": "Standardized to lowercase categories"}, "top_households_by_avg_consumption": {"HH007": 30.1, "HH005": 25.4, "HH012": 23.7}, "date_format_issues": {"formats_found": ["YYYY-MM-DD", "DD/MM/YYYY", "YYYY/M/D", "DD-MMM-YYYY", "YYYY/MM/DD"], "dates_normalized": 12}}}
{"purpose": "Analyze viewership patterns and ratings for recent TV show episodes to identify trends and data quality issues.", "raw_table": "Show_Title,Season,Episode,Air_Date,Genre,Viewers_Millions,Rating\nThe Great Escape,1,1,2023-01-15,Drama,5.2,8.5\nMystery Manor,2,3,2023/02/10,mystery,4.8,7.9\nLaugh Riot,1,2,15-03-2023,Comedy,missing,8.1\nThe Great Escape,1,2,2023-01-22,Drama,5.5,8.7\nMystery Manor,2,4,,Mystery,4.9,seven\nLaugh Riot,1,3,2023-03-22,comedy,4.1,8.0\nspace Quest,1,1,2023-04-01,SciFi,3.8,7.5\nLaugh Riot,1,,2023-03-29,Comedy,4.3,8.2\nSpace Quest,1,2,2023-04-08,sciFi,3.9,7.6\nThe great escape,1,3,2023-01-29,Drama,5.6,8.8\nMystery manor,2,5,2023-02-17,Mystery,5.0,7.8\nLaugh Riot,1,4,2023-04-05,Comedy,4.0,8.1", "eda_steps": ["Check the percentage of missing values per column", "Standardize the 'Genre' and 'Show_Title' columns capitalization", "Convert the 'Air_Date' column to a consistent date format", "Identify and summarize unique counts for categorical columns 'Show_Title' and 'Genre'", "Compute descriptive statistics for numeric columns 'Viewers_Millions' and 'Rating'", "Identify rows with non-numeric or invalid 'Rating' values and handle them", "Calculate average viewers per season for each show", "Generate value counts of episodes per season", "Visualize distribution skewness of 'Viewers_Millions'"], "eda_results": {"missing_values": {"Show_Title": "0%", "Season": "0%", "Episode": "8.3%", "Air_Date": "8.3%", "Genre": "0%", "Viewers_Millions": "8.3%", "Rating": "8.3%"}, "standardized_categories": {"Show_Title": ["The Great Escape", "Mystery Manor", "Laugh Riot", "Space Quest"], "Genre": ["Drama", "Mystery", "Comedy", "SciFi"]}, "air_date_format": "All dates converted to YYYY-MM-DD with missing date handled as NaT", "unique_counts": {"Show_Title": 4, "Genre": 4}, "summary_stats": {"Viewers_Millions": {"count": 12, "mean": 4.65, "std": 0.68, "min": 3.8, "25%": 4.1, "50%": 4.45, "75%": 5.1, "max": 5.6}, "Rating": {"count": 11, "mean": 8.01, "std": 0.52, "min": 7.5, "25%": 7.8, "50%": 8.05, "75%": 8.45, "max": 8.8}}, "invalid_ratings": {"rows_with_invalid": [5], "action_taken": "Excluded row 5 rating 'seven' from numeric analysis"}, "average_viewers_per_season": {"The Great Escape Season 1": 5.43, "Mystery Manor Season 2": 4.9, "Laugh Riot Season 1": 4.13, "Space Quest Season 1": 3.85}, "episodes_per_season": {"The Great Escape Season 1": 3, "Mystery Manor Season 2": 3, "Laugh Riot Season 1": 4, "Space Quest Season 1": 2}, "viewers_skewness": 0.21}}
{"purpose": "Analyze sales performance and customer buying patterns in retail transactions.", "raw_table": "TransactionID,CustomerID,ProductCategory,Quantity,PricePerUnit,TransactionDate,StoreLocation\nT001,C101,Electronics,2,199.99,2023/01/15,New york\nT002,C102,clothing,1,,15-01-2023,los angeles\nT003,C103,Home & Kitchen,4,25.5,2023-01-16,Chicago\nT004,C104,Electronics,,299.99,01/17/2023,New York\nT005,C101,clothing,3,45.0,2023/01/18,Houston\nT006,C105,Toys,5,15.0,18-01-2023,los angeles\nT007,C106,home & kitchen,2,30,2023.01.19,CHICAGO\nT008,C107,Electronics,1,199.99,2023-01-19,New york\nT009,C108,Clothing,2,40,01/20/2023,Houston\nT010,C109,Toys,,15.0,2023/01/21,Los Angeles\nT011,C110,Electronics,1,199.99,2023/01/22,new york\nT012,C111,Clothing,2,invalid_price,2023/01/22,houston", "eda_steps": ["Standardize capitalization in the ProductCategory and StoreLocation columns", "Check for missing values in each column and calculate the percentage missing", "Convert TransactionDate to a consistent date format", "Convert PricePerUnit and Quantity to numeric types, handling invalid or missing values", "Calculate total sales per transaction as Quantity multiplied by PricePerUnit", "Generate descriptive statistics for Quantity, PricePerUnit, and total sales", "Count the number of transactions per ProductCategory", "Identify the top 2 StoreLocation by total sales", "Check for any duplicate TransactionID values"], "eda_results": {"missing_values": {"TransactionID": "0%", "CustomerID": "0%", "ProductCategory": "0%", "Quantity": "16.7%", "PricePerUnit": "16.7%", "TransactionDate": "0%", "StoreLocation": "0%"}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home & Kitchen", "Toys"], "StoreLocation": ["New York", "Los Angeles", "Chicago", "Houston"]}, "transaction_date_range": {"earliest": "2023-01-15", "latest": "2023-01-22"}, "numeric_conversion_issues": {"PricePerUnit": ["invalid_price"], "Quantity": ["missing"]}, "descriptive_statistics": {"Quantity": {"count": 12, "mean": 2.17, "std": 1.32, "min": 1, "max": 5}, "PricePerUnit": {"count": 12, "mean": 98.81, "std": 107.64, "min": 15, "max": 299.99}, "TotalSales": {"count": 10, "mean": 188.49, "std": 184.36, "min": 30, "max": 599.98}}, "transaction_counts_per_category": {"Electronics": 4, "Clothing": 4, "Home & Kitchen": 2, "Toys": 2}, "top_store_locations_by_sales": {"New York": 1199.94, "Los Angeles": 120.0}, "duplicate_transaction_ids": 0}}
{"purpose": "Analyze customer purchase behavior and product categories in an ecommerce dataset", "raw_table": "order_id,customer_id,order_date,product_category,quantity,unit_price,total_spent\n1001,C001,2023-01-15,Electronics,2,299.99,599.98\n1002,C002,01/17/2023,fashion,1,49.99,49.99\n1003,C003,2023/01/20,Home & Kitchen,3,15.00,45.00\n1004,C004,2023-1-22,electronics, ,199.99,\n1005,C005,2023-01-25,Toys,5,9.99,49.95\n1006,C006,25-01-2023,Fashion,2,39.99,79.98\n1007,C007,2023-01-27,home & kitchen,1,20.00,20.00\n1008,C008,2023/01/28,Books,,12.50,12.50\n1009,C009,2023-01-30,Electronics,1,,299.99\n1010,C010,2023-01-31,Toys,2,9.99,19.98\n1011,C011,2023-02-01,Sports,,29.99,59.98\n1012,C012,2023-02-03,Books,4,12.50,50.00\n1013,C013,2023-02-05,Unknown,1,0,0\n1014,C014,,Fashion,3,45.00,135.00", "eda_steps": ["Check for missing values in all columns", "Standardize product_category values to consistent capitalization", "Convert order_date to datetime format and identify invalid/missing dates", "Compute descriptive statistics for numeric columns: quantity, unit_price, total_spent", "Generate value counts for product_category", "Identify top 3 product categories by total_spent sum", "Calculate correlation matrix between quantity, unit_price, and total_spent", "Check for orders where total_spent does not equal quantity multiplied by unit_price"], "eda_results": {"missing_values": {"order_id": 0, "customer_id": 0, "order_date": 1, "product_category": 0, "quantity": 3, "unit_price": 2, "total_spent": 1}, "standardized_product_categories": ["Electronics", "Fashion", "Home & Kitchen", "Electronics", "Toys", "Fashion", "Home & Kitchen", "Books", "Electronics", "Toys", "Sports", "Books", "Unknown", "Fashion"], "order_date_issues": {"invalid_or_missing": 1, "formats_detected": ["YYYY-MM-DD", "MM/DD/YYYY", "YYYY/MM/DD", "DD-MM-YYYY", "missing"]}, "summary_stats": {"quantity": {"count": 11, "mean": 2.09, "std": 1.39, "min": 1, "25%": 1, "50%": 2, "75%": 3, "max": 5}, "unit_price": {"count": 12, "mean": 74.54, "std": 101.37, "min": 0, "25%": 12.5, "50%": 29.99, "75%": 49.99, "max": 299.99}, "total_spent": {"count": 13, "mean": 99.49, "std": 121.43, "min": 0, "25%": 20.0, "50%": 49.99, "75%": 79.98, "max": 599.98}}, "value_counts_product_category": {"Electronics": 3, "Fashion": 3, "Home & Kitchen": 2, "Toys": 2, "Books": 2, "Sports": 1, "Unknown": 1}, "top_3_categories_by_total_spent": {"Electronics": 1199.95, "Fashion": 264.97, "Books": 62.5}, "correlations": {"quantity_vs_unit_price": -0.22, "quantity_vs_total_spent": 0.98, "unit_price_vs_total_spent": 0.73}, "total_spent_mismatches": [1004, 1009, 1011, 1013]}}
{"purpose": "Explore key property features and pricing trends in a real estate dataset to identify data quality issues and patterns.", "raw_table": "Property_ID,Location,Price,Size_sqft,Bedrooms,Bathrooms,Year_Built,Sale_Date\nP1001,downtown,350000,850,2,1,1998,2023/03/15\nP1002,Suburb,450000,1200,3,,2005,15-04-2023\nP1003,Uptown,390000,950,2,2,2010,2023-05-01\nP1004,suburb,470000,1300,4,3,Not Available,2023/04/20\nP1005,Downtown,NaN,900,2,1,2000,04/25/2023\nP1006,Riverside,520000,1500,4,3,2015,2023-06-01\nP1007,uptown,Invalid,1100,3,2,2012,2023/05/15\nP1008,DOWNTOWN,870,2,1,1995,2023-03-30\nP1009,Suburb,460000,1250,3,2,2008,2023/04/10\nP1010,Riverside,530000,1550,4,3,2018,2023-06-05\nP1011,Midtown,480000,1050,3,2,2011,2023/05/20\nP1012,Midtown,475000,NaN,3,2,2013,2023/05/25", "eda_steps": ["Check for missing values in each column", "Standardize the 'Location' column capitalization", "Convert 'Price' and 'Size_sqft' to numeric, handling invalid entries", "Summarize descriptive statistics for 'Price' and 'Size_sqft'", "Generate value counts for 'Bedrooms' and 'Bathrooms'", "Investigate the distribution of 'Year_Built' and identify invalid entries", "Parse and standardize 'Sale_Date' to a consistent date format", "Calculate correlation matrix between numeric features", "Identify top 3 most common locations"], "eda_results": {"missing_values": {"Price": 2, "Bathrooms": 1, "Year_Built": 1, "Size_sqft": 1}, "location_value_counts": {"downtown": 3, "suburb": 3, "uptown": 2, "riverside": 2, "midtown": 2}, "price_summary_stats": {"count": 11, "mean": 458181.82, "std": 55352.54, "min": 350000, "25%": 390000, "50%": 470000, "75%": 485000, "max": 530000}, "size_sqft_summary_stats": {"count": 11, "mean": 1175.45, "std": 238.15, "min": 850, "25%": 950, "50%": 1200, "75%": 1300, "max": 1550}, "bedrooms_value_counts": {"2": 4, "3": 5, "4": 4}, "bathrooms_value_counts": {"1": 4, "2": 4, "3": 3, "missing": 1}, "year_built_issues": {"invalid_entries": ["Not Available"], "min_year": 1995, "max_year": 2018, "mean_year": 2008.64}, "sale_date_format_standardized": true, "correlations": {"Price_Size_sqft": 0.92, "Price_Bedrooms": 0.81, "Price_Bathrooms": 0.75, "Size_sqft_Bedrooms": 0.85}, "top_3_locations": ["downtown", "suburb", "midtown"]}}
{"purpose": "Analyze student performance and attendance patterns in a middle school class.", "raw_table": "StudentID,Name,Grade,Math_Score,English_Score,Attendance,EnrollmentDate\n101,john doe,7,85,78,95%,2021/09/01\n102,Jane Smith,7,92,,88%,09-01-2021\n103,ALex Johnson,8,75,84,NaN,2021-09-01\n104,Emily Davis,7,NaN,90,93%,2021/9/1\n105,Mike Brown,8,88,79,89%,9/1/2021\n106,Lisa white,7,82,85,90%,2021/09/01\n107,Tom Clark,8,78,NaN,85%,2021-09-01\n108,,7,90,87,NaN,2021/09/01\n109,Karen Miller,8,83,91,92%,Sept 1 2021\n110,Bob Lee,7,NaN,80,87%,2021/09/01\n111,Susan king,8,77,85,not available,2021/09/01", "eda_steps": ["Check for missing values in each column", "Standardize the EnrollmentDate format to YYYY-MM-DD", "Calculate descriptive statistics for Math_Score and English_Score", "Generate value counts for Grade and Attendance", "Identify students with missing names or scores", "Calculate average scores by Grade", "Analyze attendance percentage distribution", "Check correlation between Math_Score and English_Score"], "eda_results": {"missing_values": {"StudentID": 0, "Name": 1, "Grade": 0, "Math_Score": 3, "English_Score": 3, "Attendance": 3, "EnrollmentDate": 0}, "standardized_EnrollmentDate_format": "All dates converted to 2021-09-01", "summary_stats": {"Math_Score": {"count": 8, "mean": 82.5, "std": 6.07, "min": 75, "max": 92}, "English_Score": {"count": 8, "mean": 84.87, "std": 4.6, "min": 78, "max": 91}}, "value_counts": {"Grade": {"7": 6, "8": 5}, "Attendance": {"95%": 1, "88%": 1, "93%": 1, "89%": 1, "90%": 1, "85%": 1, "92%": 1, "87%": 2, "not available": 1, "NaN": 1}}, "missing_names_or_scores": {"missing_name": [108], "missing_Math_Score": [104, 110, 111], "missing_English_Score": [102, 107, 111]}, "average_scores_by_grade": {"7": {"Math_Score": 87.25, "English_Score": 83.75}, "8": {"Math_Score": 80.2, "English_Score": 85.67}}, "attendance_distribution": {"mean_attendance_percent": 89.9, "median_attendance_percent": 89, "attendance_below_90_percent": 4}, "correlations": {"Math_English": 0.58}}}
{"purpose": "Analyze trip characteristics and identify data quality issues in a city bike-sharing dataset.", "raw_table": "TripID,StartDate,EndDate,StartStation,EndStation,UserType,TripDuration,DistanceKM\nT001,2023-04-01 08:15,2023-04-01 08:45,central park,Central Park,Subscriber,30,5.2\nT002,4/2/2023 09:00 AM,4/2/2023 09:30 AM,Downtown,uptown,Customer,30,NaN\nT003,2023-04-03 18:00,2023-04-03 18:50,Central Park,Downtown,SUBSCRIBER,50,8.1\nT004,2023/04/04 07:30,,downtown,Central park,Subscriber,45,6.0\nT005,2023-04-05 12:00,2023-04-05 12:40,Midtown,,Customer,40,7.3\nT006,2023-04-06 14:15,2023-04-06 14:50,MIDTOWN,Midtown,customer,35,5.5\nT007,2023-04-07 20:00,2023-04-07 20:45,uptown,Uptown,,45,7.0\nT008,2023-04-08 09:30,2023-04-08 10:00,Central park,Downtown,Subscriber,30,5.6\nT009,2023-04-09 13:00,2023-04-09 13:30,Downtown,midtown,Subscriber,30,6.1\nT010,04/10/2023 15:00,04/10/2023 15:50,Central Park,Midtown,Customer,50,8.0", "eda_steps": ["Check and report missing values per column", "Standardize date formats in StartDate and EndDate columns", "Count unique values and value counts for StartStation, EndStation, and UserType", "Compute descriptive statistics for TripDuration and DistanceKM columns", "Identify inconsistent capitalization issues in categorical columns", "Calculate trip duration distribution and identify any anomalies", "Check correlation between TripDuration and DistanceKM", "Summarize number of trips by UserType"], "eda_results": {"missing_values": {"TripID": 0, "StartDate": 0, "EndDate": 1, "StartStation": 0, "EndStation": 2, "UserType": 1, "TripDuration": 0, "DistanceKM": 1}, "date_format_standardized": true, "value_counts": {"StartStation": {"central park": 3, "downtown": 3, "midtown": 2, "uptown": 2}, "EndStation": {"Central Park": 2, "Downtown": 3, "Midtown": 3, "uptown": 1, "": 2}, "UserType": {"Subscriber": 5, "Customer": 4, "": 1}}, "capitalization_issues": {"StartStation": ["central park", "Central Park", "MIDTOWN", "Midtown", "uptown", "Uptown", "downtown", "Downtown"], "EndStation": ["Central park", "Central Park", "Midtown", "midtown", "uptown", "Uptown", ""], "UserType": ["Subscriber", "SUBSCRIBER", "Customer", "customer", ""]}, "descriptive_stats": {"TripDuration": {"count": 10, "mean": 39.5, "std": 8.1, "min": 30, "25%": 30, "50%": 37.5, "75%": 45, "max": 50}, "DistanceKM": {"count": 9, "mean": 6.62, "std": 1.18, "min": 5.2, "25%": 5.5, "50%": 6.1, "75%": 7.3, "max": 8.1}}, "trip_duration_distribution": {"median": 37.5, "mode": 30, "outliers": []}, "correlations": {"TripDuration_DistanceKM": 0.95}, "trips_by_usertype": {"Subscriber": 5, "Customer": 4, "Unknown": 1}}}
{"purpose": "Analyze crop yield and fertilizer usage patterns across different farms to identify inconsistencies and data quality issues.", "raw_table": "FarmID,Crop,Planting_Date,Harvest_Date,Yield_kg,Fertilizer_Type,Fertilizer_Amount_kg\nF001,Wheat,2023-03-15,2023-08-20,1500,urea,50\nf002,Maize,15/03/2023,20-08-2023,NaN,PhosphatE,45\nF003,Rice,2023/03/17,2023-08-22,1700,Urea,55\nF004,maize,03-16-2023,2023/08/19,1600,,48\nF005,Wheat,2023-03-15,2023-08-21,missing,NPK,50\nF006,Corn,03/18/2023,08/23/2023,1550,phosphate,47\nF007,RICE,2023.03.19,2023.08.20,1650,Urea,NaN\nF008,maize,2023-03-20,2023-08-25,1580,Phosphate,49\nF009,Wheat,March 15 2023,August 20 2023,1520,NPK,51\nF010,Rice,2023-03-17,2023-08-22,1680,urea,53", "eda_steps": ["Check and report missing values for all columns", "Standardize Crop names to consistent capitalization", "Parse and standardize Planting_Date and Harvest_Date to ISO format", "Calculate descriptive statistics for Yield_kg and Fertilizer_Amount_kg", "Generate value counts for Fertilizer_Type", "Identify rows with 'missing' or non-numeric Yield_kg and convert them to NaN", "Compute the correlation between Yield_kg and Fertilizer_Amount_kg", "List unique Crop types after cleaning", "Calculate the average Yield_kg per Crop type"], "eda_results": {"missing_values": {"Yield_kg": 2, "Fertilizer_Type": 1, "Fertilizer_Amount_kg": 1}, "standardized_crops": ["Wheat", "Maize", "Rice", "Corn"], "date_parsing_issues": 0, "summary_stats": {"Yield_kg": {"count": 8, "mean": 1598.75, "std": 70.7, "min": 1500, "max": 1700}, "Fertilizer_Amount_kg": {"count": 9, "mean": 49.33, "std": 2.59, "min": 45, "max": 55}}, "fertilizer_type_counts": {"Urea": 4, "Phosphate": 3, "NPK": 2, "": 1}, "correlations": {"Yield_kg_vs_Fertilizer_Amount_kg": 0.82}, "unique_crops_after_cleaning": ["Wheat", "Maize", "Rice", "Corn"], "average_yield_per_crop": {"Wheat": 1513.33, "Maize": 1593.33, "Rice": 1676.67, "Corn": 1550}}}
{"purpose": "Analyze student performance and attendance patterns in a high school semester.", "raw_table": "StudentID,Name,Grade,Subject,Score,Attendance,TestDate\n101,john doe,10,Math,88,Present,2023-03-15\n102,Jane Smith,10,math,92,,15/03/2023\n103,ALICE Johnson,11,Science,85,Present,2023/03/16\n104,Bob Brown,10,English,,Absent,03-17-2023\n105,carol lee,11,science,78,Present,March 18 2023\n106,David Wilson,10,English,90,Present,2023-03-18\n107,Eva Green,11,Math,NaN,Absent,2023-03-19\n108,Fiona White,10,Math,85,Present,2023-03-20\n109,George Black,11,science,88,Present,2023/03/21\n110,Helen Young,10,english,95,,2023-03-20", "eda_steps": ["Inspect the dataset for inconsistent capitalization in categorical columns", "Check for missing values in Score and Attendance columns", "Standardize date formats in TestDate column", "Compute descriptive statistics for Score by Subject", "Calculate attendance rate per Grade", "Generate value counts for Subject and Attendance columns", "Identify top scoring students per Subject", "Analyze correlation between Score and Attendance", "Summarize the distribution skewness for Score"], "eda_results": {"capitalization_issues": {"Subject": ["Math", "math", "Science", "science", "English", "english"], "Attendance": ["Present", "Absent", ""], "Name": ["john doe", "Jane Smith", "ALICE Johnson", "Bob Brown", "carol lee", "David Wilson", "Eva Green", "Fiona White", "George Black", "Helen Young"]}, "missing_values": {"Score": 2, "Attendance": 2}, "standardized_dates": ["2023-03-15", "2023-03-15", "2023-03-16", "2023-03-17", "2023-03-18", "2023-03-18", "2023-03-19", "2023-03-20", "2023-03-21", "2023-03-20"], "summary_stats_per_subject": {"Math": {"count": 4, "mean": 88.33, "std": 3.51, "min": 85, "max": 92}, "Science": {"count": 3, "mean": 83.67, "std": 5.51, "min": 78, "max": 88}, "English": {"count": 3, "mean": 92.5, "std": 3.54, "min": 90, "max": 95}}, "attendance_rate_per_grade": {"10": 0.83, "11": 1.0}, "value_counts": {"Subject": {"Math": 4, "Science": 3, "English": 3}, "Attendance": {"Present": 8, "Absent": 2, "Missing": 2}}, "top_scorers_per_subject": {"Math": {"StudentID": 102, "Name": "Jane Smith", "Score": 92}, "Science": {"StudentID": 109, "Name": "George Black", "Score": 88}, "English": {"StudentID": 110, "Name": "Helen Young", "Score": 95}}, "correlation_score_attendance": 0.72, "score_skewness": -0.45}}
{"purpose": "Evaluate production line efficiency and identify issues affecting output quality and timing.", "raw_table": "BatchID,ProductionDate,Shift,Operator,UnitsProduced,Defects,MachineStatus\nB001,2024-01-15,morning,John Doe,120,5,Running\nB002,15/01/2024,Evening,jane SMITH,110,3,Running\nb003,2024/01/16,Night,alex,105,,Stopped\nB004,,Morning,John Doe,115,7,Running\nB005,2024-01-17,evening,Jane Smith,NaN,2,Running\nB006,17-01-2024,Night,alex,98,4,Stopped\nB007,2024-01-18,Morning,John doe,130,6,Running\nB008,18/01/2024,Evening,jane smith,NaN,NaN,Running\nB009,2024-01-19,Night,Alex,125,3,Running\nB010,2024/01/19,MORNING,John Doe,140,5,Running", "eda_steps": ["Check and standardize date formats in ProductionDate", "Calculate missing value percentages per column", "Normalize Operator names to consistent capitalization", "Compute descriptive statistics for UnitsProduced and Defects", "Generate value counts for Shift and MachineStatus", "Identify batches with missing or zero UnitsProduced", "Compute correlation between UnitsProduced and Defects", "Summarize average UnitsProduced and Defects per Shift", "Check consistency of MachineStatus with UnitsProduced"], "eda_results": {"missing_values": {"BatchID": 0, "ProductionDate": 1, "Shift": 0, "Operator": 0, "UnitsProduced": 2, "Defects": 2, "MachineStatus": 0}, "value_counts": {"Shift": {"Morning": 4, "Evening": 3, "Night": 3}, "MachineStatus": {"Running": 7, "Stopped": 2}}, "normalized_operators": ["John Doe", "Jane Smith", "Alex"], "summary_stats": {"UnitsProduced": {"count": 8, "mean": 119.125, "std": 13.44, "min": 98, "max": 140}, "Defects": {"count": 8, "mean": 4.38, "std": 1.57, "min": 2, "max": 7}}, "correlation_UnitsProduced_Defects": -0.32, "batches_missing_units": ["B005", "B008"], "average_per_shift": {"Morning": {"UnitsProduced": 126.25, "Defects": 5.75}, "Evening": {"UnitsProduced": 110, "Defects": 2.5}, "Night": {"UnitsProduced": 109.33, "Defects": 3.67}}, "machine_status_vs_units": {"Running_mean_units": 122.14, "Stopped_mean_units": 101.5}}}
{"purpose": "Analyze city budget allocation and spending patterns across departments for fiscal year 2023.", "raw_table": "Department,Budget_Allocated,Budget_Spent,Report_Date,Manager,Region\nPublic Safety,500000,480000,2023-03-15,John Doe,North\nEducation,750000,745000,15/04/2023,Jane smith,east\nHealth,600000,,2023-05-01,Mary Johnson,West\nTransportation,450000,460000,2023/06/20,robert brown,South\nParks & Recreation,200000,195000,2023-07-10,Susan Davis,NORTH\nHousing,,180000,07-25-2023,Chris Green,East\npublic safety,520000,510000,2023-08-05,John doe,north\nEducation,730000,700000,2023-09-10,Jane Smith,EAST\nHealth,610000,605000,2023-10-01,Mary johnson,west\nTransportation,460000,455000,10/15/2023,Robert Brown,south\nParks & recreation,210000,205000,2023-11-11,Susan davis,North\nHousing,190000,185000,2023-12-05,Chris green,East\nCulture & Arts,150000,140000,2023-12-10,Anna Lee,Central\nCulture & arts,155000,150000,12-15-2023,Anna lee,central", "eda_steps": ["Check for missing values in all columns", "Standardize and unify capitalization in Department and Region columns", "Convert Report_Date to a consistent date format", "Calculate summary statistics for Budget_Allocated and Budget_Spent columns", "Compute the difference between Budget_Allocated and Budget_Spent", "Identify duplicate or inconsistent entries by Department and Manager", "Generate value counts for Region and Department", "Examine correlation between Budget_Allocated and Budget_Spent", "Find top departments by total budget allocated"], "eda_results": {"missing_values": {"Budget_Allocated": 1, "Budget_Spent": 1, "Report_Date": 0, "Manager": 0, "Region": 0}, "standardized_columns": {"Department": ["Public Safety", "Education", "Health", "Transportation", "Parks & Recreation", "Housing", "Culture & Arts"], "Region": ["North", "East", "West", "South", "Central"]}, "date_parsing_issues": 0, "summary_stats": {"Budget_Allocated": {"count": 14, "mean": 474285.71, "min": 150000, "max": 750000}, "Budget_Spent": {"count": 13, "mean": 461153.85, "min": 140000, "max": 745000}, "Budget_Difference": {"mean": 13131.58, "min": -10000, "max": 10000}}, "duplicate_entries": {"Departments_with_multiple_managers": 0, "Exact_Duplicate_Rows": 0}, "value_counts": {"Region": {"North": 4, "East": 4, "West": 2, "South": 2, "Central": 2}, "Department": {"Public Safety": 2, "Education": 2, "Health": 2, "Transportation": 2, "Parks & Recreation": 2, "Housing": 2, "Culture & Arts": 2}}, "correlations": {"Budget_Allocated_vs_Budget_Spent": 0.99}, "top_departments_by_budget": ["Education", "Health", "Public Safety"]}}
{"purpose": "Analyze student performance and attendance patterns in a high school semester.", "raw_table": "StudentID,Name,Grade,Subject,Score,Attendance,TestDate\n1,alice Johnson,10,Math,85,Present,2023-03-15\n2,Bob Smith,10,science,78,Absent,15/03/2023\n3,CHARLIE lee,11,Math,92,Present,2023/03/16\n4,Diana Prince, 11,English,,Present,16-Mar-2023\n5,Eva Green,10,Science,88,present,2023-03-17\n6,Frank O'Neil,12,Math,75,Absent,03-18-2023\n7,Gina Torres,12,english,83,Present,2023.03.19\n8,Hank Moody,11,Science,NaN,Absent,2023-03-20\n9,Ian Wright,10,Math,80,Present,2023-3-21\n10,Jill Tanner,11,English,90,Present,21/03/2023\n11,Kate Moss,12,Science,95,Present,2023-Mar-22\n12,Luke Cage,10,Math,70,Absent,2023/03/23\n13,Mia Wallace,11,science,82,present,Mar 24 2023\n14,Nick Fury,12,English,88,Present,2023-03-25", "eda_steps": ["Standardize the capitalization of the 'Subject' and 'Attendance' columns", "Parse and unify the 'TestDate' column to ISO date format", "Check for and report missing values in each column", "Compute descriptive statistics for the 'Score' column by Subject", "Generate value counts for the 'Attendance' column", "Identify number of unique students and grades", "Calculate average score by Grade level", "Check for correlations between Score and Attendance status"], "eda_results": {"missing_values": {"Score": 2, "Name": 0, "Attendance": 0, "TestDate": 0}, "value_counts": {"Attendance": {"Present": 9, "Absent": 5}, "Subject": {"Math": 5, "Science": 5, "English": 4}}, "summary_stats": {"Score_overall": {"count": 12, "mean": 83.25, "std": 7.92, "min": 70, "max": 95}, "Score_by_Subject": {"Math": {"count": 5, "mean": 80.8, "std": 8.39, "min": 70, "max": 92}, "Science": {"count": 5, "mean": 85.75, "std": 7.59, "min": 78, "max": 95}, "English": {"count": 4, "mean": 87.75, "std": 3.86, "min": 83, "max": 90}}, "Average_Score_by_Grade": {"10": 80.75, "11": 86.0, "12": 82.0}}, "unique_counts": {"Students": 14, "Grades": 3}, "correlations": {"Score_Attendance": -0.42}}}
{"purpose": "Analyze student performance and attendance patterns in a middle school class.", "raw_table": "StudentID,Name,Grade,Math_Score,English_Score,Attendance,Enrollment_Date\n101,john doe,7,85,78,95%,2022-09-01\n102,Jane Smith,7, ,88,90%,09/03/2022\n103,Bob Johnson,8,92,missing,85%,2022/09/05\n104,Alice GREEN,7,75,82,missing,2022-9-07\n105,mike Brown,8,88,85,92%,2022-09-03\n106,Lisa White,7,93,90,98%,2022-09-02\n107,Tom O'Neill,8,80,,87%,2022-09-06\n108,emma wilson,7,72,77,89%,Sept 04 2022\n109,Chris Black,7,N/A,83,91%,2022-09-01\n110,Mary-Jane,8,85,80,94%,2022-9-08", "eda_steps": ["Check for missing values and their percentages in each column", "Compute descriptive statistics for Math_Score and English_Score columns", "Generate value counts for the Grade and Attendance columns", "Standardize and parse Enrollment_Date to a consistent date format", "Identify unique student names and check for inconsistent capitalization", "Calculate correlation between Math_Score and English_Score", "Summarize attendance distribution statistics", "List students with missing or invalid scores"], "eda_results": {"missing_values": {"StudentID": "0%", "Name": "0%", "Grade": "0%", "Math_Score": "18%", "English_Score": "18%", "Attendance": "9%", "Enrollment_Date": "0%"}, "summary_stats": {"Math_Score": {"count": 9, "mean": 83.33, "std_dev": 7.18, "min": 72, "max": 93}, "English_Score": {"count": 9, "mean": 83.89, "std_dev": 4.51, "min": 77, "max": 90}, "Attendance": {"count": 11, "mean_percentage": 90.18, "min": 85, "max": 98}}, "value_counts": {"Grade": {"7": 6, "8": 5}, "Attendance": {"95%": 1, "90%": 1, "85%": 1, "missing": 1, "92%": 1, "98%": 1, "87%": 1, "89%": 1, "91%": 1, "94%": 1}}, "standardized_dates": ["2022-09-01", "2022-09-03", "2022-09-05", "2022-09-07", "2022-09-03", "2022-09-02", "2022-09-06", "2022-09-04", "2022-09-01", "2022-09-08"], "name_inconsistencies": {"john doe": "lowercase", "Jane Smith": "title case", "Bob Johnson": "title case", "Alice GREEN": "mixed case", "mike Brown": "mixed case", "Lisa White": "title case", "Tom O'Neill": "title case", "emma wilson": "lowercase", "Chris Black": "title case", "Mary-Jane": "title case"}, "correlations": {"Math_Score_vs_English_Score": 0.62}, "attendance_distribution": {"mean": 90.18, "median": 90, "min": 85, "max": 98, "std_dev": 4.59}, "students_with_missing_scores": ["102: Math_Score missing", "103: English_Score missing", "104: Attendance missing", "107: English_Score missing", "109: Math_Score N/A"]}}
{"purpose": "Analyze citizen complaints data to identify common issues and data quality concerns in municipal services.", "raw_table": "ComplaintID,Date,Department,IssueType,Status,ResolutionTime\n1,2023-05-12,PUBLIC WORKS,Noise,Resolved,3\n2,05/14/2023,Water,Leakage,Pending,\n3,2023/05/15,Public works,Street Light,Resolved,5\n4,2023-5-16,HEALTH,Sanitation,Resolved,2\n5,,Water,leakage,In Progress,4\n6,2023-05-18,Transportation,Traffic jam,Resolved,7\n7,2023-05-19,health,Sanitation,,3\n8,2023-05-20,Public Works,noise,Resolved,2\n9,2023-05-21,Transportation,,Resolved,6\n10,2023-05-22,,Garbage,Pending, \n11,2023-05-23,Water,Leakage,Resolved,3", "eda_steps": ["Check for missing values in each column", "Standardize the Department column capitalization", "Generate value counts for the Department and IssueType columns", "Compute descriptive statistics for the ResolutionTime column", "Identify entries with missing or inconsistent date formats", "Summarize the statuses and count how many complaints are Resolved, Pending, In Progress, or missing", "Analyze the distribution of complaints over dates", "Check for any duplicate ComplaintID values"], "eda_results": {"missing_values": {"ComplaintID": 0, "Date": 1, "Department": 1, "IssueType": 1, "Status": 2, "ResolutionTime": 2}, "standardized_departments": ["Public Works", "Water", "Public Works", "Health", "Water", "Transportation", "Health", "Public Works", "Transportation", null, "Water"], "value_counts_Department": {"Public Works": 3, "Water": 3, "Health": 2, "Transportation": 2, "Unknown": 1}, "value_counts_IssueType": {"Leakage": 3, "Noise": 2, "Sanitation": 2, "Street Light": 1, "Traffic jam": 1, "Garbage": 1, "Missing": 1}, "resolution_time_stats": {"count": 9, "mean": 3.89, "min": 2, "max": 7, "median": 3, "std_dev": 1.7}, "date_inconsistencies": {"inconsistent_formats": [2, 3], "missing_dates": [5]}, "status_summary": {"Resolved": 7, "Pending": 2, "In Progress": 1, "Missing": 1}, "complaints_over_dates": {"2023-05-12": 1, "2023-05-14": 1, "2023-05-15": 1, "2023-05-16": 1, "2023-05-18": 1, "2023-05-19": 1, "2023-05-20": 1, "2023-05-21": 1, "2023-05-22": 1, "2023-05-23": 1}, "duplicate_complaint_ids": []}}
{"purpose": "Analyze customer call patterns and service usage to identify potential churn risks in a telecom dataset.", "raw_table": "CustomerID,CallDurationMinutes,PlanType,LastPaymentDate,DataUsageGB,Churn\n001, 35, Prepaid, 2023-03-15, 1.2, No\n002, 12, postpaid, 15-04-2023, 3.5, yes\n003, , Prepaid, 2023/05/01, 2.1, No\n004, 48, POSTPAID, 2023-04-28, ,no\n005, 8, prepaid, , 0.5, Yes\n006, 22, Prepaid, 2023-03-30, 1.8, No\n007, 30, postPaid, 2023-04-01, 2.9, no\n008, 14, prepaid, 04/15/2023, 1.0, Yes\n009, , Postpaid, 2023-03-25, 2.2, No\n010, 50, Prepaid, 2023-04-20, 3.7, yes\n011, 28, Postpaid, 2023/04/10, , No\n012, 17, prepaid, 2023-03-29, 1.1, no", "eda_steps": ["Check and standardize capitalization in the PlanType and Churn columns", "Identify and count missing values in each column", "Convert LastPaymentDate to consistent date format", "Compute descriptive statistics for CallDurationMinutes and DataUsageGB", "Generate value counts for PlanType and Churn columns", "Calculate correlation between CallDurationMinutes and DataUsageGB", "Identify customers with missing CallDurationMinutes or DataUsageGB", "Summarize churn distribution by PlanType"], "eda_results": {"missing_values": {"CustomerID": 0, "CallDurationMinutes": 2, "PlanType": 0, "LastPaymentDate": 1, "DataUsageGB": 3, "Churn": 0}, "standardized_plantype_counts": {"Prepaid": 7, "Postpaid": 5}, "standardized_churn_counts": {"Yes": 4, "No": 8}, "last_payment_date_sample": ["2023-03-15", "2023-04-15", "2023-05-01", "2023-04-28", "2023-03-30"], "summary_stats": {"CallDurationMinutes": {"count": 10, "mean": 26.4, "std": 12.8, "min": 8, "25%": 17, "50%": 28, "75%": 35, "max": 50}, "DataUsageGB": {"count": 9, "mean": 2.06, "std": 1.06, "min": 0.5, "25%": 1.1, "50%": 1.8, "75%": 2.9, "max": 3.7}}, "correlations": {"CallDurationMinutes_vs_DataUsageGB": 0.89}, "customers_missing_call_duration": ["003", "009"], "customers_missing_data_usage": ["004", "011", "009"], "churn_by_plantype": {"Prepaid": {"Yes": 3, "No": 4}, "Postpaid": {"Yes": 1, "No": 4}}}}
{"purpose": "Analyze crop yield and fertilizer usage patterns across different farm locations.", "raw_table": "Farm_ID,Crop_Type,Planting_Date,Harvest_Date,Fertilizer_Used_kg,Yield_Tonnes,Soil_Type\n001,Wheat,2023-03-15,2023-07-20,150,3.2,loam\n002,corn,03/20/2023,07/25/2023, 200,4.1,SANDY\n003,Rice,2023/04/01,2023-08-10,NA,2.8,Clay\n004,Barley,March 22 2023,Aug 15 2023,180,3.5,loam\n005,wheat,15-03-2023,20-07-2023,160,,silty\n006,Corn,2023-03-19,07-28-2023,210,4.3,Sandy\n007,Rice,2023-04-05,08/15/2023,170,2.9,clay\n008,barley,2023.03.23,2023.08.14,175,3.4,Loam\n009,Wheat,2023-03-16,NA,155,3.1,Loam\n010,Corn,2023-03-21,07/26/2023,NA,4.0,SANDY", "eda_steps": ["Check for missing values in all columns", "Standardize Crop_Type and Soil_Type capitalization", "Parse Planting_Date and Harvest_Date into consistent date format", "Calculate the duration between Planting_Date and Harvest_Date", "Compute descriptive statistics for Fertilizer_Used_kg and Yield_Tonnes", "Generate value counts for Crop_Type", "Identify farms with missing Yield_Tonnes or Fertilizer_Used_kg", "Compute correlation between Fertilizer_Used_kg and Yield_Tonnes"], "eda_results": {"missing_values": {"Farm_ID": 0, "Crop_Type": 0, "Planting_Date": 0, "Harvest_Date": 1, "Fertilizer_Used_kg": 2, "Yield_Tonnes": 1, "Soil_Type": 0}, "standardized_categories": {"Crop_Type": ["Wheat", "Corn", "Rice", "Barley"], "Soil_Type": ["Loam", "Sandy", "Clay", "Silty"]}, "date_parsing_issues": 0, "planting_to_harvest_days": {"mean": 128, "min": 121, "max": 134}, "summary_stats": {"Fertilizer_Used_kg": {"count": 8, "mean": 173.8, "std": 20.2, "min": 150, "max": 210}, "Yield_Tonnes": {"count": 9, "mean": 3.58, "std": 0.65, "min": 2.8, "max": 4.3}}, "value_counts_Crop_Type": {"Wheat": 3, "Corn": 3, "Rice": 2, "Barley": 2}, "farms_missing_values": {"Fertilizer_Used_kg": ["003", "010"], "Yield_Tonnes": ["005"], "Harvest_Date": ["009"]}, "correlation_fertilizer_yield": 0.89}}
{"purpose": "Analyze electricity consumption patterns and identify data quality issues in household energy usage records.", "raw_table": "Household_ID,Date,Consumption_kWh,Energy_Source,Region\nH001,2023-01-01,15.4,solar,North\nH002,01/02/2023,NaN,Wind,South\nH003,2023/01/03,20.1,solar,East\nh004,2023-01-04,18.6,coal,west\nH005,2023-01-05,invalid,solar,North\nH006,2023-01-06,22.0,Wind,South\nH007,2023-01-07,19.5,Coal,East\nH008,2023-01-08,,solar,West\nH009,2023-1-09,21.3,nuclear,north\nH010,2023-01-10,17.8,wind,South\nH011,2023-01-11,16.0,Solar,East\nH012,2023-01-12,19.9,coal,west\nH013,2023-01-13,NaN,nuclear,North\nH014,13/01/2023,20.5,solar,South", "eda_steps": ["Check and summarize missing values in each column", "Standardize date formats and identify inconsistent date entries", "Clean and standardize categorical variables for Energy_Source and Region", "Convert Consumption_kWh to numeric, handling non-numeric and missing values", "Compute descriptive statistics (mean, median, std) for Consumption_kWh", "Generate value counts for Energy_Source and Region columns", "Identify correlation between Consumption_kWh and Energy_Source categories encoded numerically", "Detect any outliers or invalid consumption values"], "eda_results": {"missing_values": {"Household_ID": 0, "Date": 0, "Consumption_kWh": 3, "Energy_Source": 0, "Region": 0}, "date_format_issues": ["01/02/2023", "2023/01/03", "2023-1-09", "13/01/2023"], "standardized_energy_source_counts": {"solar": 5, "wind": 3, "coal": 3, "nuclear": 2}, "standardized_region_counts": {"north": 3, "south": 4, "east": 3, "west": 3}, "consumption_stats": {"count": 12, "mean": 18.93, "median": 19.7, "std_dev": 2.06, "min": 15.4, "max": 22.0}, "invalid_consumption_entries": ["invalid", ""], "correlation_energy_source_numeric": {"solar": 1, "wind": 2, "coal": 3, "nuclear": 4, "correlation_with_consumption": 0.12}, "outliers_detected": {"none": true}}}
{"purpose": "Analyze trip durations and passenger counts in urban taxi rides to identify data quality issues and usage patterns.", "raw_table": "Trip_ID,Start_Date,End_Date,Passenger_Count,Vehicle_Type,Fare_Amount,Payment_Method\nT001,2024-04-01 08:15,2024/04/01 08:45,2,Sedan,15.5,Credit\nT002,2024-04-01 09:00 AM,2024-04-01 09:25 AM,1,SUV,12.0,CASH\nT003,04/01/2024 10:05,2024-04-01 10:35,3,sedan,NaN,Credit\nT004,2024-4-01 11:15,2024-04-01 11:50,,Van,20.0,Credit\nT005,2024-04-01 12:00,2024-04-01 12:30,1,suv,11.0,credit\nT006,2024-04-01 13:10,2024-04-01 13:40,2,Truck,18.0,Cash\nT007,2024-04-01 14:00,2024-04-01 14:30,Two,Sedan,16.0,Credit\nT008,2024-04-01 15:20,2024-04-01 15:50,1,sedan,15.0,CASH\nT009,2024-04-01 16:00,2024-04-01 16:30,2,SUV,NaN,cash\nT010,2024-04-01 17:10,2024-04-01 17:45,3,Van,22.0,Credit\n", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in categorical columns: Vehicle_Type and Payment_Method", "Convert Passenger_Count to numeric and identify non-numeric entries", "Calculate trip duration in minutes by parsing Start_Date and End_Date", "Generate descriptive statistics for numeric columns: Fare_Amount, Passenger_Count, Trip Duration", "Check unique values and counts for Vehicle_Type and Payment_Method", "Identify any inconsistent or unusual categories in Vehicle_Type", "Analyze correlation between Fare_Amount, Passenger_Count, and Trip Duration"], "eda_results": {"missing_values": {"Trip_ID": 0, "Start_Date": 0, "End_Date": 0, "Passenger_Count": 1, "Vehicle_Type": 0, "Fare_Amount": 2, "Payment_Method": 0}, "standardized_vehicle_type_counts": {"Sedan": 4, "SUV": 3, "Van": 2, "Truck": 1}, "standardized_payment_method_counts": {"Credit": 6, "Cash": 4}, "passenger_count_issues": {"non_numeric_entries": ["Two"], "missing_entries": 1}, "trip_duration_minutes": {"min": 25, "max": 40, "mean": 31.5, "median": 30}, "fare_amount_stats": {"count": 8, "mean": 16.44, "min": 11.0, "max": 22.0, "std_dev": 3.65}, "passenger_count_stats": {"count": 8, "mean": 2.0, "min": 1, "max": 3}, "correlations": {"Fare_Amount_vs_Passenger_Count": 0.83, "Fare_Amount_vs_Trip_Duration": 0.91, "Passenger_Count_vs_Trip_Duration": 0.78}, "unusual_vehicle_types": ["Truck"]}}
{"purpose": "Analyze user engagement patterns and content type distribution on a social media platform.", "raw_table": "user_id,post_date,post_type,likes,comments,shares\nU001,2023-04-01,Image,120,15,5\nu002,2023/04/02,Video,250,30,12\nU003,04-03-2023,text,45,,3\nU004,,Image,NaN,5,2\nu005,2023-04-05,video,300,45,\nU006,2023-4-06,Text,75,10,1\nU007,2023-04-07,Poll,50,8,0\nu008,2023-04-08,IMAGE,130,20,6\nU009,2023-04-09,video,275,35,10\nU010,2023/04/10,Text,60,12,4\nU011,2023-13-11,Video,200,25,7\nU012,2023-04-12,poll,,5,1", "eda_steps": ["Standardize the date format in the post_date column", "Normalize capitalization in the post_type column", "Check for and summarize missing values in all columns", "Compute descriptive statistics for numeric columns: likes, comments, shares", "Generate value counts for the post_type column", "Identify posts with missing or inconsistent data", "Calculate the correlation matrix between likes, comments, and shares", "Determine the top 3 most common post types", "Summarize the distribution skewness for likes"], "eda_results": {"missing_values": {"user_id": 0, "post_date": 2, "post_type": 0, "likes": 2, "comments": 1, "shares": 2}, "post_date_standardized": ["2023-04-01", "2023-04-02", "2023-04-03", null, "2023-04-05", "2023-04-06", "2023-04-07", "2023-04-08", "2023-04-09", "2023-04-10", null, "2023-04-12"], "post_type_normalized_counts": {"image": 3, "video": 4, "text": 3, "poll": 2}, "descriptive_stats": {"likes": {"count": 10, "mean": 140.5, "std": 95.7, "min": 45, "25%": 60, "50%": 125, "75%": 275, "max": 300}, "comments": {"count": 11, "mean": 18.5, "std": 12.1, "min": 5, "25%": 8, "50%": 15, "75%": 30, "max": 45}, "shares": {"count": 10, "mean": 5.1, "std": 3.8, "min": 0, "25%": 2, "50%": 5, "75%": 7, "max": 12}}, "correlation_matrix": {"likes_comments": 0.92, "likes_shares": 0.88, "comments_shares": 0.8}, "top_post_types": ["video", "image", "text"], "skewness_likes": 0.45, "inconsistent_entries": {"post_date": ["", "2023-13-11"], "likes": ["NaN", ""], "comments": [""], "shares": ["", ""], "post_type": []}}}
{"purpose": "Analyze student performance and attendance patterns in a middle school class.", "raw_table": "StudentID,Name,Grade,TestScore,Attendance,EnrollmentDate,ExtraCurricular\n1,alice,7,85,95%,2023-09-01,Chess Club\n2,BOB,7,78,88%,09/03/2023,Basketball\n3,Charlie,7,,90%,2023/09/05,Drama\n4,David,8,92,92%,2023-9-02,Soccer\n5,eva,8,88,N/A,2023-09-01,none\n6,Frank,8,abc,85%,2023-09-03,Choir\n7,Grace,7,75,80%,09-04-2023,Drama\n8,Henry,8,83,87%,2023-09-06,Basketball\n9,Ivy,7,,N/A,2023/09/01,none\n10,Jack,8,90,93%,2023-09-05,Chess Club", "eda_steps": ["Check for missing values in all columns", "Standardize the EnrollmentDate to a consistent date format", "Identify and handle non-numeric or invalid entries in TestScore", "Calculate descriptive statistics for TestScore", "Generate value counts for Grade and ExtraCurricular", "Compute percentage of students with attendance below 90%", "Analyze correlation between TestScore and Attendance"], "eda_results": {"missing_values": {"TestScore": 2, "Attendance": 2, "ExtraCurricular": 0}, "date_standardization": {"original_formats": ["2023-09-01", "09/03/2023", "2023/09/05", "2023-9-02", "09-04-2023"], "standardized_format": "YYYY-MM-DD"}, "invalid_testscore_entries": {"non_numeric": ["abc"], "missing": [3, 9]}, "summary_stats": {"TestScore": {"count": 7, "mean": 84.43, "std_dev": 6.22, "min": 75, "max": 92}}, "value_counts": {"Grade": {"7": 5, "8": 5}, "ExtraCurricular": {"Chess Club": 2, "Basketball": 2, "Drama": 2, "Soccer": 1, "none": 2, "Choir": 1}}, "attendance_below_90_percent": {"count": 4, "percentage": 40}, "correlations": {"TestScore_Attendance": 0.68}}}
{"purpose": "Analyze user engagement patterns on social media posts to identify activity trends and data quality issues.", "raw_table": "Post_ID,User_ID,Post_Date,Likes,Comments,Post_Type\n101,u123,2023-04-01,25,3,Image\n102,U124,04/02/2023,30,,video\n103,u125,2023-04-03,NaN,1,text\n104,u126,2023/04/04,10,0,IMAGE\n105,u127,04-05-2023,15,2,Video\n106,u128,2023-4-06,20,1,text\n107,U129,2023-04-07,5,NaN,Live\n108,u130,4/8/2023,12,4,image\n109,u131,April 9 2023,,3,video\n110,u132,2023.04.10,22,2,TEXT\n111,u133,2023/04/11,18,0,Image\n112,u134,2023-04-12,NaN,,story\n113,u135,04/13/2023,28,5,Video\n114,u136,2023-04-14,17,1,text\n115,u137,2023-4-15,NaN,NaN,image", "eda_steps": ["Check missing value percentages for all columns", "Standardize Post_Date to a single date format", "Convert Likes and Comments columns to numeric types and handle non-numeric entries", "Generate value counts for Post_Type to identify category distribution and unusual categories", "Compute descriptive statistics (mean, median, std) for Likes and Comments", "Identify posts with zero or missing engagement (Likes and Comments)", "Analyze correlation between Likes and Comments", "Identify the top 3 users by total Likes received"], "eda_results": {"missing_values": {"Post_ID": 0, "User_ID": 0, "Post_Date": 0, "Likes": 4, "Comments": 4, "Post_Type": 1}, "standardized_date_sample": ["2023-04-01", "2023-04-02", "2023-04-03", "2023-04-04", "2023-04-05"], "likes_comments_numeric_conversion": {"Likes_non_numeric_entries": 4, "Comments_non_numeric_entries": 2}, "post_type_value_counts": {"Image": 5, "Video": 4, "Text": 4, "Live": 1, "Story": 1}, "descriptive_stats": {"Likes": {"mean": 18.14, "median": 17, "std": 7.52, "min": 5, "max": 30, "count": 11}, "Comments": {"mean": 1.91, "median": 1, "std": 1.55, "min": 0, "max": 5, "count": 11}}, "posts_zero_or_missing_engagement": {"zero_likes": 1, "zero_comments": 3, "missing_likes": 4, "missing_comments": 4}, "correlation_likes_comments": 0.82, "top_3_users_by_likes": {"u135": 28, "U124": 30, "u132": 22}}}
{"purpose": "Analyze streaming platform movie ratings and genres to understand viewer preferences and data quality.", "raw_table": "MovieID,Title,Genre,ReleaseDate,Rating,ViewerCount\n1,Inception,SCI-FI,2010-07-16,8.8,125000\n2,the godfather,Crime,1972/03/24,9.2,98000\n3,Titanic,Drama,1997-12-19,7.8,145000\n4,Avengers: Endgame,Action,2019-04-26,8.4,210000\n5,Parasite,Thriller,2019-05-30,8.6,87000\n6, JOKER ,Crime,2019-10-04,,110000\n7,The Lion King,Animation,1994-06-24,8.5,\n8,La La Land,Musical,2016-12-09,8.0,95000\n9,Get Out,Horror,2017-02-24,7.7,73000\n10,Interstellar,Sci-fi,2014-11-07,8.6,115000\n11,Avengers: Infinity War,action,2018-04-23,8.5,200000\n12,Black Panther,Action,2018-02-16,7.9,175000\n13,Frozen,Animation,2013-11-27,7.5,160000\n14,Coco,animation,2017-11-22,8.4,140000", "eda_steps": ["Check missing value counts for each column", "Standardize Genre capitalization and find unique genres", "Calculate descriptive statistics for Rating and ViewerCount", "Generate value counts for Genre", "Identify top 3 movies by ViewerCount", "Summarize distribution skewness of Rating", "Convert ReleaseDate to consistent datetime format and find earliest and latest dates"], "eda_results": {"missing_values": {"Rating": 1, "ViewerCount": 1}, "unique_genres": ["Sci-fi", "Crime", "Drama", "Action", "Thriller", "Animation", "Musical", "Horror"], "genre_value_counts": {"Action": 3, "Animation": 3, "Crime": 2, "Sci-fi": 2, "Drama": 1, "Thriller": 1, "Musical": 1, "Horror": 1}, "summary_stats": {"Rating": {"count": 13, "mean": 8.16, "std": 0.53, "min": 7.5, "25%": 7.8, "50%": 8.4, "75%": 8.6, "max": 9.2}, "ViewerCount": {"count": 13, "mean": 130230.77, "std": 44136.76, "min": 73000, "25%": 95000, "50%": 115000, "75%": 160000, "max": 210000}}, "top_movies_by_viewercount": [{"Title": "Avengers: Endgame", "ViewerCount": 210000}, {"Title": "Avengers: Infinity War", "ViewerCount": 200000}, {"Title": "Black Panther", "ViewerCount": 175000}], "rating_skewness": -0.32, "release_date_range": {"earliest": "1972-03-24", "latest": "2019-10-04"}}}
{"purpose": "Analyze daily electricity consumption patterns across different regions to identify data quality issues and consumption trends.", "raw_table": "Date,Region,Consumption_kWh,Weather,Households\n2024-01-01,NORTH,1500,Sunny,100\n2024/01/02,South,1450,cloudy,95\n01-03-2024,East,NaN,Rainy,90\n2024-01-04,NORTH,1600,Sunny,NaN\n2024-01-05,west,1550,Cloudy,85\n2024-01-06,south,NaN,Rainy,80\n2024-01-07,East,1400,Sunny,88\n2024-01-08,NORTH,1580,Sunny,102\n2024-01-09,West,1520,cloudy,87\n2024-01-10,South,1490,RAINY,83\n2024-01-11,East,1380,sunny,89\n2024-1-12,north,NaN,Cloudy,105", "eda_steps": ["Standardize date column to a single consistent format", "Normalize region names to consistent capitalization", "Identify and report missing values in each column", "Compute descriptive statistics for Consumption_kWh and Households", "Generate value counts for Weather categories", "Calculate average Consumption_kWh per Region", "Check correlation between Consumption_kWh and Households", "Identify rows with missing Consumption_kWh values", "Summarize consumption distribution skewness"], "eda_results": {"missing_values": {"Date": 0, "Region": 0, "Consumption_kWh": 3, "Weather": 0, "Households": 1}, "value_counts_weather": {"Sunny": 4, "Cloudy": 3, "Rainy": 3}, "summary_stats_consumption_kWh": {"count": 9, "mean": 1493.33, "std": 75.68, "min": 1380, "25%": 1437.5, "50%": 1500, "75%": 1575, "max": 1600, "skewness": -0.15}, "summary_stats_households": {"count": 11, "mean": 91.82, "std": 7.75, "min": 80, "25%": 85, "50%": 89, "75%": 100, "max": 105}, "average_consumption_by_region": {"North": 1543.5, "South": 1476.67, "East": 1393.33, "West": 1535}, "correlation_consumption_households": 0.82, "rows_with_missing_consumption": [3, 5, 11]}}
{"purpose": "Explore the characteristics of recent real estate listings to identify data quality issues and understand property features distribution.", "raw_table": "ListingID,DateListed,Price,Location,Bedrooms,Bathrooms,SquareFeet,PropertyType\n1001,2023-01-15,350000,Downtown,3,2,1500,Condo\n1002,15/02/2023,450000,suburbs,4,3,2300,Single Family\n1003,2023/03/01,,Midtown,2,,1100,townhouse\n1004,2023-03-20,375000,Downtown,3,2,1400,Condo\n1005,2023-04-05,NaN,Suburbs,3,2,1600,Single family\n1006,2023-04-10,500000,midtown,5,4,3200,Single Family\n1007,04-15-2023,275000,Downtown,1,1,850,Condo\n1008,2023-04-20,600000,Suburbs,4,3,,Single Family\n1009,2023-04-22,410000,Midtown,3,2,1800,TownHouse\n1010,2023-05-01,390000,downtown,3,2,1450,Condo\n1011,2023-05-05,NaN,,2,1,900,Condo\n1012,2023-05-10,480000,Suburbs,4,3,2200,single family\n", "eda_steps": ["Check for missing values in each column", "Standardize the date format in the DateListed column", "Compute descriptive statistics for numeric columns: Price, Bedrooms, Bathrooms, SquareFeet", "Generate value counts for the PropertyType and Location columns", "Identify rows with inconsistent capitalization in categorical columns", "Calculate the percentage of missing Price values", "Summarize the distribution of Bedrooms and Bathrooms", "Check for any outliers in Price and SquareFeet"], "eda_results": {"missing_values": {"ListingID": 0, "DateListed": 0, "Price": 3, "Location": 1, "Bedrooms": 0, "Bathrooms": 2, "SquareFeet": 1, "PropertyType": 0}, "date_standardization": "All dates converted to ISO format YYYY-MM-DD", "summary_stats": {"Price": {"count": 9, "mean": 433333.33, "std": 102062.13, "min": 275000, "max": 600000}, "Bedrooms": {"count": 12, "mean": 3.17, "std": 1.08, "min": 1, "max": 5}, "Bathrooms": {"count": 10, "mean": 2.3, "std": 1.05, "min": 1, "max": 4}, "SquareFeet": {"count": 11, "mean": 1734.55, "std": 652.88, "min": 850, "max": 3200}}, "value_counts": {"PropertyType": {"Condo": 5, "Single Family": 5, "Townhouse": 2}, "Location": {"Downtown": 4, "Suburbs": 4, "Midtown": 3, "": 1}}, "inconsistent_capitalization": {"Location": ["suburbs", "Suburbs", "midtown", "Midtown", "downtown", "Downtown"], "PropertyType": ["Single family", "single family", "Single Family", "TownHouse", "townhouse"]}, "missing_price_percentage": 25, "bedrooms_distribution": {"1": 1, "2": 2, "3": 5, "4": 3, "5": 1}, "bathrooms_distribution": {"1": 1, "2": 5, "3": 3, "4": 1}, "outliers": {"Price": {"Lower bound": 135208, "Upper bound": 652792, "Outliers": []}, "SquareFeet": {"Lower bound": 516, "Upper bound": 2951, "Outliers": [3200]}}}}
{"purpose": "Analyze customer purchase behavior and product category performance in a retail store.", "raw_table": "TransactionID,CustomerID,ProductCategory,PurchaseAmount,PurchaseDate,PaymentMethod\nT001,Cust01,Electronics,299.99,2023-01-15,Credit Card\nT002,Cust02,clothing,49.95,15/01/2023,CASH\nT003,Cust03,Home & Kitchen,NaN,2023-01-16,credit card\nT004,Cust04,Electronics,189.50,2023/01/17,Debit Card\nT005,Cust05,Toys,29.99,17-01-2023,cash\nT006,Cust01,Clothing,not available,2023-01-18,Credit card\nT007,Cust06,home & kitchen,99.99,18 Jan 2023,PayPal\nT008,Cust07,Toys,15.00,,Debit Card\nT009,Cust08,Electronics,399.95,2023-01-20,Credit Card\nT010,Cust09,Books,12.50,2023-01-21,Cash\nT011,Cust10,Books,NaN,2023-01-22,Cash\nT012,Cust11,Clothing,59.99,2023/01/23,credit card\nT013,Cust12,Electronics,249.99,2023-01-24,Debit Card\nT014,Cust13,Books,8.99,24-01-2023,Cash\nT015,Cust14,Toys,NaN,2023-01-25,Paypal", "eda_steps": ["Check for missing values in each column", "Standardize inconsistent capitalization in ProductCategory and PaymentMethod columns", "Fix inconsistent date formats in PurchaseDate column and parse into a uniform date format", "Convert PurchaseAmount to numeric, handling non-numeric and missing values", "Compute descriptive statistics for PurchaseAmount", "Generate value counts for ProductCategory and PaymentMethod", "Identify top 3 ProductCategories by total PurchaseAmount", "Summarize number of purchases per customer"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 0, "ProductCategory": 0, "PurchaseAmount": 4, "PurchaseDate": 1, "PaymentMethod": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home & Kitchen", "Toys", "Books"], "PaymentMethod": ["Credit Card", "Cash", "Debit Card", "PayPal"]}, "date_format_parsed": {"earliest_date": "2023-01-15", "latest_date": "2023-01-25", "missing_dates_count": 1}, "purchase_amount_stats": {"count": 11, "mean": 141.04, "median": 59.99, "min": 8.99, "max": 399.95, "missing": 4}, "value_counts": {"ProductCategory": {"Electronics": 4, "Clothing": 3, "Home & Kitchen": 2, "Toys": 3, "Books": 3}, "PaymentMethod": {"Credit Card": 4, "Cash": 4, "Debit Card": 3, "PayPal": 2}}, "top_3_categories_by_purchase_amount": {"Electronics": 1139.43, "Home & Kitchen": 99.99, "Clothing": 109.94}, "purchases_per_customer": {"Cust01": 2, "Cust02": 1, "Cust03": 1, "Cust04": 1, "Cust05": 1, "Cust06": 1, "Cust07": 1, "Cust08": 1, "Cust09": 1, "Cust10": 1, "Cust11": 1, "Cust12": 1, "Cust13": 1, "Cust14": 1}}}
{"purpose": "Analyze retail transaction data to understand sales distribution and customer purchasing behavior.", "raw_table": "TransactionID,CustomerID,ProductCategory,Quantity,Price,TransactionDate,StoreLocation\n1001,C001,Electronics,2,299.99,2023/01/15,New York\n1002,C002,home Appliances,,189.50,15-01-2023,los angeles\n1003,,Electronics,1,199.99,2023-01-16,Chicago\n1004,C004,Clothing,3,49.99,01/17/2023,new york\n1005,C005,clothing,1,,2023-01-17,New York\n1006,C006,Toys,5,15.99,2023/01/18,Houston\n1007,C007,Home appliances,2,199.95,18-01-2023,Los Angeles\n1008,C002,Electronics,1,299.99,2023-01-19,Chicago\n1009,C008,TOYS,3,15.99,01/20/2023,Houston\n1010,C009,Furniture,1,499.99,2023/01/21,Boston\n1011,C010,Electronics,2,not_available,2023-01-22,NEW YORK\n1012,C011,Clothing,4,39.99,22-01-2023,New york\n1013,C012,Furniture,1,599.99,2023/01/23,Boston\n1014,C013,Home appliances,1,189.50,2023-01-24,LOS ANGELES", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in ProductCategory and StoreLocation", "Convert TransactionDate to a consistent date format", "Compute descriptive statistics for Quantity and Price", "Generate value counts for ProductCategory and StoreLocation", "Identify transactions with missing or invalid Price values", "Calculate total sales amount per ProductCategory", "Determine the number of unique customers", "Summarize the distribution of TransactionDate over time"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 1, "ProductCategory": 0, "Quantity": 1, "Price": 2, "TransactionDate": 0, "StoreLocation": 0}, "standardized_categories": {"ProductCategory": {"electronics": 4, "home appliances": 3, "clothing": 3, "toys": 2, "furniture": 2}, "StoreLocation": {"new york": 4, "los angeles": 3, "chicago": 2, "houston": 2, "boston": 2}}, "date_range": {"min_date": "2023-01-15", "max_date": "2023-01-24"}, "descriptive_stats": {"Quantity": {"count": 14, "mean": 2.43, "std": 1.36, "min": 1, "max": 5}, "Price": {"count": 12, "mean": 224.31, "std": 185.58, "min": 15.99, "max": 599.99}}, "invalid_price_transactions": [1011], "total_sales_per_category": {"electronics": 1799.94, "home appliances": 579.85, "clothing": 289.95, "toys": 79.95, "furniture": 1099.98}, "unique_customers": 13, "transaction_date_distribution": {"2023-01-15": 2, "2023-01-16": 1, "2023-01-17": 2, "2023-01-18": 2, "2023-01-19": 1, "2023-01-20": 1, "2023-01-21": 1, "2023-01-22": 2, "2023-01-23": 1, "2023-01-24": 1}}}
{"purpose": "Analyze student performance and attendance patterns to identify potential factors affecting grades.", "raw_table": "StudentID,Name,Grade,Attendance,EnrollmentDate,Major,FinalScore\n101,alice,10,95%,2023/01/15,Computer Science,88\n102,BOB,11,88%,15-02-2023,Mathematics,92\n103,Charlie,10,,2023-02-01,computer science,85\n104,diana,12,90%,01/03/2023,Physics,78\n105,edward,11,85%,2023/3/05,Math,83\n106,Fiona,10,80%,2023-02-20,Physics,missing\n107,George,,75%,2023/02/25,COMPUTER SCIENCE,79\n108,henry,12,92%,2023-03-01,physics,88\n109,Irene,11,NaN,03-03-2023,Mathematics,91\n110,jack,10,87%,2023/02/28,Computer Science,84", "eda_steps": ["Check data types and convert EnrollmentDate to datetime format", "Identify and quantify missing values in each column", "Standardize categorical columns: Name capitalization and Major categories", "Compute descriptive statistics for numeric columns: Grade, Attendance, FinalScore", "Calculate value counts for Major and Grade", "Analyze correlation between Attendance and FinalScore", "Identify students with missing FinalScore and their characteristics", "Summarize distribution of FinalScore by Major"], "eda_results": {"missing_values": {"Grade": 1, "Attendance": 2, "FinalScore": 1}, "value_counts": {"Major": {"computer science": 4, "mathematics": 3, "physics": 3, "math": 1}, "Grade": {"10": 4, "11": 3, "12": 3, "": 1}}, "summary_stats": {"Grade": {"count": 14, "mean": 10.8, "min": 10, "max": 12}, "Attendance_pct": {"count": 12, "mean": 87.4, "min": 75, "max": 95}, "FinalScore": {"count": 13, "mean": 85.7, "min": 78, "max": 92}}, "correlations": {"Attendance_vs_FinalScore": 0.65}, "students_missing_finalscore": [{"StudentID": 106, "Name": "Fiona", "Grade": 10, "Major": "Physics", "Attendance": 80}], "finalscore_distribution_by_major": {"computer science": {"mean": 84, "count": 4}, "mathematics": {"mean": 89.3, "count": 3}, "physics": {"mean": 83, "count": 3}, "math": {"mean": 83, "count": 1}}}}
{"purpose": "Analyze public transportation ridership patterns and identify data quality issues.", "raw_table": "Route_ID,Date,Boardings,Weather,Driver_Name\n101,2023-07-01,350,sunny,John Doe\n102,07/02/2023,NaN,Rainy,Mary Smith\n103,2023/07/03,420,Cloudy,ALAN TURING\n101,2023-7-04,380,sunny,jane doe\n104,2023-07-05,invalid,Sunny,David Lee\n102,2023-07-06,410,rainy,Mary Smith\n103,7-07-2023,400,Cloudy,Alan Turing\n105,2023-07-08,NaN,clear,Robert Brown\n101,2023-07-09,360,sunny,John Doe\n104,2023-07-10,390,Sunny,David Lee\n102,2023-07-11,405,Rainy,mary smith\n105,2023-7-12,370,CLEAR,Robert Brown", "eda_steps": ["Check for missing values in each column", "Standardize date format to YYYY-MM-DD", "Convert 'Boardings' column to numeric and identify invalid entries", "Generate value counts for the 'Weather' column", "Identify unique drivers and standardize their name capitalization", "Compute summary statistics for 'Boardings'", "Identify routes with the highest average boardings", "Analyze the distribution of boardings over days"], "eda_results": {"missing_values": {"Route_ID": 0, "Date": 0, "Boardings": 2, "Weather": 0, "Driver_Name": 0}, "date_standardization": "All dates converted to YYYY-MM-DD format", "boardings_conversion": {"invalid_entries": ["invalid"], "missing_converted_to_NaN": 2, "converted_to_numeric": true}, "weather_value_counts": {"Sunny": 5, "Rainy": 3, "Cloudy": 2, "Clear": 2}, "driver_name_standardization": {"unique_drivers_before": 6, "unique_drivers_after": 4, "standardized_names": ["John Doe", "Mary Smith", "Alan Turing", "David Lee", "Robert Brown"]}, "boardings_summary_stats": {"count": 13, "mean": 386.15, "std": 25.47, "min": 350, "25%": 370, "50%": 380, "75%": 410, "max": 420}, "top_routes_by_avg_boardings": {"103": 410, "102": 405, "104": 390, "101": 363.33, "105": 370}, "boardings_over_days_distribution": "Boardings generally stable with slight peak on 2023-07-03 and 2023-07-06"}}
{"purpose": "Examine production line efficiency and defect rates to identify bottlenecks and quality issues.", "raw_table": "Production_ID,Machine,Operator,Start_Date,End_Date,Units_Produced,Defects,Shift\nP001,Press_A,alice,2023/01/10,2023-01-10,100,2,Day\nP002,press_b,Bob,01-11-2023,2023/01/11,95,,Night\nP003,Press_A,Charlie,2023-01-12,2023/01/12,110,5,day\nP004,press_C,alice,,2023-01-13,105,3,Night\nP005,Press_B,Bob,2023/01/14,2023-01-14,NaN,1,Day\nP006,Press_C,David,2023-01-15,2023/01/15,108,0,night\nP007,Press_A,Alice,2023-01-16,2023-01-16,115,4,Day\nP008,PRESS_B,charlie,2023-01-17,2023/01/17,98,2,Day\nP009,Press_C,David,2023-01-18,2023/01/18,103,,Night\nP010,Press_A,Alice,2023/01/19,2023/01/19,NaN,3,DAY", "eda_steps": ["Check missing values for each column", "Standardize capitalization for Machine, Operator, and Shift columns", "Convert Start_Date and End_Date columns to datetime format", "Compute descriptive statistics for Units_Produced and Defects columns", "Generate value counts for Machine and Shift columns", "Identify number of production runs with missing Units_Produced", "Calculate average defect rate per Machine", "Detect any inconsistent or unusual date entries"], "eda_results": {"missing_values": {"Production_ID": 0, "Machine": 0, "Operator": 0, "Start_Date": 1, "End_Date": 0, "Units_Produced": 2, "Defects": 2, "Shift": 0}, "standardized_categories": {"Machine": ["Press_A", "Press_B", "Press_C"], "Operator": ["Alice", "Bob", "Charlie", "David"], "Shift": ["Day", "Night"]}, "date_conversion_issues": {"Start_Date": ["Missing in row 4"], "End_Date": []}, "summary_stats": {"Units_Produced": {"count": 13, "mean": 104.5, "std_dev": 6.2, "min": 95, "max": 115}, "Defects": {"count": 8, "mean": 2.75, "std_dev": 1.6, "min": 0, "max": 5}}, "value_counts": {"Machine": {"Press_A": 4, "Press_B": 3, "Press_C": 3}, "Shift": {"Day": 6, "Night": 4}}, "missing_units_produced_count": 2, "average_defect_rate_per_machine": {"Press_A": 3.5, "Press_B": 1.5, "Press_C": 1.5}}}
{"purpose": "Analyze energy consumption patterns across different regions and energy sources to identify usage trends and data quality issues.", "raw_table": "Region,Energy Source,Consumption_kWh,Date,Price_per_kWh,Notes\nNorth,solar,1200,2023-01-15,0.12,normal\nsouth,Wind,1350,15/01/2023,0.11,delayed entry\nEAST,coal,NaN,2023-01-16,0.09,\nWest,solar,1100,2023/01/17,0.12,Normal\nnorth,Wind,1280,2023-01-18,missing,check meter\nSouth,Coal,1400,2023-01-19,0.10,normal\nEast,solar,1150,01-20-2023,0.12,\nWEST,Wind,NaN,2023-01-21,0.11,estimated\nnorth,coal,1300,2023-01-22,0.09,normal\nsouth,solar,1250,2023-01-23,NA,delayed\nEast,Wind,1275,2023-01-24,0.11,Normal\nwest,coal,1350,2023-01-25,0.09,Check Meter\n", "eda_steps": ["Check for missing values in all columns", "Standardize the 'Region' and 'Energy Source' categorical columns to consistent capitalization", "Parse and unify the 'Date' column into a single date format", "Compute descriptive statistics for 'Consumption_kWh' and 'Price_per_kWh'", "Generate value counts for the 'Region' and 'Energy Source' columns", "Identify entries with missing or non-numeric 'Consumption_kWh' or 'Price_per_kWh'", "Calculate the correlation between 'Consumption_kWh' and 'Price_per_kWh'", "Summarize notes to find common remarks"], "eda_results": {"missing_values": {"Region": 0, "Energy Source": 0, "Consumption_kWh": 2, "Date": 0, "Price_per_kWh": 3, "Notes": 2}, "standardized_categories": {"Region": ["North", "South", "East", "West"], "Energy Source": ["Solar", "Wind", "Coal"]}, "date_formats_unified": true, "summary_stats": {"Consumption_kWh": {"count": 12, "mean": 1262.5, "std": 71.4, "min": 1100, "max": 1400}, "Price_per_kWh": {"count": 9, "mean": 0.104, "std": 0.013, "min": 0.09, "max": 0.12}}, "value_counts": {"Region": {"North": 3, "South": 3, "East": 3, "West": 3}, "Energy Source": {"Solar": 4, "Wind": 4, "Coal": 4}}, "invalid_numeric_entries": {"Consumption_kWh": ["NaN", "NaN"], "Price_per_kWh": ["missing", "NA", ""]}, "correlations": {"Consumption_kWh_vs_Price_per_kWh": -0.15}, "notes_summary": {"normal": 5, "delayed entry": 2, "check meter": 2, "estimated": 1, "": 2}}}
{"purpose": "Analyze movie streaming platform user engagement and identify key usage patterns.", "raw_table": "User_ID,Subscription_Type,Watch_Time_Hours,Last_Login,Favorite_Genre,Rating_Given\n001,premium,15.5,2023-03-10,Action,4.5\n002,Free,,Mar 8 2023,Comedy,\n003,PREMIUM,20,2023/03/09,Drama,5\n004,free,8.2,2023-3-07,comedy,3\n005,Premium,12.7,03-11-2023,Action,4\n006,Free,5.5,2023-03-10,Documentary,3.5\n007,PREMIUM,,2023-03-10,Action,4\n008,Free,7,2023/03/08,comedy,N/A\n009,Premium,18.3,,Drama,5\n010,free,6.1,2023-03-09,action,2\n011,Premium,14.2,2023-03-11,Drama,4\n012,Free,4.8,2023-03-06,documentary,3\n013,PREMIUM,19.7,2023-03-12,Action,5\n014,,9.1,2023-03-05,Thriller,4\n015,free,3.4,2023-03-07,Horror,\n", "eda_steps": ["Check missing value percentages for each column", "Standardize subscription type capitalization and count unique types", "Parse and unify last login dates into a consistent format", "Compute descriptive statistics for watch time and rating given", "Generate value counts for favorite genres", "Identify users with missing watch time or ratings", "Calculate average watch time by subscription type", "Determine the most common last login date", "Find correlation between watch time and rating given"], "eda_results": {"missing_values": {"User_ID": 0, "Subscription_Type": 1, "Watch_Time_Hours": 2, "Last_Login": 1, "Favorite_Genre": 0, "Rating_Given": 3}, "subscription_type_counts": {"premium": 6, "free": 7, "missing": 1}, "last_login_date_range": {"earliest": "2023-03-05", "latest": "2023-03-12"}, "watch_time_stats": {"count": 13, "mean": 11.84, "std": 5.5, "min": 3.4, "max": 20.0}, "rating_given_stats": {"count": 12, "mean": 4.04, "std": 0.96, "min": 2.0, "max": 5.0}, "favorite_genre_counts": {"Action": 5, "Comedy": 3, "Drama": 3, "Documentary": 2, "Thriller": 1, "Horror": 1}, "users_missing_watch_time": ["002", "007"], "users_missing_ratings": ["002", "008", "015"], "average_watch_time_by_subscription": {"premium": 16.34, "free": 6.36, "missing": 9.1}, "most_common_last_login": "2023-03-10", "correlation_watchtime_rating": 0.67}}
{"purpose": "Analyze crop yield and irrigation practices to identify factors affecting productivity in different farms.", "raw_table": "FarmID,Crop,PlantingDate,IrrigationType,Yield_kg,SoilPH,FertilizerUsed\nF001,Wheat,2023-03-15,Drip,1200,6.5,Nitrogen\nF002,maize,15/03/2023,Flood,950,7.0,Phosphorus\nF003,Rice,,Sprinkler,1100,6.8,\nF004,Barley,2023-03-17,drip,NaN,6.3,Nitrogen\nF005,Maize,2023/03/16,Flood,980,,Potassium\nF006,wheat,2023-03-14,Drip,1250,6.7,Nitrogen\nF007,Rice,03-15-2023,sprinkler,1080,6.9,Phosphorus\nF008,SOYBEAN,2023-03-15,,890,6.5,Nitrogen\nF009,Barley,2023-03-16,Flood,1010,6.4,Potassium\nF010,Maize,2023-03-15,Drip,1000,NaN,Nitrogen", "eda_steps": ["Check for missing values in all columns", "Standardize Crop and IrrigationType column capitalization", "Parse and unify PlantingDate to YYYY-MM-DD format", "Compute descriptive statistics for numeric columns: Yield_kg and SoilPH", "Generate value counts for Crop and IrrigationType", "Identify rows with missing Yield_kg or SoilPH and quantify them", "Calculate average Yield_kg per Crop type", "Examine correlation between SoilPH and Yield_kg", "Summarize fertilizer usage frequency"], "eda_results": {"missing_values": {"PlantingDate": 1, "IrrigationType": 1, "Yield_kg": 1, "SoilPH": 2, "FertilizerUsed": 1}, "value_counts": {"Crop": {"Wheat": 2, "Maize": 3, "Rice": 2, "Barley": 2, "Soybean": 1}, "IrrigationType": {"Drip": 4, "Flood": 3, "Sprinkler": 2, "": 1}}, "descriptive_statistics": {"Yield_kg": {"count": 9, "mean": 1043.33, "std": 119.23, "min": 890, "25%": 980, "50%": 1010, "75%": 1200, "max": 1250}, "SoilPH": {"count": 8, "mean": 6.61, "std": 0.25, "min": 6.3, "25%": 6.45, "50%": 6.65, "75%": 6.85, "max": 7.0}}, "average_yield_per_crop": {"Wheat": 1225, "Maize": 976.67, "Rice": 1090, "Barley": 1010, "Soybean": 890}, "correlation_SoilPH_Yieldkg": 0.42, "top_fertilizers": {"Nitrogen": 5, "Phosphorus": 2, "Potassium": 2, "": 1}}}
{"purpose": "Analyze sales performance and customer demographics to identify trends and data quality issues.", "raw_table": "OrderID,CustomerName,ProductCategory,Quantity,Price,OrderDate,Region\n1001,alice,Electronics,2,199.99,2023-1-05,North\n1002,Bob,Clothing,,49.99,01/15/2023,South\n1003,CHARLIE,Home,1,89.5,2023/01/20,East\n1004,David,Electronics,3,199.99,2023-1-25,north\n1005,,Clothing,5,39.99,2023-01-28,West\n1006,Eva,TOYS,2,29.99,15-02-2023,South\n1007,Frank,home,1,85,02/20/2023,East\n1008,Gina,Electronics,1,NaN,2023-02-21,North\n1009,Helen,Clothing,4,44.99,,South\n1010,Ian,toys,2,30.5,2023-02-25,West\n1011,Jack,Home,NaN,95,2023-02-27,East\n1012,KATE,Clothing,3,,2023-02-28,SOUTH\n1013,Liam,Electronics,1,210.99,2023-03-01,North\n1014,Mia,Home,2,88.00,03/05/2023,East", "eda_steps": ["Check missing value percentages for all columns", "Standardize capitalization in ProductCategory and Region columns", "Compute descriptive statistics for Quantity and Price columns", "Generate value counts for ProductCategory and Region", "Convert OrderDate to a consistent date format", "Identify number of unique customers", "Calculate total sales per ProductCategory", "Detect and report any anomalies or outliers in Price"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerName": 1, "ProductCategory": 0, "Quantity": 2, "Price": 3, "OrderDate": 1, "Region": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Clothing", "Home", "Toys"], "Region": ["North", "South", "East", "West"]}, "summary_stats": {"Quantity": {"count": 12, "mean": 2.08, "std": 1.22, "min": 1, "25%": 1, "50%": 2, "75%": 3, "max": 5}, "Price": {"count": 11, "mean": 90.89, "std": 64.42, "min": 29.99, "25%": 44.99, "50%": 85, "75%": 199.99, "max": 210.99}}, "value_counts": {"ProductCategory": {"Electronics": 4, "Clothing": 4, "Home": 4, "Toys": 2}, "Region": {"North": 4, "South": 4, "East": 4, "West": 2}}, "unique_customers": 13, "total_sales_per_category": {"Electronics": 1111.95, "Clothing": 479.85, "Home": 353.5, "Toys": 120.98}, "price_anomalies": {"High_outlier": 210.99, "Missing_prices": [1008, 1012]}}}
{"purpose": "Analyze customer purchase patterns and identify data quality issues in retail transactions.", "raw_table": "TransactionID,CustomerID,PurchaseDate,ProductCategory,Quantity,UnitPrice,PaymentType\nT001,C123,2023-01-15,Electronics,2,299.99,Credit Card\nT002,c124,15/01/2023,Home & Garden,1,89.5,credit card\nT003,C125,2023/01/16,Clothing,3,,Cash\nT004,C126,,electronics,1,199.95,PayPal\nT005,C127,2023-01-17,Clothing,2,49.9,Cash\nT006,C128,17-01-2023,Toys,5,15.99,Credit card\nT007,C129,2023-01-18,home & garden,1,,Paypal\nT008,C130,2023-01-18,Books,1,12.5,Cash\nT009,C131,2023-01-19,Clothing,NaN,59.99,Credit Card\nT010,C132,2023/01/20,Electronics,1,299.99,Cash\nT011,C133,2023-01-20,Toys,2,15.99,credit Card\nT012,C134,01-21-2023,Toys,,15.99,Cash\nT013,C135,2023-01-21,Books,3,NaN,Credit Card", "eda_steps": ["Check and summarize missing values for each column", "Standardize and count unique PaymentType values", "Normalize ProductCategory capitalization and count unique categories", "Compute descriptive statistics for Quantity and UnitPrice columns", "Identify top 3 most frequent ProductCategory values", "Check the date format consistency in PurchaseDate and parse dates", "Calculate total sales amount per transaction (Quantity * UnitPrice) handling missing values", "Summarize number of transactions per PaymentType"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 0, "PurchaseDate": 1, "ProductCategory": 0, "Quantity": 3, "UnitPrice": 3, "PaymentType": 0}, "payment_type_counts": {"credit card": 5, "cash": 4, "paypal": 2}, "product_category_counts": {"electronics": 3, "home & garden": 2, "clothing": 3, "toys": 3, "books": 2}, "descriptive_statistics": {"Quantity": {"count": 10, "mean": 2.1, "std": 1.39, "min": 1, "25%": 1, "50%": 2, "75%": 3, "max": 5}, "UnitPrice": {"count": 9, "mean": 108.42, "std": 124.91, "min": 12.5, "25%": 15.99, "50%": 49.9, "75%": 199.95, "max": 299.99}}, "top_3_product_categories": ["electronics", "clothing", "toys"], "purchase_date_formats": {"YYYY-MM-DD": 8, "DD/MM/YYYY": 1, "YYYY/MM/DD": 2, "DD-MM-YYYY": 1, "missing_or_invalid": 1}, "total_sales_per_transaction": {"T001": 599.98, "T002": 89.5, "T003": null, "T004": 199.95, "T005": 99.8, "T006": 79.95, "T007": null, "T008": 12.5, "T009": null, "T010": 299.99, "T011": 31.98, "T012": null, "T013": null}, "transactions_per_payment_type": {"credit card": 5, "cash": 4, "paypal": 2}}}
{"purpose": "Analyze temperature and precipitation patterns across different climate zones to identify missing data and distribution characteristics.", "raw_table": "Date,Location,Climate_Zone,Avg_Temp_C,Precipitation_mm\n2023-01-01,New York,Temperate,3.5,5.2\n01/02/2023,los angeles,Arid,18.2,0\n2023/01/03,Chicago,Temperate,-5.1,2.3\n2023-01-04,,Temperate,NaN,3.1\n2023-01-05,Houston,Subtropical,14.3,15.5\n2023-01-06,miami,SubTropical,22.0,NaN\n2023-01-07,Phoenix,Arid,19.8,0\n2023-1-08,Anchorage,Subpolar,-12.5,1.0\n2023-01-09,Denver,Temperate,1.1,NaN\n2023-01-10,Boston,Temperate,2.8,4.8\n2023-01-11,Seattle,temperate,6.4,6.7\n2023-01-12,New York,temperate,4.0,5.0\n2023-01-13,Boston,Temperate,INVALID,3.9", "eda_steps": ["Parse and standardize the Date column to a consistent format", "Check for and quantify missing values in all columns", "Normalize capitalization in categorical columns: Location and Climate_Zone", "Convert Avg_Temp_C to numeric values, handling invalid entries", "Compute descriptive statistics (mean, median, std) for numeric columns Avg_Temp_C and Precipitation_mm", "Generate value counts for the Climate_Zone column", "Identify rows with missing Location values", "Calculate the percentage of zero precipitation days", "Summarize the distribution skewness for Avg_Temp_C"], "eda_results": {"date_parsing_issues": 0, "missing_values": {"Date": 0, "Location": 1, "Climate_Zone": 0, "Avg_Temp_C": 2, "Precipitation_mm": 3}, "location_normalized_samples": ["New York", "Los Angeles", "Chicago", "Houston", "Miami", "Phoenix", "Anchorage", "Denver", "Boston", "Seattle"], "climate_zone_value_counts": {"Temperate": 8, "Arid": 2, "Subtropical": 2, "Subpolar": 1}, "avg_temp_numeric_conversion": {"invalid_entries": 1, "converted_missing_due_to_invalid": 1}, "avg_temp_stats": {"mean": 6.77, "median": 4.0, "std_dev": 10.15}, "precipitation_stats": {"mean": 4.94, "median": 3.9, "std_dev": 5.19, "zero_precip_days_percentage": 15.4}, "rows_missing_location": 1, "avg_temp_skewness": 0.85}}
{"purpose": "Analyze housing market data to understand price distribution and attribute relationships", "raw_table": "PropertyID,Location,Price,Bedrooms,Bathrooms,Size_sqft,ListedDate,PropertyType\n1001,downtown,350000,3,2,1450,2023-01-15,Condo\n1002,Suburb,450000,4,3,2000,01/20/2023,Single Family\n1003,suburb,NaN,3,,1800,2023-02-01,Single-family\n1004,Midtown,375000,2,2,1300,15-02-2023,condo\n1005,DOWNTOWN,500000,4,3,2100,2023/02/20,Apartment\n1006,Suburb,420000,3,2,1700,,single family\n1007,Midtown,390000,3,2,1600,2023-03-01,Condo\n1008,Downtown,NaN,2,1,1100,2023-03-10,Apartment\n1009,Suburb,460000,4,3,2050,03-15-2023,Single_family\n1010,Midtown,385000,3,2,1580,2023-03-20,Condo\n1011,Suburb,,3,2,1750,2023-04-01,Single Family\n1012,Downtown,470000,3,2,,2023-04-05,apartment\n1013,Midtown,380000,2,2,1400,2023-04-10,Condo\n1014,suburb,440000,4,3,1950,2023-04-15,Single Family", "eda_steps": ["Check for and quantify missing values in each column", "Standardize Location and PropertyType column capitalization", "Compute descriptive statistics for numeric columns: Price, Bedrooms, Bathrooms, Size_sqft", "Generate value counts for categorical columns: Location, PropertyType", "Identify date format inconsistencies in ListedDate and standardize to YYYY-MM-DD", "Calculate correlation matrix for numeric features including Price", "Identify top 2 locations by number of listings", "Summarize distribution skewness for Price and Size_sqft", "Examine relationship between Bedrooms and Price using group means"], "eda_results": {"missing_values": {"Price": 3, "Bedrooms": 0, "Bathrooms": 2, "Size_sqft": 2, "ListedDate": 1}, "value_counts": {"Location": {"Downtown": 4, "Suburb": 5, "Midtown": 5}, "PropertyType": {"Condo": 5, "Single Family": 6, "Apartment": 3}}, "summary_stats": {"Price": {"count": 11, "mean": 419545.45, "std": 48130.45, "min": 350000, "25%": 380000, "50%": 420000, "75%": 460000, "max": 500000, "skewness": 0.25}, "Bedrooms": {"count": 14, "mean": 3.21, "std": 0.83, "min": 2, "max": 4}, "Bathrooms": {"count": 12, "mean": 2.21, "std": 0.6, "min": 1, "max": 3}, "Size_sqft": {"count": 12, "mean": 1705.83, "std": 320.14, "min": 1100, "max": 2100, "skewness": 0.1}}, "correlations": {"Price": {"Bedrooms": 0.85, "Bathrooms": 0.78, "Size_sqft": 0.9}}, "top_categories": {"Location": ["Suburb", "Midtown"], "PropertyType": ["Single Family", "Condo"]}, "date_standardization": {"formats_found": ["YYYY-MM-DD", "MM/DD/YYYY", "DD-MM-YYYY", "YYYY/MM/DD", "MM-DD-YYYY"], "standardized": true}, "bedrooms_price_relationship": {"2_bedrooms_mean_price": 371250, "3_bedrooms_mean_price": 410000, "4_bedrooms_mean_price": 462500}}}
{"purpose": "Analyze user ratings and genre distribution of a recent movie streaming platform dataset.", "raw_table": "MovieID,Title,Genre,UserRating,ReleaseDate,Duration_Minutes\n1,The great Escape,Action,8.2,2023-01-15,125\n2,Love in Times,Romance,7.5,2023/02/28, Ninety\n3,Shadow Realm,thriller,8.7,15-03-2023,110\n4,Comedy Nights,Comedy,6.9,,95\n5,The great escape,Action,8.4,2023-01-15,125\n6,Unknown,Drama,missing,2023/04/01,130\n7,Lost in Space,SCI-FI,7.8,2023-05-12,140\n8,Love in times,Romance,7.6,2023-02-28,90\n9,Shadow realm,Thriller,8.8,2023-03-15,110\n10,Comic Relief,comedy,7.0,2023/06/05,98\n11,Space Odyssey,Sci-fi,8.1,2023-05-12, 142\n12,Drama Queen,Drama,7.3,April 10 2023,120\n13,Unknown,Drama,7.0,2023-04-01,130\n14,THE GREAT ESCAPE,action,8.3,2023-01-15,125", "eda_steps": ["Standardize the Genre column capitalization", "Parse ReleaseDate to a consistent date format", "Convert Duration_Minutes to numeric, handling non-numeric entries", "Identify and count missing values per column", "Compute descriptive statistics for UserRating and Duration_Minutes", "Generate value counts for the Genre column", "Identify duplicate movie entries by Title and ReleaseDate", "Calculate the average UserRating by Genre", "List top 3 longest movies by Duration_Minutes"], "eda_results": {"missing_values": {"MovieID": 0, "Title": 0, "Genre": 0, "UserRating": 1, "ReleaseDate": 1, "Duration_Minutes": 1}, "standardized_genres_value_counts": {"Action": 3, "Romance": 2, "Thriller": 2, "Comedy": 2, "Drama": 3, "Sci-Fi": 2}, "parsed_dates_format": {"earliest": "2023-01-15", "latest": "2023-06-05"}, "duration_minutes_numeric": {"converted_non_numeric": ["Ninety"], "mean_duration": 117.5, "min_duration": 90, "max_duration": 142}, "user_rating_stats": {"count": 13, "mean": 7.68, "min": 6.9, "max": 8.8, "std_dev": 0.57}, "duplicate_movies": [{"Title": "The great Escape", "ReleaseDate": "2023-01-15", "count": 3}, {"Title": "Love in Times", "ReleaseDate": "2023-02-28", "count": 2}, {"Title": "Shadow Realm", "ReleaseDate": "2023-03-15", "count": 2}, {"Title": "Unknown", "ReleaseDate": "2023-04-01", "count": 2}], "average_user_rating_by_genre": {"Action": 8.3, "Romance": 7.55, "Thriller": 8.75, "Comedy": 6.95, "Drama": 7.15, "Sci-Fi": 7.95}, "top_3_longest_movies": [{"Title": "Space Odyssey", "Duration_Minutes": 142}, {"Title": "Lost in Space", "Duration_Minutes": 140}, {"Title": "Unknown", "Duration_Minutes": 130}]}}
{"purpose": "Examine patient demographics and vital signs to identify missing data patterns and common conditions in a small clinical dataset.", "raw_table": "Patient_ID,Age,Gender,Admission_Date,Diagnosis,Blood_Pressure,Heart_Rate,Temperature\n001,45,Male,2023-01-15,Hypertension,130/85,78,98.6\n002,38,Female,15/02/2023,diabetes,120/80,82,99.1\n003,,male,2023/03/10,Asthma,110/70,missing,98.4\n004,52,FEMALE,April 5, 2023,hypertension,140/90,88,99.5\n005,29,Female,2023-05-12,Diabetes,,75,97.9\n006,64,Male,2023-06-01,Heart Disease,150/95,85,\n007,47,,2023-07-20,asthma,115/75,80,98.8\n008,51,Female,2023/08/15,Hypertension,135/88,missing,99.0\n009,36,Male,08-20-2023,diabetes,125/82,78,98.5\n010,58,Female,2023-09-10,,130/85,77,98.7\n011,44,Male,2023-10-05,Asthma,118/76,83,99.2\n012,50,Female,2023-11-11,hypertension,140/92,90,missing", "eda_steps": ["Check the data types and formats for each column", "Identify and count missing values in each column", "Standardize the 'Diagnosis' column capitalization", "Compute descriptive statistics for numeric columns: Age, Heart_Rate, Temperature", "Extract systolic and diastolic values from Blood_Pressure and summarize them", "Generate value counts for Gender and Diagnosis", "Analyze the distribution of Admission_Date formats and convert to a uniform format", "Calculate correlation coefficients between Age, Heart_Rate, Temperature, and Blood Pressure components", "Identify patients with missing vital sign data"], "eda_results": {"missing_values": {"Age": 1, "Gender": 1, "Admission_Date": 0, "Diagnosis": 1, "Blood_Pressure": 1, "Heart_Rate": 2, "Temperature": 2}, "value_counts": {"Gender": {"Female": 6, "Male": 5, "": 1}, "Diagnosis": {"Hypertension": 5, "Diabetes": 3, "Asthma": 3, "Heart Disease": 1, "": 1}}, "standardized_diagnosis": ["Hypertension", "Diabetes", "Asthma", "Hypertension", "Diabetes", "Heart Disease", "Asthma", "Hypertension", "Diabetes", "", "Asthma", "Hypertension"], "age_stats": {"count": 14, "mean": 47.9, "std": 10.4, "min": 29, "max": 64}, "heart_rate_stats": {"count": 12, "mean": 81.0, "std": 5.1, "min": 75, "max": 90}, "temperature_stats": {"count": 10, "mean": 98.9, "std": 0.55, "min": 97.9, "max": 99.5}, "blood_pressure_systolic": {"count": 13, "mean": 130.7, "std": 11.7, "min": 110, "max": 150}, "blood_pressure_diastolic": {"count": 13, "mean": 83.3, "std": 7.5, "min": 70, "max": 95}, "admission_date_formats": {"YYYY-MM-DD": 8, "DD/MM/YYYY": 1, "YYYY/MM/DD": 2, "Month D, YYYY": 1, "MM-DD-YYYY": 1}, "correlations": {"Age_vs_Systolic_BP": 0.62, "Age_vs_Heart_Rate": -0.15, "Temperature_vs_Heart_Rate": 0.3}, "patients_missing_vitals": ["003", "005", "006", "007", "008", "012"]}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones to identify data quality issues and basic trends.", "raw_table": "Date,Location,Climate_Zone,Temperature_C,Precipitation_mm\n2024-01-01,New York,temperate,3.2,12\n01/15/2024,los angeles,arid,18.5,0\n2024/02/01,Chicago,Temperate,,8\n2024-02-15,Houston,Subtropical,15.0,25\n2024-03-01,Phoenix,Arid,22.3,NaN\n2024-03-15,new york,temperate,7,14\n2024-04-01,Chicago,Temperate,10.5,20\n04/15/2024,Houston,subtropical,18,30\n2024-05-01,Phoenix,Arid,28.1,0\n2024-05-15,Los Angeles,arid,21.7,1\n2024-06-01,New York,temperate,25.0,5\n2024-06-15,Houston,Subtropical,27.3,18\n2024-07-01,phoenix,arid,35.2,0\n2024-07-15,Chicago,Temperate,29.0,12", "eda_steps": ["Standardize capitalization in Location and Climate_Zone columns", "Parse and unify Date column formats into a consistent datetime format", "Check for missing values and their proportions in each column", "Compute descriptive statistics for Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone", "Identify top 3 locations with the highest average temperature", "Calculate correlation between Temperature_C and Precipitation_mm"], "eda_results": {"missing_values": {"Date": 0, "Location": 0, "Climate_Zone": 0, "Temperature_C": 1, "Precipitation_mm": 1}, "value_counts": {"Climate_Zone": {"temperate": 5, "arid": 5, "subtropical": 3}}, "summary_stats": {"Temperature_C": {"count": 13, "mean": 19.6, "std": 9.7, "min": 3.2, "25%": 10.5, "50%": 18.5, "75%": 27.3, "max": 35.2}, "Precipitation_mm": {"count": 13, "mean": 11.5, "std": 11.3, "min": 0, "25%": 0, "50%": 8, "75%": 18, "max": 30}}, "top_categories": {"Highest_avg_temperature_locations": {"Phoenix": 30.2, "Houston": 20.8, "Los Angeles": 20.1}}, "correlations": {"Temperature_vs_Precipitation": -0.42}}}
{"purpose": "Analyze crop yield variations and planting patterns across different farms and crop types.", "raw_table": "Farm_ID,Crop_Type,Planting_Date,Yield_kg,Soil_Quality,Fertilizer_Type\nF001,Wheat,2023/03/15,1200,High,organic\nF002,corn,15-04-2023,950,medium,Chemical\nF003,Rice,2023-05-01,,Low,Organic\nF004,wheat,04/20/2023,1100,MediuM,chem\nF005,Barley,2023/03/25,870,high,Organic\nF006,Corn,2023/04/18,980,,chemical\nF007,rice,2023-05-05,1020,Low,organic\nF008,Wheat,,1150,HIGH,Organic\nF009,Barley,2023/03/30,890,Medium,chem\nF010,corn,04/22/2023,920,medium,Chemical\nF011,Rice,2023-05-10,1005,Low,Organic\nF012,Wheat,2023/03/18,1180,High,organic", "eda_steps": ["Check for missing values in all columns", "Standardize capitalization in categorical columns Crop_Type, Soil_Quality, and Fertilizer_Type", "Parse and unify Planting_Date into YYYY-MM-DD format", "Compute descriptive statistics for Yield_kg", "Generate value counts for Crop_Type and Fertilizer_Type", "Calculate the percentage of missing Yield_kg values per Crop_Type", "Identify correlation between Soil_Quality (encoded ordinally) and Yield_kg", "Summarize the distribution of Planting_Date over months"], "eda_results": {"missing_values": {"Farm_ID": 0, "Crop_Type": 0, "Planting_Date": 1, "Yield_kg": 1, "Soil_Quality": 1, "Fertilizer_Type": 0}, "standardized_categories": {"Crop_Type": {"Wheat": 4, "Corn": 3, "Rice": 3, "Barley": 2}, "Soil_Quality": {"High": 4, "Medium": 4, "Low": 3, "Missing": 1}, "Fertilizer_Type": {"Organic": 6, "Chemical": 5}}, "planting_dates_parsed": ["2023-03-15", "2023-04-15", "2023-05-01", "2023-04-20", "2023-03-25", "2023-04-18", "2023-05-05", null, "2023-03-30", "2023-04-22", "2023-05-10", "2023-03-18"], "yield_kg_stats": {"count": 11, "mean": 1019.55, "std": 123.43, "min": 870, "25%": 920, "50%": 980, "75%": 1150, "max": 1200}, "crop_type_value_counts": {"Wheat": 4, "Corn": 3, "Rice": 3, "Barley": 2}, "fertilizer_type_value_counts": {"Organic": 6, "Chemical": 5}, "missing_yield_by_crop": {"Wheat": 0, "Corn": 0, "Rice": 1, "Barley": 0}, "soil_quality_encoding": {"High": 3, "Medium": 2, "Low": 1, "Missing": 0}, "correlation_soil_yield": 0.62, "planting_month_distribution": {"March": 4, "April": 4, "May": 3, "Missing": 1}}}
{"purpose": "Analyze user engagement patterns on a social media platform over a two-week period.", "raw_table": "UserID,PostDate,PostType,Likes,Shares,Comments\nu101,2024/04/01,photo,15,2,5\nU102,2024-04-01,video,25,,8\nu103,04-02-2024,text,5,0,2\nU104,,link,8,1,nan\nu105,2024-4-03,Photo,20,3,7\nu106,2024/04/03,video,NaN,5,9\nU107,2024-04-04,text,12,,4\nu108,2024-04-05,Live,18,2,6\nU109,2024/04/05,video,22,3,NaN\nU110,2024-4-06,photo,30,5,10\nu111,04-07-2024,link,NaN,0,3\nU112,2024/04/07,Text,10,1,1\nu113,2024/04/08,video,28,4,8\nu114,2024/04/08,PHOTO,35,,12", "eda_steps": ["Check for and count missing values in all columns", "Standardize PostDate column to a single date format", "Normalize PostType values to lowercase", "Compute descriptive statistics for Likes, Shares, and Comments columns", "Generate value counts for PostType to identify the most common post types", "Calculate the average Likes per PostType", "Identify users with missing PostDate or Likes values", "Summarize the distribution of Shares and Comments to check skewness", "Check correlation between Likes, Shares, and Comments"], "eda_results": {"missing_values": {"UserID": 0, "PostDate": 1, "PostType": 0, "Likes": 3, "Shares": 4, "Comments": 2}, "standardized_dates": ["2024-04-01", "2024-04-01", "2024-04-02", null, "2024-04-03", "2024-04-03", "2024-04-04", "2024-04-05", "2024-04-05", "2024-04-06", "2024-04-07", "2024-04-07", "2024-04-08", "2024-04-08"], "normalized_posttype_counts": {"photo": 4, "video": 4, "text": 3, "link": 2, "live": 1}, "descriptive_stats": {"Likes": {"count": 11, "mean": 19.64, "std": 9.11, "min": 5, "25%": 12, "50%": 20, "75%": 28, "max": 35}, "Shares": {"count": 10, "mean": 2.1, "std": 1.84, "min": 0, "25%": 1, "50%": 2, "75%": 3, "max": 5}, "Comments": {"count": 12, "mean": 6.25, "std": 3.24, "min": 1, "25%": 4, "50%": 6, "75%": 8, "max": 12}}, "average_likes_per_posttype": {"photo": 25, "video": 25.75, "text": 9, "link": 8, "live": 18}, "users_missing_critical": ["u104 (missing PostDate)", "u106 (missing Likes)", "u111 (missing Likes)"], "shares_comments_skewness": {"Shares": 0.75, "Comments": 0.42}, "correlations": {"Likes_Shares": 0.89, "Likes_Comments": 0.85, "Shares_Comments": 0.78}}}
{"purpose": "Analyze monthly temperature and precipitation patterns across different climate zones to understand seasonal variability.", "raw_table": "Date,Climate_Zone,Avg_Temperature_C,Precipitation_mm,Humidity_Percent\n01-Jan-2023,tropical,29.5,120.3,85\n2023/02/01,TROPICAL,30.1,NaN,88\n03-01-2023,Temperate,5.6,45.2,70\n2023-04-01,temperate,12.4,30.0,65\n05/01/2023,polar,-15.2,5.0,90\n2023-06-01,Polar,-13.8,,92\n07-01-2023,temperate,18.3,20.5,60\n2023/08/01,tropical,28.9,150.0,87\n09/01/2023,unknown,22.0,NaN,80\n2023-10-01,polar,-10.5,7.2,88\n11/01/2023,temperate,7.8,40.0,68\n12/01/2023,tropical,31.2,110.5,90", "eda_steps": ["Check and report missing values for all columns", "Standardize Climate_Zone values to lowercase", "Parse Date column into a consistent datetime format", "Compute descriptive statistics for Avg_Temperature_C and Precipitation_mm", "Generate value counts for Climate_Zone", "Calculate average humidity by Climate_Zone", "Identify months with highest average precipitation", "Examine correlation between temperature and humidity"], "eda_results": {"missing_values": {"Avg_Temperature_C": 0, "Precipitation_mm": 3, "Humidity_Percent": 0, "Climate_Zone": 0, "Date": 0}, "value_counts": {"climate_zone": {"tropical": 4, "temperate": 4, "polar": 3, "unknown": 1}}, "summary_stats": {"Avg_Temperature_C": {"count": 12, "mean": 13.425, "std": 17.96, "min": -15.2, "25%": 5.6, "50%": 12.4, "75%": 28.9, "max": 31.2}, "Precipitation_mm": {"count": 9, "mean": 54.3, "std": 58.1, "min": 5.0, "25%": 20.5, "50%": 40.0, "75%": 120.3, "max": 150.0}}, "avg_humidity_by_zone": {"tropical": 87.5, "temperate": 65.75, "polar": 90, "unknown": 80}, "months_highest_precipitation": [{"month": "August", "precipitation_mm": 150.0}, {"month": "January", "precipitation_mm": 120.3}, {"month": "December", "precipitation_mm": 110.5}], "correlation_temperature_humidity": -0.62}}
{"purpose": "Analyze user engagement patterns on a social media platform to identify trends in post interactions and activity levels.", "raw_table": "user_id,post_date,post_type,likes,comments,shares\n101,2023/01/05,photo,25,5,2\n102,2023-1-07,Video,30,,1\n103,01-10-2023,text,NaN,1,0\n104,2023-01-11,PHOTO,15,3,NaN\n105,,video,45,7,4\n106,2023-01-13,link,10,0,0\n107,2023-01-14,Text,5,,1\n108,2023/01/15,video,50,10,5\n109,2023-01-16,Photo,NaN,NA,2\n110,2023-01-17,video,35,6,3\n111,2023-01-18,Poll,20,4,1\n112,2023-01-19,video,abc,8,2", "eda_steps": ["Check the percentage of missing values in each column", "Standardize the capitalization in the post_type column", "Convert post_date to a consistent date format and identify missing dates", "Compute summary statistics for the numeric columns: likes, comments, and shares", "Identify and handle non-numeric or invalid values in numeric columns", "Generate value counts for post_type to find the most common post types", "Calculate the average likes, comments, and shares per post_type", "Examine correlations between likes, comments, and shares", "Identify posts with zero interactions and their distribution across post types"], "eda_results": {"missing_values": {"user_id": 0, "post_date": 1, "post_type": 0, "likes": 2, "comments": 3, "shares": 1}, "post_type_standardized_counts": {"photo": 4, "video": 5, "text": 2, "link": 1, "poll": 1}, "post_date_missing_rows": [5], "summary_stats": {"likes": {"count": 10, "mean": 27.5, "median": 27.5, "min": 5, "max": 50}, "comments": {"count": 9, "mean": 4.9, "median": 5, "min": 0, "max": 10}, "shares": {"count": 10, "mean": 1.9, "median": 1.5, "min": 0, "max": 5}}, "invalid_likes_rows": [12], "average_interactions_per_post_type": {"photo": {"likes": 20, "comments": 3, "shares": 1.5}, "video": {"likes": 40, "comments": 7, "shares": 3.25}, "text": {"likes": 5, "comments": 0.5, "shares": 0.5}, "link": {"likes": 10, "comments": 0, "shares": 0}, "poll": {"likes": 20, "comments": 4, "shares": 1}}, "correlations": {"likes_comments": 0.9, "likes_shares": 0.85, "comments_shares": 0.88}, "zero_interactions_posts": {"likes": 0, "comments": 1, "shares": 2, "distribution_across_post_type": {"photo": 1, "video": 1, "text": 1}}}}
{"purpose": "Explore patient demographics and lab test results to identify data quality issues and summarize key statistics.", "raw_table": "PatientID,Age,Gender,Diagnosis,AdmissionDate,Cholesterol,Glucose\n001,45,Male,Hypertension,2023/01/15,200,105\n002,Thirty,Female,diabetes,15-02-2023,NaN,110\n003,60,male,Asthma,2023-03-10,180,NaN\n004,54,Female,,2023/04/05,210,130\n005,49,Other,Hypertension,2023-04-20,190,115\n006,38,FEMALE,Diabetes,04/25/2023,NaN,100\n007,NaN,Male,hypertension,2023-05-01,220,140\n008,50,M,Diabetes,,185,NaN\n009,62,Female,ASTHMA,2023-06-10,195,125\n010,55,Female,Hypertension,2023/06/15,205,135", "eda_steps": ["Check data types and identify inconsistent or incorrect types in Age and Gender columns", "Calculate missing value percentages for each column", "Standardize Gender entries to consistent categories", "Standardize Diagnosis categories to title case", "Parse AdmissionDate into a standard date format and identify missing dates", "Compute basic descriptive statistics for numeric columns: Age, Cholesterol, and Glucose", "Generate value counts for the Diagnosis column", "Identify correlation between Cholesterol and Glucose levels"], "eda_results": {"data_types_issues": {"Age": ["Entry 'Thirty' is non-numeric", "One missing value"], "Gender": ["Mixed capitalization", "Entry 'M' ambiguous"]}, "missing_values": {"Age": 1, "Gender": 0, "Diagnosis": 1, "AdmissionDate": 1, "Cholesterol": 2, "Glucose": 2}, "standardized_gender": {"male": 4, "female": 4, "other": 1, "unknown": 1}, "standardized_diagnosis": {"Hypertension": 4, "Diabetes": 3, "Asthma": 2, "Unknown": 1}, "admission_date_parsing": {"valid_dates": 9, "missing_dates": 1, "formats_detected": ["YYYY/MM/DD", "DD-MM-YYYY", "YYYY-MM-DD", "MM/DD/YYYY"]}, "descriptive_statistics": {"Age": {"count": 9, "mean": 51.4, "min": 38, "max": 62}, "Cholesterol": {"count": 8, "mean": 198.125, "min": 180, "max": 220}, "Glucose": {"count": 8, "mean": 118.75, "min": 100, "max": 140}}, "diagnosis_value_counts": {"Hypertension": 4, "Diabetes": 3, "Asthma": 2, "Unknown": 1}, "correlations": {"Cholesterol_Glucose": 0.87}}}
{"purpose": "Explore patient demographics and lab results to identify data quality issues and summarize key health indicators.", "raw_table": "PatientID,Gender,Age,Diagnosis,AdmissionDate,Cholesterol,Glucose\nP001,Male,45,Hypertension,2023-01-15,210,85\nP002,Female,38,diabetes,15/02/2023,NaN,98\nP003,,50,Hypertension,2023/03/05,195,NaN\nP004,FEMALE,27,Asthma,04-03-2023,180,88\nP005,Male,n/a,Hypertension,2023-04-12,220,105\nP006,Female,33,Diabetes,2023-04-15,NaN,102\nP007,Male,48,Asthma,2023-03-22,199,89\nP008,Female,41,hypertension,03/25/2023,205,92\nP009,Male,29,COPD,2023-02-28,210,NaN\nP010,female,35,COPD,2023-04-01,198,90\nP011,Male,NaN,Diabetes,2023-01-30,215,100\nP012,Female,44,Asthma,,190,95", "eda_steps": ["Check and report missing values for each column", "Standardize the 'Gender' column capitalization", "Parse and unify 'AdmissionDate' into a consistent date format", "Compute descriptive statistics (mean, median, std) for 'Age', 'Cholesterol', and 'Glucose'", "Generate value counts for the 'Diagnosis' column", "Identify rows with inconsistent or missing 'Age' values", "Calculate correlation between 'Cholesterol' and 'Glucose'", "Find top 2 most common diagnoses"], "eda_results": {"missing_values": {"PatientID": 0, "Gender": 1, "Age": 2, "Diagnosis": 0, "AdmissionDate": 1, "Cholesterol": 3, "Glucose": 3}, "standardized_gender_counts": {"Male": 5, "Female": 6, "Missing": 1}, "parsed_admission_dates": {"formatted_dates": ["2023-01-15", "2023-02-15", "2023-03-05", "2023-03-04", "2023-04-12", "2023-04-15", "2023-03-22", "2023-03-25", "2023-02-28", "2023-04-01", "2023-01-30", null]}, "descriptive_statistics": {"Age": {"mean": 38.9, "median": 40.0, "std": 7.9}, "Cholesterol": {"mean": 202.6, "median": 201.5, "std": 13.2}, "Glucose": {"mean": 93.3, "median": 90.0, "std": 6.8}}, "diagnosis_value_counts": {"Hypertension": 4, "Diabetes": 3, "Asthma": 3, "COPD": 2}, "rows_with_missing_or_invalid_age": ["P005", "P011"], "choles_glucose_correlation": 0.81, "top_2_diagnoses": ["Hypertension", "Diabetes"]}}
{"purpose": "Analyze streaming platform movie viewership patterns and data quality issues.", "raw_table": "MovieID,Title,Genre,ReleaseDate,Views,Rating,UserReviews\n1,The Great Escape,Action,2020-05-15,150000,4.5,1200\n2,romantic tales,romance,15/03/2019,95000,,850\n3,Space Odyssey,Sci-Fi,20181201,230000,4.8,2100\n4,Comedy Nights,comedy,2019-11-07,87000,3.9,missing\n5,Horror House,HORROR,07-15-2021, ,3.5,450\n6,The Last Dance,Drama,2021/02/28,120000,4.1,900\n7,Animated Fun,Animation,,78000,4.0,700\n8,THE GREAT ESCAPE,Action,2020-5-15,152000,4.6,1250\n9,Silent Whisper,Thriller,2020-08-30,89000,missing,600\n10,Romantic Tales,Romance,2019-03-15,99000,4.2,880\n11,Space Odyssey,sci-fi,2018-12-01,,4.7,2050", "eda_steps": ["Check the data types of each column", "Identify and count missing values per column", "Standardize the Genre column capitalization", "Parse and unify ReleaseDate format to YYYY-MM-DD", "Compute descriptive statistics for Views and Rating columns", "Generate value counts for the Genre column", "Identify duplicate movie entries by Title ignoring case", "Calculate average Rating per Genre", "Summarize the distribution of UserReviews including missing or non-numeric values"], "eda_results": {"data_types": {"MovieID": "integer", "Title": "string", "Genre": "string", "ReleaseDate": "string", "Views": "string", "Rating": "string", "UserReviews": "string"}, "missing_values": {"ReleaseDate": 1, "Views": 2, "Rating": 2, "UserReviews": 1}, "standardized_genres": {"Action": 2, "Romance": 2, "Sci-Fi": 2, "Comedy": 1, "Horror": 1, "Drama": 1, "Animation": 1, "Thriller": 1}, "parsed_release_dates": ["2020-05-15", "2019-03-15", "2018-12-01", "2019-11-07", "2021-07-15", "2021-02-28", null, "2020-05-15", "2020-08-30", "2019-03-15", "2018-12-01"], "views_stats": {"count": 9, "mean": 118555.56, "min": 78000, "max": 230000, "missing": 2}, "rating_stats": {"count": 9, "mean": 4.26, "min": 3.5, "max": 4.8, "missing": 2}, "genre_value_counts": {"Action": 2, "Romance": 2, "Sci-Fi": 2, "Comedy": 1, "Horror": 1, "Drama": 1, "Animation": 1, "Thriller": 1}, "duplicate_titles": ["The Great Escape", "Romantic Tales", "Space Odyssey"], "average_rating_per_genre": {"Action": 4.55, "Romance": 4.2, "Sci-Fi": 4.75, "Comedy": 3.9, "Horror": 3.5, "Drama": 4.1, "Animation": 4.0, "Thriller": null}, "user_reviews_summary": {"count": 10, "missing_or_non_numeric": 1, "mean": 1078, "min": 450, "max": 2100}}}
{"purpose": "Analyze crop yield patterns and field conditions to identify factors influencing productivity.", "raw_table": "Field_ID,Crop,Planting_Date,Harvest_Date,Yield_kg,Soil_Type,Irrigation,Notes\nF001,Corn,2023-03-15,2023-09-20,1200,Clay,yes,Good growth\nF002,WHEAT,15/03/2023,20-09-2023,980,Sandy,No, \nF003,Rice,2023/03/17,,1100,Loam,YES,late planting\nF004,barley,03-16-2023,09/21/2023,870,clay,,Pest issues\nF005,corn,2023-03-18,2023-09-22,NaN,Sandy,yes,\nF006,Rice,17 Mar 2023,21 Sep 2023,1150,Loam,Yes,\nF007,Barley,2023-03-16,2023-09-20,890,Clay,No, \nF008,Corn,2023-03-20,2023-09-26,1250,Clay,YES,excellent yield\nF009,Wheat,2023-03-14,2023-09-19,1000,SANDY,No, \nF010,Rice,Mar 18 2023,Sep 22 2023,1120,Loam,yes,\nF011,Corn,2023-03-21,2023-09-27,1300,sandY,yes,\nF012,,2023-03-19,2023-09-23,900,Clay,No,missing crop\nF013,Barley,2023-03-17,2023-09-24,880,Clay,No, \n", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize Crop names capitalization", "Parse and standardize date formats for Planting_Date and Harvest_Date", "Calculate the duration between Planting_Date and Harvest_Date for each record", "Compute descriptive statistics for Yield_kg including mean, median, and standard deviation", "Generate value counts for Soil_Type and Irrigation columns", "Identify records with missing or inconsistent Crop information", "Analyze the correlation between Yield_kg and irrigation status", "Summarize notes to identify common field issues"], "eda_results": {"missing_values": {"Field_ID": 0, "Crop": 1, "Planting_Date": 0, "Harvest_Date": 1, "Yield_kg": 1, "Soil_Type": 0, "Irrigation": 1, "Notes": 3}, "standardized_crops": {"Corn": 4, "Wheat": 2, "Rice": 3, "Barley": 3, "Missing": 1}, "date_parsing_issues": {"Planting_Date": 0, "Harvest_Date": 1}, "duration_days": {"min": 184, "max": 192, "mean": 188.5, "median": 189}, "yield_stats": {"count": 12, "mean": 1057.5, "median": 1000, "std_dev": 147.2, "min": 870, "max": 1300}, "soil_type_counts": {"Clay": 6, "Sandy": 4, "Loam": 3}, "irrigation_counts": {"Yes": 7, "No": 4, "Missing": 2}, "yield_vs_irrigation_avg": {"Yes": 1132.9, "No": 911.4}, "notes_summary": {"Good growth": 1, "Pest issues": 1, "Late planting": 1, "Excellent yield": 1, "Missing or blank": 7}}}
{"purpose": "Analyze property listing characteristics and data quality in a real estate dataset.", "raw_table": "Listing_ID,Price,Location,Property_Type,Bedrooms,Bathrooms,Listing_Date,Agent\n1001,350000,Downtown,residence,3,2,2023-01-15,John Doe\n1002,NaN,Uptown,Apartment,2,,01/20/2023,jane smith\n1003,420000,Suburbs,Condo,3,2,2023/01/25,ANN LEE\n1004,375000,downtown,Residence,3,2.5,15-01-2023,John Doe\n1005,NaN,midtown,Apartment,2,1,2023-01-30,Mary-Jane\n1006,500000,Suburbs,condo,,3,2023-02-01,Ann Lee\n1007,430000,Uptown,Apartment ,2,1,2023-02-05,Jane Smith\n1008,390000,MIDTOWN,Residence,3,,02/07/2023,Mary-jane\n1009,NaN,Downtown,Residence,3,2,2023-01-18,John Doe\n1010,410000,Uptown,Apartment,2,1,2023-02-10,Jane Smith", "eda_steps": ["Check missing value percentages for all columns", "Standardize capitalization in categorical columns: Location, Property_Type, Agent", "Convert Listing_Date to a consistent date format", "Compute descriptive statistics for Price, Bedrooms, and Bathrooms", "Generate value counts for Location and Property_Type", "Identify listings with missing Prices", "Calculate correlation between Price and number of Bedrooms and Bathrooms", "Determine top agents by number of listings"], "eda_results": {"missing_values": {"Price": 3, "Location": 0, "Property_Type": 0, "Bedrooms": 1, "Bathrooms": 3, "Listing_Date": 0, "Agent": 0}, "standardized_categories": {"Location": ["Downtown", "Uptown", "Suburbs", "Midtown"], "Property_Type": ["Residence", "Apartment", "Condo"], "Agent": ["John Doe", "Jane Smith", "Ann Lee", "Mary-Jane"]}, "listing_date_format": "All dates converted to YYYY-MM-DD", "summary_stats": {"Price": {"count": 7, "mean": 417142.86, "min": 350000, "max": 500000, "std_dev": 53615.53}, "Bedrooms": {"count": 9, "mean": 2.67, "min": 2, "max": 3, "std_dev": 0.49}, "Bathrooms": {"count": 7, "mean": 1.79, "min": 1, "max": 3, "std_dev": 0.68}}, "value_counts": {"Location": {"Downtown": 3, "Uptown": 3, "Suburbs": 2, "Midtown": 2}, "Property_Type": {"Residence": 4, "Apartment": 4, "Condo": 2}}, "listings_missing_price": ["1002", "1005", "1009"], "correlations": {"Price_Bedrooms": 0.87, "Price_Bathrooms": 0.71}, "top_agents": {"John Doe": 3, "Jane Smith": 3, "Ann Lee": 2, "Mary-Jane": 2}}}
{"purpose": "Analyze ridership patterns and trip durations across different transportation modes in a metropolitan area.", "raw_table": "Trip_ID,Start_Date,End_Date,Mode,Duration_Minutes,Passenger_Count,Route_Code\nT001,2024-03-01,2024-03-01 08:15,Bus,45,2,R12\nT002,03/02/2024,2024-03-02 09:05,SubWay,30,1,R07\nT003,2024-3-03,2024-03-03 07:50,Bus, ,3,r12\nT004,2024-03-04,2024-03-04 10:00,Train,60, ,T1\nT005,2024/03/05,2024-03-05 08:40,BUS,50,1,r15\nT006,2024-03-06,2024-03-06 09:20,Subway,35,2,R07\nT007,2024-03-07,2024-03-07 08:55,Car-Sharing,25,1,CAR1\nT008,2024-03-08,2024-03-08 07:30,train,55,2,T1\nT009,2024-03-09,not recorded,Bus,40,2,R12\nT010,2024-03-10,2024-03-10 09:15,Subway, thirty,1,R07\nT011,2024/03/11,2024-03-11 08:45,Bus,42,,r12\nT012,2024-03-12,2024-03-12 09:00,Train,65,3,T2\nT013,2024-03-13,2024-03-13 07:40,Subway,28,1,r07\nT014,2024-03-14,2024-03-14 08:10,Car-sharing,27,1,CAR2", "eda_steps": ["Check for and report missing values in each column", "Standardize Mode column capitalization and correct obvious typos", "Convert Duration_Minutes to numeric values, handling non-numeric and missing entries", "Calculate summary statistics for Duration_Minutes and Passenger_Count", "Generate value counts for Mode and Route_Code", "Identify trips with inconsistent or missing End_Date", "Calculate average trip duration per Mode", "Find the top 3 most frequent Route_Codes"], "eda_results": {"missing_values": {"Trip_ID": 0, "Start_Date": 0, "End_Date": 1, "Mode": 0, "Duration_Minutes": 2, "Passenger_Count": 3, "Route_Code": 0}, "mode_value_counts": {"Bus": 5, "Subway": 4, "Train": 3, "Car-Sharing": 2}, "duration_minutes_cleaned": [45, 30, null, 60, 50, 35, 25, 55, 40, null, 42, 65, 28, 27], "summary_stats": {"Duration_Minutes": {"count": 12, "mean": 41.75, "std": 12.56, "min": 25, "25%": 30.25, "50%": 42, "75%": 50, "max": 65}, "Passenger_Count": {"count": 11, "mean": 1.73, "std": 0.75, "min": 1, "25%": 1, "50%": 2, "75%": 2, "max": 3}}, "end_date_issues": {"missing_or_inconsistent": ["T009"]}, "average_duration_per_mode": {"Bus": 43.4, "Subway": 31, "Train": 60, "Car-Sharing": 26}, "top_route_codes": ["R12", "R07", "T1"]}}
{"purpose": "Examine employment statistics and demographic distribution across government departments.", "raw_table": "Department,Employee_ID,Age,Gender,Hire_Date,Salary,Job_Level\nFinance,00123,45,Male,2015-06-23,75000,Senior\nhealth,00124,,Female,2018/09/15,58000,Mid\nEDucation,00125,29,Male,12-05-2017,46000,Junior\nTransportation,00126,38,Female,2016-07-01,62000,Mid\nFinance,,50,Male,2014-03-11,82000,Senior\nHealth,00128,42,,2019-04-20,,Mid\nEDUCATION,00129,30,female,2017/11/30,49000,Junior\ntransportation,00130,35,Male,2015-08-15,60000,Mid\nFinance,00131,NaN,Male,2013/12/01,90000,Senior\nHealth,00132,28,Female,2019-01-25,57000,mid\nEducation,00133,33,Male,2016-02-29,51000,Junior\nTransportation,00134,40,Female,2018-10-10,63000,Mid\nFinance,00135,48,male,2012-05-19,85000,Senior", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization of categorical columns: Department, Gender, Job_Level", "Parse and unify the date format in the Hire_Date column to ISO format", "Calculate descriptive statistics for the numeric columns: Age and Salary", "Generate value counts for the Department and Job_Level columns", "Identify records with missing Employee_ID values", "Compute average Salary by Department and Job_Level", "Summarize the distribution of Age by Gender"], "eda_results": {"missing_values": {"Department": 0, "Employee_ID": 1, "Age": 2, "Gender": 1, "Hire_Date": 0, "Salary": 1, "Job_Level": 0}, "standardized_categories": {"Department": ["Finance", "Health", "Education", "Transportation"], "Gender": ["Male", "Female"], "Job_Level": ["Senior", "Mid", "Junior"]}, "hire_date_formats_unified": {"example_earliest": "2012-05-19", "example_latest": "2019-04-20"}, "summary_stats": {"Age": {"count": 13, "mean": 37.23, "std": 7.26, "min": 28, "25%": 30, "50%": 35, "75%": 42, "max": 50}, "Salary": {"count": 13, "mean": 65538, "std": 14114, "min": 46000, "25%": 57000, "50%": 62000, "75%": 82000, "max": 90000}}, "value_counts": {"Department": {"Finance": 4, "Health": 4, "Education": 3, "Transportation": 4}, "Job_Level": {"Senior": 4, "Mid": 6, "Junior": 3}}, "missing_employee_id_records": [{"Department": "Finance", "Employee_ID": "", "Age": 50, "Gender": "Male", "Hire_Date": "2014-03-11", "Salary": 82000, "Job_Level": "Senior"}], "average_salary_by_department_and_job_level": {"Finance": {"Senior": 80500, "Mid": null, "Junior": null}, "Health": {"Senior": null, "Mid": 57500, "Junior": null}, "Education": {"Senior": null, "Mid": null, "Junior": 48667}, "Transportation": {"Senior": null, "Mid": 61667, "Junior": null}}, "age_distribution_by_gender": {"Male": {"count": 6, "mean": 37.5, "min": 29, "max": 50}, "Female": {"count": 7, "mean": 37.0, "min": 28, "max": 45}}}}
{"purpose": "Analyze machine downtime causes and production output efficiency in a manufacturing plant.", "raw_table": "MachineID,Date,Shift,DowntimeMinutes,Operator,Product,OutputUnits\nM01,2024/02/01,morning,30,John Doe,WidgetA,100\nM02,2024-02-01,Afternoon,,jane SMITH,widgetB,90\nm01,02-02-2024,night,45,JOHN DOE,WidgetA,95\nM03,2024/02/02,morning,15,,WidgetC,80\nM02,2024-02-03,Afternoon,0,Jane Smith,widgetB,110\nM01,2024/02/03,Night,25,John Doe,widgeta,105\nM03,2024/02/03,morning,NA,Mary Ann,WidgetC,85\nM02,2024-02-04,afternoon,10,jane smith,WidgetB,100\nM01,2024/02/04,Morning,20,John D.,WidgetA,102\nm03,2024/02/04,MORNING,5,Mary Ann,widgetc,90\nM02,02/05/2024,Afternoon,12,Jane Smith,WidgetB,108", "eda_steps": ["Check and report missing values per column", "Standardize the 'Shift' column capitalization", "Standardize the 'Operator' names to title case and unify duplicates", "Convert 'Date' column to a consistent date format", "Calculate descriptive statistics for 'DowntimeMinutes' and 'OutputUnits'", "Generate value counts for 'Product' and 'Shift'", "Identify correlation between 'DowntimeMinutes' and 'OutputUnits'", "Find the total downtime and average output per MachineID", "Summarize the top 2 Operators by total output units"], "eda_results": {"missing_values": {"MachineID": 0, "Date": 0, "Shift": 0, "DowntimeMinutes": 2, "Operator": 1, "Product": 0, "OutputUnits": 0}, "standardized_Shift_counts": {"Morning": 4, "Afternoon": 4, "Night": 2}, "standardized_Operator_counts": {"John Doe": 4, "Jane Smith": 4, "Mary Ann": 2, "John D.": 1, "": 1}, "date_format": "All dates converted to yyyy-mm-dd format ranging from 2024-02-01 to 2024-02-05", "summary_stats": {"DowntimeMinutes": {"count": 9, "mean": 17.11, "std": 13.45, "min": 0, "25%": 10, "50%": 15, "75%": 25, "max": 45}, "OutputUnits": {"count": 11, "mean": 96.36, "std": 9.52, "min": 80, "25%": 90, "50%": 100, "75%": 105, "max": 110}}, "value_counts": {"Product": {"WidgetA": 5, "WidgetB": 4, "WidgetC": 3}, "Shift": {"Morning": 4, "Afternoon": 4, "Night": 2}}, "correlations": {"DowntimeMinutes_OutputUnits": -0.68}, "machine_summary": {"M01": {"total_downtime": 120, "average_output": 100.4}, "M02": {"total_downtime": 22, "average_output": 102.0}, "M03": {"total_downtime": 20, "average_output": 85.0}}, "top_operators_output": {"John Doe": 402, "Jane Smith": 408}}}
{"purpose": "Analyze energy consumption patterns and identify data quality issues in household electricity usage records.", "raw_table": "Household_ID,Date,Energy_Consumed_kWh,Energy_Source,Region\nH001,2023-01-10,15.2,Solar,North\nh002,1/15/2023,NaN,wind,South\nH003,2023-01-20,20.5,Coal,East\nh004,2023/01/25,18.7,solar,west\nH005,01-30-2023,NaN,Wind,North\nH006,2023-02-02,22.1,coal,East\nh007,2023-02-05,19.3,Hydro,South\nH008,2023-02-10,17.8,hydro,West\nH009,2023-02-15,NaN,solar,North\nH010,2023-02-20,21.0,Coal,East", "eda_steps": ["Check for missing values in all columns", "Standardize date formats and parse dates", "Normalize categorical values for Energy_Source and Region columns", "Compute descriptive statistics for Energy_Consumed_kWh", "Generate value counts for Energy_Source and Region", "Visualize distribution of Energy_Consumed_kWh", "Identify any correlations between Energy_Consumed_kWh and Region"], "eda_results": {"missing_values": {"Household_ID": 0, "Date": 0, "Energy_Consumed_kWh": 3, "Energy_Source": 0, "Region": 0}, "date_format_standardized": true, "normalized_categories": {"Energy_Source": ["Solar", "Wind", "Coal", "Hydro"], "Region": ["North", "South", "East", "West"]}, "summary_stats": {"Energy_Consumed_kWh": {"count": 8, "mean": 19.575, "std": 2.274, "min": 15.2, "25%": 17.375, "50%": 19.3, "75%": 21.0, "max": 22.1}}, "value_counts": {"Energy_Source": {"Solar": 3, "Wind": 2, "Coal": 3, "Hydro": 2}, "Region": {"North": 3, "South": 2, "East": 3, "West": 2}}, "correlations": {"Energy_Consumed_kWh_vs_Region": "No strong correlation detected between energy consumption and region."}}}
{"purpose": "Analyze city bus trip data to understand trip durations, identify missing information, and explore route popularity.", "raw_table": "Trip_ID,Route,Start_Time,End_Time,Passenger_Count,Driver_ID\n1,Route 12,2023-03-01 08:00 AM,2023-03-01 08:45 AM,25,D01\n2,route 5,03/01/2023 09:15,03/01/2023 09:50,18,d02\n3,ROUTE 12,2023-03-01 10:00,2023-03-01 10:40,22,D01\n4,Route 7,2023-03-01 08:30 AM,2023-03-01 09:05 AM,NA,D03\n5,Route 5,2023/03/01 11:00,2023/03/01 11:45,20,d02\n6,route 5,2023-03-01 12:15 PM,2023-03-01 12:55 PM,,D04\n7,Route 12,,2023-03-01 01:30 PM,30,D01\n8,Route 7,2023-03-01 02:00 PM,2023-03-01 02:40 PM,17,D03\n9,route 15,2023-03-01 03:15 PM,03/01/2023 03:55 PM,10,d05\n10,Route 15,2023-03-01 04:00 PM,2023-03-01 04:45 PM,12,d05\n", "eda_steps": ["Check for missing values in each column", "Standardize the Route column to consistent capitalization", "Parse and unify Start_Time and End_Time into datetime format", "Calculate trip duration in minutes for each trip", "Compute descriptive statistics for Passenger_Count and trip duration", "Generate value counts for Route and Driver_ID", "Identify trips with missing Start_Time or Passenger_Count", "Check correlation between Passenger_Count and trip duration"], "eda_results": {"missing_values": {"Trip_ID": 0, "Route": 0, "Start_Time": 1, "End_Time": 0, "Passenger_Count": 2, "Driver_ID": 0}, "standardized_routes": {"Route 5": 3, "Route 7": 2, "Route 12": 3, "Route 15": 2}, "trip_durations_minutes": {"min": 35, "max": 55, "mean": 44.5, "median": 45}, "passenger_count_stats": {"min": 10, "max": 30, "mean": 19.5, "median": 20, "missing_count": 2}, "value_counts": {"Driver_ID": {"D01": 3, "D02": 2, "D03": 2, "D04": 1, "D05": 2}}, "trips_with_missing_start_time": [7], "trips_with_missing_passenger_count": [4, 6], "correlation_passenger_duration": 0.68}}
{"purpose": "Analyze student performance and attendance patterns across different courses to identify data quality issues and trends.", "raw_table": "StudentID,Course,Score,Attendance,EnrollmentDate\n101,Math,88,Present,2023-01-15\n102,english,92,Absent,15/02/2023\n103,History,,Present,2023/03/05\n104,math,75,Present,2023-01-22\n105,Science,85,Absent,March 3, 2023\n106,English,91,Present,\n107,history,NaN,Present,2023-03-07\n108,Science,78,present,2023-03-02\n109,MATH,82,Absent,2023-01-30\n110,English,95,,2023-02-20\n111,science,88,Present,2023-03-01\n112,History,80,Absent,2023-03-08\n113,math,not available,Present,2023-01-25\n114,English,90,Present,20-02-2023", "eda_steps": ["Check missing value percentages for each column", "Standardize course names to lowercase", "Convert EnrollmentDate to a consistent date format", "Calculate descriptive statistics for the Score column excluding non-numeric entries", "Generate value counts for Attendance categories", "Identify number of unique students", "Find the earliest and latest enrollment dates", "Count how many scores are non-numeric or missing", "Summarize average score by course"], "eda_results": {"missing_values": {"StudentID": 0, "Course": 0, "Score": 3, "Attendance": 2, "EnrollmentDate": 1}, "value_counts_attendance": {"Present": 8, "Absent": 4, "present": 1, "": 1}, "unique_students": 14, "enrollment_date_range": {"earliest": "2023-01-15", "latest": "2023-03-08"}, "non_numeric_scores_count": 2, "score_stats": {"count": 10, "mean": 86.4, "std": 6.52, "min": 75, "25%": 82, "50%": 88, "75%": 91, "max": 95}, "average_score_by_course": {"math": 81.67, "english": 92.0, "history": 80.0, "science": 83.67}}}
{"purpose": "Analyze sales performance and customer purchasing behavior for different product categories over time.", "raw_table": "OrderID,CustomerName,ProductCategory,Quantity,UnitPrice,OrderDate,StoreLocation\n1001,alice SMITH,electronics,2,299.99,2023-01-15,New York\n1002,Bob Johnson,Home & kitchen,1,,15/01/2023,los angeles\n1003,,Clothing,3,49.99,2023/01/16,Chicago\n1004,David Lee,electronics,1,299.99,17-01-2023,New York\n1005,Eva Green,clothing,,39.99,2023-01-18,Houston\n1006,Fiona Chen,HOME & KITCHEN,2,89.50,2023-01-20,Los Angeles\n1007,George King,Electronics,1,299.99,2023.01.21,new york\n1008,Helen Park,clothing,4,39.99,,Chicago\n1009,Ian Wright,Home & Kitchen,2,89.50,2023-01-22,Houston\n1010,Jackie Chan,Electronics,1,299.99,2023/01/23,New York\n1011,Karen Davis,Clothing,2,49.99,01-24-2023,Chicago\n1012,Larry Page,home & kitchen,3,89.50,2023-01-25,LOS ANGELES\n1013,Monica Belluci,,1,19.99,2023-01-26,Miami", "eda_steps": ["Check for missing values in each column", "Standardize capitalization for ProductCategory and StoreLocation", "Parse OrderDate into a consistent date format", "Compute descriptive statistics for Quantity and UnitPrice", "Generate value counts for ProductCategory", "Identify top 2 StoreLocation by number of orders", "Calculate total sales per ProductCategory", "Find orders with missing CustomerName or missing Quantity"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerName": 1, "ProductCategory": 1, "Quantity": 2, "UnitPrice": 1, "OrderDate": 1, "StoreLocation": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Home & Kitchen", "Clothing", null], "StoreLocation": ["New York", "Los Angeles", "Chicago", "Houston", "Miami"]}, "parsed_dates_sample": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18"], "summary_stats": {"Quantity": {"count": 13, "mean": 1.92, "median": 1.5, "min": 1, "max": 4, "missing": 2}, "UnitPrice": {"count": 14, "mean": 127.66, "median": 89.5, "min": 19.99, "max": 299.99, "missing": 1}}, "value_counts": {"ProductCategory": {"Electronics": 5, "Home & Kitchen": 5, "Clothing": 4, "missing": 1}}, "top_store_locations": {"New York": 4, "Los Angeles": 3}, "total_sales_per_category": {"Electronics": 2099.93, "Home & Kitchen": 1342.5, "Clothing": 359.91, "missing": 19.99}, "orders_with_missing_info": {"missing_CustomerName": [1003], "missing_Quantity": [1005, 1008]}}}
{"purpose": "Analyze patterns in daily public transport usage and identify data quality issues.", "raw_table": "Date,Route_ID,Passengers,Weather,Delay_Minutes\n2024-04-01,101,230,Sunny,5\n04/02/2024,102,195,cloudy,0\n2024/04/03,103,,Rainy,10\n2024-4-04,101,215,Sunny,NA\n2024-04-05,104,180,Cloudy,3\n2024-04-6,105,220,rainy,15\n2024-04-07,101,210,,7\n2024-04-08,102,NaN,Sunny,2\n2024-4-09,103,190,Cloudy,0\n2024-04-10,104,205,sunny,4\n2024-04-11,105,225,Rainy,6\n2024/04/12,101,200,Sunny,NA\n2024-04-13,102,185,cloudy,2", "eda_steps": ["Check for missing values in each column", "Standardize date formats into YYYY-MM-DD", "Convert 'Passengers' and 'Delay_Minutes' to numeric types and handle invalid entries", "Generate value counts for the 'Weather' column", "Calculate descriptive statistics for 'Passengers' and 'Delay_Minutes'", "Identify top 2 busiest routes based on average passengers", "Check correlation between 'Passengers' and 'Delay_Minutes'", "Summarize distribution skewness for 'Passengers'"], "eda_results": {"missing_values": {"Date": 0, "Route_ID": 0, "Passengers": 2, "Weather": 1, "Delay_Minutes": 2}, "standardized_dates": ["2024-04-01", "2024-04-02", "2024-04-03", "2024-04-04", "2024-04-05", "2024-04-06", "2024-04-07", "2024-04-08", "2024-04-09", "2024-04-10", "2024-04-11", "2024-04-12", "2024-04-13"], "weather_value_counts": {"Sunny": 5, "Cloudy": 4, "Rainy": 3, "": 1}, "descriptive_stats": {"Passengers": {"count": 11, "mean": 205.45, "std": 16.54, "min": 180, "25%": 190, "50%": 210, "75%": 220, "max": 230}, "Delay_Minutes": {"count": 11, "mean": 5.18, "std": 4.64, "min": 0, "25%": 2, "50%": 5, "75%": 7, "max": 15}}, "top_routes_by_avg_passengers": {"101": 211.25, "105": 222.5}, "correlation_Passengers_Delay": -0.12, "passengers_skewness": -0.25}}
{"purpose": "Analyze customer purchase behavior and identify missing data patterns in recent ecommerce transactions.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,Price,PaymentMethod\n1001,C123,2023-04-01,Electronics,2,299.99,Credit Card\n1002,C124,2023/04/02,Fashion,1,49.99,Paypal\n1003,,04-03-2023,Home & Garden,3,19.95,Credit card\n1004,C126,2023-4-4,Fashion,Two,39.99,Cash\n1005,C127,2023-04-05,Electronics,,199.99,credit card\n1006,C128,2023/04/06,Fashion,1,NA,Paypal\n1007,C129,2023-04-07,sports,5,15.00,Credit Card\n1008,C130,2023-04-08,Home & garden,2,22.50,Cash\n1009,C131,2023-04-09,Electronics,1,299.99,\n1010,C132,2023-04,Electronics,1,299.99,Credit Card\n1011,C133,2023-04-11,Fashion,1,59.99,Paypal\n1012,C134,2023-04-12,HOME & GARDEN,1,25.00,Credit card", "eda_steps": ["Check and summarize missing values per column", "Standardize and unify ProductCategory capitalization", "Convert Quantity and Price columns to numeric types, handling errors", "Compute descriptive statistics for Quantity and Price", "Generate value counts for PaymentMethod", "Identify top 3 ProductCategory by total Quantity sold", "Check for inconsistent or invalid OrderDate formats", "Summarize unique CustomerID counts and missing entries"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 1, "ProductCategory": 0, "Quantity": 1, "Price": 1, "PaymentMethod": 1}, "standardized_ProductCategory_counts": {"Electronics": 4, "Fashion": 4, "Home & Garden": 3, "Sports": 1}, "quantity_numeric_conversion": {"converted_successfully": 13, "failed_conversion": ["Two"]}, "price_numeric_conversion": {"converted_successfully": 13, "failed_conversion": ["NA"]}, "descriptive_stats": {"Quantity": {"count": 13, "mean": 1.92, "std": 1.33, "min": 1, "max": 5}, "Price": {"count": 13, "mean": 121.07, "std": 126.7, "min": 15.0, "max": 299.99}}, "PaymentMethod_value_counts": {"Credit Card": 5, "Paypal": 3, "Cash": 2, "credit card": 1, "": 1}, "top_3_ProductCategory_by_quantity": {"Electronics": 4, "Fashion": 6, "Home & Garden": 6}, "OrderDate_issues": {"invalid_formats": ["2023-04"], "different_separators_detected": true}, "CustomerID_summary": {"unique_customers": 11, "missing_customerID_count": 1}}}
{"purpose": "Analyze customer purchase behavior and product category performance for a mid-sized ecommerce store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod,DeliveryStatus\n1001,C001,2023-01-15,Electronics,2,199.99,Credit Card,Delivered\n1002,C002,15/01/2023,home appliances,1,89.5,Paypal,delivered\n1003,C003,2023/01/16,Fashion,3,29.99,CREDIT CARD,Pending\n1004,,01-17-2023,Beauty,2,,Debit Card,Delivered\n1005,C005,2023-01-18,Electronics,1,199.99,Credit Card,Delivered\n1006,C006,2023-01-19,Fashion,NaN,39.99,Paypal,Cancelled\n1007,C007,2023-01-20,home Appliances,4,85.0,Credit card,Delivered\n1008,C008,2023/01/21,beauty,1,15.5,Credit Card,Returned\n1009,C009,01-22-2023,Fashion,2,29.99,PayPal,Delivered\n1010,C010,2023-01-23,Electronics,1,199.99,,Pending\n1011,C011,2023-01-24,TOYS,5,9.99,Credit Card,Delivered\n1012,C012,2023-01-25,Toys,3,10.5,Debit card,delivered", "eda_steps": ["Check missing values and their percentages for each column", "Standardize the ProductCategory and PaymentMethod capitalization and naming", "Convert OrderDate to a consistent datetime format", "Calculate summary statistics for Quantity and UnitPrice columns", "Count unique customers and number of orders per customer", "Generate value counts for DeliveryStatus to understand order outcomes", "Identify top product categories by total quantity sold", "Calculate total revenue per product category", "Check correlation between Quantity and UnitPrice"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 0, "ProductCategory": 0, "Quantity": 1, "UnitPrice": 1, "PaymentMethod": 1, "DeliveryStatus": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Home Appliances", "Fashion", "Beauty", "Toys"], "PaymentMethod": ["Credit Card", "Paypal", "Debit Card"]}, "order_date_format": "All dates converted to YYYY-MM-DD", "summary_stats": {"Quantity": {"count": 14, "mean": 2.64, "std": 1.47, "min": 1, "25%": 1.75, "50%": 2, "75%": 3.5, "max": 5}, "UnitPrice": {"count": 14, "mean": 85.35, "std": 76.23, "min": 9.99, "25%": 15.5, "50%": 39.99, "75%": 199.99, "max": 199.99}}, "unique_customers": 12, "orders_per_customer": {"max": 1, "min": 1, "mode": 1}, "delivery_status_counts": {"Delivered": 8, "Pending": 2, "Cancelled": 1, "Returned": 1}, "top_product_categories_by_quantity": {"Home Appliances": 5, "Toys": 8, "Fashion": 7, "Electronics": 4, "Beauty": 3}, "total_revenue_per_category": {"Electronics": 799.96, "Home Appliances": 344.5, "Fashion": 209.93, "Beauty": 15.5, "Toys": 77.43}, "correlation_quantity_unitprice": -0.12}}
{"purpose": "Explore viewer ratings and trends for recent movie releases to identify popular genres and rating distributions.", "raw_table": "MovieID,Title,Genre,ReleaseDate,Duration,ViewerRating,BoxOfficeMillion\n1,The Lost City,Adventure,2023-03-15,124,8.1,150.5\n2,haunted nights,Horror,15/04/2023,95,6.5,45.2\n3,Love & War,Romance,2023/05/20,110,7.3,78.9\n4,SPACE QUEST,Sci-Fi,,130,8.7,200.1\n5,Underwater,Adventure,2023-06-01,,7.0,88.0\n6,Midnight Run,Thriller,2023-03-30,115,,54.3\n7,The Great Heist,Action,2023-04-20,105,8.0,\n8,Dance Fever,Musical,2023-05-25,100,7.8,60.6\n9,Ghost Town,Horror,2023-03-05,98,5.9,30.0\n10,Unknown,tHRiller,2023-06-10,110,7.2,70.0\n", "eda_steps": ["Check for missing values in all columns", "Standardize genre capitalization", "Compute descriptive statistics for numeric columns Duration, ViewerRating, and BoxOfficeMillion", "Generate value counts for Genre column", "Identify movies with missing ReleaseDate and impute placeholder", "Summarize distribution skewness for ViewerRating", "Find correlation between ViewerRating and BoxOfficeMillion", "Identify top 3 genres by number of movies"], "eda_results": {"missing_values": {"MovieID": 0, "Title": 0, "Genre": 0, "ReleaseDate": 1, "Duration": 1, "ViewerRating": 1, "BoxOfficeMillion": 1}, "standardized_genres": {"Adventure": 2, "Horror": 2, "Romance": 1, "Sci-Fi": 1, "Thriller": 2, "Action": 1, "Musical": 1}, "summary_stats": {"Duration": {"count": 13, "mean": 108.5, "std": 11.4, "min": 95, "25%": 100, "50%": 110, "75%": 115, "max": 130}, "ViewerRating": {"count": 9, "mean": 7.28, "std": 0.91, "min": 5.9, "25%": 7.0, "50%": 7.3, "75%": 8.0, "max": 8.7}, "BoxOfficeMillion": {"count": 9, "mean": 88.62, "std": 55.8, "min": 30.0, "25%": 54.3, "50%": 70.0, "75%": 150.5, "max": 200.1}}, "viewer_rating_skewness": -0.54, "correlations": {"ViewerRating_BoxOfficeMillion": 0.72}, "top_genres": [{"Genre": "Adventure", "Count": 2}, {"Genre": "Horror", "Count": 2}, {"Genre": "Thriller", "Count": 2}]}}
{"purpose": "Analyze electricity consumption patterns across different regions and customer types to identify usage trends and data quality issues.", "raw_table": "Record_ID,Region,Customer_Type,Date,Consumption_kWh,Peak_Hour_Consumption,Payment_Status\n1,North,residential,2023-01-15,350,100,paid\n2,SOUTH,Commercial,15/01/2023,1250,400,Paid\n3,East,Residential,2023/01/16,,150,unpaid\n4,west,industrial,2023-01-16,2300,750,paid\n5,North,,2023-01-17,400,120,paid\n6,South,Commercial,2023-1-18,1300,410,\n7,EAST,Residential,17-01-2023,370,NaN,unpaid\n8,West,Industrial,2023-01-18,2400,770,paid\n9,North,Residential,2023-01-19,360,110,PAID\n10,South,commercial,2023-01-19,1280,420,unPaid\n11,East,Residential,2023/01/20,390,160,paid\n12,West,Industrial,2023-01-20,2500,800,Paid\n13,North,Residential,,380,115,paid\n14,South,Commercial,2023-01-21,1350,430,paid", "eda_steps": ["Standardize the Region and Customer_Type columns capitalization", "Check and report missing values across all columns", "Parse and unify the Date column format", "Compute descriptive statistics for Consumption_kWh and Peak_Hour_Consumption", "Generate value counts for Payment_Status to assess payment compliance", "Identify any inconsistent or unusual categories in Customer_Type", "Calculate correlation between Consumption_kWh and Peak_Hour_Consumption", "List top 2 Regions by average Consumption_kWh", "Summarize how many records have missing Consumption_kWh or Peak_Hour_Consumption"], "eda_results": {"missing_values": {"Record_ID": 0, "Region": 0, "Customer_Type": 1, "Date": 1, "Consumption_kWh": 1, "Peak_Hour_Consumption": 1, "Payment_Status": 1}, "value_counts": {"Region": {"North": 4, "South": 4, "East": 3, "West": 3}, "Customer_Type": {"Residential": 7, "Commercial": 4, "Industrial": 3, "": 1}, "Payment_Status": {"paid": 7, "unpaid": 3, "": 1}}, "standardized_categories": {"Region": ["North", "South", "East", "West"], "Customer_Type": ["Residential", "Commercial", "Industrial"]}, "date_range": {"min_date": "2023-01-15", "max_date": "2023-01-21"}, "summary_stats": {"Consumption_kWh": {"count": 13, "mean": 1067.69, "std": 845.12, "min": 350, "25%": 370, "50%": 400, "75%": 1350, "max": 2500}, "Peak_Hour_Consumption": {"count": 13, "mean": 370.77, "std": 241.86, "min": 100, "25%": 120, "50%": 160, "75%": 430, "max": 800}}, "correlations": {"Consumption_kWh_vs_Peak_Hour_Consumption": 0.995}, "top_regions_by_avg_consumption": {"West": 2400, "South": 1295}, "missing_data_summary": {"records_missing_Consumption_kWh": 1, "records_missing_Peak_Hour_Consumption": 1}}}
{"purpose": "Analyze crop yield patterns and soil conditions to identify factors affecting productivity.", "raw_table": "Farm_ID,Crop,Planting_Date,Soil_Type,Yield_tons,Precipitation_mm\n101,Wheat,2023-03-15,Loamy,2.5,120\n102,corn,15/04/2023,Clay,3.0,85\n103,Rice,,SANDY,1.8,100\n104,barley,2023/04/20,loamy,,110\n105,Wheat,2023-03-18,Clay,2.7,N/A\n106,Corn,Apr 25 2023,Clay,3.2,95\n107,Rice,2023-04-15,Loamy,1.9,NaN\n108,Barley,2023-04-19,Sandy,2.1,105\n109,wheat,03-20-2023,loamy,2.6,115\n110,Corn,2023-04-16,clay,3.1,90\n111,rye,2023-04-10,Loamy,2.0,102\n112,Rice,2023-04-12,Sandy,1.7,98\n113,Barley,2023-04-18,Clay,,100", "eda_steps": ["Check and report missing values in each column", "Standardize Crop and Soil_Type column values to consistent capitalization", "Parse and standardize Planting_Date into a uniform date format", "Compute descriptive statistics (mean, median, std) for Yield_tons and Precipitation_mm", "Generate frequency counts for Crop and Soil_Type categories", "Identify correlation between Yield_tons and Precipitation_mm", "Summarize the number of unique farms for each crop type", "Identify rows with missing Yield_tons and analyze their Soil_Type distribution"], "eda_results": {"missing_values": {"Farm_ID": 0, "Crop": 0, "Planting_Date": 1, "Soil_Type": 0, "Yield_tons": 3, "Precipitation_mm": 2}, "standardized_categories": {"Crop": {"Wheat": 3, "Corn": 3, "Rice": 3, "Barley": 3, "Rye": 1}, "Soil_Type": {"Loamy": 4, "Clay": 5, "Sandy": 3}}, "date_range": {"earliest_planting_date": "2023-03-15", "latest_planting_date": "2023-04-25"}, "yield_statistics": {"mean": 2.41, "median": 2.5, "std_dev": 0.55, "count": 12}, "precipitation_statistics": {"mean": 101.9, "median": 100, "std_dev": 11.7, "count": 11}, "crop_farm_counts": {"Wheat": 3, "Corn": 3, "Rice": 3, "Barley": 3, "Rye": 1}, "yield_precipitation_correlation": 0.64, "missing_yield_soil_distribution": {"Loamy": 1, "Clay": 1, "Sandy": 1}}}
{"purpose": "Analyze customer purchase behavior and identify missing data patterns in ecommerce transactions.", "raw_table": "OrderID,CustomerID,ProductCategory,PurchaseDate,Quantity,Price,PaymentMethod\n1001,C001,Electronics,2023/01/15,2,299.99,Credit Card\n1002,c002,Home & Kitchen,15-01-2023,1,89.5,Paypal\n1003,C003,electronics,2023-01-16,3,,Credit card\n1004,C004,Sports,2023/01/17,2,45.0,Credit Card\n1005,,Fashion,2023-01-18,1,120.0,CASH\n1006,C006,Fashion,,2,75.0,Paypal\n1007,C007,Home & kitchen,2023/1/19,1,89.5,credit card\n1008,C008,Sports,2023/01/20,1,NaN,Credit Card\n1009,C009,Electronics,2023/01/20,1,299.99,CASH\n1010,C010,,2023/01/21,2,49.99,Paypal\n1011,C011,Fashion,2023-01-22,1,125.0,Credit Card\n1012,C012,Electronics,01/23/2023,1,299.99,Paypal", "eda_steps": ["Check for missing values in each column and calculate their percentages", "Standardize 'ProductCategory' capitalization and correct inconsistent categories", "Parse and standardize 'PurchaseDate' to a consistent date format", "Compute descriptive statistics for numeric columns 'Quantity' and 'Price'", "Generate value counts for 'PaymentMethod' and 'ProductCategory'", "Identify rows with missing 'CustomerID' or 'ProductCategory' values", "Calculate the average purchase price by product category", "Detect any duplicate 'OrderID' entries"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "ProductCategory": 1, "PurchaseDate": 1, "Quantity": 0, "Price": 2, "PaymentMethod": 0}, "value_counts": {"PaymentMethod": {"Credit Card": 5, "Paypal": 4, "CASH": 2, "credit card": 1}, "ProductCategory": {"Electronics": 4, "Home & Kitchen": 2, "Sports": 2, "Fashion": 3, "": 1}}, "standardized_categories": ["Electronics", "Home & Kitchen", "Electronics", "Sports", "Fashion", "Fashion", "Home & Kitchen", "Sports", "Electronics", "", "Fashion", "Electronics"], "purchase_date_standardized": ["2023-01-15", "2023-01-15", "2023-01-16", "2023-01-17", "2023-01-18", null, "2023-01-19", "2023-01-20", "2023-01-20", "2023-01-21", "2023-01-22", "2023-01-23"], "summary_stats": {"Quantity": {"count": 12, "mean": 1.58, "std": 0.67, "min": 1, "25%": 1, "50%": 1.5, "75%": 2, "max": 3}, "Price": {"count": 10, "mean": 130.04, "std": 114.37, "min": 45.0, "25%": 75.0, "50%": 89.5, "75%": 125.0, "max": 299.99}}, "average_price_by_category": {"Electronics": 299.99, "Home & Kitchen": 89.5, "Sports": 45.0, "Fashion": 106.67, "": null}, "rows_with_missing_customerID_or_category": [{"OrderID": "1005", "CustomerID": null, "ProductCategory": "Fashion"}, {"OrderID": "1010", "CustomerID": "C010", "ProductCategory": ""}], "duplicate_orderIDs": []}}
{"purpose": "Analyze customer call patterns and service usage to identify potential churn risk factors.", "raw_table": "CustomerID,CallDate,CallDuration,ServiceType,CustomerSegment,DataUsageGB,Churn\n001,2024-05-01,15,Voice,Premium,2.5,No\n002,05/02/2024,30,voice,standard,NA,yes\n003,2024-5-03,45,VOICE,Standard,5.1,no\n004,2024/05/04,NA,Data,Premium,10.0,No\n005,May 5 2024,20,Data,premium,8.3,YES\n006,2024-05-06,25,voice,Standard,,No\n007,2024-05-07,35,Voice,Standard,4.7,No\n008,2024-05-08,40,Data,PREMIUM,9.1,No\n009,,50,Voice,Standard,3.5,Yes\n010,2024-05-10,NA,Data,Standard,7.0,No\n011,2024-05-11,10,voice,Standard,2.0,No\n012,2024/05/12,15,Data,standard,6.4,No", "eda_steps": ["Check missing value percentages for each column", "Standardize the 'ServiceType' column to lowercase", "Convert 'CallDate' to a consistent date format and identify missing dates", "Compute descriptive statistics for numeric columns: CallDuration and DataUsageGB", "Generate value counts for 'CustomerSegment' and 'Churn' columns", "Identify top 2 most frequent 'ServiceType' categories", "Calculate average CallDuration by CustomerSegment", "Examine correlation between CallDuration and DataUsageGB", "Summarize churn rate by CustomerSegment"], "eda_results": {"missing_values": {"CustomerID": 0, "CallDate": 1, "CallDuration": 2, "ServiceType": 0, "CustomerSegment": 0, "DataUsageGB": 2, "Churn": 0}, "value_counts": {"CustomerSegment": {"Standard": 8, "Premium": 4}, "Churn": {"No": 8, "Yes": 4}}, "service_type_standardized_counts": {"voice": 7, "data": 5}, "calldate_missing": 1, "callduration_stats": {"count": 10, "mean": 29.5, "std": 12.93, "min": 10, "25%": 17.5, "50%": 27.5, "75%": 40, "max": 50}, "datausage_stats": {"count": 10, "mean": 5.46, "std": 3.02, "min": 2, "25%": 2.5, "50%": 5.1, "75%": 8.3, "max": 10}, "top_service_types": ["voice", "data"], "avg_callduration_by_segment": {"Premium": 23.33, "Standard": 32.14}, "correlation_call_duration_data_usage": 0.65, "churn_rate_by_segment": {"Premium": 0.25, "Standard": 0.375}}}
{"purpose": "Analyze machine downtime causes and durations to identify maintenance priorities.", "raw_table": "MachineID,Date,DowntimeHours,Shift,Operator,FailureType\nM001,2024-01-15,2.5,MORNING,john doe,Electrical\nm002,15/01/2024,1.0,night,Anna K,Mechanical\nM003,2024-01-16,NA,Afternoon,unknown,Electrical\nM004,2024/01/16,3.0,Morning,Mark L,hydraulic\nM005,,2.0,Night,Anna K,Mechanical\nm006,2024-01-17,0.5,afternoon,John Doe,Electrical\nM007,2024-01-17,,Morning,,Mechanical\nM008,17-01-2024,1.5,Night,Mary P,Unknown\nm009,2024-01-18,2,NIGHT,Mary P,Mechanical\nM010,2024-01-18,1.2,Afternoon,mark l,Hydraulic", "eda_steps": ["Check and summarize missing values per column", "Standardize capitalization in categorical columns Shift, Operator, and FailureType", "Convert DowntimeHours to numeric and summarize descriptive statistics", "Parse and standardize Date column to a consistent date format", "Generate value counts for FailureType and Shift", "Identify top 2 Operators by number of downtime incidents", "Calculate average DowntimeHours per FailureType", "Check correlation between DowntimeHours and Shift (encoded as categorical numeric)", "List rows with missing DowntimeHours or Operator"], "eda_results": {"missing_values": {"MachineID": 0, "Date": 1, "DowntimeHours": 2, "Shift": 0, "Operator": 2, "FailureType": 0}, "standardized_categories": {"Shift": ["Morning", "Night", "Afternoon"], "Operator": ["John Doe", "Anna K", "Unknown", "Mark L", "Mary P"], "FailureType": ["Electrical", "Mechanical", "Hydraulic", "Unknown"]}, "descriptive_stats_downtime": {"count": 11, "mean": 1.77, "std": 0.88, "min": 0.5, "25%": 1.0, "50%": 1.5, "75%": 2.5, "max": 3.0}, "date_format_standardized": true, "value_counts": {"FailureType": {"Mechanical": 4, "Electrical": 3, "Hydraulic": 2, "Unknown": 1}, "Shift": {"Morning": 3, "Night": 4, "Afternoon": 4}}, "top_operators_by_incidents": {"Anna K": 2, "Mary P": 2}, "average_downtime_per_failure": {"Electrical": 1.67, "Mechanical": 1.63, "Hydraulic": 2.1, "Unknown": 1.5}, "correlation_downtime_shift_encoded": {"correlation_coefficient": 0.12, "note": "Shift encoded as Morning=0, Afternoon=1, Night=2"}, "rows_with_missing_data": [{"MachineID": "M003", "DowntimeHours": null, "Operator": "unknown"}, {"MachineID": "M007", "DowntimeHours": null, "Operator": null}, {"MachineID": "M005", "Date": null}]}}
{"purpose": "Explore patient demographics and vital sign measurements to identify missing data patterns and distribution characteristics in a cardiology outpatient dataset.", "raw_table": "Patient_ID,Age,Gender,Visit_Date,Blood_Pressure,Heart_Rate,Diagnosis\n001,45,Male,2023-01-15,120/80,72,Hypertension\n002,38,Female,15-02-2023,130/85,NA,Hypertension\n003,,female,03/01/2023,115/75,68,Normal\n004,52,M,2023/02/28,140/90,80,Hypertension\n005,47,Female,2023-3-05,,78,HYPERtension\n006,29,Male,2023-03-12,110/70,65,normal\n007,60,F,2023/03/15,145/95,85,Diabetes\n008,55,Male,2023-03-20,138/88,82,diabetes\n009,42,Female,2023-03-22,125/82,,Hypertension\n010,33,,2023-03-25,118/76,70,\n011,50,Female,2023-03-27,135/89,77,Hypertension\n012,47,Male,2023-03-30,129/84,75,Pre-Diabetes\n013,NaN,Female,2023-04-01,132/86,80,Diabetes\n014,54,Male,04/04/2023,139/90,82,Hypertension", "eda_steps": ["Check for missing values in each column", "Standardize the Gender column values", "Parse and unify the Visit_Date column into a consistent date format", "Extract systolic and diastolic values from Blood_Pressure and compute their descriptive statistics", "Compute summary statistics for Age and Heart_Rate columns", "Generate value counts for the Diagnosis column", "Identify the number of unique patients", "Calculate the percentage of missing entries per column", "Visualize distribution skewness for Age and Heart_Rate"], "eda_results": {"missing_values": {"Patient_ID": 0, "Age": 2, "Gender": 1, "Visit_Date": 0, "Blood_Pressure": 1, "Heart_Rate": 2, "Diagnosis": 1}, "standardized_gender_counts": {"Male": 6, "Female": 6, "Unknown": 1}, "visit_date_formats": {"YYYY-MM-DD": 9, "DD-MM-YYYY": 1, "MM/DD/YYYY": 2, "YYYY/MM/DD": 2}, "blood_pressure_stats": {"Systolic": {"mean": 129.8, "min": 110, "max": 145, "missing": 1}, "Diastolic": {"mean": 84.2, "min": 70, "max": 95, "missing": 1}}, "age_stats": {"mean": 46.3, "min": 29, "max": 60, "missing": 2}, "heart_rate_stats": {"mean": 75.3, "min": 65, "max": 85, "missing": 2}, "diagnosis_value_counts": {"Hypertension": 6, "Diabetes": 3, "Normal": 2, "Pre-Diabetes": 1, "": 1}, "unique_patients": 14, "missing_percentage_per_column": {"Age": 14.3, "Gender": 7.1, "Blood_Pressure": 7.1, "Heart_Rate": 14.3, "Diagnosis": 7.1}, "skewness": {"Age": 0.18, "Heart_Rate": 0.05}}}
{"purpose": "Analyze recent stock trading activity and identify key patterns in trade volume and price fluctuations.", "raw_table": "Trade_ID,Stock_Symbol,Trade_Date,Trade_Time,Trade_Price,Trade_Volume,Trader_Type\nT001,AAPL,2023/04/01,09:30 AM,145.32,1000,Institutional\nT002,googl,04-01-2023,09:33,2734.5,500,Retail\nT003,MSFT,2023-04-01,09:35 AM,missing,750,Institutional\nT004,AmZn,01-Apr-2023,09:40 AM,3342.88,NaN,Retail\nT005,aapl,2023/4/1,09:45,146.00,1200,retail\nT006,GOOGL,1/4/2023,09:50 AM,2736.0,300,Institutional\nT007,msft,04/01/2023,09:55,289.1,800,Retail\nT008,AMZN,2023-04-01,10:00,3345.5,1000,Institutional\nT009,AAPL,04/01/23,10:05,145.85,1100,Institutional\nT010,googl,2023/04/01,10:10 AM,2735.2,450,Retail\nT011,MSFT,April 1, 2023,10:15,288.5,700,Retail\nT012,amzn,2023/04/01,10:20 AM,missing,900,Institutional", "eda_steps": ["Check and count missing values in each column", "Standardize the Stock_Symbol column to uppercase", "Convert Trade_Date and Trade_Time columns into a single datetime column", "Compute descriptive statistics for Trade_Price and Trade_Volume", "Generate value counts for Trader_Type", "Identify rows with missing Trade_Price or Trade_Volume", "Calculate correlation between Trade_Price and Trade_Volume", "Summarize average trade price per stock symbol"], "eda_results": {"missing_values": {"Trade_Price": 2, "Trade_Volume": 1, "Trade_Date": 0, "Trade_Time": 0, "Stock_Symbol": 0, "Trader_Type": 0}, "standardized_stock_symbols": ["AAPL", "GOOGL", "MSFT", "AMZN", "AAPL", "GOOGL", "MSFT", "AMZN", "AAPL", "GOOGL", "MSFT", "AMZN"], "parsed_datetime_sample": ["2023-04-01 09:30:00", "2023-04-01 09:33:00", "2023-04-01 09:35:00", "2023-04-01 09:40:00"], "summary_stats": {"Trade_Price": {"count": 10, "mean": 1293.12, "std": 1344.16, "min": 145.32, "25%": 288.55, "50%": 289.1, "75%": 2735.15, "max": 3345.5}, "Trade_Volume": {"count": 11, "mean": 819.09, "std": 274.46, "min": 300, "25%": 700, "50%": 800, "75%": 1000, "max": 1200}}, "trader_type_counts": {"Institutional": 6, "Retail": 6}, "rows_with_missing_trade_price_or_volume": ["T003", "T004", "T012"], "correlation_trade_price_volume": 0.88, "average_trade_price_per_stock": {"AAPL": 145.72, "GOOGL": 2735.23, "MSFT": 288.23, "AMZN": 3344.19}}}
{"purpose": "Analyze city public transportation usage patterns and identify data quality issues.", "raw_table": "Date,Route,Passengers,Delay (minutes),Driver,Status\n2024-05-01,Route 5,120,5,john smith,On Time\n05/02/2024,route 7,NaN,15,Jane Doe,Delayed\n2024/05/03,route 5,95,0,John Smith,On time\n2024-05-04,Route 9,85,,jane doe,On Time\n2024-05-05,Route 7,110,20,Mark Johnson,DELAYED\n2024-5-06,Route 5,NaN,0,Mark Johnson,On time\n2024-05-07,route 9,90,7,Ann Lee,\n2024-05-08,Route 7,105,12,Ann Lee,Delayed\n2024-05-09,route 5,100,3,JOHN SMITH,On Time\n2024-05-10,Route 9,80,NaN,Jane Doe,On Time", "eda_steps": ["Parse and standardize the Date column to a uniform format", "Convert Route and Status columns to consistent capitalization", "Identify and quantify missing values in each column", "Compute descriptive statistics for the Passengers and Delay columns", "Generate value counts for the Route and Status columns", "Check for duplicate records based on Date and Route", "Analyze the average delay per Route", "Identify unique drivers and count their total trips", "Visualize the distribution of Passengers across Routes (conceptual step)"], "eda_results": {"missing_values": {"Date": 0, "Route": 0, "Passengers": 2, "Delay (minutes)": 3, "Driver": 0, "Status": 1}, "value_counts": {"Route": {"Route 5": 4, "Route 7": 3, "Route 9": 3}, "Status": {"On Time": 6, "Delayed": 3, "": 1}}, "summary_stats": {"Passengers": {"count": 8, "mean": 99.375, "min": 80, "max": 120, "std": 12.44}, "Delay (minutes)": {"count": 7, "mean": 7.43, "min": 0, "max": 20, "std": 7.26}}, "average_delay_per_route": {"Route 5": 2.67, "Route 7": 15.67, "Route 9": 3.5}, "unique_drivers": {"John Smith": 3, "Jane Doe": 3, "Mark Johnson": 2, "Ann Lee": 2}, "duplicates_found": 0}}
{"purpose": "Explore key metrics and data quality issues in a sample real estate property listing dataset.", "raw_table": "PropertyID,Location,Price,Bedrooms,Bathrooms,SquareFeet,ListDate,PropertyType\n1,Downtown,450000,3,2,1500,2023-01-15,Condo\n2,suburbs,350000,4,,1800,01/20/2023,House\n3,Midtown,NaN,2,1,900,2023/01/25,Townhouse\n4,uptown,500000,3,3,2000,15-02-2023,House\n5,Suburbs,380000,3,2,1600,2023-02-18,house\n6,Downtown,480000,3,2,NaN,2023-02-20,Condo\n7,midtown,420000,3,2,1400,02/25/2023,TownHouse\n8,Suburbs,400000,NaN,2,1700,2023-02-28,House\n9,Uptown,520000,4,3,2100,28-02-2023,house\n10,downtown,460000,3,2,1550,2023-03-01,Condo", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization of Location and PropertyType columns", "Convert ListDate column to a consistent date format", "Compute descriptive statistics for Price, Bedrooms, Bathrooms, and SquareFeet", "Generate value counts for PropertyType and Location", "Identify the number of unique PropertyIDs", "Calculate correlation matrix for numeric columns", "Find the average Price per PropertyType"], "eda_results": {"missing_values": {"PropertyID": 0, "Location": 0, "Price": 1, "Bedrooms": 1, "Bathrooms": 1, "SquareFeet": 1, "ListDate": 0, "PropertyType": 0}, "standardized_values": {"Location": ["Downtown", "Suburbs", "Midtown", "Uptown"], "PropertyType": ["Condo", "House", "Townhouse"]}, "listdate_format": "All dates converted to YYYY-MM-DD", "summary_stats": {"Price": {"count": 9, "mean": 445555.56, "min": 350000, "max": 520000, "std": 56547.01}, "Bedrooms": {"count": 9, "mean": 3.22, "min": 2, "max": 4, "std": 0.67}, "Bathrooms": {"count": 9, "mean": 2.22, "min": 1, "max": 3, "std": 0.67}, "SquareFeet": {"count": 9, "mean": 1622.22, "min": 900, "max": 2100, "std": 382.04}}, "value_counts": {"PropertyType": {"House": 5, "Condo": 3, "Townhouse": 2}, "Location": {"Downtown": 3, "Suburbs": 3, "Midtown": 2, "Uptown": 2}}, "unique_PropertyID_count": 10, "correlations": {"Price-Bedrooms": 0.89, "Price-Bathrooms": 0.85, "Price-SquareFeet": 0.92}, "average_price_per_propertytype": {"Condo": 463333.33, "House": 430000, "Townhouse": 420000}}}
{"purpose": "Analyze customer purchase patterns and product category performance in an ecommerce store.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,UnitPrice,PaymentMethod,CustomerRegion\n1001,cust_01,2023-03-15,Electronics,2,199.99,Credit Card,North America\n1002,CUST_02,15/03/2023,Books,1,15.5,Paypal,europe\n1003,cust_03,2023-03-16,electronics,,299.99,Credit card,Asia\n1004,cust_04,2023/03/16,Home & Kitchen,3,45.0,Cash,North America\n1005,cust_05,03-17-2023,Toys,2,25.0,Credit Card,South America\n1006,,2023-03-17,Books,1,15.5,Credit Card,Europe\n1007,cust_07,2023.03.18,Books,2,,Paypal,Europe\n1008,cust_08,2023-03-19,home & kitchen,1,50.0,Cash,North america\n1009,cust_09,2023-03-19,Electronics,1,199.99,credit card,Africa\n1010,cust_10,Mar 20 2023,Toys,1,25.0,Credit Card,South america\n1011,cust_11,2023-03-20,Books,1,not available,Paypal,europe\n1012,cust_12,2023-03-21,Clothing,2,35.0,Credit Card,North America\n1013,CUST_13,03/21/2023,Clothing,1,35.0,Paypal,Europe\n1014,cust_14,2023-03-22,,1,12.0,Cash,Asia", "eda_steps": ["Check for missing values across all columns", "Standardize capitalization in categorical columns: ProductCategory, PaymentMethod, CustomerRegion", "Parse and unify OrderDate into ISO format YYYY-MM-DD", "Compute descriptive statistics for Quantity and UnitPrice", "Generate value counts for ProductCategory and PaymentMethod", "Calculate total sales amount per ProductCategory (Quantity * UnitPrice)", "Identify orders with invalid or missing UnitPrice values", "Summarize number of unique customers and orders", "Analyze distribution of orders by CustomerRegion"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 0, "ProductCategory": 1, "Quantity": 1, "UnitPrice": 2, "PaymentMethod": 0, "CustomerRegion": 0}, "standardized_categories": {"ProductCategory": ["Electronics", "Books", "Home & Kitchen", "Toys", "Clothing", null], "PaymentMethod": ["Credit Card", "Paypal", "Cash", "Credit Card", "Paypal", "Cash"], "CustomerRegion": ["North America", "Europe", "Asia", "South America", "Africa"]}, "date_range": {"min_date": "2023-03-15", "max_date": "2023-03-22"}, "summary_stats": {"Quantity": {"count": 13, "mean": 1.54, "min": 1, "max": 3, "median": 1}, "UnitPrice": {"count": 12, "mean": 89.77, "min": 12.0, "max": 299.99, "median": 35.0}}, "value_counts": {"ProductCategory": {"Books": 4, "Electronics": 3, "Home & Kitchen": 2, "Toys": 2, "Clothing": 2, "null": 1}, "PaymentMethod": {"Credit Card": 7, "Paypal": 4, "Cash": 3}}, "total_sales_per_category": {"Electronics": 899.96, "Books": 62.0, "Home & Kitchen": 185.0, "Toys": 75.0, "Clothing": 105.0, "null": 12.0}, "orders_with_invalid_price": [1011, 1007], "unique_customers": 13, "total_orders": 14, "orders_by_region": {"North America": 4, "Europe": 4, "Asia": 2, "South America": 2, "Africa": 1}}}
{"purpose": "Explore student performance and attendance patterns in a middle school to identify data quality issues and key trends.", "raw_table": "Student_ID,Name,Grade,Math_Score,English_Score,Attendance,Enrollment_Date\n101,alice,7,88,92,95%,2022-09-01\n102,Bob,7,,85,90%,09/05/2022\n103,charlie,8,75,,85%,2022/09/10\n104,Diana,7,82,78,missing,2022-9-08\n105,Eva,8,91,88,98%,2022-09-07\n106,Fred,7,not available,80,87%,2022-09-01\n107,george,8,84,79,89%,2022-09-11\n108,Hannah,8,90,85,,2022-09-12\n109,Ian,7,77,83,92%,2022-09-01\n110,Jack,7,85,NaN,93%,2022-09-03", "eda_steps": ["Check the data types of each column", "Identify and quantify missing values in the dataset", "Standardize the date format in Enrollment_Date column", "Convert Attendance percentages to numeric values", "Calculate descriptive statistics for Math_Score and English_Score", "Count unique grades and analyze their distribution", "Identify any non-numeric or inconsistent entries in score columns", "Calculate correlation between Math_Score and English_Score", "Summarize attendance rate distribution"], "eda_results": {"data_types": {"Student_ID": "int", "Name": "string", "Grade": "string", "Math_Score": "string/object due to mixed type", "English_Score": "string/object due to mixed type", "Attendance": "string", "Enrollment_Date": "string"}, "missing_values": {"Math_Score": 2, "English_Score": 2, "Attendance": 2}, "standardized_dates": ["2022-09-01", "2022-09-05", "2022-09-10", "2022-09-08", "2022-09-07", "2022-09-01", "2022-09-11", "2022-09-12", "2022-09-01", "2022-09-03"], "attendance_numeric": [95, 90, 85, null, 98, 87, 89, null, 92, 93], "summary_stats": {"Math_Score": {"count": 8, "mean": 83.25, "min": 75, "max": 91, "std_dev": 5.88}, "English_Score": {"count": 8, "mean": 84, "min": 78, "max": 92, "std_dev": 4.85}}, "grade_distribution": {"7": 6, "8": 4}, "non_numeric_scores": {"Math_Score": ["not available", ""], "English_Score": ["NaN", ""]}, "correlations": {"Math_Score_vs_English_Score": 0.76}, "attendance_summary": {"mean_attendance": 90.9, "min_attendance": 85, "max_attendance": 98, "missing_count": 2}}}
{"purpose": "Analyze city government employee demographics and department distribution to identify data quality issues and workforce composition.", "raw_table": "EmployeeID,Department,JobTitle,Salary,StartDate,Status\n101,Public Works,Manager,85000,2018-05-10,Active\n102,HEALTH,Analyst,61000,2017/03/15,active\n103,Finance,Clerk,45000,2019-11-01,Inactive\n104,public works,Technician,,2016-07-23,Active\n105,Health,Manager,78000,07-12-2018,Active\n106,,Analyst,62000,2019-01-20,Active\n107,Finance,Senior Analyst,70000,2019/05/30,\n108,Transportation,Engineer,72000,2018-10-01,active\n109,Transportation,engineer,71000,2018-10-01,Active\n110,Finance,Clerk,46000,2017-06-15,Active\n111,Public Works,Technician,49000,2016/07/23,Inactive\n112,Health,,67000,2017/12/05,Active\n113,Finance,Manager,90000,,Active\n114,Transportation,Technician,55000,2018-09-10,Active", "eda_steps": ["Check the number and percentage of missing values for each column", "Standardize the 'Department' column capitalization", "Generate value counts for the 'Status' column", "Compute descriptive statistics for the 'Salary' column", "Identify duplicate job titles with different capitalizations", "Analyze the distribution of employees by department", "Check for inconsistent or missing 'StartDate' entries", "Summarize the count of employees per job title"], "eda_results": {"missing_values": {"EmployeeID": 0, "Department": 1, "JobTitle": 1, "Salary": 1, "StartDate": 2, "Status": 1}, "department_counts": {"Public Works": 3, "Health": 3, "Finance": 4, "Transportation": 4, "": 1}, "status_value_counts": {"Active": 9, "Inactive": 2, "": 1}, "salary_stats": {"count": 13, "mean": 65538.46, "min": 45000, "max": 90000, "median": 62000, "std_dev": 15047.06}, "job_title_duplicates": [{"title_variants": ["Engineer", "engineer"], "count": 2}], "start_date_issues": {"missing_count": 2, "inconsistent_formats": ["2017/03/15", "07-12-2018", "2019/05/30", "2016/07/23"]}, "employees_per_job_title": {"Manager": 3, "Analyst": 2, "Clerk": 2, "Technician": 3, "Senior Analyst": 1, "Engineer": 2, "": 1}}}
{"purpose": "Evaluate crop yield factors and data quality issues in farm production records.", "raw_table": "Farm_ID,Crop_Type,Planting_Date,Harvest_Date,Yield_kg,Soil_Type,Fertilizer_Used,Rainfall_mm\n101,Wheat,2023/03/15,2023-08-10,3500,Loam,Yes,450\n102,CORN,15-04-2023,10-09-2023,4200,Sandy,No,380\n103,Rice,2023-05-01,,2800,Clay,yes,500\n104,Barley,2023/03/20,2023-08-25,NaN,Silt,No,tbd\n105,Wheat,2023-03-18,2023-08-12,3600,loam,Yes,430\n106,corn,2023/04/16,2023-09-12,4000,SANDY,No,410\n107,Rice,2023-05-02,2023-09-30,2900,Clay,Yes,480\n108,Barley,,2023-08-28,3100,Silt,No,450\n109,Wheat,2023-03-17,2023-08-11,3550,Loam,Yes,NaN\n110,Corn,2023-04-14,2023-09-11,4150,Sandy,No,395", "eda_steps": ["Convert date columns to consistent datetime format and identify missing dates", "Standardize categorical columns capitalization (Crop_Type, Soil_Type, Fertilizer_Used)", "Check missing value percentages per column", "Compute descriptive statistics for numeric columns: Yield_kg and Rainfall_mm", "Generate value counts for Crop_Type and Soil_Type", "Calculate correlation between Yield_kg and Rainfall_mm", "Identify rows with anomalous or missing Yield_kg values", "Summarize fertilizer usage frequency", "Analyze average yield per crop type"], "eda_results": {"missing_values": {"Farm_ID": 0, "Crop_Type": 0, "Planting_Date": 1, "Harvest_Date": 1, "Yield_kg": 1, "Soil_Type": 0, "Fertilizer_Used": 0, "Rainfall_mm": 2}, "standardized_categories": {"Crop_Type": ["Wheat", "Corn", "Rice", "Barley"], "Soil_Type": ["Loam", "Sandy", "Clay", "Silt"], "Fertilizer_Used": ["Yes", "No"]}, "value_counts": {"Crop_Type": {"Wheat": 3, "Corn": 3, "Rice": 2, "Barley": 2}, "Soil_Type": {"Loam": 3, "Sandy": 3, "Clay": 2, "Silt": 2}, "Fertilizer_Used": {"Yes": 5, "No": 5}}, "descriptive_stats": {"Yield_kg": {"count": 9, "mean": 3488.89, "std": 471.92, "min": 2800, "25%": 3100, "50%": 3550, "75%": 4000, "max": 4200}, "Rainfall_mm": {"count": 8, "mean": 440, "std": 38.73, "min": 380, "25%": 410, "50%": 440, "75%": 480, "max": 500}}, "correlations": {"Yield_kg_vs_Rainfall_mm": 0.65}, "anomalies": {"missing_yield_rows": [4], "missing_planting_date_rows": [7], "missing_harvest_date_rows": [2]}, "fertilizer_usage": {"Yes": 5, "No": 5}, "average_yield_per_crop": {"Wheat": 3550, "Corn": 4116.67, "Rice": 2850, "Barley": 3100}}}
{"purpose": "Analyze customer purchase behavior and product category trends over a two-week period.", "raw_table": "OrderID,CustomerID,ProductCategory,Quantity,Price,OrderDate,PaymentMethod\n1001,cust_01,Electronics,2,399.99,2024-04-01,Credit Card\n1002,CUST_02,home & garden,1,,04/02/2024,Paypal\n1003,cust_03,Fashion,3,29.99,2024/04/03,Credit card\n1004,cust_04,Electronics,1,199.99,2024-4-04,Cash\n1005,,Fashion,2,25.50,2024-04-05,credit card\n1006,cust_06,Home & Garden,,89.99,April 06 2024,Paypal\n1007,cust_07,SPORTS,1,59.99,2024-04-07,credit card\n1008,CUST_08,Electronics,1,499.99,2024-4-8,Credit Card\n1009,cust_09,Fashion,4,19.99,2024-04-09,CASH\n1010,cust_10,sports,2,49.99,04-10-2024,Paypal\n1011,cust_11,Home & garden,1,79.99,2024-04-11,Credit Card\n1012,cust_12,Electronics,3,299.99,2024/04/12,Cash\n1013,cust_13,,1,15.00,2024-04-13,Credit card", "eda_steps": ["Check the percentage of missing values in each column", "Standardize capitalization in ProductCategory and PaymentMethod columns", "Parse and unify the OrderDate format to YYYY-MM-DD", "Compute descriptive statistics for Quantity and Price columns", "Generate value counts for ProductCategory", "Identify the most common PaymentMethod", "Calculate total sales amount per ProductCategory (Quantity * Price)", "Find orders missing CustomerID or ProductCategory", "Summarize distribution skewness for Quantity and Price"], "eda_results": {"missing_values": {"OrderID": "0%", "CustomerID": "7.69%", "ProductCategory": "7.69%", "Quantity": "7.69%", "Price": "7.69%", "OrderDate": "0%", "PaymentMethod": "0%"}, "standardized_categories": {"ProductCategory": ["Electronics", "Home & Garden", "Fashion", "Sports", "Unknown"], "PaymentMethod": ["Credit Card", "Paypal", "Cash"]}, "order_date_format": "All dates converted to YYYY-MM-DD", "summary_stats": {"Quantity": {"count": 13, "mean": 1.92, "std": 1.07, "min": 1, "25%": 1, "50%": 1, "75%": 2, "max": 4, "skewness": 1.12}, "Price": {"count": 12, "mean": 173.4, "std": 165.01, "min": 15.0, "25%": 49.99, "50%": 79.99, "75%": 299.99, "max": 499.99, "skewness": 1.67}}, "value_counts": {"ProductCategory": {"Electronics": 4, "Fashion": 4, "Home & Garden": 3, "Sports": 2, "Unknown": 1}, "PaymentMethod": {"Credit Card": 6, "Paypal": 3, "Cash": 3}}, "top_payment_method": "Credit Card", "total_sales_per_category": {"Electronics": 2799.93, "Fashion": 184.94, "Home & Garden": 269.98, "Sports": 159.97, "Unknown": 15.0}, "orders_missing_customer_or_category": [{"OrderID": 1005, "Missing": "CustomerID"}, {"OrderID": 1013, "Missing": "ProductCategory"}]}}
{"purpose": "Analyze real estate listings to understand price distributions, missing data, and property type prevalence.", "raw_table": "ListingID,DateListed,Price,PropertyType,Bedrooms,Bathrooms,SquareFeet,Location\n001,2023-01-15,350000,Condo,2,1,900,Downtown\n002,15/02/2023,450000,Single Family,3,2,1400,Suburb\n003,2023/03/05,,Townhouse,3,,1300,Midtown\n004,04-20-2023,550000,single family,4,3,1800,Suburb\n005,2023-05-10,NaN,Condo,1,1,700,downtown\n006,2023-06-01,620000,Multi-family,5,4,2500,Suburb\n007,06/15/2023,480000,Townhouse,,2,1500,Midtown\n008,2023-07-03,720000,Single family,4,3,2000,Suburb\n009,2023-07-15,415000,CONDO,2,1,850,Downtown\n010,2023-08-01,NaN,Multi-family,4,3,,Suburb\n011,2023-08-10,510000,Townhouse,3,2,1450,MIDTOWN\n012,2023-08-20,495000,Apartment,2,2,1100,Downtown\n013,2023-09-01,530000,Single Family,3,2,1600,Suburb", "eda_steps": ["Check and standardize date formats in the DateListed column", "Calculate the percentage of missing values per column", "Convert Price to numeric and summarize descriptive statistics", "Normalize PropertyType values for consistent capitalization", "Count unique values and frequency for PropertyType", "Summarize Bedroom and Bathroom counts including missing data", "Analyze distribution of SquareFeet and handle missing values", "Compute correlation matrix between numeric variables: Price, Bedrooms, Bathrooms, SquareFeet", "Identify top locations by number of listings"], "eda_results": {"missing_values": {"Price": "15.4%", "Bedrooms": "7.7%", "Bathrooms": "7.7%", "SquareFeet": "7.7%", "DateListed": "0%", "PropertyType": "0%", "Location": "0%"}, "date_formats_standardized": true, "summary_stats": {"Price": {"count": 11, "mean": 513636.36, "std": 107854.88, "min": 350000, "25%": 450000, "50%": 510000, "75%": 550000, "max": 720000}, "Bedrooms": {"count": 12, "mean": 3.17, "std": 1.07, "min": 1, "25%": 2, "50%": 3, "75%": 4, "max": 5}, "Bathrooms": {"count": 11, "mean": 2.18, "std": 0.87, "min": 1, "25%": 1.5, "50%": 2, "75%": 3, "max": 4}, "SquareFeet": {"count": 12, "mean": 1392.5, "std": 493.6, "min": 700, "25%": 900, "50%": 1400, "75%": 1800, "max": 2500}}, "value_counts": {"PropertyType": {"Single Family": 5, "Condo": 3, "Townhouse": 3, "Multi-family": 2, "Apartment": 1}, "Location": {"Suburb": 6, "Downtown": 4, "Midtown": 3}}, "correlations": {"Price-Bedrooms": 0.89, "Price-Bathrooms": 0.85, "Price-SquareFeet": 0.92, "Bedrooms-Bathrooms": 0.95, "Bedrooms-SquareFeet": 0.88, "Bathrooms-SquareFeet": 0.87}, "top_locations_by_listings": {"Suburb": 6, "Downtown": 4, "Midtown": 3}}}
{"purpose": "Analyze ride-sharing trip data to understand trip durations, popular vehicle types, and identify data quality issues.", "raw_table": "trip_id,request_time,pickup_location,dropoff_location,vehicle_type,duration_minutes,fare\nT001,2024-06-01 08:15, Downtown,Airport,Sedan,25,35.5\nT002,06/01/2024 09:00,Suburb, Downtown,suv,40,48.0\nT003,2024/06/01 10:30,,Airport,Sedan,30,NA\nT004,2024-06-01 11:00,Downtown,suburb,Van, ,52.0\nT005,2024-06-01 12:15,Airport,Downtown,bike,15,12.0\nT006,06-01-2024 13:00,Suburb,Airport,Sedan,35,40.0\nT007,2024-6-1 14:20,Downtown,Suburb,sedan,45,55.0\nT008,2024-06-01 15:45,Airport,Suburb,SUV, ,60.0\nT009,2024-06-01 16:10,Suburb,Downtown,Van,50,58.0\nT010,June 1, 2024 17:00,Downtown,Airport,Sedan,20,30.0\nT011,2024-06-01 18:30,Downtown,,SUV,55,65.0\nT012,2024-06-01 19:00,Suburb,Airport,Van,NA,54.0\nT013,2024-06-01 20:15,Airport,Suburb,Sedan,40,45.0", "eda_steps": ["Check for missing values in each column", "Standardize date format in the request_time column", "Normalize vehicle_type capitalization", "Compute descriptive statistics for duration_minutes and fare columns", "Generate value counts for vehicle_type", "Identify top 3 pickup locations", "Calculate correlation between duration_minutes and fare", "Identify rows with inconsistent or missing locations"], "eda_results": {"missing_values": {"trip_id": 0, "request_time": 0, "pickup_location": 1, "dropoff_location": 2, "vehicle_type": 0, "duration_minutes": 4, "fare": 1}, "standardized_date_sample": ["2024-06-01T08:15:00", "2024-06-01T09:00:00", "2024-06-01T10:30:00"], "vehicle_type_counts": {"Sedan": 5, "SUV": 3, "Van": 3, "Bike": 1}, "top_pickup_locations": {"Downtown": 5, "Airport": 4, "Suburb": 4}, "descriptive_stats": {"duration_minutes": {"count": 9, "mean": 35.56, "std": 11.17, "min": 15, "25%": 25, "50%": 35, "75%": 45, "max": 55}, "fare": {"count": 12, "mean": 47.96, "std": 14.08, "min": 12, "25%": 35.5, "50%": 48, "75%": 55, "max": 65}}, "duration_fare_correlation": 0.92, "inconsistent_location_rows": [3, 11]}}
{"purpose": "Analyze patient demographic and clinical characteristics in a small cardiology outpatient dataset.", "raw_table": "PatientID,Age,Gender,VisitDate,Diagnosis,BloodPressure,Cholesterol\n001,45,Male,2023-01-05,Hypertension,135/85,220\n002,52,Female,01/15/2023,hypertension,140/90,NaN\n003,37,Male,2023/02/10,CAD,130/80,180\n004,,female,2023-02-20,Coronary artery disease,128/82,200\n005,60,M,2/25/23,Hypertensive heart disease,145/95,250\n006,48,Female,,CAD,135/88,NaN\n007,55,MALE,03-05-2023,hypertension,,215\n008,50,F,2023-03-10,coronary Artery Disease,138/85,205\n009,47,Female,2023-03-15,,140/90,190\n010,53,Male,03/20/2023,Hypertension,NaN,210", "eda_steps": ["Check for missing values in each column", "Standardize the Gender column values to consistent capitalization and unify categories", "Parse and unify VisitDate into a consistent date format", "Extract systolic and diastolic values from the BloodPressure column", "Compute descriptive statistics for Age, systolic BP, diastolic BP, and Cholesterol", "Generate value counts for the Diagnosis column after standardizing diagnosis names", "Identify the percentage of missing values per column", "Calculate correlation between Age, systolic BP, diastolic BP, and Cholesterol"], "eda_results": {"missing_values": {"PatientID": 0, "Age": 1, "Gender": 0, "VisitDate": 1, "Diagnosis": 1, "BloodPressure": 1, "Cholesterol": 2}, "gender_value_counts": {"Male": 5, "Female": 4, "M": 1, "F": 1, "MALE": 1, "female": 1}, "standardized_gender_counts": {"Male": 7, "Female": 4}, "diagnosis_value_counts_raw": {"Hypertension": 4, "hypertension": 2, "CAD": 3, "Coronary artery disease": 1, "Hypertensive heart disease": 1, "coronary Artery Disease": 1, "": 1}, "standardized_diagnosis_counts": {"Hypertension": 6, "Coronary Artery Disease": 5, "Hypertensive Heart Disease": 1, "Missing": 1}, "age_statistics": {"count": 9, "mean": 49.0, "min": 37, "max": 60, "std_dev": 7.3}, "blood_pressure_extracted": {"systolic": {"count": 8, "mean": 137.4, "min": 128, "max": 145, "std_dev": 5.9}, "diastolic": {"count": 8, "mean": 87.9, "min": 80, "max": 95, "std_dev": 5.2}}, "cholesterol_statistics": {"count": 8, "mean": 211.3, "min": 180, "max": 250, "std_dev": 23.7}, "missing_percentage": {"Age": 10, "VisitDate": 10, "Diagnosis": 10, "BloodPressure": 10, "Cholesterol": 20}, "correlations": {"Age_SystolicBP": 0.68, "Age_DiastolicBP": 0.57, "Age_Cholesterol": 0.74, "SystolicBP_DiastolicBP": 0.91, "SystolicBP_Cholesterol": 0.62, "DiastolicBP_Cholesterol": 0.49}}}
{"purpose": "Analyze monthly transaction patterns and customer segmentation in a retail banking dataset.", "raw_table": "TransactionID,CustomerID,TransactionDate,TransactionAmount,AccountType,Region\nTX1001,CUST01,2023/01/15,1200,Checking,North\nTX1002,CUST02,15-02-2023,850,SAVINGS,South\nTX1003,CUST03,2023-03-02,NaN,checking,East\nTX1004,CUST04,,400,Savings,west\nTX1005,CUST01,2023/04/10,700,Checking,North\nTX1006,CUST05,2023-05-05,950,,East\nTX1007,CUST06,06-06-2023,1100,SAVING,South\nTX1008,CUST07,2023/07/20,NaN,Checking,North\nTX1009,CUST08,2023-08-18,-300,Savings,Central\nTX1010,CUST09,2023-09-10,1300,CHECKING,South\nTX1011,CUST10,10/10/2023,500,Checking,West\nTX1012,CUST11,2023-11-11,NaN,Savings,East\nTX1013,CUST12,2023-12-12,1050,Checking,North\nTX1014,CUST13,2023-13-01,870,Savings,South\n", "eda_steps": ["Convert 'TransactionDate' to a consistent datetime format and handle parsing errors", "Identify and count missing values in each column", "Standardize the capitalization for 'AccountType' and 'Region' columns", "Compute descriptive statistics for the 'TransactionAmount' column", "Generate value counts for 'AccountType' and 'Region' columns", "Detect transactions with negative or zero amounts", "Calculate the distribution of transactions per month", "Identify unique customers and count transactions per customer"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 0, "TransactionDate": 1, "TransactionAmount": 3, "AccountType": 1, "Region": 0}, "date_conversion_errors": 1, "standardized_account_types": {"Checking": 7, "Savings": 6, "Unknown": 1}, "standardized_regions": {"North": 4, "South": 4, "East": 3, "West": 2, "Central": 1}, "transaction_amount_stats": {"count": 11, "mean": 822.73, "std": 420.28, "min": -300, "25%": 500, "50%": 850, "75%": 1100, "max": 1300}, "negative_transactions": 1, "transactions_per_month": {"Jan": 1, "Feb": 1, "Mar": 1, "Apr": 1, "May": 1, "Jun": 1, "Jul": 1, "Aug": 1, "Sep": 1, "Oct": 1, "Nov": 1, "Dec": 1}, "unique_customers": 13, "transactions_per_customer": {"CUST01": 2, "CUST02": 1, "CUST03": 1, "CUST04": 1, "CUST05": 1, "CUST06": 1, "CUST07": 1, "CUST08": 1, "CUST09": 1, "CUST10": 1, "CUST11": 1, "CUST12": 1, "CUST13": 1}}}
{"purpose": "Examine citizen complaints data to identify common issues and data quality problems.", "raw_table": "Complaint_ID,Date_Received,Agency,Complaint_Type,Status,Resolution_Time_Days\n1001,2023-01-15,Water Dept,Leakage,Pending,5\n1002,01/20/2023,Electricity,Power Outage,RESOLVED,3\n1003,2023/02/05,water dept,leakage,Resolved, \n1004,15-02-2023,Sanitation,Trash Collection,Closed,2\n1005,2023-02-18,Electricity,Power outage,,4\n1006,,Water Dept,Leakage,Closed,7\n1007,2023-02-25,Sanitation,trash collection,Open,NA\n1008,2023-03-01,Electricity,Power Outage,Resolved,6\n1009,2023-03-05,Transportation,Road Repair,Closed,10\n1010,03-10-2023,Transportation,road repair,Pending,8\n1011,2023/03/12,Electricity,Power Outage,Closed,4\n1012,2023-03-15,Water dept,Leakage,Resolved,3", "eda_steps": ["Check the percentage of missing values per column", "Standardize the date format in the Date_Received column", "Normalize capitalization for Agency and Complaint_Type columns", "Compute descriptive statistics for the Resolution_Time_Days column", "Generate value counts for Complaint_Type", "Generate value counts for Status", "Identify the average resolution time by Agency", "Identify the number of complaints by month", "Check for duplicate Complaint_ID values"], "eda_results": {"missing_values": {"Complaint_ID": "0%", "Date_Received": "8.33%", "Agency": "0%", "Complaint_Type": "0%", "Status": "8.33%", "Resolution_Time_Days": "8.33%"}, "date_format_standardized": true, "normalized_categories": {"Agency": ["Water Dept", "Electricity", "Sanitation", "Transportation"], "Complaint_Type": ["Leakage", "Power Outage", "Trash Collection", "Road Repair"], "Status": ["Pending", "Resolved", "Closed", "Open"]}, "summary_stats_Resolution_Time_Days": {"count": 12, "mean": 5.17, "std_dev": 2.54, "min": 2, "max": 10, "median": 4.5}, "value_counts_Complaint_Type": {"Leakage": 4, "Power Outage": 4, "Trash Collection": 2, "Road Repair": 2}, "value_counts_Status": {"Resolved": 4, "Closed": 4, "Pending": 2, "Open": 1, "": 1}, "avg_resolution_time_by_Agency": {"Water Dept": 5.0, "Electricity": 4.25, "Sanitation": 2.0, "Transportation": 9.0}, "complaints_by_month": {"January": 2, "February": 5, "March": 5}, "duplicate_Complaint_ID": false}}
{"purpose": "Analyze streaming platform movie ratings and user engagement to identify trends and data quality issues.", "raw_table": "MovieID,Title,Genre,ReleaseDate,UserRating,Views,DurationMinutes\n1,Inception,Sci-Fi,2010-07-16,8.8,10500,148\n2,Avengers: Endgame,action,26-04-2019,8.4,20500,181\n3,Toy Story 4,Animation,2019/06/21,7.8,8700,100\n4,parasite,Thriller,2019-05-30,8.6,9600,132\n5,Joker,Thriller,10-10-2019,,11000,122\n6,The Lion King,animation,,7.0,12000,88\n7,TENET,Sci-Fi,2020-08-26,7.5,6800,150\n8,The Godfather,Crime,1972/03/24,9.2,,175\n9,Spirited Away,animation,2001-07-20,8.6,7000,125\n10,Avengers: Infinity war,Action,2018-04-23,8.5,19000,149\n11,Frozen II,Animation,2019-11-22,7.2,8300,103", "eda_steps": ["Check missing value percentages per column", "Compute descriptive statistics for numeric columns: UserRating, Views, DurationMinutes", "Generate value counts for Genre column", "Identify inconsistent or unusual categories in Genre", "Analyze ReleaseDate format inconsistencies and count unique years", "Identify top 3 most viewed movies", "Check correlation between UserRating and Views", "Summarize the distribution skewness of UserRating"], "eda_results": {"missing_values": {"ReleaseDate": 1, "UserRating": 1, "Views": 1}, "summary_stats": {"UserRating": {"count": 10, "mean": 8.12, "std": 0.62, "min": 7.0, "25%": 7.5, "50%": 8.4, "75%": 8.6, "max": 9.2}, "Views": {"count": 10, "mean": 11360, "std": 4767, "min": 6800, "25%": 8300, "50%": 9600, "75%": 19000, "max": 20500}, "DurationMinutes": {"count": 11, "mean": 133.9, "std": 28.6, "min": 88, "25%": 100, "50%": 132, "75%": 149, "max": 181}}, "value_counts": {"Genre": {"Animation": 4, "action": 1, "Thriller": 2, "Sci-Fi": 2, "Crime": 1, "Action": 1}}, "inconsistent_genres": ["action", "Action", "animation", "Animation"], "release_years_count": 8, "top_3_most_viewed_movies": [{"Title": "Avengers: Endgame", "Views": 20500}, {"Title": "Avengers: Infinity war", "Views": 19000}, {"Title": "The Lion King", "Views": 12000}], "correlations": {"UserRating_Views": 0.67}, "user_rating_skewness": -0.34}}
{"purpose": "Examine monthly transaction patterns and customer segments in retail banking data.", "raw_table": "Customer_ID,Transaction_Date,Transaction_Amount,Account_Type,Transaction_Type,Branch\n001,2023-01-15,1200,Savings,Deposit,New York\n002,15/02/2023,,-Checking,withdrawal,los angeles\n003,2023-03-05,300.50,Savings,Withdrawal,Chicago\n004,2023/04/12,450,checking,deposit,NEW YORK\n005,2023-05-20,NaN,Savings,Transfer,Chicago\n006,06-2023-06,700,CHECKING,Withdrawal,los angeles\n007,2023-07-10,1500,Savings,Deposit,New York\n008,2023-08-09,500,checking,transfer,Chicago\n009,2023-09-15,400,,Deposit,NEW york\n010,2023-10-01,NaN,Savings,,los angeles\n011,2023-11-22,1000,Checking,Withdrawal,chicago\n012,2023-12-31,850,Savings,Deposit,New York", "eda_steps": ["Standardize date formats in Transaction_Date to YYYY-MM-DD", "Identify and count missing values per column", "Normalize capitalization in Account_Type and Branch columns", "Calculate descriptive statistics for Transaction_Amount", "Generate value counts for Account_Type and Transaction_Type", "Analyze distribution of transactions by Branch", "Calculate the correlation between Transaction_Amount and Account_Type (encoded)", "Identify transactions missing Transaction_Type", "Summarize total transaction amounts per month"], "eda_results": {"missing_values": {"Customer_ID": 0, "Transaction_Date": 0, "Transaction_Amount": 3, "Account_Type": 1, "Transaction_Type": 2, "Branch": 0}, "value_counts": {"Account_Type": {"Savings": 6, "Checking": 5, "": 1}, "Transaction_Type": {"Deposit": 5, "Withdrawal": 4, "Transfer": 2, "": 1}}, "summary_stats": {"Transaction_Amount": {"count": 9, "mean": 766.72, "std": 460.44, "min": 300.5, "25%": 450, "50%": 700, "75%": 1000, "max": 1500}}, "branch_distribution": {"New York": 4, "Los Angeles": 3, "Chicago": 5}, "transactions_missing_type": [10, 5], "correlation_transaction_amount_account_type": 0.21, "total_transaction_amount_per_month": {"2023-01": 1200, "2023-02": 0, "2023-03": 300.5, "2023-04": 450, "2023-05": 0, "2023-06": 700, "2023-07": 1500, "2023-08": 500, "2023-09": 400, "2023-10": 0, "2023-11": 1000, "2023-12": 850}}}
{"purpose": "Analyze monthly transactions and identify patterns in transaction types and amounts for a financial services firm.", "raw_table": "TransactionID,CustomerID,TransactionDate,TransactionType,Amount,Currency,Status\nTXN001,CUST1001,2023-01-15,Deposit,1500,usd,Completed\nTXN002,CUST1002,15/02/2023,withdrawal, -500,USD,completed\nTXN003,CUST1003,2023/03/05,Deposit,2000,Usd,Pending\nTXN004,CUST1001,2023-03-20,Payment,abc,USD,Completed\nTXN005,CUST1004,,deposit,700,usd,Failed\nTXN006,CUST1002,2023-04-01,Withdrawal,1200,USD,Completed\nTXN007,CUST1005,2023-04-15,Payment,300,usD,Canceled\nTXN008,CUST1003,2023-05-10,Deposit,,USD,Completed\nTXN009,CUST1006,2023-05-25,withdrawal,800,USD,Completed\nTXN010,CUST1007,2023-06-05,Payment,400,usd,completed\nTXN011,CUST1001,2023-06-10,DEPOSIT,500,USD,Completed\nTXN012,CUST1008,2023-06-15,withdrawal,-,usd,Pending\nTXN013,CUST1009,07-07-2023,deposit,1000,USD,Completed", "eda_steps": ["Check for missing values in each column", "Standardize capitalization in 'TransactionType', 'Currency', and 'Status' columns", "Convert 'TransactionDate' to a consistent date format", "Convert 'Amount' to numeric and identify non-numeric or missing values", "Compute descriptive statistics (mean, median, min, max) for the 'Amount' column", "Generate value counts for 'TransactionType' and 'Status'", "Calculate the number of transactions per month", "Identify transactions with negative or zero amounts", "Summarize unique customers and their transaction counts"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 0, "TransactionDate": 1, "TransactionType": 0, "Amount": 3, "Currency": 0, "Status": 0}, "standardized_categories": {"TransactionType": ["Deposit", "Withdrawal", "Payment"], "Currency": ["USD"], "Status": ["Completed", "Pending", "Failed", "Canceled"]}, "date_format_consistency": {"original_formats": ["YYYY-MM-DD", "DD/MM/YYYY", "YYYY/MM/DD", "MM-DD-YYYY"], "converted_to_iso": "All dates converted to YYYY-MM-DD format except missing"}, "amount_numeric_conversion": {"non_numeric_entries": ["abc", "-", ""], "converted_to_NaN": 3}, "summary_stats": {"Amount": {"count": 10, "mean": 770, "median": 700, "min": -500, "max": 2000}}, "value_counts": {"TransactionType": {"Deposit": 5, "Withdrawal": 4, "Payment": 3}, "Status": {"Completed": 7, "Pending": 2, "Failed": 1, "Canceled": 1}}, "transactions_per_month": {"2023-01": 1, "2023-02": 1, "2023-03": 2, "2023-04": 2, "2023-05": 2, "2023-06": 3, "2023-07": 1}, "negative_or_zero_amounts": {"count": 2, "transaction_ids": ["TXN002", "TXN006"]}, "unique_customers": {"total_unique_customers": 9, "top_customers_by_transactions": {"CUST1001": 3, "CUST1003": 2}}}}
{"purpose": "Analyze monthly transaction patterns and customer demographics for a retail bank.", "raw_table": "TransactionID,CustomerID,TransactionDate,TransactionAmount,Currency,AccountType,CustomerAge,BranchCode\nT001,C123,2024-01-15,250.00,USD,checking,34,BR01\nT002,c124,15/02/2024,,-usd,Savings,29,BR02\nT003,C125,2024/03/20,150.5,USD,Checking,NaN,br01\nT004,c126,04-15-2024,300,usd,credit,45,BR03\nT005,C127,2024-05-05,NaN,USD,SAVINGS,38,BR02\nT006,c128,2024-06-25,500.75,usd,Credit,41,\nT007,C129,07/30/2024,200,USD,checking,27,BR01\nT008,c130,2024-08-10,400,USD,SAVINGS,NaN,BR03\nT009,C131,2024-09-15,NaN,usd,checking,31,BR02\nT010,C132,10-20-2024,350,USD,Credit,39,BR01\nT011,C133,2024/11/11,100,,Savings,33,BR03\nT012,C134,12/12/2024,275,usd,Checking,30,BR01", "eda_steps": ["Check missing value percentages per column", "Standardize TransactionDate to ISO format", "Correct inconsistent capitalization in Currency and AccountType columns", "Compute descriptive statistics for TransactionAmount and CustomerAge", "Generate value counts for AccountType and BranchCode", "Identify number of unique customers", "Calculate correlation between TransactionAmount and CustomerAge", "List transactions with missing or zero TransactionAmount"], "eda_results": {"missing_values": {"TransactionID": 0, "CustomerID": 0, "TransactionDate": 0, "TransactionAmount": 3, "Currency": 1, "AccountType": 0, "CustomerAge": 2, "BranchCode": 1}, "standardized_dates": ["2024-01-15", "2024-02-15", "2024-03-20", "2024-04-15", "2024-05-05", "2024-06-25", "2024-07-30", "2024-08-10", "2024-09-15", "2024-10-20", "2024-11-11", "2024-12-12"], "corrected_categories": {"Currency": {"USD": 11, "": 1}, "AccountType": {"Checking": 5, "Savings": 3, "Credit": 3}}, "summary_stats": {"TransactionAmount": {"count": 9, "mean": 280.92, "min": 100, "max": 500.75, "std": 126.29}, "CustomerAge": {"count": 10, "mean": 34.7, "min": 27, "max": 45, "std": 5.96}}, "value_counts": {"AccountType": {"Checking": 5, "Savings": 3, "Credit": 3}, "BranchCode": {"BR01": 5, "BR02": 3, "BR03": 3, "": 1}}, "unique_customers": 12, "correlations": {"TransactionAmount_vs_CustomerAge": 0.74}, "transactions_missing_or_zero_amount": ["T002", "T005", "T009"]}}
{"purpose": "Analyze student performance and attendance patterns in a high school to identify potential areas for intervention.", "raw_table": "Student_ID,Name,Grade,Math_Score,English_Score,Attendance,Enrollment_Date\n101,alice,10,88,92,95%,2022-09-01\n102,Bob,10,75,81,90%,09/02/2022\n103,charlie,11,NaN,79,85%,2022/09/03\n104,Diana,10,92,NaN,98%,2022-9-04\n105,eric,12,68,72,missing,2022-09-05\n106,Fiona,11,83,87,80,2022-09-06\n107,george,12,77,85,88%,20220907\n108,Hannah,11,90,NaN,92%,2022.09.08\n109,Ian,10,85,88,93%,\n110,Julia,12,95,97,99%,2022-09-10", "eda_steps": ["Check for missing values in all columns", "Compute descriptive statistics for Math_Score and English_Score", "Analyze distribution of Attendance values and standardize percentages", "Count number of students per Grade", "Identify enrollment date formats and standardize them", "Calculate correlation between Math_Score and English_Score", "List students with missing test scores", "Find average Attendance by Grade"], "eda_results": {"missing_values": {"Math_Score": 1, "English_Score": 3, "Attendance": 1, "Enrollment_Date": 1}, "summary_stats": {"Math_Score": {"count": 9, "mean": 83.22, "std": 9.17, "min": 68, "max": 95}, "English_Score": {"count": 7, "mean": 85.43, "std": 7.66, "min": 72, "max": 97}}, "attendance_standardized": {"values": [95, 90, 85, 98, null, 80, 88, 92, 93, 99], "missing_replaced": 1}, "grade_counts": {"10": 4, "11": 3, "12": 3}, "enrollment_date_formats": {"yyyy-mm-dd": 7, "mm/dd/yyyy": 1, "yyyy/mm/dd": 1, "yyyymmdd": 1, "yyyy.mm.dd": 1, "missing": 1}, "correlations": {"Math_Score_vs_English_Score": 0.87}, "students_missing_scores": ["103 (Math_Score)", "104 (English_Score)", "108 (English_Score)"], "average_attendance_by_grade": {"10": 90.75, "11": 85.67, "12": 88.67}}}
{"purpose": "Analyze monthly stock trading data to understand volume patterns and price behavior.", "raw_table": "Date,Ticker,Open,Close,Volume,Market_Sector\n2023-01-05,aapl,130.5,132.0,1000000,Technology\n01/06/2023,GOOG,2200.0,2215.5,850000,technology\n2023-01-07,AMZN,3200.7,,900000,Consumer Discretionary\n2023/01/08,msft,240.1,239.5,missing,Technology\n2023-1-09,FB,265.0,268.0,750000,Communication\n2023-01-10,NFLX,500.0,505.0,620000,consumer discretionary\n2023-01-11,TSLA,700.5,710.0,1000000,Automotive\n2023-01-12,aapl,131.0,133.5,1100000,TECHNOLOGY\n2023-01-13,GOOG,2210.0,2220.0,870000,Technology\n13/01/2023,AMZN,3210.0,3220.0,950000,Consumer Discretionary\n2023-01-14,MSFT,239.0,241.0,800000,Technology\n2023-01-15,FB,missing,270.0,780000,Communication\n2023-01-16,NFLX,505.0,507.0,630000,Consumer Discretionary", "eda_steps": ["Standardize the Date column to a consistent date format", "Identify and count missing values in all columns", "Convert the Volume column to numeric, handling non-numeric entries", "Standardize Market_Sector categories to consistent capitalization", "Calculate descriptive statistics for Open, Close, and Volume columns", "Generate value counts for Market_Sector and Ticker columns", "Calculate correlation between Open, Close, and Volume", "Identify days with the highest and lowest trading volumes", "Summarize the number of unique trading days per ticker"], "eda_results": {"missing_values": {"Date": 0, "Ticker": 0, "Open": 1, "Close": 1, "Volume": 1, "Market_Sector": 0}, "standardized_dates": ["2023-01-05", "2023-01-06", "2023-01-07", "2023-01-08", "2023-01-09", "2023-01-10", "2023-01-11", "2023-01-12", "2023-01-13", "2023-01-13", "2023-01-14", "2023-01-15", "2023-01-16"], "volume_conversion_issues": [{"index": 3, "value": "missing"}], "market_sector_counts": {"Technology": 7, "Consumer Discretionary": 4, "Communication": 2, "Automotive": 1}, "descriptive_stats": {"Open": {"count": 12, "mean": 903.28, "min": 130.5, "max": 3210.0}, "Close": {"count": 12, "mean": 906.63, "min": 132.0, "max": 3220.0}, "Volume": {"count": 12, "mean": 822500, "min": 620000, "max": 1100000}}, "ticker_value_counts": {"AAPL": 2, "GOOG": 2, "AMZN": 2, "MSFT": 2, "FB": 2, "NFLX": 2, "TSLA": 1}, "correlations": {"Open_Close": 0.998, "Open_Volume": 0.04, "Close_Volume": 0.05}, "extreme_volumes": {"highest_volume": {"Date": "2023-01-12", "Ticker": "AAPL", "Volume": 1100000}, "lowest_volume": {"Date": "2023-01-10", "Ticker": "NFLX", "Volume": 620000}}, "unique_trading_days_per_ticker": {"AAPL": 2, "GOOG": 2, "AMZN": 2, "MSFT": 2, "FB": 2, "NFLX": 2, "TSLA": 1}}}
{"purpose": "Analyze customer purchase behavior and order characteristics in an ecommerce setting.", "raw_table": "OrderID,CustomerID,OrderDate,ProductCategory,Quantity,PricePerUnit,PaymentMethod,CustomerRegion\n1001,C001,2023-01-15,Electronics,2,199.99,Credit Card,North\n1002,C002,01/18/2023,home & garden,1,49.5,PayPal,South\n1003,C003,2023/01/20,Electronics,three,299.99,credit card,East\n1004,C004,,Books,5,15.0,Cash,west\n1005,C001,2023-01-22,Toys,2,,Credit card,North\n1006,C005,23-Jan-2023,Books,1,12.5,PayPal,South\n1007,C006,2023-01-25,Home & Garden,4,55.0,Credit Card,East\n1008,,2023-01-27,TOYS,1,20.0,Cash,North\n1009,C007,2023-01-29,Electronics,1,199.99,Credit Card,Unknown\n1010,C008,2023/01/30,Books,,15.0,Paypal,South", "eda_steps": ["Check for missing values in each column", "Standardize the capitalization of ProductCategory and PaymentMethod columns", "Identify and handle non-numeric values in Quantity and PricePerUnit", "Calculate total order value as Quantity multiplied by PricePerUnit", "Generate descriptive statistics for numeric columns including Quantity, PricePerUnit, and total order value", "Count unique values and frequency of categories in ProductCategory and CustomerRegion", "Analyze distribution of PaymentMethod usage", "Examine order dates for consistency and range"], "eda_results": {"missing_values": {"OrderID": 0, "CustomerID": 1, "OrderDate": 1, "ProductCategory": 0, "Quantity": 2, "PricePerUnit": 1, "PaymentMethod": 0, "CustomerRegion": 1}, "standardized_categories": {"ProductCategory": ["Electronics", "Home & Garden", "Books", "Toys"], "PaymentMethod": ["Credit Card", "PayPal", "Cash"]}, "quantity_issues": {"non_numeric_entries": ["three"], "missing_entries": 2}, "price_per_unit_issues": {"missing_entries": 1}, "total_order_value_stats": {"count": 12, "mean": 137.5, "min": 12.5, "max": 599.98, "std_dev": 168.3}, "product_category_counts": {"Electronics": 3, "Home & Garden": 2, "Books": 3, "Toys": 2}, "customer_region_counts": {"North": 3, "South": 3, "East": 2, "West": 1, "Unknown": 1}, "payment_method_distribution": {"Credit Card": 5, "PayPal": 3, "Cash": 2}, "order_date_range": {"earliest": "2023-01-15", "latest": "2023-01-30", "inconsistent_formats_found": true}}}
{"purpose": "Analyze patient admission characteristics and identify common diagnoses and missing data patterns.", "raw_table": "Patient_ID,Age,Gender,Admission_Date,Diagnosis,Blood_Pressure_Systolic,Blood_Pressure_Diastolic,Heart_Rate,Smoker_Status\nP001,45,Male,2023/01/15,Hypertension,140,90,85,Yes\nP002,38,Female,15-02-2023,diabetes,130,,78,NO\nP003,,female,2023-03-05,Asthma,125,80,,yes\nP004,29,Male,3/10/2023,,135,85,88,No\nP005,52,Male,2023.04.01,Hypertension,NaN,95,92,YES\nP006,46,Female,2023/04/15,Diabetes,128,82,80,\nP007,34,Female,2023-04-20,hypertension,138,89,90,No\nP008,55,Male,2023-05-01,ASTHMA,142,94,88,YES\nP009,47,male,2023/05/10,Diabetes,132,86,NaN,No\nP010,60,FEMALE,05-15-2023,Heart Disease,150,100,95,yes\nP011,50,Male,,Hypertension,135,88,85,No\nP012,48,Female,2023-06-01,Diabetes,129,83,82,NO\nP013,41,Male,2023/06/05,Asthma,,81,78,Yes", "eda_steps": ["Check the data types of each column", "Compute descriptive statistics for numeric columns including Age, Blood Pressure, and Heart Rate", "Identify and count missing values in each column", "Standardize the Gender and Smoker_Status columns to have consistent capitalization", "Generate value counts for the Diagnosis column", "Analyze date formats and standardize Admission_Date to a single format", "Calculate the average systolic and diastolic blood pressure by Diagnosis category", "Check the distribution of Age and identify any outliers"], "eda_results": {"data_types": {"Patient_ID": "string", "Age": "float", "Gender": "string", "Admission_Date": "string", "Diagnosis": "string", "Blood_Pressure_Systolic": "float", "Blood_Pressure_Diastolic": "float", "Heart_Rate": "float", "Smoker_Status": "string"}, "summary_stats": {"Age": {"count": 13, "mean": 46.31, "std": 8.62, "min": 29, "max": 60}, "Blood_Pressure_Systolic": {"count": 12, "mean": 134.67, "std": 7.94, "min": 125, "max": 150}, "Blood_Pressure_Diastolic": {"count": 13, "mean": 87.23, "std": 6.91, "min": 80, "max": 100}, "Heart_Rate": {"count": 12, "mean": 85.75, "std": 5.48, "min": 78, "max": 95}}, "missing_values": {"Age": 1, "Gender": 0, "Admission_Date": 1, "Diagnosis": 1, "Blood_Pressure_Systolic": 2, "Blood_Pressure_Diastolic": 0, "Heart_Rate": 2, "Smoker_Status": 1}, "standardized_categories": {"Gender": {"Male": 6, "Female": 7}, "Smoker_Status": {"Yes": 6, "No": 6, "Missing": 1}}, "diagnosis_value_counts": {"Hypertension": 4, "Diabetes": 4, "Asthma": 3, "Heart Disease": 1, "Missing": 1}, "admission_date_formats": {"YYYY/MM/DD": 6, "DD-MM-YYYY": 2, "MM/DD/YYYY": 2, "YYYY-MM-DD": 3, "YYYY.MM.DD": 1, "Missing": 1}, "average_bp_by_diagnosis": {"Hypertension": {"Systolic": 138.25, "Diastolic": 89.5}, "Diabetes": {"Systolic": 129.75, "Diastolic": 83.67}, "Asthma": {"Systolic": 133.5, "Diastolic": 85}, "Heart Disease": {"Systolic": 150, "Diastolic": 100}, "Missing": {"Systolic": 135, "Diastolic": 85}}, "age_outliers": {"outlier_count": 0, "age_range": [29, 60]}}}
{"purpose": "Analyze municipal service request patterns and identify common issues reported by residents.", "raw_table": "Request_ID,Service_Type,Request_Date,Status,Priorty,Resolution_Time_Days\n1001,Water Leak,2023-03-15,Closed,High,5\n1002,Street Light,3/17/2023,Open,medium,\n1003,Trash Collection,2023/03/18,closed,Low,2\n1004,Pothole,03-19-2023,In Progress,HIGH,7\n1005,Water leak,2023-3-20,Closed,Medium,4\n1006,Street light,,Open,MEDIUM,NA\n1007,graffiti,2023-03-22,Closed,Low,3\n1008,Pothole,2023-03-23,closed,,6\n1009,Trash Collection,Mar 24 2023,Closed,low,1\n1010,Power outage,2023-03-25,Open,High,NA\n1011,Trash collection,03/26/2023,Closed,Low,2\n1012,water Leak,2023-03-27,Closed,High,3\n1013,Pothole,2023-03-28,Closed,medium,4\n1014,graffiti,03/29/2023,Open,Low,\n", "eda_steps": ["Clean and standardize 'Service_Type' entries to consistent capitalization", "Parse and standardize 'Request_Date' into a uniform date format", "Identify and quantify missing values in each column", "Compute descriptive statistics for 'Resolution_Time_Days' ignoring missing and non-numeric values", "Generate value counts for 'Service_Type' and 'Status'", "Analyze average resolution time by 'Priorty' level", "Check for inconsistencies or typos in 'Priorty' and standardize them", "Summarize number of requests per day", "Identify the proportion of open vs closed requests"], "eda_results": {"missing_values": {"Request_ID": 0, "Service_Type": 0, "Request_Date": 1, "Status": 0, "Priorty": 2, "Resolution_Time_Days": 4}, "value_counts": {"Service_Type": {"Water Leak": 3, "Street Light": 2, "Trash Collection": 3, "Pothole": 3, "Graffiti": 2, "Power Outage": 1}, "Status": {"Closed": 9, "Open": 4, "In Progress": 1}}, "summary_stats": {"Resolution_Time_Days": {"count": 10, "mean": 3.7, "std": 1.76, "min": 1, "25%": 2, "50%": 4, "75%": 5, "max": 7}}, "priority_standardization": {"high": 4, "medium": 4, "low": 5, "missing": 2}, "avg_resolution_by_priority": {"High": 4.25, "Medium": 3.5, "Low": 2.0, "Missing": null}, "requests_per_day": {"2023-03-15": 1, "2023-03-17": 1, "2023-03-18": 1, "2023-03-19": 1, "2023-03-20": 1, "2023-03-22": 1, "2023-03-23": 1, "2023-03-24": 1, "2023-03-25": 1, "2023-03-26": 1, "2023-03-27": 1, "2023-03-28": 1, "2023-03-29": 1, "missing_date": 1}, "open_vs_closed_ratio": {"Open": 4, "Closed": 9, "In Progress": 1}}}
